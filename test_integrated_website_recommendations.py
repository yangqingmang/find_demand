#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›†æˆå»ºç«™å»ºè®®åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•è‡ªåŠ¨å»ºç«™è„šæœ¬ä¸å»ºç«™å»ºè®®ç³»ç»Ÿçš„é›†æˆæ•ˆæœ
"""

import sys
import os
import pandas as pd
import tempfile

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_demand_mining_with_recommendations():
    """æµ‹è¯•éœ€æ±‚æŒ–æ˜ç®¡ç†å™¨çš„å»ºç«™å»ºè®®åŠŸèƒ½"""
    print("=== æµ‹è¯•éœ€æ±‚æŒ–æ˜ç®¡ç†å™¨å»ºç«™å»ºè®®åŠŸèƒ½ ===")
    
    try:
        from src.demand_mining.demand_mining_main import DemandMiningManager
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶
        test_data = pd.DataFrame({
            'query': [
                'best ai writing tools',
                'how to use chatgpt',
                'ai image generator free',
                'chatgpt login',
                'ai tool not working'
            ]
        })
        
        # ä¿å­˜æµ‹è¯•æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            test_data.to_csv(f.name, index=False)
            temp_file = f.name
        
        print(f"åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶: {temp_file}")
        print(f"æµ‹è¯•å…³é”®è¯: {', '.join(test_data['query'].tolist())}")
        
        # åˆ›å»ºéœ€æ±‚æŒ–æ˜ç®¡ç†å™¨
        manager = DemandMiningManager()
        
        # æ‰§è¡Œåˆ†æ
        print("\nå¼€å§‹æ‰§è¡Œéœ€æ±‚æŒ–æ˜åˆ†æ...")
        results = manager.analyze_keywords(temp_file)
        
        # æ£€æŸ¥ç»“æœ
        print(f"\nåˆ†æå®Œæˆï¼Œå…±å¤„ç† {results['total_keywords']} ä¸ªå…³é”®è¯")
        
        # æ˜¾ç¤ºå»ºç«™å»ºè®®ç»“æœ
        print("\nå»ºç«™å»ºè®®ç»“æœ:")
        for i, keyword_result in enumerate(results['keywords'], 1):
            keyword = keyword_result['keyword']
            intent_info = keyword_result['intent']
            website_recommendations = intent_info.get('website_recommendations', {})
            
            print(f"\n{i}. {keyword}")
            print(f"   æ„å›¾: {intent_info.get('primary_intent', 'æœªçŸ¥')}")
            print(f"   ç½‘ç«™ç±»å‹: {website_recommendations.get('website_type', 'æœªçŸ¥')}")
            print(f"   AIç±»åˆ«: {website_recommendations.get('ai_tool_category', 'æœªçŸ¥')}")
            
            # æ˜¾ç¤ºå¼€å‘ä¼˜å…ˆçº§
            priority_info = website_recommendations.get('development_priority', {})
            if isinstance(priority_info, dict):
                priority = priority_info.get('level', 'æœªçŸ¥')
                timeline = priority_info.get('timeline', 'æœªçŸ¥')
                print(f"   å¼€å‘ä¼˜å…ˆçº§: {priority} ({timeline})")
            
            # æ˜¾ç¤ºåŸŸåå»ºè®®
            domains = website_recommendations.get('domain_suggestions', [])
            if domains:
                print(f"   åŸŸåå»ºè®®: {', '.join(domains[:3])}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_file)
        
        print("\nâœ“ éœ€æ±‚æŒ–æ˜ç®¡ç†å™¨å»ºç«™å»ºè®®åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— éœ€æ±‚æŒ–æ˜ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_website_builder_with_recommendations():
    """æµ‹è¯•ç½‘ç«™å»ºè®¾å™¨çš„å»ºç«™å»ºè®®åŠŸèƒ½"""
    print("\n=== æµ‹è¯•ç½‘ç«™å»ºè®¾å™¨å»ºç«™å»ºè®®åŠŸèƒ½ ===")
    
    try:
        from src.website_builder.builder_core import IntentBasedWebsiteBuilder
        
        # åˆ›å»ºåŒ…å«å»ºç«™å»ºè®®çš„æµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'query': ['ai writing assistant'],
            'intent_primary': ['E'],
            'intent_confidence': [0.85],
            'website_type': ['AIå·¥å…·ç«™ (SaaSå¹³å°)'],
            'ai_tool_category': ['AIå†™ä½œå·¥å…·'],
            'domain_suggestions': [['aiwriter.com', 'writeai.io', 'smartwriter.ai']],
            'monetization_strategy': [['Freemiumæ¨¡å¼', 'APIè°ƒç”¨æ”¶è´¹', 'è®¢é˜…åˆ¶']],
            'technical_requirements': [['AI APIé›†æˆ', 'å®æ—¶å¤„ç†èƒ½åŠ›', 'ç”¨æˆ·è´¦æˆ·']],
            'development_priority': [{'level': 'é«˜', 'timeline': '1-2ä¸ªæœˆ', 'score': 85}],
            'content_strategy': [['äº§å“é¡µé¢', 'å®šä»·é¡µé¢', 'å…è´¹è¯•ç”¨']]
        })
        
        # ä¿å­˜æµ‹è¯•æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            test_data.to_csv(f.name, index=False)
            temp_file = f.name
        
        print(f"åˆ›å»ºæµ‹è¯•æ„å›¾æ•°æ®æ–‡ä»¶: {temp_file}")
        
        # åˆ›å»ºç½‘ç«™å»ºè®¾å™¨
        builder = IntentBasedWebsiteBuilder(
            intent_data_path=temp_file,
            output_dir="test_output",
            config={'project_name': 'test_ai_writer'}
        )
        
        # åŠ è½½æ•°æ®
        print("\nåŠ è½½æ„å›¾æ•°æ®...")
        if builder.load_intent_data():
            print("âœ“ æ„å›¾æ•°æ®åŠ è½½æˆåŠŸ")
            
            # ç”Ÿæˆç½‘ç«™ç»“æ„
            print("\nç”Ÿæˆç½‘ç«™ç»“æ„...")
            structure = builder.generate_website_structure()
            
            if structure:
                print("âœ“ ç½‘ç«™ç»“æ„ç”ŸæˆæˆåŠŸ")
                
                # æ£€æŸ¥å»ºç«™å»ºè®®æ˜¯å¦è¢«æ­£ç¡®å¤„ç†
                recommendations = structure.get('website_recommendations', {})
                print(f"\nå»ºç«™å»ºè®®æ‘˜è¦:")
                print(f"  ä¸»è¦ç½‘ç«™ç±»å‹: {recommendations.get('primary_website_type', 'æœªçŸ¥')}")
                print(f"  ä¸»è¦AIç±»åˆ«: {recommendations.get('primary_ai_category', 'æœªçŸ¥')}")
                print(f"  åŸŸåå»ºè®®æ•°é‡: {len(recommendations.get('domain_suggestions', []))}")
                print(f"  æŠ€æœ¯è¦æ±‚æ•°é‡: {len(recommendations.get('technical_requirements', []))}")
                
                # æ˜¾ç¤ºå¼€å‘ä¼˜å…ˆçº§åˆ†æ
                priorities = recommendations.get('development_priorities', {})
                if priorities:
                    print(f"  é«˜ä¼˜å…ˆçº§é¡¹ç›®: {priorities.get('high_priority_count', 0)}")
                    print(f"  ä¼˜å…ˆçº§æ¯”ä¾‹: {priorities.get('priority_ratio', 0):.2%}")
                
                print("\nâœ“ ç½‘ç«™å»ºè®¾å™¨å»ºç«™å»ºè®®åŠŸèƒ½æµ‹è¯•é€šè¿‡")
            else:
                print("âœ— ç½‘ç«™ç»“æ„ç”Ÿæˆå¤±è´¥")
                return False
        else:
            print("âœ— æ„å›¾æ•°æ®åŠ è½½å¤±è´¥")
            return False
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_file)
        
        return True
        
    except Exception as e:
        print(f"âœ— ç½‘ç«™å»ºè®¾å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_integrated_workflow():
    """æµ‹è¯•é›†æˆå·¥ä½œæµçš„å»ºç«™å»ºè®®åŠŸèƒ½"""
    print("\n=== æµ‹è¯•é›†æˆå·¥ä½œæµå»ºç«™å»ºè®®åŠŸèƒ½ ===")
    
    try:
        from src.integrated_workflow import IntegratedWorkflow
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶
        test_data = pd.DataFrame({
            'query': [
                'ai chatbot builder',
                'image generation api'
            ]
        })
        
        # ä¿å­˜æµ‹è¯•æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            test_data.to_csv(f.name, index=False)
            temp_file = f.name
        
        print(f"åˆ›å»ºæµ‹è¯•å…³é”®è¯æ–‡ä»¶: {temp_file}")
        print(f"æµ‹è¯•å…³é”®è¯: {', '.join(test_data['query'].tolist())}")
        
        # åˆ›å»ºé›†æˆå·¥ä½œæµ
        workflow = IntegratedWorkflow({
            'min_opportunity_score': 0,  # é™ä½é˜ˆå€¼ä»¥ä¾¿æµ‹è¯•
            'max_projects_per_batch': 2,
            'auto_deploy': False  # ç¦ç”¨è‡ªåŠ¨éƒ¨ç½²
        })
        
        # æ‰§è¡Œå·¥ä½œæµï¼ˆä»…æµ‹è¯•å‰å‡ ä¸ªæ­¥éª¤ï¼‰
        print("\nå¼€å§‹æ‰§è¡Œé›†æˆå·¥ä½œæµ...")
        
        # æ­¥éª¤1: éœ€æ±‚æŒ–æ˜
        print("\næ‰§è¡Œéœ€æ±‚æŒ–æ˜...")
        demand_results = workflow._run_demand_mining(temp_file)
        
        if demand_results and 'keywords' in demand_results:
            print(f"âœ“ éœ€æ±‚æŒ–æ˜å®Œæˆï¼Œåˆ†æäº† {len(demand_results['keywords'])} ä¸ªå…³é”®è¯")
            
            # æ£€æŸ¥å»ºç«™å»ºè®®æ•°æ®
            for keyword_data in demand_results['keywords']:
                keyword = keyword_data['keyword']
                intent_info = keyword_data.get('intent', {})
                website_recommendations = intent_info.get('website_recommendations', {})
                
                print(f"\nå…³é”®è¯: {keyword}")
                print(f"  ç½‘ç«™ç±»å‹: {website_recommendations.get('website_type', 'æœªçŸ¥')}")
                print(f"  AIç±»åˆ«: {website_recommendations.get('ai_tool_category', 'æœªçŸ¥')}")
                
                # æ£€æŸ¥å¼€å‘ä¼˜å…ˆçº§
                priority_info = website_recommendations.get('development_priority', {})
                if isinstance(priority_info, dict):
                    print(f"  å¼€å‘ä¼˜å…ˆçº§: {priority_info.get('level', 'æœªçŸ¥')}")
            
            # æ­¥éª¤2: ç­›é€‰é«˜ä»·å€¼å…³é”®è¯
            print("\nç­›é€‰é«˜ä»·å€¼å…³é”®è¯...")
            high_value_keywords = workflow._filter_high_value_keywords(demand_results)
            print(f"âœ“ ç­›é€‰å‡º {len(high_value_keywords)} ä¸ªé«˜ä»·å€¼å…³é”®è¯")
            
            # æµ‹è¯•é¡¹ç›®åç§°ç”Ÿæˆ
            if high_value_keywords:
                keyword_data = high_value_keywords[0]
                keyword = keyword_data['keyword']
                intent_info = keyword_data.get('intent', {})
                website_recommendations = intent_info.get('website_recommendations', {})
                
                project_name = workflow._generate_project_name_with_recommendations(keyword, website_recommendations)
                print(f"\nç”Ÿæˆçš„é¡¹ç›®åç§°: {project_name}")
                
                # æµ‹è¯•é¡¹ç›®é…ç½®ç”Ÿæˆ
                project_config = workflow._create_project_config(website_recommendations, project_name)
                print(f"é¡¹ç›®é…ç½®:")
                print(f"  ç½‘ç«™ç±»å‹: {project_config.get('website_type')}")
                print(f"  AIç±»åˆ«: {project_config.get('ai_category')}")
                print(f"  æ¨¡æ¿ç±»å‹: {project_config.get('template_type')}")
                print(f"  åŸŸåé€‰é¡¹æ•°é‡: {len(project_config.get('domain_options', []))}")
            
            print("\nâœ“ é›†æˆå·¥ä½œæµå»ºç«™å»ºè®®åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        else:
            print("âœ— éœ€æ±‚æŒ–æ˜ç»“æœä¸ºç©º")
            return False
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_file)
        
        return True
        
    except Exception as e:
        print(f"âœ— é›†æˆå·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("é›†æˆå»ºç«™å»ºè®®åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•ç»“æœ
    results = []
    
    # 1. æµ‹è¯•éœ€æ±‚æŒ–æ˜ç®¡ç†å™¨
    results.append(test_demand_mining_with_recommendations())
    
    # 2. æµ‹è¯•ç½‘ç«™å»ºè®¾å™¨
    results.append(test_website_builder_with_recommendations())
    
    # 3. æµ‹è¯•é›†æˆå·¥ä½œæµ
    results.append(test_integrated_workflow())
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“:")
    print(f"  éœ€æ±‚æŒ–æ˜ç®¡ç†å™¨: {'âœ“ é€šè¿‡' if results[0] else 'âœ— å¤±è´¥'}")
    print(f"  ç½‘ç«™å»ºè®¾å™¨: {'âœ“ é€šè¿‡' if results[1] else 'âœ— å¤±è´¥'}")
    print(f"  é›†æˆå·¥ä½œæµ: {'âœ“ é€šè¿‡' if results[2] else 'âœ— å¤±è´¥'}")
    
    if all(results):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å»ºç«™å»ºè®®ç³»ç»Ÿå·²æˆåŠŸé›†æˆåˆ°è‡ªåŠ¨å»ºç«™è„šæœ¬ï¼")
        print("\né›†æˆæ•ˆæœ:")
        print("âœ“ éœ€æ±‚æŒ–æ˜é˜¶æ®µè‡ªåŠ¨ç”Ÿæˆå»ºç«™å»ºè®®")
        print("âœ“ ç½‘ç«™å»ºè®¾å™¨åŸºäºå»ºç«™å»ºè®®ä¼˜åŒ–ç»“æ„")
        print("âœ“ é›†æˆå·¥ä½œæµæ™ºèƒ½ç”Ÿæˆé¡¹ç›®é…ç½®")
        print("âœ“ é¡¹ç›®åç§°åŸºäºç½‘ç«™ç±»å‹æ™ºèƒ½å‘½å")
        print("âœ“ åŸŸåå»ºè®®å’ŒæŠ€æœ¯è¦æ±‚è‡ªåŠ¨é›†æˆ")
        print("âœ“ å¼€å‘ä¼˜å…ˆçº§æŒ‡å¯¼é¡¹ç›®æ’åº")
        
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("```bash")
        print("# ä½¿ç”¨é›†æˆå·¥ä½œæµï¼ˆè‡ªåŠ¨åŒ…å«å»ºç«™å»ºè®®ï¼‰")
        print("python -m src.integrated_workflow keywords.csv")
        print("")
        print("# æˆ–å•ç‹¬ä½¿ç”¨éœ€æ±‚æŒ–æ˜ï¼ˆåŒ…å«å»ºç«™å»ºè®®ï¼‰")
        print("python -m src.demand_mining.demand_mining_main keywords.csv")
        print("```")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        print("\nå¯èƒ½çš„é—®é¢˜:")
        print("- å¯¼å…¥è·¯å¾„é”™è¯¯")
        print("- ä¾èµ–æ¨¡å—ç¼ºå¤±")
        print("- é…ç½®æ–‡ä»¶é—®é¢˜")
        print("- æ•°æ®æ ¼å¼ä¸åŒ¹é…")

if __name__ == "__main__":
    main()