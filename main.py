#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éœ€æ±‚æŒ–æ˜åˆ†æå·¥å…· - ç»Ÿä¸€ä¸»å…¥å£æ–‡ä»¶
æ•´åˆå…­å¤§éœ€æ±‚æŒ–æ˜æ–¹æ³•çš„å®Œæ•´æ‰§è¡Œå…¥å£
"""

import argparse
import sys
import os
import json
from datetime import datetime
from typing import Dict, Any

def get_reports_dir() -> str:
    """ä»é…ç½®æ–‡ä»¶è·å–æŠ¥å‘Šè¾“å‡ºç›®å½•"""
    try:
        config_path = os.path.join(os.path.dirname(__file__), 'config/integrated_workflow_config.json')
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return config.get('output_settings', {}).get('reports_dir', 'output/reports')
    except:
        pass
    return 'output/reports'

from src.demand_mining.tools.multi_platform_keyword_discovery import MultiPlatformKeywordDiscovery
from src.utils.enhanced_features import (
        monitor_competitors, predict_keyword_trends, generate_seo_audit,
        batch_build_websites
    )
# ç›´æ¥å¯¼å…¥éœ€æ±‚æŒ–æ˜ç®¡ç†å™¨ç»„ä»¶
from src.demand_mining.managers import KeywordManager, DiscoveryManager, TrendManager
from src.utils.logger import setup_logger

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))


class CommandRegistry:
    """å‘½ä»¤æ³¨å†Œå™¨ - è®©å‚æ•°å’Œæ‰§è¡Œå‡½æ•°çš„æ˜ å°„æ›´ç›´è§‚"""
    
    def __init__(self):
        self.commands = {}
    
    def register(self, param_name, description="", priority=0):
        """æ³¨å†Œå‘½ä»¤è£…é¥°å™¨"""
        def decorator(func):
            self.commands[param_name] = {
                'handler': func,
                'description': description,
                'priority': priority,
                'function_name': func.__name__
            }
            return func
        return decorator
    
    def execute(self, args, manager):
        """æ‰§è¡ŒåŒ¹é…çš„å‘½ä»¤"""
        sorted_commands = sorted(
            self.commands.items(), 
            key=lambda x: x[1]['priority'], 
            reverse=True
        )
        
        for param_name, command_info in sorted_commands:
            param_value = getattr(args, param_name.replace('-', '_'), None)
            
            if param_value is not None and param_value is not False:
                if not args.quiet:
                    print(f"ğŸ¯ æ‰§è¡Œæ¨¡å¼: {param_name}")
                    print(f"ğŸ“‹ æ‰§è¡Œå‡½æ•°: {command_info['function_name']}")
                    if command_info['description']:
                        print(f"ğŸ“ åŠŸèƒ½æè¿°: {command_info['description']}")
                    print("")
                
                command_info['handler'](manager, args)
                return True
        
        return False
    
    def list_commands(self):
        """åˆ—å‡ºæ‰€æœ‰æ³¨å†Œçš„å‘½ä»¤"""
        print("å·²æ³¨å†Œçš„å‘½ä»¤:")
        for param_name, command_info in self.commands.items():
            print(f"  --{param_name} -> {command_info['function_name']}() - {command_info['description']}")


# åˆ›å»ºå…¨å±€å‘½ä»¤æ³¨å†Œå™¨
command_registry = CommandRegistry()


class CommandRegistry:
    """å‘½ä»¤æ³¨å†Œå™¨ - è®©å‚æ•°å’Œæ‰§è¡Œå‡½æ•°çš„æ˜ å°„æ›´ç›´è§‚"""
    
    def __init__(self):
        self.commands = {}
    
    def register(self, param_name, description="", priority=0):
        """æ³¨å†Œå‘½ä»¤è£…é¥°å™¨
        
        Args:
            param_name: å‚æ•°åç§°
            description: å‘½ä»¤æè¿°
            priority: ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        """
        def decorator(func):
            self.commands[param_name] = {
                'handler': func,
                'description': description,
                'priority': priority,
                'function_name': func.__name__
            }
            return func
        return decorator
    
    def execute(self, args, manager):
        """æ‰§è¡ŒåŒ¹é…çš„å‘½ä»¤"""
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        sorted_commands = sorted(
            self.commands.items(), 
            key=lambda x: x[1]['priority'], 
            reverse=True
        )
        
        for param_name, command_info in sorted_commands:
            param_value = getattr(args, param_name.replace('-', '_'), None)
            
            if param_value is not None and param_value is not False:
                if not args.quiet:
                    print(f"ğŸ¯ æ‰§è¡Œæ¨¡å¼: {param_name}")
                    print(f"ğŸ“‹ æ‰§è¡Œå‡½æ•°: {command_info['function_name']}")
                    if command_info['description']:
                        print(f"ğŸ“ åŠŸèƒ½æè¿°: {command_info['description']}")
                    print("")
                
                # æ‰§è¡Œå¯¹åº”çš„å¤„ç†å‡½æ•°
                command_info['handler'](manager, args)
                return True
        
        return False
    
    def list_commands(self):
        """åˆ—å‡ºæ‰€æœ‰æ³¨å†Œçš„å‘½ä»¤"""
        print("å·²æ³¨å†Œçš„å‘½ä»¤:")
        for param_name, command_info in self.commands.items():
            print(f"  --{param_name} -> {command_info['function_name']}() - {command_info['description']}")


# åˆ›å»ºå…¨å±€å‘½ä»¤æ³¨å†Œå™¨
command_registry = CommandRegistry()


class IntegratedDemandMiningManager:
    """é›†æˆéœ€æ±‚æŒ–æ˜ç®¡ç†å™¨ - ç»Ÿä¸€æ‰€æœ‰åŠŸèƒ½"""
    
    def __init__(self, config_path: str = None):
        self.config_path = config_path
        self.logger = setup_logger(__name__)
        
        # åˆå§‹åŒ–å„ä¸ªç®¡ç†å™¨
        self.keyword_manager = KeywordManager(config_path)
        self.discovery_manager = DiscoveryManager(config_path)
        self.trend_manager = TrendManager(config_path)
        
        # åˆå§‹åŒ–æ–°è¯æ£€æµ‹å™¨
        try:
            from src.demand_mining.analyzers.new_word_detector import NewWordDetector
            self.new_word_detector = NewWordDetector()
            self.new_word_detection_available = True
            print("âœ… æ–°è¯æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
        except ImportError as e:
            self.new_word_detector = None
            self.new_word_detection_available = False
            print(f"âš ï¸ æ–°è¯æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        print("ğŸš€ é›†æˆéœ€æ±‚æŒ–æ˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print("ğŸ“Š å·²åŠ è½½å…³é”®è¯ç®¡ç†å™¨ã€å‘ç°ç®¡ç†å™¨ã€è¶‹åŠ¿ç®¡ç†å™¨")
        if self.new_word_detection_available:
            print("ğŸ” æ–°è¯æ£€æµ‹åŠŸèƒ½å·²å¯ç”¨")

    def analyze_keywords(self, input_file: str, output_dir: str = None, enable_serp: bool = False) -> Dict[str, Any]:
        """åˆ†æå…³é”®è¯æ–‡ä»¶ï¼ˆåŒ…å«æ–°è¯æ£€æµ‹å’Œå¯é€‰çš„SERPåˆ†æï¼‰"""
        # æ‰§è¡ŒåŸºç¡€å…³é”®è¯åˆ†æ
        result = self.keyword_manager.analyze(input_file, 'file', output_dir)

        # å¦‚æœå¯ç”¨SERPåˆ†æï¼Œæ‰§è¡ŒSERPåˆ†æ
        if enable_serp:
            try:
                print("ğŸ” æ­£åœ¨è¿›è¡ŒSERPåˆ†æ...")
                result = self._perform_serp_analysis(result, input_file)
                print("âœ… SERPåˆ†æå®Œæˆ")
            except Exception as e:
                print(f"âš ï¸ SERPåˆ†æå¤±è´¥: {e}")
                result['serp_analysis_error'] = str(e)

        # æ·»åŠ æ–°è¯æ£€æµ‹
        if self.new_word_detection_available:
            try:
                print("ğŸ” æ­£åœ¨è¿›è¡Œæ–°è¯æ£€æµ‹...")

                # è¯»å–å…³é”®è¯æ•°æ®
                import pandas as pd
                df = pd.read_csv(input_file)

                # æ‰§è¡Œæ–°è¯æ£€æµ‹
                new_word_results = self.new_word_detector.detect_new_words(df)

                # å°†æ–°è¯æ£€æµ‹ç»“æœåˆå¹¶åˆ°åˆ†æç»“æœä¸­
                if 'keywords' in result:
                    for i, keyword_data in enumerate(result['keywords']):
                        if i < len(new_word_results):
                            # æ·»åŠ æ–°è¯æ£€æµ‹ä¿¡æ¯
                            row = new_word_results.iloc[i]
                            keyword_data['new_word_detection'] = {
                                'is_new_word': bool(row.get('is_new_word', False)),
                                'new_word_score': float(row.get('new_word_score', 0)),
                                'new_word_grade': str(row.get('new_word_grade', 'D')),
                                'growth_rate_7d': float(row.get('growth_rate_7d', 0)),
                                'confidence_level': str(row.get('confidence_level', 'low'))
                            }

                            # å¦‚æœæ˜¯æ–°è¯ï¼Œå¢åŠ æœºä¼šåˆ†æ•°åŠ æˆ
                            if row.get('is_new_word', False):
                                original_score = keyword_data.get('opportunity_score', 0)
                                new_word_bonus = row.get('new_word_score', 0) * 0.1  # 10%åŠ æˆ
                                keyword_data['opportunity_score'] = min(100, original_score + new_word_bonus)
                                keyword_data['new_word_bonus'] = new_word_bonus

                # ç”Ÿæˆæ–°è¯æ£€æµ‹æ‘˜è¦
                new_words_count = len(new_word_results[new_word_results['is_new_word'] == True])
                high_confidence_count = len(new_word_results[new_word_results['confidence_level'] == 'high'])

                result['new_word_summary'] = {
                    'total_analyzed': len(new_word_results),
                    'new_words_detected': new_words_count,
                    'high_confidence_new_words': high_confidence_count,
                    'new_word_percentage': round(new_words_count / len(new_word_results) * 100, 1) if len(new_word_results) > 0 else 0
                }

                print(f"âœ… æ–°è¯æ£€æµ‹å®Œæˆ: å‘ç° {new_words_count} ä¸ªæ–°è¯ ({high_confidence_count} ä¸ªé«˜ç½®ä¿¡åº¦)")

            except Exception as e:
                print(f"âš ï¸ æ–°è¯æ£€æµ‹å¤±è´¥: {e}")
                result['new_word_summary'] = {
                    'error': str(e),
                    'new_words_detected': 0
                }

        return result

    def _perform_serp_analysis(self, result: Dict[str, Any], input_file: str) -> Dict[str, Any]:
        """æ‰§è¡ŒSERPåˆ†æ"""
        try:
            from src.demand_mining.analyzers.serp_analyzer import SerpAnalyzer
            
            # åˆå§‹åŒ–SERPåˆ†æå™¨
            serp_analyzer = SerpAnalyzer()
            
            # è¯»å–å…³é”®è¯æ•°æ®
            import pandas as pd
            df = pd.read_csv(input_file)
            
            # å¯¹æ¯ä¸ªå…³é”®è¯è¿›è¡ŒSERPåˆ†æ
            serp_results = []
            total_keywords = len(df)
            
            for i, row in df.iterrows():
                keyword = row.get('query', row.get('keyword', ''))
                if keyword:
                    print(f"  åˆ†æå…³é”®è¯ {i+1}/{total_keywords}: {keyword}")
                    serp_result = serp_analyzer.analyze_keyword_serp(keyword)
                    serp_results.append({
                        'keyword': keyword,
                        'serp_features': serp_result.get('serp_features', {}),
                        'serp_intent': serp_result.get('intent', 'I'),
                        'serp_confidence': serp_result.get('confidence', 0.0),
                        'serp_secondary_intent': serp_result.get('secondary_intent', None)
                    })
            
            # å°†SERPåˆ†æç»“æœåˆå¹¶åˆ°åŸç»“æœä¸­
            if 'keywords' in result and serp_results:
                for i, keyword_data in enumerate(result['keywords']):
                    if i < len(serp_results):
                        serp_data = serp_results[i]
                        keyword_data['serp_analysis'] = {
                            'features': serp_data['serp_features'],
                            'intent': serp_data['serp_intent'],
                            'confidence': serp_data['serp_confidence'],
                            'secondary_intent': serp_data['serp_secondary_intent']
                        }
                        
                        # å¦‚æœSERPåˆ†æç½®ä¿¡åº¦é«˜ï¼Œå¯ä»¥è°ƒæ•´æœºä¼šåˆ†æ•°
                        if serp_data['serp_confidence'] > 0.8:
                            original_score = keyword_data.get('opportunity_score', 0)
                            serp_bonus = serp_data['serp_confidence'] * 5  # æœ€å¤š5åˆ†åŠ æˆ
                            keyword_data['opportunity_score'] = min(100, original_score + serp_bonus)
                            keyword_data['serp_bonus'] = serp_bonus
            
            # ç”ŸæˆSERPåˆ†ææ‘˜è¦
            high_confidence_serp = len([r for r in serp_results if r['serp_confidence'] > 0.8])
            commercial_intent = len([r for r in serp_results if r['serp_intent'] in ['C', 'T']])
            
            result['serp_summary'] = {
                'total_analyzed': len(serp_results),
                'high_confidence_serp': high_confidence_serp,
                'commercial_intent_keywords': commercial_intent,
                'serp_analysis_enabled': True
            }
            
            return result
            
        except ImportError:
            print("âš ï¸ SERPåˆ†æå™¨æœªæ‰¾åˆ°ï¼Œè·³è¿‡SERPåˆ†æ")
            result['serp_summary'] = {
                'error': 'SERPåˆ†æå™¨æœªæ‰¾åˆ°',
                'serp_analysis_enabled': False
            }
            return result
        except Exception as e:
            print(f"âš ï¸ SERPåˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            result['serp_summary'] = {
                'error': str(e),
                'serp_analysis_enabled': False
            }
            return result
    
    def analyze_root_words(self, output_dir: str = None) -> Dict[str, Any]:
        """åˆ†æè¯æ ¹è¶‹åŠ¿"""
        try:
            # ä½¿ç”¨å·²æœ‰çš„è¶‹åŠ¿ç®¡ç†å™¨ï¼Œé¿å…åˆ›å»ºæ–°çš„åˆ†æå™¨å®ä¾‹
            analyzer_output_dir = output_dir or f"{get_reports_dir()}/root_word_trends"
            
            # ç›´æ¥ä½¿ç”¨è¶‹åŠ¿ç®¡ç†å™¨è¿›è¡Œåˆ†æ
            results = self.trend_manager.analyze(
                'root_trends',
                timeframe="now 7-d",
                batch_size=5,
                output_dir=analyzer_output_dir
            )
            
            # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
            if results is None:
                results = {
                    'total_root_words': 0,
                    'summary': {
                        'successful_analyses': 0,
                        'failed_analyses': 0,
                        'top_trending_words': [],
                        'declining_words': [],
                        'stable_words': []
                    }
                }
            
            # è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
            return {
                'total_root_words': results.get('total_root_words', 0),
                'successful_analyses': results.get('summary', {}).get('successful_analyses', 0),
                'failed_analyses': results.get('summary', {}).get('failed_analyses', 0),
                'top_trending_words': results.get('summary', {}).get('top_trending_words', []),
                'declining_words': results.get('summary', {}).get('declining_words', []),
                'stable_words': results.get('summary', {}).get('stable_words', []),
                'output_path': analyzer_output_dir
            }
            
        except Exception as e:
            self.logger.error(f"è¯æ ¹è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
            return {
                'error': f'è¯æ ¹è¶‹åŠ¿åˆ†æå¤±è´¥: {e}',
                'total_root_words': 0,
                'successful_analyses': 0,
                'top_trending_words': []
            }
    
    def generate_daily_report(self, date: str = None) -> str:
        """ç”Ÿæˆæ—¥æŠ¥"""
        report_date = date or datetime.now().strftime("%Y-%m-%d")
        report_path = f"{get_reports_dir()}/daily_report_{report_date}.txt"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(f"éœ€æ±‚æŒ–æ˜æ—¥æŠ¥ - {report_date}\n")
                f.write("=" * 50 + "\n\n")
                
                # è·å–å„ç®¡ç†å™¨ç»Ÿè®¡
                stats = self.get_manager_stats()
                for manager_name, manager_stats in stats.items():
                    f.write(f"{manager_name}:\n")
                    if isinstance(manager_stats, dict):
                        for key, value in manager_stats.items():
                            f.write(f"  {key}: {value}\n")
                    else:
                        f.write(f"  çŠ¶æ€: {manager_stats}\n")
                    f.write("\n")
            
            return report_path
        except Exception as e:
            return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}"

    def get_manager_stats(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰ç®¡ç†å™¨çš„ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'keyword_manager': self.keyword_manager.get_stats(),
            'discovery_manager': self.discovery_manager.get_discovery_stats(),
            'trend_manager': self.trend_manager.get_stats(),
        }


def print_quiet_summary(result):
    """é™é»˜æ¨¡å¼ä¸‹çš„ç®€è¦ç»“æœæ˜¾ç¤º"""
    print("\nğŸ¯ éœ€æ±‚æŒ–æ˜åˆ†æç»“æœæ‘˜è¦:")
    print(f"   â€¢ å…³é”®è¯æ€»æ•°: {result.get('total_keywords', 0)}")
    print(f"   â€¢ é«˜æœºä¼šå…³é”®è¯: {result.get('market_insights', {}).get('high_opportunity_count', 0)}")
    print(f"   â€¢ å¹³å‡æœºä¼šåˆ†æ•°: {result.get('market_insights', {}).get('avg_opportunity_score', 0)}")
    
    # æ˜¾ç¤ºTop 3å…³é”®è¯
    top_keywords = result.get('market_insights', {}).get('top_opportunities', [])[:3]
    if top_keywords:
        print("\nğŸ† Top 3 æœºä¼šå…³é”®è¯:")
        for i, kw in enumerate(top_keywords):
            intent_desc = kw.get('intent', {}).get('intent_description', 'æœªçŸ¥')
            score = kw.get('opportunity_score', 0)
            print(f"   {i+1}. {kw['keyword']} (æœºä¼šåˆ†æ•°: {score}, æ„å›¾: {intent_desc})")


@command_registry.register('input', 'åˆ†æCSVæ–‡ä»¶ä¸­çš„å…³é”®è¯', priority=10)
@command_registry.register('input', 'åˆ†æCSVæ–‡ä»¶ä¸­çš„å…³é”®è¯', priority=10)
def handle_input_file_analysis(manager, args):
    """å¤„ç†è¾“å…¥æ–‡ä»¶åˆ†æ"""
    if not args.quiet:
        print("ğŸš€ å¼€å§‹åˆ†æå…³é”®è¯æ–‡ä»¶...")
        if args.serp:
            print("ğŸ” å·²å¯ç”¨SERPåˆ†æåŠŸèƒ½")
    
    result = manager.analyze_keywords(args.input, args.output, enable_serp=args.serp)
    
    # æ˜¾ç¤ºç»“æœ
    if args.quiet:
        print_quiet_summary(result)
    else:
        print(f"\nğŸ‰ åˆ†æå®Œæˆ! å…±åˆ†æ {result['total_keywords']} ä¸ªå…³é”®è¯")
        print(f"ğŸ“Š é«˜æœºä¼šå…³é”®è¯: {result['market_insights']['high_opportunity_count']} ä¸ª")
        print(f"ğŸ“ˆ å¹³å‡æœºä¼šåˆ†æ•°: {result['market_insights']['avg_opportunity_score']}")
        
        # æ˜¾ç¤ºæ–°è¯æ£€æµ‹æ‘˜è¦
        if 'new_word_summary' in result and result['new_word_summary'].get('new_words_detected', 0) > 0:
            summary = result['new_word_summary']
            print(f"ğŸ” æ–°è¯æ£€æµ‹: å‘ç° {summary['new_words_detected']} ä¸ªæ–°è¯ ({summary['new_word_percentage']}%)")
            print(f"   é«˜ç½®ä¿¡åº¦æ–°è¯: {summary['high_confidence_new_words']} ä¸ª")

        # æ˜¾ç¤ºSERPåˆ†ææ‘˜è¦
        if 'serp_summary' in result and result['serp_summary'].get('serp_analysis_enabled', False):
            serp_summary = result['serp_summary']
            print(f"ğŸ” SERPåˆ†æ: åˆ†æäº† {serp_summary['total_analyzed']} ä¸ªå…³é”®è¯")
            print(f"   é«˜ç½®ä¿¡åº¦SERP: {serp_summary['high_confidence_serp']} ä¸ª")
            print(f"   å•†ä¸šæ„å›¾å…³é”®è¯: {serp_summary['commercial_intent_keywords']} ä¸ª")

        # æ˜¾ç¤ºTop 5å…³é”®è¯
        top_keywords = result['market_insights']['top_opportunities'][:5]
        if top_keywords:
            print("\nğŸ† Top 5 æœºä¼šå…³é”®è¯:")
            for i, kw in enumerate(top_keywords, 1):
                intent_desc = kw['intent']['intent_description']
                score = kw['opportunity_score']
                new_word_info = ""
                if 'new_word_detection' in kw and kw['new_word_detection']['is_new_word']:
                    new_word_grade = kw['new_word_detection']['new_word_grade']
                    new_word_info = f" [æ–°è¯-{new_word_grade}çº§]"
                print(f"   {i}. {kw['keyword']} (åˆ†æ•°: {score}, æ„å›¾: {intent_desc}){new_word_info}")


@command_registry.register('keywords', 'åˆ†ææŒ‡å®šçš„å…³é”®è¯åˆ—è¡¨', priority=9)
@command_registry.register('keywords', 'åˆ†ææŒ‡å®šçš„å…³é”®è¯åˆ—è¡¨', priority=9)
def handle_keywords_analysis(manager, args):
    """å¤„ç†ç›´æ¥è¾“å…¥å…³é”®è¯åˆ†æ"""
    if not args.quiet:
        print("ğŸš€ å¼€å§‹åˆ†æè¾“å…¥çš„å…³é”®è¯...")
    
    # åˆ›å»ºä¸´æ—¶CSVæ–‡ä»¶
    import pandas as pd
    import tempfile
    
    temp_df = pd.DataFrame([{'query': kw} for kw in args.keywords])
    with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8') as f:
        temp_df.to_csv(f.name, index=False)
        temp_file = f.name
    
    try:
        result = manager.analyze_keywords(temp_file, args.output, enable_serp=args.serp)
        
        # æ˜¾ç¤ºç»“æœ
        if args.quiet:
            print_quiet_summary(result)
        else:
            print(f"\nğŸ‰ åˆ†æå®Œæˆ! å…±åˆ†æ {len(args.keywords)} ä¸ªå…³é”®è¯")
            
            # æ˜¾ç¤ºæ¯ä¸ªå…³é”®è¯çš„ç»“æœ
            print("\nğŸ“‹ å…³é”®è¯åˆ†æç»“æœ:")
            for kw_result in result['keywords']:
                keyword = kw_result['keyword']
                score = kw_result['opportunity_score']
                intent = kw_result['intent']['intent_description']
                print(f"   â€¢ {keyword}: æœºä¼šåˆ†æ•° {score}, æ„å›¾: {intent}")
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_file)


@command_registry.register('discover', 'å¤šå¹³å°å…³é”®è¯å‘ç°', priority=8)
@command_registry.register('discover', 'å¤šå¹³å°å…³é”®è¯å‘ç°', priority=8)
def handle_discover_mode(manager, args):
    """å¤„ç†å¤šå¹³å°å…³é”®è¯å‘ç°"""
    search_terms = args.discover if args.discover != ['default'] else ['AI tool', 'AI generator', 'AI assistant']
    
    if not args.quiet:
        print("ğŸ” å¼€å§‹å¤šå¹³å°å…³é”®è¯å‘ç°...")
        print(f"ğŸ“Š æœç´¢è¯æ±‡: {', '.join(search_terms)}")
    
    try:
        # åˆ›å»ºå‘ç°å·¥å…·
        discoverer = MultiPlatformKeywordDiscovery()
        
        # æ‰§è¡Œå‘ç°
        df = discoverer.discover_all_platforms(search_terms)

        if not df.empty:
            # åˆ†æè¶‹åŠ¿
            analysis = discoverer.analyze_keyword_trends(df)
            
            # ä¿å­˜ç»“æœ
            output_dir = os.path.join(args.output, 'multi_platform_discovery')
            csv_path, json_path = discoverer.save_results(df, analysis, output_dir)
            
            if args.quiet:
                # é™é»˜æ¨¡å¼æ˜¾ç¤º
                print(f"\nğŸ¯ å¤šå¹³å°å…³é”®è¯å‘ç°ç»“æœ:")
                print(f"   â€¢ å‘ç°å…³é”®è¯: {analysis['total_keywords']} ä¸ª")
                print(f"   â€¢ å¹³å°åˆ†å¸ƒ: {analysis['platform_distribution']}")
                
                # æ˜¾ç¤ºTop 3å…³é”®è¯
                top_keywords = analysis['top_keywords_by_score'][:3]
                if top_keywords:
                    print("\nğŸ† Top 3 çƒ­é—¨å…³é”®è¯:")
                    for i, kw in enumerate(top_keywords, 1):
                        print(f"   {i}. {kw['keyword']} (è¯„åˆ†: {kw['score']}, æ¥æº: {kw['platform']})")
            else:
                # è¯¦ç»†æ¨¡å¼æ˜¾ç¤º
                print(f"\nğŸ‰ å¤šå¹³å°å…³é”®è¯å‘ç°å®Œæˆ!")
                print(f"ğŸ“Š å‘ç° {analysis['total_keywords']} ä¸ªå…³é”®è¯")
                print(f"ğŸŒ å¹³å°åˆ†å¸ƒ: {analysis['platform_distribution']}")
                
                print(f"\nğŸ† çƒ­é—¨å…³é”®è¯:")
                for i, kw in enumerate(analysis['top_keywords_by_score'][:5], 1):
                    print(f"  {i}. {kw['keyword']} (è¯„åˆ†: {kw['score']}, æ¥æº: {kw['platform']})")
            
            print(f"\nğŸ“ ç»“æœå·²ä¿å­˜:")
            print(f"  CSV: {csv_path}")
            print(f"  JSON: {json_path}")
            
            # è¯¢é—®æ˜¯å¦è¦ç«‹å³åˆ†æå‘ç°çš„å…³é”®è¯
            if not args.quiet:
                user_input = input("\nğŸ¤” æ˜¯å¦è¦ç«‹å³åˆ†æè¿™äº›å…³é”®è¯çš„æ„å›¾å’Œå¸‚åœºæœºä¼š? (y/n): ")
                if user_input.lower() in ['y', 'yes', 'æ˜¯']:
                    print("ğŸ”„ å¼€å§‹åˆ†æå‘ç°çš„å…³é”®è¯...")
                    result = manager.analyze_keywords(csv_path, args.output)
                    print(f"âœ… å…³é”®è¯åˆ†æå®Œæˆ! å…±åˆ†æ {result['total_keywords']} ä¸ªå…³é”®è¯")
                    print(f"ğŸ“Š é«˜æœºä¼šå…³é”®è¯: {result['market_insights']['high_opportunity_count']} ä¸ª")
        else:
            print("âš ï¸ æœªå‘ç°ä»»ä½•å…³é”®è¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–è°ƒæ•´æœç´¢å‚æ•°")
            
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤šå¹³å°å‘ç°å·¥å…·å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–å·²æ­£ç¡®å®‰è£…")
    except Exception as e:
        print(f"âŒ å¤šå¹³å°å…³é”®è¯å‘ç°å¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()


def handle_enhanced_features(args):
    """å¤„ç†å¢å¼ºåŠŸèƒ½"""
    if args.monitor_competitors:
        # ç«å“ç›‘æ§
        sites = args.sites or ['canva.com', 'midjourney.com', 'openai.com']
        if not args.quiet:
            print(f"ğŸ” å¼€å§‹ç›‘æ§ {len(sites)} ä¸ªç«å“ç½‘ç«™...")
        
        result = monitor_competitors(sites, args.output)
        print(f"âœ… ç«å“ç›‘æ§å®Œæˆ: åˆ†æäº† {len(result['competitors'])} ä¸ªç«å“")
        
        if not args.quiet:
            print("\nğŸ“Š ç›‘æ§ç»“æœæ‘˜è¦:")
            for comp in result['competitors'][:3]:
                print(f"  â€¢ {comp['site']}: {comp['new_keywords_count']} ä¸ªæ–°å…³é”®è¯")
    
    elif args.predict_trends:
        # è¶‹åŠ¿é¢„æµ‹
        if not args.quiet:
            print(f"ğŸ“ˆ å¼€å§‹é¢„æµ‹æœªæ¥ {args.timeframe} çš„å…³é”®è¯è¶‹åŠ¿...")
        
        result = predict_keyword_trends(args.timeframe, args.output)
        print(f"âœ… è¶‹åŠ¿é¢„æµ‹å®Œæˆ: é¢„æµ‹äº† {len(result['rising_keywords'])} ä¸ªä¸Šå‡å…³é”®è¯")
        
        if not args.quiet:
            print("\nğŸ“ˆ è¶‹åŠ¿é¢„æµ‹æ‘˜è¦:")
            for kw in result['rising_keywords'][:3]:
                print(f"  ğŸ“ˆ {kw['keyword']}: {kw['predicted_growth']} (ç½®ä¿¡åº¦: {kw['confidence']:.0%})")
    
    elif args.seo_audit:
        # SEOå®¡è®¡
        if not args.domain:
            print("âŒ è¯·æŒ‡å®šè¦å®¡è®¡çš„åŸŸå (--domain)")
            return
        
        if not args.quiet:
            print(f"ğŸ” å¼€å§‹SEOå®¡è®¡: {args.domain}")
        
        result = generate_seo_audit(args.domain, args.keywords)
        print(f"âœ… SEOå®¡è®¡å®Œæˆ: å‘ç° {len(result['keyword_opportunities'])} ä¸ªå…³é”®è¯æœºä¼š")
        
        if not args.quiet:
            print("\nğŸ¯ SEOä¼˜åŒ–å»ºè®®:")
            for gap in result['content_gaps'][:3]:
                print(f"  â€¢ {gap}")
    
    elif args.build_websites:
        # æ‰¹é‡å»ºç«™
        if not args.quiet:
            print(f"ğŸ—ï¸ å¼€å§‹æ‰¹é‡ç”Ÿæˆ {args.top_keywords} ä¸ªç½‘ç«™...")
        
        result = batch_build_websites(args.top_keywords, args.output)
        print(f"âœ… æ‰¹é‡å»ºç«™å®Œæˆ: æˆåŠŸæ„å»º {result['successful_builds']} ä¸ªç½‘ç«™")
        
        if not args.quiet:
            print("\nğŸŒ æ„å»ºçš„ç½‘ç«™:")
            for site in result['websites'][:3]:
                print(f"  â€¢ {site['keyword']}: {site['domain_suggestion']}")


@command_registry.register('hotkeywords', 'æœç´¢çƒ­é—¨å…³é”®è¯', priority=5)
@command_registry.register('hotkeywords', 'æœç´¢çƒ­é—¨å…³é”®è¯', priority=5)
def handle_hot_keywords_analysis(manager, args):
    """å¤„ç†çƒ­é—¨å…³é”®è¯åˆ†æ"""
    if not args.quiet:
        print("ğŸ”¥ å¼€å§‹æœç´¢çƒ­é—¨å…³é”®è¯å¹¶è¿›è¡Œéœ€æ±‚æŒ–æ˜...")
    
    try:
        # ä½¿ç”¨å•ä¾‹è·å– TrendsCollector
        from src.collectors.trends_singleton import get_trends_collector
        
        # è·å– TrendsCollector å•ä¾‹å®ä¾‹
        trends_collector = get_trends_collector()
        
        # ä½¿ç”¨ fetch_rising_queries è·å–çƒ­é—¨å…³é”®è¯
        if not args.quiet:
            print("ğŸ” æ­£åœ¨è·å– Rising Queries...")
        
        rising_queries = trends_collector.fetch_rising_queries()
        
        # å°† rising queries è½¬æ¢ä¸ºDataFrameæ ¼å¼
        import pandas as pd
        # å¤„ç†ä¸åŒç±»å‹çš„ rising_queries è¿”å›å€¼
        if isinstance(rising_queries, pd.DataFrame):
            # å¦‚æœå·²ç»æ˜¯DataFrameï¼Œç›´æ¥ä½¿ç”¨
            trending_df = rising_queries.head(20)  # é™åˆ¶å‰20ä¸ª
            # ç¡®ä¿æœ‰queryåˆ—
            if 'query' not in trending_df.columns:
                if 'title' in trending_df.columns:
                    trending_df = trending_df.rename(columns={'title': 'query'})
                elif len(trending_df.columns) > 0:
                    trending_df = trending_df.rename(columns={trending_df.columns[0]: 'query'})
        elif rising_queries and len(rising_queries) > 0:
            # å¦‚æœè¿”å›çš„æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
            if isinstance(rising_queries[0], str):
                trending_df = pd.DataFrame([
                    {'query': query}
                    for query in rising_queries[:20]  # é™åˆ¶å‰20ä¸ª
                ])
            # å¦‚æœè¿”å›çš„æ˜¯å­—å…¸åˆ—è¡¨
            elif isinstance(rising_queries[0], dict):
                trending_df = pd.DataFrame([
                    {
                        'query': item.get('query', item.get('keyword', str(item))),
                        'value': item.get('value', item.get('interest', 0))
                    }
                    for item in rising_queries[:20]  # é™åˆ¶å‰20ä¸ª
                ])
            else:
                # å…¶ä»–æ ¼å¼ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                trending_df = pd.DataFrame([
                    {'query': str(query)}
                    for query in rising_queries[:20]
                ])
        else:
            trending_df = pd.DataFrame(columns=['query'])

        if trending_df is not None and not trending_df.empty:
            # ä¿å­˜çƒ­é—¨å…³é”®è¯åˆ°ä¸´æ—¶æ–‡ä»¶
            import tempfile
            from datetime import datetime
            
            # ç¡®ä¿DataFrameæœ‰æ­£ç¡®çš„åˆ—å
            if 'query' not in trending_df.columns and len(trending_df.columns) > 0:
                # å¦‚æœæ²¡æœ‰queryåˆ—ï¼Œä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºå…³é”®è¯
                trending_df = trending_df.rename(columns={trending_df.columns[0]: 'query'})
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶è¿›è¡Œéœ€æ±‚æŒ–æ˜åˆ†æ
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8') as f:
                trending_df.to_csv(f.name, index=False)
                temp_file = f.name
            
            try:
                if not args.quiet:
                    print(f"ğŸ” è·å–åˆ° {len(trending_df)} ä¸ª Rising Queriesï¼Œå¼€å§‹éœ€æ±‚æŒ–æ˜åˆ†æ...")
                
                # æ‰§è¡Œéœ€æ±‚æŒ–æ˜åˆ†æï¼Œç¦ç”¨æ–°è¯æ£€æµ‹é¿å…429é”™è¯¯
                manager.new_word_detection_available = False
                result = manager.analyze_keywords(temp_file, args.output, enable_serp=False)
                
                # æ˜¾ç¤ºç»“æœ
                if args.quiet:
                    print_quiet_summary(result)
                else:
                    print(f"\nğŸ‰ éœ€æ±‚æŒ–æ˜åˆ†æå®Œæˆ! å…±åˆ†æ {result['total_keywords']} ä¸ª Rising Queries")
                    print(f"ğŸ“Š é«˜æœºä¼šå…³é”®è¯: {result['market_insights']['high_opportunity_count']} ä¸ª")
                    print(f"ğŸ“ˆ å¹³å‡æœºä¼šåˆ†æ•°: {result['market_insights']['avg_opportunity_score']}")
                    
                    # æ˜¾ç¤ºæ–°è¯æ£€æµ‹æ‘˜è¦
                    if 'new_word_summary' in result and result['new_word_summary'].get('new_words_detected', 0) > 0:
                        summary = result['new_word_summary']
                        print(f"ğŸ” æ–°è¯æ£€æµ‹: å‘ç° {summary['new_words_detected']} ä¸ªæ–°è¯ ({summary['new_word_percentage']}%)")
                        print(f"   é«˜ç½®ä¿¡åº¦æ–°è¯: {summary['high_confidence_new_words']} ä¸ª")

                    # æ˜¾ç¤ºTop 5æœºä¼šå…³é”®è¯
                    top_keywords = result['market_insights']['top_opportunities'][:5]
                    if top_keywords:
                        print("\nğŸ† Top 5 æœºä¼šå…³é”®è¯:")
                        for i, kw in enumerate(top_keywords, 1):
                            intent_desc = kw['intent']['intent_description']
                            score = kw['opportunity_score']
                            new_word_info = ""
                            if 'new_word_detection' in kw and kw['new_word_detection']['is_new_word']:
                                new_word_grade = kw['new_word_detection']['new_word_grade']
                                new_word_info = f" [æ–°è¯-{new_word_grade}çº§]"
                            print(f"   {i}. {kw['keyword']} (åˆ†æ•°: {score}, æ„å›¾: {intent_desc}){new_word_info}")
                    
                    # æ˜¾ç¤ºåŸå§‹Rising Queriesä¿¡æ¯
                    print(f"\nğŸ”¥ åŸå§‹ Rising Queries æ•°æ®:")
                    print(f"   â€¢ æ•°æ®æ¥æº: Google Trends Rising Queries")
                    if 'value' in trending_df.columns:
                        print(f"   â€¢ å¹³å‡çƒ­åº¦: {trending_df['value'].mean():.1f}")
                    
                    # ä¿å­˜åŸå§‹Rising Queries
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    trending_output_file = os.path.join(args.output, f"rising_queries_raw_{timestamp}.csv")
                    os.makedirs(args.output, exist_ok=True)
                    trending_df.to_csv(trending_output_file, index=False, encoding='utf-8')
                    print(f"ğŸ“ åŸå§‹ Rising Queries å·²ä¿å­˜åˆ°: {trending_output_file}")
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.unlink(temp_file)
                
        else:
            # å½“æ— æ³•è·å–Rising Queriesæ—¶ï¼Œç›´æ¥æŠ¥å‘Šå¤±è´¥
            print("âŒ æ— æ³•è·å– Rising Queriesï¼Œå¯èƒ½çš„åŸå› :")
            print("ğŸ’¡ å»ºè®®:")
            print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print("   2. ç¨åé‡è¯•")
            print("   3. æˆ–ä½¿ç”¨ --input å‚æ•°æŒ‡å®šå…³é”®è¯æ–‡ä»¶è¿›è¡Œåˆ†æ")
            sys.exit(1)

    except Exception as e:
        print(f"âŒ è·å– Rising Queries æˆ–éœ€æ±‚æŒ–æ˜æ—¶å‡ºé”™: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()


def _handle_report_generation(manager, args):
    """å¤„ç†æŠ¥å‘Šç”Ÿæˆ"""
    if not args.quiet:
        print("ğŸ“Š ç”Ÿæˆä»Šæ—¥åˆ†ææŠ¥å‘Š...")
    
    report_path = manager.generate_daily_report()
    print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")


@command_registry.register('use_root_words', 'ä½¿ç”¨51ä¸ªè¯æ ¹è¿›è¡Œè¶‹åŠ¿åˆ†æ', priority=6)
@command_registry.register('use_root_words', 'ä½¿ç”¨51ä¸ªè¯æ ¹è¿›è¡Œè¶‹åŠ¿åˆ†æ', priority=6)
def handle_root_words_analysis(manager, args):
    """å¤„ç†è¯æ ¹è¶‹åŠ¿åˆ†æ"""
    if not args.quiet:
        print("ğŸŒ± å¼€å§‹ä½¿ç”¨51ä¸ªè¯æ ¹è¿›è¡Œè¶‹åŠ¿åˆ†æ...")
    
    result = manager.analyze_root_words(args.output)
    
    # æ˜¾ç¤ºç»“æœ
    if args.quiet:
        print_quiet_summary(result)
    else:
        print(f"\nğŸ‰ è¯æ ¹è¶‹åŠ¿åˆ†æå®Œæˆ! å…±åˆ†æ {result.get('total_root_words', 0)} ä¸ªè¯æ ¹")
        print(f"ğŸ“Š æˆåŠŸåˆ†æ: {result.get('successful_analyses', 0)} ä¸ª")
        print(f"ğŸ“ˆ ä¸Šå‡è¶‹åŠ¿è¯æ ¹: {len(result.get('top_trending_words', []))}")
        
        # æ˜¾ç¤ºTop 5è¯æ ¹
        top_words = result.get('top_trending_words', [])[:5]
        if top_words:
            print("\nğŸ† Top 5 çƒ­é—¨è¯æ ¹:")
            for i, word_data in enumerate(top_words, 1):
                print(f"   {i}. {word_data['word']}: å¹³å‡å…´è¶£åº¦ {word_data['average_interest']:.1f}")


@command_registry.register('report', 'ç”Ÿæˆä»Šæ—¥åˆ†ææŠ¥å‘Š', priority=7)
def handle_report_generation(manager, args):
    """å¤„ç†æŠ¥å‘Šç”Ÿæˆ"""
    if not args.quiet:
        print("ğŸ“Š ç”Ÿæˆä»Šæ—¥åˆ†ææŠ¥å‘Š...")
    report_path = manager.generate_daily_report()
    print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")


@command_registry.register('monitor_competitors', 'ç›‘æ§ç«å“å…³é”®è¯å˜åŒ–', priority=4)
def handle_monitor_competitors(manager, args):
    """å¤„ç†ç«å“ç›‘æ§"""
    return handle_enhanced_features(args)


@command_registry.register('predict_trends', 'é¢„æµ‹å…³é”®è¯è¶‹åŠ¿', priority=3)
def handle_predict_trends(manager, args):
    """å¤„ç†è¶‹åŠ¿é¢„æµ‹"""
    return handle_enhanced_features(args)


@command_registry.register('seo_audit', 'ç”ŸæˆSEOä¼˜åŒ–å»ºè®®', priority=2)
def handle_seo_audit(manager, args):
    """å¤„ç†SEOå®¡è®¡"""
    return handle_enhanced_features(args)


@command_registry.register('build_websites', 'æ‰¹é‡ç”Ÿæˆç½‘ç«™', priority=1)
def handle_build_websites(manager, args):
    """å¤„ç†ç½‘ç«™æ„å»º"""
    return handle_enhanced_features(args)


def main():
    """ä¸»å‡½æ•° - æä¾›ç»Ÿä¸€çš„æ‰§è¡Œå…¥å£ï¼ˆé‡æ„ç‰ˆæœ¬ï¼‰"""
    import os, sys, asyncio
    print("ğŸ” éœ€æ±‚æŒ–æ˜åˆ†æå·¥å…· v2.0")
    print("æ•´åˆå…­å¤§éœ€æ±‚æŒ–æ˜æ–¹æ³•çš„æ™ºèƒ½åˆ†æç³»ç»Ÿ")
    print("=" * 60)

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='éœ€æ±‚æŒ–æ˜åˆ†æå·¥å…· - æ•´åˆå…­å¤§æŒ–æ˜æ–¹æ³•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
            ğŸ¯ å…­å¤§éœ€æ±‚æŒ–æ˜æ–¹æ³•:
              1. åŸºäºè¯æ ¹å…³é”®è¯æ‹“å±• (52ä¸ªæ ¸å¿ƒè¯æ ¹)
              2. åŸºäºSEOå¤§ç«™æµé‡åˆ†æ (8ä¸ªç«å“ç½‘ç«™)
              3. æœç´¢å¼•æ“ä¸‹æ‹‰æ¨è
              4. å¾ªç¯æŒ–æ˜æ³•
              5. ä»˜è´¹å¹¿å‘Šå…³é”®è¯åˆ†æ
              6. æ”¶å…¥æ’è¡Œæ¦œåˆ†æ
            
            ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹:
              # åˆ†æå…³é”®è¯æ–‡ä»¶
              python main.py --input data/keywords.csv
              
              # åˆ†æå…³é”®è¯æ–‡ä»¶å¹¶å¯ç”¨SERPåˆ†æ
              python main.py --input data/keywords.csv --serp
              
              # åˆ†æå•ä¸ªå…³é”®è¯
              python main.py --keywords "ai generator" "ai converter"
              
              # å¤šå¹³å°å…³é”®è¯å‘ç°
              python main.py --discover "AI image generator" "AI writing tool"
              
              # ç”Ÿæˆåˆ†ææŠ¥å‘Š
              python main.py --report
            
              # ä½¿ç”¨51ä¸ªè¯æ ¹è¿›è¡Œè¶‹åŠ¿åˆ†æ
              python main.py --use-root-words
            
              # é™é»˜æ¨¡å¼åˆ†æ
              python main.py --input data/keywords.csv --quiet
        """
    )

    # è¾“å…¥æ–¹å¼é€‰æ‹©
    input_group = parser.add_mutually_exclusive_group(required=False)
    input_group.add_argument('--input', help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„')
    input_group.add_argument('--keywords', nargs='+', help='ç›´æ¥è¾“å…¥å…³é”®è¯ï¼ˆå¯ä»¥æ˜¯å¤šä¸ªï¼‰')
    input_group.add_argument('--discover', nargs='+', help='å¤šå¹³å°å…³é”®è¯å‘ç°ï¼ˆå¯æŒ‡å®šæœç´¢è¯æ±‡ï¼‰')
    input_group.add_argument('--report', action='store_true', help='ç”Ÿæˆä»Šæ—¥åˆ†ææŠ¥å‘Š')
    input_group.add_argument('--hotkeywords', action='store_true', help='æœç´¢çƒ­é—¨å…³é”®è¯')
    input_group.add_argument('--use-root-words', action='store_true', help='ä½¿ç”¨51ä¸ªè¯æ ¹è¿›è¡Œè¶‹åŠ¿åˆ†æ')
    
    # å¢å¼ºåŠŸèƒ½ç»„ - åˆç†ä½¿ç”¨ default å‚æ•°
    enhanced_group = parser.add_argument_group('å¢å¼ºåŠŸèƒ½')
    enhanced_group.add_argument('--monitor-competitors', action='store_true', help='ç›‘æ§ç«å“å…³é”®è¯å˜åŒ–')
    enhanced_group.add_argument('--sites', nargs='+', help='ç«å“ç½‘ç«™åˆ—è¡¨')
    enhanced_group.add_argument('--predict-trends', action='store_true', help='é¢„æµ‹å…³é”®è¯è¶‹åŠ¿')
    enhanced_group.add_argument('--timeframe', default='30d', help='é¢„æµ‹æ—¶é—´èŒƒå›´')
    enhanced_group.add_argument('--seo-audit', action='store_true', help='ç”ŸæˆSEOä¼˜åŒ–å»ºè®®')
    enhanced_group.add_argument('--domain', help='è¦å®¡è®¡çš„åŸŸå')
    enhanced_group.add_argument('--build-websites', action='store_true', help='æ‰¹é‡ç”Ÿæˆç½‘ç«™')
    enhanced_group.add_argument('--top-keywords', type=int, default=10, help='ä½¿ç”¨å‰Nä¸ªå…³é”®è¯')

    # å…¶ä»–å‚æ•° - åˆç†ä½¿ç”¨ default å‚æ•°
    parser.add_argument('--output', default=get_reports_dir(), help='è¾“å‡ºç›®å½•')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œåªæ˜¾ç¤ºæœ€ç»ˆç»“æœ')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†æ¨¡å¼ï¼Œæ˜¾ç¤ºæ‰€æœ‰ä¸­é—´è¿‡ç¨‹')
    parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--serp', action='store_true', help='å¯ç”¨SERPåˆ†æåŠŸèƒ½')
    parser.add_argument('--list-commands', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨å‘½ä»¤')
    
    args = parser.parse_args()
    
    # ç»Ÿä¸€å‚æ•°éªŒè¯å’Œå¤„ç†
    if args.list_commands:
        command_registry.list_commands()
        return
    
    # éªŒè¯è¾“å‡ºç›®å½•å‚æ•°
    if args.output and not os.path.exists(os.path.dirname(args.output)):
        try:
            os.makedirs(os.path.dirname(args.output), exist_ok=True)
        except Exception as e:
            print(f"âŒ æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {e}")
            sys.exit(1)
    
    # éªŒè¯é…ç½®æ–‡ä»¶å‚æ•°
    if args.config and not os.path.exists(args.config):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        sys.exit(1)
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶å‚æ•°
    if args.input and not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    # éªŒè¯å…³é”®è¯å‚æ•°
    if args.keywords and len(args.keywords) == 0:
        print("âŒ å…³é”®è¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        sys.exit(1)
    
    # éªŒè¯å‘ç°å‚æ•°
    if args.discover and len(args.discover) == 0:
        print("âŒ å‘ç°æœç´¢è¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        sys.exit(1)
    
    # éªŒè¯å¢å¼ºåŠŸèƒ½å‚æ•°
    if args.monitor_competitors and not args.sites:
        print("âš ï¸ æœªæŒ‡å®šç«å“ç½‘ç«™ï¼Œå°†ä½¿ç”¨é»˜è®¤ç½‘ç«™åˆ—è¡¨")
    
    if args.seo_audit and not args.domain:
        print("âŒ SEOå®¡è®¡éœ€è¦æŒ‡å®šåŸŸå (--domain)")
        sys.exit(1)
    
    if args.top_keywords <= 0:
        print("âŒ --top-keywords å¿…é¡»æ˜¯æ­£æ•´æ•°")
        sys.exit(1)
    
    # æ˜¾ç¤ºåˆ†æå‚æ•°
    if not args.quiet:
        if args.input:
            print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {args.input}")
        elif args.keywords:
            print(f"ğŸ”¤ åˆ†æå…³é”®è¯: {', '.join(args.keywords)}")
        elif args.report:
            print("ğŸ“Š ç”Ÿæˆä»Šæ—¥åˆ†ææŠ¥å‘Š")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output}")
        print("")
    
    try:
        # åˆ›å»ºé›†æˆéœ€æ±‚æŒ–æ˜ç®¡ç†å™¨
        manager = IntegratedDemandMiningManager(args.config)
        
        # æ˜¾ç¤ºç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯
        if args.stats:
            stats = manager.get_manager_stats()
            print("\nğŸ“Š ç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯:")
            for manager_name, manager_stats in stats.items():
                if isinstance(manager_stats, dict):
                    print(f"\n{manager_name}:")
                    for key, value in manager_stats.items():
                        print(f"  {key}: {value}")
                else:
                    print(f"{manager_name}: {manager_stats}")
            return
        
        # ä½¿ç”¨å‘½ä»¤æ³¨å†Œå™¨æ‰§è¡Œå¯¹åº”çš„å¤„ç†å‡½æ•°
        if not command_registry.execute(args, manager):
            print("â“ æœªæŒ‡å®šæœ‰æ•ˆçš„æ‰§è¡Œæ¨¡å¼")
            parser.print_help()
            return
        
        print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° {args.output} ç›®å½•")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()