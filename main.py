#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éœ€æ±‚æŒ–æ˜åˆ†æå·¥å…· - ä¸»å…¥å£æ–‡ä»¶
æ•´åˆå…­å¤§éœ€æ±‚æŒ–æ˜æ–¹æ³•çš„ç»Ÿä¸€æ‰§è¡Œå…¥å£
"""

import argparse
import sys
import os
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

# å¯¼å…¥æœ€æ–°çš„éœ€æ±‚æŒ–æ˜ç®¡ç†å™¨
from src.demand_mining.demand_mining_main import DemandMiningManager
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸‚åœºéœ€æ±‚åˆ†æå·¥å…· - ä¸»å…¥å£æ–‡ä»¶
Market Demand Analysis Toolkit - Main Entry Point
"""


def print_quiet_summary(result):
    """é™é»˜æ¨¡å¼ä¸‹çš„ç®€è¦ç»“æœæ˜¾ç¤º"""
    print("\nğŸ¯ éœ€æ±‚æŒ–æ˜åˆ†æç»“æœæ‘˜è¦:")
    print(f"   â€¢ å…³é”®è¯æ€»æ•°: {result.get('total_keywords', 0)}")
    print(f"   â€¢ é«˜æœºä¼šå…³é”®è¯: {result.get('market_insights', {}).get('high_opportunity_count', 0)}")
    print(f"   â€¢ å¹³å‡æœºä¼šåˆ†æ•°: {result.get('market_insights', {}).get('avg_opportunity_score', 0)}")
    
    # æ˜¾ç¤ºTop 3å…³é”®è¯
    top_keywords = result.get('market_insights', {}).get('top_opportunities', [])[:3]
    if top_keywords:
        print("\nğŸ† Top 3 æœºä¼šå…³é”®è¯:")
        for i, kw in enumerate(top_keywords):
            intent_desc = kw.get('intent', {}).get('intent_description', 'æœªçŸ¥')
            score = kw.get('opportunity_score', 0)
            print(f"   {i+1}. {kw['keyword']} (æœºä¼šåˆ†æ•°: {score}, æ„å›¾: {intent_desc})")

def main():
    """ä¸»å‡½æ•° - æä¾›ç»Ÿä¸€çš„æ‰§è¡Œå…¥å£"""
    
    print("ğŸ” éœ€æ±‚æŒ–æ˜åˆ†æå·¥å…· v2.0")
    print("æ•´åˆå…­å¤§éœ€æ±‚æŒ–æ˜æ–¹æ³•çš„æ™ºèƒ½åˆ†æç³»ç»Ÿ")
    print("=" * 60)
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description='éœ€æ±‚æŒ–æ˜åˆ†æå·¥å…· - æ•´åˆå…­å¤§æŒ–æ˜æ–¹æ³•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸ¯ å…­å¤§éœ€æ±‚æŒ–æ˜æ–¹æ³•:
  1. åŸºäºè¯æ ¹å…³é”®è¯æ‹“å±• (52ä¸ªæ ¸å¿ƒè¯æ ¹)
  2. åŸºäºSEOå¤§ç«™æµé‡åˆ†æ (8ä¸ªç«å“ç½‘ç«™)
  3. æœç´¢å¼•æ“ä¸‹æ‹‰æ¨è
  4. å¾ªç¯æŒ–æ˜æ³•
  5. ä»˜è´¹å¹¿å‘Šå…³é”®è¯åˆ†æ
  6. æ”¶å…¥æ’è¡Œæ¦œåˆ†æ

ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹:
  # åˆ†æå…³é”®è¯æ–‡ä»¶
  python main.py --input data/keywords.csv
  
  # åˆ†æå•ä¸ªå…³é”®è¯
  python main.py --keywords "ai generator" "ai converter"
  
  # ç”Ÿæˆåˆ†ææŠ¥å‘Š
  python main.py --report
  
  # é™é»˜æ¨¡å¼åˆ†æ
  python main.py --input data/keywords.csv --quiet
        """
    )
    
    # è¾“å…¥æ–¹å¼é€‰æ‹© - ä¿®æ”¹ä¸ºéå¿…éœ€ï¼Œæ”¯æŒé»˜è®¤è¯æ ¹åˆ†æ
    input_group = parser.add_mutually_exclusive_group(required=False)
    input_group.add_argument('--input', help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„')
    input_group.add_argument('--keywords', nargs='+', help='ç›´æ¥è¾“å…¥å…³é”®è¯ï¼ˆå¯ä»¥æ˜¯å¤šä¸ªï¼‰')
    input_group.add_argument('--report', action='store_true', help='ç”Ÿæˆä»Šæ—¥åˆ†ææŠ¥å‘Š')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--output', default='src/demand_mining/reports', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œåªæ˜¾ç¤ºæœ€ç»ˆç»“æœ')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†æ¨¡å¼ï¼Œæ˜¾ç¤ºæ‰€æœ‰ä¸­é—´è¿‡ç¨‹')
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºåˆ†æå‚æ•°
    if not args.quiet:
        if args.input:
            print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {args.input}")
        elif args.keywords:
            print(f"ğŸ”¤ åˆ†æå…³é”®è¯: {', '.join(args.keywords)}")
        elif args.report:
            print("ğŸ“Š ç”Ÿæˆä»Šæ—¥åˆ†ææŠ¥å‘Š")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output}")
        print("")
    
    try:
        # åˆ›å»ºéœ€æ±‚æŒ–æ˜ç®¡ç†å™¨
        manager = DemandMiningManager(args.config)
        
        if args.input:
            # åˆ†æå…³é”®è¯æ–‡ä»¶
            if not args.quiet:
                print("ğŸš€ å¼€å§‹åˆ†æå…³é”®è¯æ–‡ä»¶...")
            
            result = manager.analyze_keywords(args.input, args.output)
            
            # æ˜¾ç¤ºç»“æœ
            if args.quiet:
                print_quiet_summary(result)
            else:
                print(f"\nğŸ‰ åˆ†æå®Œæˆ! å…±åˆ†æ {result['total_keywords']} ä¸ªå…³é”®è¯")
                print(f"ğŸ“Š é«˜æœºä¼šå…³é”®è¯: {result['market_insights']['high_opportunity_count']} ä¸ª")
                print(f"ğŸ“ˆ å¹³å‡æœºä¼šåˆ†æ•°: {result['market_insights']['avg_opportunity_score']}")
                
                # æ˜¾ç¤ºTop 5å…³é”®è¯
                top_keywords = result['market_insights']['top_opportunities'][:5]
                if top_keywords:
                    print("\nğŸ† Top 5 æœºä¼šå…³é”®è¯:")
                    for i, kw in enumerate(top_keywords, 1):
                        intent_desc = kw['intent']['intent_description']
                        score = kw['opportunity_score']
                        print(f"   {i}. {kw['keyword']} (åˆ†æ•°: {score}, æ„å›¾: {intent_desc})")
        
        elif args.keywords:
            # åˆ†æå•ä¸ªå…³é”®è¯
            if not args.quiet:
                print("ğŸš€ å¼€å§‹åˆ†æè¾“å…¥çš„å…³é”®è¯...")
            
            # åˆ›å»ºä¸´æ—¶CSVæ–‡ä»¶
            import pandas as pd
            import tempfile
            
            temp_df = pd.DataFrame([{'query': kw} for kw in args.keywords])
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8') as f:
                temp_df.to_csv(f.name, index=False)
                temp_file = f.name
            
            try:
                result = manager.analyze_keywords(temp_file, args.output)
                
                # æ˜¾ç¤ºç»“æœ
                if args.quiet:
                    print_quiet_summary(result)
                else:
                    print(f"\nğŸ‰ åˆ†æå®Œæˆ! å…±åˆ†æ {len(args.keywords)} ä¸ªå…³é”®è¯")
                    
                    # æ˜¾ç¤ºæ¯ä¸ªå…³é”®è¯çš„ç»“æœ
                    print("\nğŸ“‹ å…³é”®è¯åˆ†æç»“æœ:")
                    for kw_result in result['keywords']:
                        keyword = kw_result['keyword']
                        score = kw_result['opportunity_score']
                        intent = kw_result['intent']['intent_description']
                        print(f"   â€¢ {keyword}: æœºä¼šåˆ†æ•° {score}, æ„å›¾: {intent}")
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.unlink(temp_file)
        
        elif args.report:
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            if not args.quiet:
                print("ğŸ“Š ç”Ÿæˆä»Šæ—¥åˆ†ææŠ¥å‘Š...")
            
            report_path = manager.generate_daily_report()
            print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        
        else:
            # é»˜è®¤ï¼šä½¿ç”¨51ä¸ªè¯æ ¹è¿›è¡Œè¶‹åŠ¿åˆ†æ
            if not args.quiet:
                print("ğŸŒ± å¼€å§‹ä½¿ç”¨51ä¸ªè¯æ ¹è¿›è¡Œè¶‹åŠ¿åˆ†æ...")
            
            result = manager.analyze_root_words(args.output)
            
            # æ˜¾ç¤ºç»“æœ
            if args.quiet:
                print_quiet_summary(result)
            else:
                print(f"\nğŸ‰ è¯æ ¹è¶‹åŠ¿åˆ†æå®Œæˆ! å…±åˆ†æ {result.get('total_root_words', 0)} ä¸ªè¯æ ¹")
                print(f"ğŸ“Š æˆåŠŸåˆ†æ: {result.get('successful_analyses', 0)} ä¸ª")
                print(f"ğŸ“ˆ ä¸Šå‡è¶‹åŠ¿è¯æ ¹: {len(result.get('top_trending_words', []))}")
                
                # æ˜¾ç¤ºTop 5è¯æ ¹
                top_words = result.get('top_trending_words', [])[:5]
                if top_words:
                    print("\nğŸ† Top 5 çƒ­é—¨è¯æ ¹:")
                    for i, word_data in enumerate(top_words, 1):
                        print(f"   {i}. {word_data['word']}: å¹³å‡å…´è¶£åº¦ {word_data['average_interest']:.1f}")
        
        print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° {args.output} ç›®å½•")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()