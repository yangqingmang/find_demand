[
  {
    "url": "https://www.lummstudio.com/docs/20240102",
    "title": "蜘蛛池是什么？如何利用？",
    "description": "日期：2024-01-02",
    "content": "日期：2024-01-02\n聊聊蜘蛛池。\n首先说一下，乱用蜘蛛池，会被谷歌打击，之前我们拆解过一个网站，就是用了蜘蛛池的做法。\n之前的拆解具体看这里：利用 AI 和过期域名 coopwb.in 实现了短期内大量自然搜索流量和收益的黑帽 SEO 策略\nhttps://web.cafe/messages/topic/66814\n先说蜘蛛池是什么？\n顾名思义，就是有一个内容池，里边有很多个网站，池子里养着很多各个搜索引擎的爬虫蜘蛛，内容与内容之前形成了网状结构，蜘蛛进来了，就会一直在里边爬。而且因为时刻在更新大量新内容，有新页面产生，所以蜘蛛来的特别频繁。所以新页面也会很快被收录。\n并且因为内容与内容之间的合理链接，就会让网页的权重变高，排名上升，可以获得谷歌的搜索流量。\n至于蜘蛛池到底有什么用，黑灰产怎么使用，哥飞就不聊了，感兴趣的可以自己去研究。\n有哪些正规的类似蜘蛛池的网站？最典型的也是大家最熟悉的例子就是 V2EX.com。\nV2EX 不是蜘蛛池，但胜似蜘蛛池。因为 V2EX 十几年如一日的大量产出高质量内容，首页内容更新很快，所以爬虫来得特别频繁，最后结果就是新发的帖子，十几分钟就会被谷歌收录。\n最近的一次群里的例子就是 gptshunter.com\n通过 site 发现，谷歌最后一次来爬是 8:07，也就是 76 分钟之前。也就是说谷歌爬虫来 gptshunter.com 的频率很可能是 1 个小时一次，甚至更短也有可能。\ngptshunter.com 怎么做到的呢？并不是上线第一天就给出几十万内容给谷歌，而是从少到多，不断放出新内容给谷歌。\n包括像 toolify.ai，首页本身会不断放出被收录的 AI 工具，同时页面底部增加了个 Read More 模块，把产生的新内容，不断在这个模块里显示，让每一次谷歌爬虫过来，都有新东西可以爬。\n最后说下，白帽怎么用蜘蛛池？\n我们不需要完整的复刻一个蜘蛛池出来，但可以借鉴一些做法。如不断的生成新内容给谷歌收录，并且要控制好内容的质量，争取被收录的每个页面每个月都至少有 10 个来自于搜索引擎的访问量。\n这就需要跟踪统计每一个页面，每个月的访问量，最好能够识别 referer，判断是搜索引擎过来的流量还是用户直接打开的流量。\n新内容发布之后，还需要持\u0000续跟踪，看看是否被谷歌收录。对于没有被收录的页面，可以尝试再次放出来给谷歌看到。对于收录了但没有搜索流量的页面，就需要分析，为什么没有流量。\n补充一下，点击工具，选择最近一小时，也可以看到最近收录的网页。\n另外，新内容，要慢慢放出来，不要一上来就放几十万个页面出来。前期要有一个引蜘蛛的过程，后面慢慢逐渐加大放出页面的数量。\n提问：\n1、新内容分批次放，第一批多少以内算合适？\n答：要看蜘蛛的胃口，刚上线，放出 1000 条左右，然后以 10 分钟 1 条的速度放出剩下的，一天能放出 144 条。持续观察，如果每次放出的都很快被收录了，就可以考虑 5 分钟一条，后面再变成 1 分钟一条，一天就有 1440 条了。再后面就可以 1 分钟 2 条，3 条。\n没有什么一定有效的办法，每个域名都不一样，根据自己实际情况处理。",
    "scraped_at": "2025-09-03T15:13:25.377850",
    "original_title": "蜘蛛池是什么？如何利用？",
    "date": "2024-01-02"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240119",
    "title": "分享一个错过的机会",
    "description": "日期：2024-01-19",
    "content": "日期：2024-01-19\n今天聊聊一个错过的机会。\ntherundown.ai 的创始人，在 12 月 22 日发了一条推特，后来又删除了。\n这条推特说，Rowan Cheung 做的 TheRundown.ai 每个月有 8.3 万搜索都是来自于某个关键词。这个关键词是一个 AI 工具，不过这个 AI 工具已经下线了，用户无法使用。\n他说他是否可以自己做一个同名的 AI  工具来承接这个流量。\n好了，现在的问题是，已知一个域名，已知这个域名能够从某个关键词获取每个月 8.3 万的流量，请问要如何找出这个关键词来？\n第一个想法，直接打开 Similarweb 看数据。\n现在看 Similarweb 的数据，直接就出答案了，这个词直接就排到了 therundown.ai 有流量关键词的第一名。\nsemrush 上是 vocal remover 这个词 第一名\n从这里可以看出来，找对了，空格、字形轮廓都对的上。\n从当时的谷歌搜索截图也可以确认，therundown.ai 排第二名。\n为什么说错过的机会呢，现在搜索，第二名是一个李鬼网站，我当时看到了这个词，但是没有去动手做。\n不过流量也不算特别大。\n但其实 12 月份已经迟了，为什么呢？请看下面的 humanornot.ai 的流量数据曲线。\n从曲线可以看到，7 月份流量其实已经没有最高峰（图里看不到）高了，然后 8 月份流量更低了，为什么呢？\n因为 6 月 28 日后\u0000\u0000，这个工具就下线了，所以流量一直在下降。如果 7 月份就发现这个下线消息，大家去做一个同样功能网站，就能够承接到大部分流量了。\n后来估计是官方发现流量又上升了，下线之后，又有很多人想要体验，于是官方在 2024 年 的 1 月，又把游戏上线了。\n所以目前，官方是可用状态的。\n这个词的谷歌搜索巅峰时期是 2023 年 5 月中下旬。",
    "scraped_at": "2025-09-03T15:13:26.745869",
    "original_title": "分享一个错过的机会",
    "date": "2024-01-19"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240220",
    "title": "如何覆盖更多关键词？",
    "description": "日期：2024-02-20",
    "content": "日期：2024-02-20\n想要网站有更多自然流量，就要覆盖更多关键词。\n怎么覆盖更多关键词？记住一句话，一个页面优化一个主关键词，围绕看主关键词还可以建很多次级关键词页面，所以想要拿到更多关键词的更多自然流量就要做更多页面，覆盖更多关键词。\n而页面，不一定是文章，也可以是模板化的页面。\n举例，拿\nhttps://www.toolify.ai/\n来说，每多收录一个 AI 产品，都可能给他带来更多流量。拿\nhttps://www.gptshunter.com/\n来说，没多收录一个 GPTs，都可能给他带来更多流量。\n做好了模板页面，不断向数据库添加数据记录即可。添加的过程可以是自动化的。",
    "scraped_at": "2025-09-03T15:13:28.124515",
    "original_title": "如何覆盖更多关键词？",
    "date": "2024-02-20"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240227",
    "title": "为什么新词可以快速拿到结果？",
    "description": "日期：2024-02-27",
    "content": "日期：2024-02-27\n排名既跟域名权重有关，也跟选择的关键词有关。越是竞争不激烈的词，权重低的域名才能够拿到排名。\n这也是为什么让大家前几个网站先去做新词的原因，因为新词可以快速拿到结果。\n那么对于类似于\nhttps://eightify.app/\n这种靠海量内容的网站，我们新站要怎么做呢？\n我觉得可以参考的是 gptshunter.com 路径。gptshunter 收录的内容都是全新的，之前几乎没有在互联网上出现过的。这样的关键词，网页供应量少，新站也能够有机会排到前面。\n所以现在又老话重提，2024 年 2 月快要结束了，再做一个 AI导航站有没有可能拿到流量。哥飞觉得是有可能的，只要你胃口不要那么大。比别人更快的收录更多全新的网站，只要有人搜索这些网站的品牌名称，你的页面就有可能拿到排名。\n并且内容循序渐进的发布，不要一口吃成胖子，不要一下子放出几万几十万的内容。\n有句话叫虚不受补，我们新站就是这样的，不能急，得慢慢养。\n并且 gptshunter.com 的内容也是不断增加的，并不是一开始就有很多内容。因为在不断增加内容，就会让谷歌知道，你的站更新很频繁，那么爬虫也会来得越频繁。\n这次发布 sorawebui，我几乎每天都会在谷歌搜索这个词很多次，这是一个全新的词，每次搜索都能够看到排名变化，也看到新站都能够拿到这个词的排名。\n原因就是新词，网页供应量很少，所以只要是有这个关键词出现的网页，都能够被搜索出来，都会有曝光。\n现在假设我们做了一个网站，如果每天很及时的收录这类新词，是不是也能够拿到排名，拿到曝光，拿到流量？",
    "scraped_at": "2025-09-03T15:13:29.491594",
    "original_title": "为什么新词可以快速拿到结果？",
    "date": "2024-02-27"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240304",
    "title": "Google 的高权重域名是什么，如何利用？",
    "description": "日期：2024-03-04",
    "content": "日期：2024-03-04\n这种看起来低竞争度的词，前两名能够拿到大流量，你会不会心动，想要去做这个词？\n如果你想了，那么就掉陷阱了。\n难度低是因为这是内页，ahrefs 的竞争度算法缺陷导致判断为难度低。\n实际这是高权重域名下的内页，而且有几百个反链网站，有几千个反链。\n我们即使是拿一个域名去竞争，也很难竞争做前两名。\n但是，基于这个，就给我们启发，我们可以用 Google Sites 服务，做一个页面来拿某些词的排名。这是高权重域名下的内页，会比较容易拿到排名。\n总结：\nAhrefs 的优化难度不能完全相信，还需要根据搜索结果综合判断\n可以用 Google Sites 服务拿我们想要的关键词权重\n用 Google Sites 还有个好处，可以抢带 “Google” 的关键词。就像用 GPTs 可以抢带 “ChatGPT” 的关键词一样。\n除了 Google Sites 之外，还有 Google blogger，也是高权重域名，可以直接建站。\nGoogle Sites：\nhttps://sites.google.com/\nGoogle blogger：\nhttps://www.blogger.com/",
    "scraped_at": "2025-09-03T15:13:30.850682",
    "original_title": "Google 的高权重域名是什么，如何利用？",
    "date": "2024-03-04"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240416",
    "title": "同一个页面，不要同时有大词和小词",
    "description": "日期：2024-04-16",
    "content": "日期：2024-04-16\n一个小经验，同一个页面，不要同时有大词和小词。\n或者说，不要去盲目追大词，不然可能会因为拿到了大词的曝光，但是排名低点击率低，就使得整体点击率降低，于是影响你的小词的排名和点击率。\n还是应该坚持一个词一个页面逻辑，小词放一个页面，大词放另一个内页或者子目录，这样互不干涉，还可以单独加外链。\n而且我的感觉，谷歌那边排名的最小颗粒度是页面，而不是网站。\n我们通常说网站拿到排名，其实是网站首页拿到排名，而首页其实也是一个页面，只不过是入口，以及整站权重汇聚的中心点。\n有些 Java 做的网站，首页会自动跳转到 /welcome，这个对于谷歌来说就是一个内页了，但是依然可以拿到排名。\n这就可以支撑我上面的论点：谷歌排名的最小颗粒度是页面。\n大家好好体会一下按照页面的逻辑去做网页，这个时候，内链就特别重要了，内链指向到哪里，权重就汇聚到哪里。",
    "scraped_at": "2025-09-03T15:13:32.236697",
    "original_title": "同一个页面，不要同时有大词和小词",
    "date": "2024-04-16"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240421",
    "title": "做有人会搜索相关关键词的页面",
    "description": "日期：2024-04-21",
    "content": "日期：2024-04-21\n一起来看下 looka.com 的流量页面分布，可以看到有以下几类：\n首页\n博文页，以 /blog 开头\n功能页，如 /logo-maker /business-name-generator\n不同的 logo 生成方式，以 /logo-ideas 开头\n不同的 logo 形态，以 /logo-styles 开头\n不同的 logo 使用场景，以 /logo-maker 开头\n他回去做那些页面，是因为真的有人会搜索相关关键词。我们做页面，目的是为了拿到关键词排名，拿到搜索流量。那么对于有些关键词，自然而然就能想到，要用子目录的方式去做，因为还有很多下级关键词。\n进而我们可以想到，为什么要去做海量页面，因为有海量关键词会被搜索。\n那么，这个时候做页面，就会有两种方式，一种是，我有什么数据，我就去做什么页面；第二种是因为有人会搜索相关关键词，所以我要去做对应的页面。\n从获取流量的角度，显然第二种能够获取到更多流量。",
    "scraped_at": "2025-09-03T15:13:33.604361",
    "original_title": "做有人会搜索相关关键词的页面",
    "date": "2024-04-21"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240509",
    "title": "一个关键词一个页面原则",
    "description": "日期：2024-05-09",
    "content": "日期：2024-05-09\nhttps://ahrefs.com/blog/zh/keyword-cannibalization/\nAhrefs 这篇博文的结论在开头已经给出来了，后文只是在展开解释说明。\n“许多人认为，拥有多个关于同一关键词排名的页面会使搜索引擎感到困惑，并导致搜索引擎对“错误的”页面进行排名。用 Patrick Stox 的话来说，这整个想法是“荒谬的”。他是对的，拥有多个关于同一关键词的页面可能会导致“意外”。但这并不总是意味着你需要修复它们。因为它有时可能预示着，你只需要整合内容就可以提高排名和展示的机会。”\n有很多人会有误解，认为一个网站对于一个关键词只能做一个页面。\n这个理解是错误的。\n我们只要始终记住“一个关键词一个页面原则”就好。\n一个核心关键词会有很多变种说法，也有很多二级、三级关键词，每一个细分关键词都可\u0000\u0000以做一个页面。\n之后最重要的一件事情就是整合，也就是做好合理的内链，把权重从最末端页面不断向上一级关键词汇聚，直到核心关键词页面。\n这就又要提我之前总结的六字真言了“分门别类罗列”，你的核心关键词页面，需要这样做，你的二级、三级关键词页面也要这样做。具象化就是树状机构。\n通过合理的内链结构，可以把权重从主干传递到支干，也能到树叶。还可以把所有枝叶和支干的权重汇聚到核心关键词主页。\n我们之前说过，对于一个词，要举全站之力优化，通过今天上面聊的就知道，这需要整个网站很多内页通过合理的页面结构才能举全站之力。千万不要简单理解为注册一个域名，做一个首页就完事。\n举例说明，Coloring Pages 是核心关键词。左图下方列表就是二级关键词，右图有选择其中一个二级关键词之后，又能看到很多三级关键词。",
    "scraped_at": "2025-09-03T15:13:34.951121",
    "original_title": "一个关键词一个页面原则",
    "date": "2024-05-09"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240514",
    "title": "为什么说谷歌的最小排序粒度是网页，而不是网站？",
    "description": "日期：2024-05-14",
    "content": "日期：2024-05-14\n我最近有种感觉，其实谷歌的最小排序粒度是网页，而不是网站。\n我们通常说一个网站的权重高，其实也可以说是他的首页权重高。大多数时候，首页就是根目录，但有些网站是 /home 或者 /index 或者 /welcome 等带路径的。是根目录还好理解，为什么带路径的首页，在排序时也能够有优待呢？\n我的理解，是因为权重都汇聚到了首页（含带路径的首页）\n而一个页面的权重怎么来的？一看你的这个页面是否能够【说到做到】，而是别的网页怎么【称呼你】\n【说到做到】，就是我们之前说的，需要满足用户搜索需求。谷歌没办法运行我们的功能，所以只能通过网页内容来推断功能是什么，然后再通过用户在页面的互动来推断是否满足用户搜索需求。\n【称呼你】靠的是链接，包含我们自己站内的链接和别的网站的反链。\n所以我们\u0000都很多内页，每一个内页都有指向到首页的链接，甚至可以不止一个衔接，而是多个。通过链接锚文字，我们可以告诉搜索引擎，我们怎么称呼首页。\n外部链接，其实也应该是锚文字带关键词的链接效果最好，因为这样可以告诉搜索引擎，别人怎么称呼我们网站。\n这里举个例子，假设你的域名是 GPT4o.com，你想优化的关键词是“GPT-4o” 和 “GPT 4o”，那么你的每一个内页，都可以有三个到首页的链接，分别如下：\n<a href=\"\">GTP4o.com</a>\n<a href=\"你的首页地址如 https://gpt4o.com/\">GPT-4o</a>\n<a href=\"你的首页地址如 https://gpt4o.com/\">GPT 4o</a>\n我们获取外链，最好也是上面三种，如果实在没办法，下面这种也是可以的。\n<a href=\"你的首页地址如 https://gpt4o.com/\">https://gpt4o.com/</a>\n当你理解最小粒度是网页之后，就能够理解为什么“youtube mp3 download” 出来的前五结果都不是首页，而是内页了。",
    "scraped_at": "2025-09-03T15:13:36.284264",
    "original_title": "为什么说谷歌的最小排序粒度是网页，而不是网站？",
    "date": "2024-05-14"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240515",
    "title": "如何查看 checkout.stripe.com 导入流量的 100 名外的网站？",
    "description": "日期：2024-05-15",
    "content": "日期：2024-05-15\n受限于共享账号的套餐，我们看 checkout.stripe.com 的导入流量排行榜之前看到前面 100 个网站，后面的就要求你升级账号才能看到。今天，哥飞教大家一个方法，不用升级账号也能够看到。\n这个方法也没有办法用在太小流量的网站，所以需要找到排行榜里，国家地区排名靠前的网站。如我这里找出来的 1287 名和 3518 名。\n在 Similarweb 的网站品类分析功能里，把刚才复制的分类填进去，打开科学与教育分类，按照国家\u0000与地区排名，找到#1287，你就会发现，网站是 wordwall.net。\n我们可以去验证一下，回到导入流量页面，选择包含 wordwall.net。\n找出来的，虽然依然看不到域名，但是只找出来一条结果，说明就是这个网站，并且行业和排名也对得上。\n刚才的#3518 也找出来了，是我们的老朋友 fotor.com。\n方法教完了，是不是就完了呢？不是的，我们完全可以在 Similarweb 的分类里边把所有能够看到的网站全部导出，然后和导入流量排行榜撞一下，是不是就能够把所有能够撞上的网站都找出来呢？\n再进一步，我们是否可以做一个浏览器插件，帮助用户看到更多数据呢？\n这个方法，暂时别外传，我们群里朋友先用哈。",
    "scraped_at": "2025-09-03T15:13:37.662156",
    "original_title": "如何查看 checkout.stripe.com 导入流量的 100 名外的网站？",
    "date": "2024-05-15"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240516",
    "title": "如何获取某个网站的 icon？",
    "description": "日期：2024-05-16",
    "content": "日期：2024-05-16\n今晚哥飞小课堂，分享如何获取某个网站的 ICON，大家做导航站用得着。\n主要有三种方法：\n1、利用谷歌的 API（可以获取任意网站的）\nhttps://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://hix.ai&size=256\n2、利用 FaviconKit 的 API（缺点是只能获取大站的）\nhttps://api.faviconkit.com/twitter.com/256\n3、自己抓取 html 中的 icon\n其实上面两种方法的图片就是来自于 html 中，具体主要看两个，一是看 rel=\"shortcut icon\"，二是看 ref=\"apple-touch-icon\"。",
    "scraped_at": "2025-09-03T15:13:39.022780",
    "original_title": "如何获取某个网站的 icon？",
    "date": "2024-05-16"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240523",
    "title": "如何找到优秀的文章模板？",
    "description": "日期：2024-05-23",
    "content": "日期：2024-05-23\n今晚的哥飞小课堂，分享如何找到能够从搜索引擎拿到流量的文章模板。\n其实说白了很简单，就是拿一些有流量的关键词，去谷歌搜索，找排在前面的内容页面。\n拿个实际例子来说，在谷歌搜索“dalle 3 prompts”，可以看到前两名都是 openai 社区里的帖子，先略过。第三名就是一个外部网站的内页了。\n网址：\nhttps://www.mlq.ai/dalle-prompts/\n标题：20+ DALL·E 3 Prompts\n内容：总分总结构，还给出了小目录\n现在我们找到了一个页面，那么通常就可以认为，既然他这个页面能够拿到流量，是不是有其他页面也能够拿到其他关键词的流量呢？\n打开 Similarweb，看这个网站的流量关键词，果然有看到了很多关键词，都拿到\u0000了流量。再拿 “midjourney v6 prompts”，这次排第二名了。\n网址：\nhttps://www.mlq.ai/midjourney-v6-prompts/\n标题：25+ Midjourney V6 Prompts\n内容：同样的总分总结构，有小目录，有题图。\n第三名我刚才截图没有截到，是\nhttps://midlibrary.io/midguide/midjourney-v6-in-depth-review-part-2-prompting\n，这样我们又发现一个网站 midlibrary.io，再看这个网站的流量关键词：\nmidlibrary\nmidjourney library\nmidjourney styles\n这些都拿到了比较靠前的位置。\n而且是首页直接拿到的排名，那就可以看看首页的结构。\nT: Andrei Kovalev's Midlibrary: Midjourney AI Styles Library and Guide\nD: The most advanced Midjourney AI Styles Library on the web. 5300+ styles in V5, V4, V3, and niji + Midjourney Guide and weekly Style Tops\nH: The most advanced library of genres, artistic movements, techniques, titles, and artists' styles for Midjourney AI.\n总结一下，通过一个关键词发现一些内页，然后找到这个网站的更多关键词，再根据关键词去找更多的网站，通过这样不断的循环查找，你就能够发现一批能够拿到排名的文章。\n仔细分析这些文章的结构，然后模仿这些文章，让 GPT 帮你生成新文章。\n注意，这里不是让 GPT 凭空生成文章，而是要提供资料给 GPT，让 GPT 基于资料进行创作，这样可以确保尽可能少出现幻觉，保证内容的真实性。\n类似的方法还能用于找新词。\n你先随便输入一些新词，在谷歌里看看有哪些网站出现了这些词。然后再去这些网站看看是否可以找到更多的词。基于这些更多的词，你在谷歌可以找到更多的网站，然后再找到更多的词。\n最后你就能够得到一个经常出现新词的网站列表。然后重点关注这些网站的最新内容。\n提问：\n1、这里有一个洗稿的 prompt 文章，讲的很好，可以套用起来，\nhttps://u604y5x4sg.feishu.cn/wiki/WwZQwBMKLioKaMk7G3qcbocinrU",
    "scraped_at": "2025-09-03T15:13:40.383859",
    "original_title": "如何找到优秀的文章模板？",
    "date": "2024-05-23"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240529",
    "title": "用户归因是什么？如何做？",
    "description": "日期：2024-05-29",
    "content": "日期：2024-05-29\n今晚哥飞小课堂，跟大家讲一下一些用户归因的小知识。\n如果我们想知道用户来自于哪里，可以用流量统计。但是如果想知道付费用户来自哪里？是在 PC端还是移动端付费的？这些信息，就需要我们能够对每一位用户进行归因。\n通常的做法是在用户表记录一下用户来源，在订单表记录本地订单的设备信息（从 User Agent 可以读取到）。\n这样你就可以关联用户表和订单表，查出各个不同渠道来的用户付费转化率怎么样，甚至细分到不同设备平台的转化率是多少。\n那么要怎么记录用户来源呢？\n最常见的做法是在用户首次打开我们网站时进行染色处理。\n如先根据url 里的参数如 ?ref=xxx、?f=xxx 等参数识别用户来源。如果没有这些参数，就看 referer。\n总之通过某些方法获取来源信息，然后把来源信息写入 cookie 里。当用户注册后，记录来源信息到用户表。\n记录来源还有\u0000两种方法，一种是按照最早来源，一种是按照最新来源。\n举例，假设一个用户先通过谷歌搜索打开了你网站，之后在你发到即刻的宣传帖子里又点进来了，之后才注册的。\n按照最早来源，那么你应该记录该用户从谷歌搜索过来的，按照最新来源，你应该记录来自于即刻。\n如果你去投广告，就更是要能够区分不同广告平台，甚至不同的广告计划，这样你就知道到底哪个平台的广告效果好，哪个广告计划的效果好。\n我们做基础框架时，如果一开始就考虑到这个需求，把用户来源情况记录好，之后每一个新项目都能够用得上。而不会在需要去分析时才抓瞎，没统计，区分不了数据。\n一些可能需要记录的信息：\nUser Agent\n可以分析出用户的设备平台（移动端、PC 端、平板）、系统（Windows、macOS、iOS、Android）等信息\nIP\n可以分析出用户所在的地理位置信息（国家、地区、省市）。\n时间\n可以按照年、年月、年月日、小时（24 小时制）等维度统计。\nlanguage\n用户浏览器首选语言。",
    "scraped_at": "2025-09-03T15:13:41.717080",
    "original_title": "用户归因是什么？如何做？",
    "date": "2024-05-29"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240603",
    "title": "如何使用谷歌趋势找新词？",
    "description": "日期：2024-06-03",
    "content": "日期：2024-06-03\n今晚哥飞小课堂，跟大家复习一下，如何使用谷歌趋势找新词，如何判断一个关键词是新词。\n方法很简单，把这个词放到谷歌趋势里搜索，然后看最近 30 天、90 天、12 个月、5 年的曲线图。\n如我们查一下 ChatGPT，看过去 12 个月，都是比较平稳的，这就说明这个词在 12 个月之前就出现了。\n那就再往前看，我们看过去 5 年的数据。我们知道，ChatGPT 这个词是 2022 年 11 月 30 日出现的，拉长到五年之后，的确可以看到，就是从那个时间点开始有数据的。所以根据谷歌趋势曲线，看一个词什么时候开始有曲线，就能够知道这个词的出现日期。\n假如出现日期在 30 天内，那就最好不过了，新鲜热乎的新词，我们最喜欢了。\n我们再拿 GPT 4o 的相关词验证下，可以看到这些词就是 5 月 13 日开始出现的。而 OpenAI 的发布会也是这一天发布的，所以我们现在可以确认，用谷歌趋势就可以看到一个词最先出来的时间，进而通过时间来判断是否是新词。\n好，现在我们已经知道怎么判断一个词是否是新词了，那要怎么找出更多的新词呢？有很多办法，如你在任何地方看到的一个词，都可以放到谷歌趋势查询判断一下。今天要教的方法是@Banbri 去年 12 月的线下聚会教过大家的方法。\n我们打开谷歌趋势，输入任意一个关键词，举例 TTS，选择全球，选择最近七天，看相关查询，是不是就看到了 ChatTTS 和 chaTTS。\n这里我们发现，ChatTTS 是我们之前就已经知道的，最近几天出现的新词。并且还发现了一个 Typo 词（就是拼写错误词），ChaTTS，这就很有意思了，多个 T 连在一起，有些人记不住，就会少输入一个 T。\n好，现在方法学会了，我们只需要不断的输入一些词，就能够找到这个词相关的新词。举例，如果你输入 AI，是不是就能够找到 AI 相关的新词？但是 AI 太泛了，太大了，你还可以输入 AI Music，再选择 90 天，就把 udio 给找出来了。\n输入 udio，就\u0000把 suno 给找出来了，也就是说，你知道一个产品后，就可以拿着这个产品名称，或者这个产品所在品类的名称去谷歌趋势搜索，就能够找到更多的词。\n找新词，不可能一击必中，你只能不断的探索，才可能会有发现。所以方法就是不断的输入词汇，找到更多词汇。\n那么这个方法可以自动化吗？那就要找 Google Trends 的接口。找接口的方法很简单，我通常就是直接去谷歌搜索，输入 Google Trends API，就找到了。\n再把之前哥飞教给大家的方法用上，先从随便一个词，在谷歌找到一些网站，再去看这些网站获取自然流量的关键词，拿着这些词去找新词。\n不断的在 网站\n<->\n词\n<->\n更多词\n<->\n更多网站之间循环，你就能够打开一个全新的世界。\n找词，找需求，不再是拍脑袋了，而是有科学方法去找。\nhttps://mp.weixin.qq.com/s/pFi683ZoT_WJXO_t770vSQ\n把上面文章里总结的 51 个关键词放到谷歌趋势里去，也能找到一些新词。\n这是一个很有意思的现象，用户记不住你的产品名称，就会去搜索你的产品功能名称。\n假设，别人做一个产品很火，他有三个功能，分别是 A、B、C，此时，你直接做一个名字叫 A 的产品，主打 A 功能，很有可能就能够拿到流量。",
    "scraped_at": "2025-09-03T15:13:43.094319",
    "original_title": "如何使用谷歌趋势找新词？",
    "date": "2024-06-03"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240604",
    "title": "你也许能学到更多，两个SEO优化的失败案例",
    "description": "日期：2024-06-04",
    "content": "日期：2024-06-04\n之前总给大家讲成功案例，今晚哥飞小课堂，给大家讲讲我们最近两个月的两个失败案例，还挺典型的，对大家会有一些帮助。\n先说第一个失败案例 AISong.ai，为什么说失败呢？大家看看 SGC 后台截图就知道了。\nAISong.ai 是 4 月初上线的，当时偷懒，直接拿已经上线的 SunoAI.ai 的代码和数据就部署上线了。所以相当于我自己给自己做了一个完全复制粘贴的网站，这在谷歌眼里是大忌，属于重复网站，重复网页。\n当时为什么我明知道重复网页是大忌，也要这样去做呢？主要是一开始我就是想着把 AISong.ai 当做备胎的，随时把 SunoAI.ai 切过去，也就是 301 过去。\n不过后来计划出现了偏差，4 月 18 日，我做了个错误操作，在 GSC 后台提交了 AISong.ai ，\u0000\u0000之后谷歌就开始大量收录网页。\n到 4 月 23 日，就收录了 9 万个页面。\n到了 5 月 18 日，收录数量达到了 18.9 万。\n之后收录数量就开始下跌，现在只剩下 7 万多个。\n从点击数据可以看到，4.18 开始，到 4.29 这段时间每天都在增长。4.29 之后就下跌，直到 5.4 完全跌没了，直到现在。\n从关键词排名变化也可以看到，4.18 到 5.3 都是差不多 11 名左右。到了 5.4，直接给干到了 63 名，这就是被惩罚了。\n现在已经 80 多名了，几乎没任何点击了。\n现在回过来总结，被惩罚有两个原因：\n重复的网页，也就是在谷歌眼里这是低质量网站了\n新网站上线就准备了海量页面，谷歌特别不喜欢这样\n我之前一直跟大家说，新网站放出页面需要慢慢放，实际自己执行的时候，执行不彻底，然后就被谷歌干了。所以，信哥飞，还是很有用的。\n好，说完第一个失败案例，现在说第二个。\n这个网站是 chatgpt4o.ai，看下面的曲线，是不是跟上面的 aisong.ai 的曲线很相似？是的，这也是被惩罚了。\n虽然这个网站收录数量不多，但也属于刚上线就有比较多页面。而且这个站的页面还有一个特点，内容跟网站核心关键词 GPT 4o 没有任何关系。\n看 chatgpt4o.ai 这个数据表格就能够看到，5 月 24 日数据出现了断崖式下跌。5 月 23 日发生了什么呢？\n我们当时发了一版代码，首页做了一个错误处理，在首页输出最新 6 条问答时，把问题和答案全文输出了。\n本来首页主要内容是围绕着核心关键词 GPT 4o 来做的，结果全文输出问题和答案后，首页单词有 400 多增加到了 2、3千，这些新增的文字都跟 GPT 4o 没有任何关系。在谷歌看来，就是一个本来是关于 GPT 4o 的网站，突然变成了关于别的关键词。于是谷歌的排名系统开始发挥作用了，降排名，降点击。\n5 月 23 日，我还在畅想美好未来，5 月 24 日就打\u0000\u0000入地狱，曝光没了，点击没了。\n5 月 23 日，拿到了曝光和点击的关键词是 ChatGPT4o。\n5 月 24 日，ChatGPT4o 这个关键词的曝光没了，多了“飞哥”的曝光。这是为什么？因为有人问了飞哥相关问题。\n好，第二个失败案例，失败的原因是内容失控了，关键词密度降低了。所以大家知道为什么我这么关心每一个站的核心关键词密度了吧。也知道为什么我强烈建议 blank 的 AITDK 浏览器插件增加关键词密度查询功能了吧。\n今天的分享环节结束了。\n提问：\n1、有没有指定拯救计划？还是就直接放弃了，我们知道这两轮算法后，谷歌惩罚还是蛮严格的。\n答：被惩罚相当于进入了小黑屋，你需要花费比新网站多 10 倍的努力才有可能有效果，所以不如注册个新域名，重新做。像 ChatGPT4o.ai，我其实在 5 月 24 日发现之后，立马就改回去了，也就是说，持续时间其实一天都不到，但是后来排名和曝光就没有回来过。\n2、这么多细节，我这有的小白肯定会踩坑，踩了还不知道，那么肯定还有别的细节问题，怎么办？\n答：细心细心再细心，以及多踩踩坑，后面就容易吸取教训了。这就是为什么要多上站，你网站上多了，自然经验就多了。\n3、注册域名时，怎么避免选到这类被 Google 惩罚的老域名？\n答：查 archive.org 看看这个域名是否被使用过，如果被发现使用过，就放弃掉，换一个域名最省事。\n4、做 AI 导航站，关键词密度核心是 Ai 么？因为网站信息很杂乱，怎么避免呢？\n答：AI 导航站有个不太一样的地方，你的网站关键词是“AI Tool List”，你的首页内容是 AI 产品列表，那么就属\u0000\u0000于我之前提到的分门别类罗列，这是没问题的。谷歌会根据语义分析来判断，认为你的内容和主题是相关的。\n不过，也要注意，不能直接在首页列表中把 AI 产品详细介绍给显示出来，首页列表放 AI 产品名称、一句话介绍、产品标签就可以了。\n5、使用导航站模板改的，代码重复有影响吗？\n答：同样的代码做多个网站，只要网站内容不一样，就没有问题的。AISong.ai的问题是用了 SunoAI.ai 的数据库，也就是不仅代码相同，数据也相同。\n6、如果网站被惩罚或者网站纯粹上线后没运维导致没流量，后续改正后能提升吗，还是直接买新域名？\n答：只要没有被惩罚，一般都能改正之后提升流量，如果被惩罚，直接买新域名。\n7、意思是首页问答没有围绕关键词写吗？那这些问题是什么类型问题\n答：这里说的不是首页 FAQ，而是 chatgpt4o.ai 在首页会列出用户问的最新的 6 个问题，这些问题五花八门，跟网站核心关键词没有任何关系。目前已经下架这个模块了，所以大家看不到，本来设置这个模块的目的是让首页的内容持续保持更新，这样就能够不断吸引爬虫过来，最新的问答就能够快速被收录。\n8、为什么在 GSC 后台提交就会有大量收录\n答：虽然你的网站上线了，但是你不提交，也没有外链，在谷歌看来，你的网站就是不存在的。提交到 GSC 后台后，谷歌发现了你的网站，然后就开始派爬虫来抓取，收录。又因为我这个网站直接用的另一个网址的数据库，里边有很多页面，所以谷歌的爬虫就爬的很欢。\n9、如果看到一家网站很好，照搬照抄是不是也是重复网页，一般就会拿不到排名？\n答：是的，不能直接搬运对方的内容。你可以分析出对方能够获取流量的关键词是哪些，然后自己做一个网站，也做这些关键词。这其实就是我们社区里教的挖掘需求方法之一，找到别的网站能够获取流量的关键词。\n10、为什么新站谷歌能收录那么多，是谷歌自己爬虫采的吗？还是提交了 sitemap，我的站即使提交了 sitemap 收录也是非常缓慢，因为哥飞的网站外链质量比较高吗？\n答：没有 sitemap 文件，单纯就是因为我的网站内链做得好，很方便谷歌爬虫爬取。收录快慢，一是看你的内链有没有做好，二是有没有初始的外链，不需要多，有一两个就可以。\n11、主页主关键词密度太高也不太好，所以推荐的关键词密度范围是多少？\n答：关键词密度 3% - 5%，不要超过 8%\n12、之前做的新词新站，发现跟另外一个网站 title 撞了，高度相似，一直排名不上去，改了之后立马见效了\n13、问答列表模块，要不要单独做个页面，在首页放置个入口，这样首页关键词密度不被稀释，然后也可以让谷歌去抓取列表页面？\n答：吸引爬虫的最简单方式就是首页时刻有新内容，我为了让爬虫不断来首页，于是放了这个模块。至于在另一个页面放问答列表，不断更新是否能够吸引爬虫，我现在不太确定。首页时刻有新内容，导航站可以不断收录，可以做到。",
    "scraped_at": "2025-09-03T15:13:44.497675",
    "original_title": "你也许能学到更多，两个SEO优化的失败案例",
    "date": "2024-06-04"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240606",
    "title": "Ahrefs DR 值计算的小漏洞",
    "description": "日期：2024-06-06",
    "content": "日期：2024-06-06\n今晚哥飞小课堂发一个小技巧，不知道大家有没有对比过，为什么 woy.ai在 ahrefs的 DR 这么高？\n看图你会发现，woy.ai 只有 56 个外链网站，就有 53 的 DR，而 toolify.ai 和 hix.ai 有几千个外链网站，也才 60 多的 DR？\n目前我观察到的 ahrefs 的 DR 计算，有个小漏洞，当一个网站的反链大部分都是网站首页时，ahrefs 就会认为传递的权重高，于是 DR 就高。我发现这个算法漏洞后，又在多个网站上测试了，可复现。\n这意味着什么？\n意味着 ahrefs DR 可以伪造，可以人为造出虚高的 DR。\n那么，假如你去买别人网站时，就要小心，是不是这样造出来的高 DR。\n更准确的描述是首页 + 全站链接 + dofollow。\nahrefs 不止 DR 算法有问题，KD 算法也有问题。有些关键词明明搜索量巨大，竞争异常\u0000\u0000激烈，ahrefs 的 KD 算法却计算出来了一个很小的 KD 值。\n典型关键词就是 youtube mp3 download，第一名月访问量 40 万，KD 居然是 1。\n我猜测，ahrefs 的 KD 算法只考虑了首页、内页、外链、DR 等因素，并且是否是首页、是否是内页权重太大。当一个词的搜索结果全是内页，即使关键词搜索量巨大，也会被认为 KD 很低。\n但是我看关键词 KD 依然还是用 ahrefs ，大多数关键词都是比较准确的，一些极端情况多检验就好了。",
    "scraped_at": "2025-09-03T15:13:45.865134",
    "original_title": "Ahrefs DR 值计算的小漏洞",
    "date": "2024-06-06"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240609",
    "title": "Henry 分享：如何通过内容运营，拿下主词？",
    "description": "日期：2024-06-09",
    "content": "日期：2024-06-09\n今晚的哥飞小课堂，我给没有参加北京场线下聚会的朋友们讲讲 Henry 的分享内容。先从一张图说起。\n怎么理解这张图呢？\n网站首页瞄准主关键词，但是新网站上线，没什么权重，谷歌不会给排名和曝光。\n这时候，可以做的是，做扎实站内内容，同时做好外链。\n站内内容可以从主关键词开始下探，找出所有二级词，但是二级词也是概括性的词，有一定优化难度，所以可以用子目录来做二级词。\n再继续每一个二级词下探，找到三级词，在子目录下做三级词内页。\n一个三级词一个内页，做扎实内容。\n争取做到，每上线一个新的三级词页面，就能够从谷歌获取到想要的三级关键词的搜索量。\n等到一个三级词页面做好了，就再做一个另一个三级词页面，不断把所有三级词做好。\n等过段时间你会发现，二级词子目录慢慢有排名有曝光了。\n最后当你把所有的二级词以及下面的三级词都做了之后，你会发现，首页核心关键词也有排名和曝光了。\n这个时候，你就可以拓展边界了，把三级词下的所有四级次也都做一遍。\n以上时间线，就是 Henry 的网站在做了不同的事情之后的流量曲线。这根曲线我在他的 GSC 后台看过，这是真实的 GSC 后台点击曲线。\n海外工具从需求挖掘到网站制作全流程让你一篇文章学会\n从网站站内优化到部署上线再到推广运营一篇文章让你学明白\n以上两篇是以前的分享，也有讲过类似的思路。事实上 Henry 在进群之前，从来没有做过网站，更没有 SEO 基础。他的所有相关知识来自于群里。再加上他自己聪明的头脑，理解，运用。\n提问：\n新站其实只要花很久时间经营才能有排名是不是\n新词很快，老词要时间，因为你要谷歌证明，你比目前排到了前面的网站更好。\n拿到排名，其实就是把别人挤下去了。谷歌凭什么要把你的给拿上来，把别人的降下去？不就是因为你向谷歌证明了你能够更好的满足用户搜索需求嘛",
    "scraped_at": "2025-09-03T15:13:47.483540",
    "original_title": "Henry 分享：如何通过内容运营，拿下主词？",
    "date": "2024-06-09"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240611",
    "title": "为什么你需要关注未编入索引网页数量？",
    "description": "日期：2024-06-11",
    "content": "日期：2024-06-11\n之前跟大家聊的失败案例，最近几天又有其他朋友跟我报告类似的情况。我总结了一下，有了一个猜想，不一定对，但我觉得是有参考意义的。\n几乎所有上图这种点击骤降的网站，都有图里下半部分的情况，未编入索引网页数量超过了已编入索引数量。\n也就是说，大家需要每天关注自己网站的未编入索引网页数量，如果持续出现上升趋势，那么就要考虑一下，你的生成网页的策略是不是有问题了。\n下面说一下我的猜想。在我看来，已抓取而未索引的网页，都是被谷歌算法检测过的，低质量页面。如果你的网站在持续生成大量的低质量网页，那么谷歌就有理由认为你的网站不是一个好网站。\n有时候还会出现已索引的网页数量变少，这说明有些之前被索引的网页，经过谷歌算法的二次检测，认为是低质量网页，而清除了索引。\n我觉得我们需要关注那些发布之后，但从来没有从谷歌获取到点击的网页数量，也就是0 曝光 0 点击页面。如果你的网站这种页面比较多，而且随着你生成的网页数量越来越多，这类页面的占比也越多，那么你的生成策略一定是有问题的。你生成的都是低质量垃圾页面。\n这个站，目前正在自救，有可能能够救回来。\n现在大家再来回顾一下，之前给大家分享的 Henry 做的页面策略，页面不需要太多，但是每上线一个都是精品，都奔着从谷歌获取对应关键词的排名和流量的目标去的。\n谷歌如何定义精品页面？谷歌可能会有很多指标，但我觉得可以简化一下，我们就看页面能不能拿到对应关键词的排名和曝光。\n如果你上线的每一个页面，都有排名和曝光，那么这个页面对你的主页才会有加成作用，才能够让你的网站主关键词排名越来越靠前。\n最后给大家补一个例子，woy.ai 虽然目前每天点击不多，但也还在增长中。虽然页面是 AI 生成的，但也有人工参与，控制一下质量。不过最近的未索引页面比例已经有 23%了，我需要去控制一下了。",
    "scraped_at": "2025-09-03T15:13:48.879688",
    "original_title": "为什么你需要关注未编入索引网页数量？",
    "date": "2024-06-11"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240613",
    "title": "SEO三原则：什么是“分门别类罗列“和“一个关键词一个页面”",
    "description": "日期：2024-06-13",
    "content": "日期：2024-06-13\n今天的哥飞小课堂给大家看一个专业 SEO 玩家怎么做哥飞之前总结的六字真言“分门别类罗列”和“一个关键词一个页面”两个原则的。\n网址在这里\nhttps://ahrefs.com/writing-tools/\n，为了给大家看清楚整个页面的脉络，我缩小了页面截了一张图。\n更具体的结构，看上面 Headings 更清晰。效果是，这个关键词，Ahrefs 的这个页面拿到了第三名。\n好，上面说的是“分门别类罗列”，下面再说下“一个关键词一个页面”原则。\n为什么 Ahrefs 要做这么多页面？\n就是因为一级关键词下面有二级关键词，二级关键词下面有三级关键词。也就是说有很多细分的关键词，这么多关键词，不可能只靠一个页面拿下。\n每一个关键词都对应一个功能，也没必要一个页面放很多功能。正确的做法就是一个页面放一个功能，让每一个页面的核心关键词都足够突出，也就是我们说的一个关键词一个页面原则。其实首页、列表页面，跟内页是一样的，都应该遵循一个页面一个关键词原则，因为首页、列表页也是一个页面。\n从谷歌的角度，从用户的角度理解也应该一样的，搜索一个关键词，就应该有一个对应的页面来满足用户需求。举例搜索 Outline Generator，Ahrefs 的这个页面拿下来第一名的位置。\nhttps://ahrefs.com/writing-tools/outline-generator\n，页面打开之后，就是我们提过无数次的，经典工具页面布局，先大大的 H1 标题放核心关键词，然后下面就是工具表单入口，之后是大段大段的介绍性文字。\n为什么工具页面需要文字？因为谷歌爬虫不可能像人一样来操作测试你的工具，所以只能是通过“看”你网页里的文字来理解你这个工具到底是什么工具，能够满足什么需求？\n谷歌怕不怕站长乱写呢？也怕。\n但是，谷歌选择先相信你写的，你说什么，我就\u0000\u0000信你。\n然后给一些曝光，看看用户是否会点进你的页面。再点进去后，是否停留，是否又回到了搜索结果页面。通过积累这些用户行为，谷歌可以判断，你说的内容是否跟你的工具匹配，是否满足用户搜索意图。\n如果能够满足，那就给你更多流量，继续看，如果你能够持续满足，那么你就能够得到更靠前的排名，更多的曝光，更多的点击。\n最终拿下第一名也是有可能的。\n好了，以上就是哥飞总结的两大 SEO 原则：\n分门别类罗列\n一个关键词一个页面\n再配合合理的内链以及合理的关键词密度，你就能够拿下几乎所有新词。\n对了，补充一点，可以看到二级关键词，Ahrefs 没有做页面，而是直接在一级页面里列出了所有的三级页面。这里我猜测是因为 Ahrefs 觉得很少人回去搜索这些二级关键词。这还是“一个关键词一个页面”的体现，做页面，只做用户可能会搜索的关键词。",
    "scraped_at": "2025-09-03T15:13:50.243315",
    "original_title": "SEO三原则：什么是“分门别类罗列“和“一个关键词一个页面”",
    "date": "2024-06-13"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240625",
    "title": "如何拿下大词？网站多语言的重要性",
    "description": "日期：2024-06-25",
    "content": "日期：2024-06-25\n上来先给大家看词，并且哥飞整理了前三名网站信息。\npokerogue.net 2024-02-25注册，210 个反链网站\npokerogue.io 2024-04-17 注册，270 个反链网站\npokeroguegame.io 2024-05-08 注册，252 个反链网站\n先给两三分钟，大家先研究下这几个网站。\n以上三个网站，都不是群友做的网站，也就是说，在别的网站已经吃掉了前三名流量的前提下，群友做的网站还有 28 天 40 万的点击，说明大词真香，人人都有可能分一杯羹。\n先给大家看下第一名网站的恐怖流量，2024-02-25 注册的域名，5 月份的访问量是 5376 万。\n主要流量地区都是发达国家，也就是流量很值钱。\n30%的自然搜索流量，65%的直接访问。说明既能够源源不断从搜索引擎补充新流量，也能够把用户留下来。\n主要搜索关键词，就是核心关键词 pokerogue，在社交平台上也能够看到很多人在分享这个游戏画面截图。\nPokeRogue 是一款基于宝可梦 IP 的休闲 roguelike 游戏。\n如果去看谷歌趋势的话，会发现从 3 月 28 日开始有数据，在 4 月 2 日左右开始超过 GPTs 的热度，之后一骑绝尘。\n同时大家会看到，我在上面分别用了大小写，曲线是重叠的，也就是谷歌其实不区分大小写的。\n在谷歌趋势上看这个关键词的地区可以发现，热度第一名居然是韩国，这也是为什么群友做的这个网站可以在三个高外链网站围堵情况下拿到 40 万点击的原因之一，我们等下详聊。\n哥飞先说说最开始我们列出来的三个网站，大家有没有发现一个特点\u0000\u0000，三个网站的反链网站都很多，而且都是两百多个。\nAhrefs 上暂时查不到这个词的 KD，所以就用 Similarweb 的数据来看，上面显示关键词难度只有 4。\n为什么难度这么低的词，那三个网站需要做两百多个外链？\n我有一个猜测，做这些游戏站的，都是一帮老手，他们对于游戏站，已经有自己的 SOP 了，怎么发现新词，怎么做好站内优化，怎么开发上线，怎么搞到很多外链，拿下绝对稳固的排名。\n也就是说，通过分析上面这三个网站，我们也许能够找出他们的更多游戏站，进而有更大的发现，不过今天哥飞不展开了，大家当做家庭作业去做吧。\n有一个点需要提醒下，大家可以去分析三个站的外链，看看这600 多个外链都是怎么得来的，我们是否可以得到这些外链。\n好，现在开始聊一下，群友做的关于这个词的网站。域名是 pokerogue.cc，5 月 1 日注册的，群友发现这个词了，特意等到 5 月开始了，才注册这个域名，来参加 5 月新词新站比赛。\n首先，特别感谢群友，愿意把网站拿出来当做案例分析，并且愿意授权 GSC 权限给哥飞，让哥飞可以更好的给大家分析。\n上面 GSC 的曲线，看起来这是好看啊，巅峰时期每天有两万多的点击，即使到现在，每天也还有一万五左右的点击。\n可能大家会好奇，为什么平均排名第 6 名，居然会有 20%的点击率。这是因为排名和点击率被平均了，某些关键词，某些网页拿到了很靠前的排名，拿到了很高的点击率，但是跟其他比较靠后的页面和关键词平均之后，排名就变低了，点击率也变低了。\n看上面，当我筛选了韩语页面，并且地区选择了韩国之后，平均排名就是第 2 名了，点击率就是 45%以上了。\n不管是直接在谷歌搜索，还是用 Serper 的谷歌搜索接口模拟，都可以看到其实\nhttps://pokerogue.cc/ko\n都拿下了第一名。\n这就是点击率接近 50%的答案，因为拿下来第一名。\n核心关键词密度 3.76%，这是一个恰到好处的密度值，不大不小刚刚好。\nHeadings 结构清晰，多处出现核心关键词。\n为了快速上线网站，群\u0000\u0000里朋友并没有自己开发游戏，而是点击开始游戏后，跳转到了之前我们提到的谷歌搜索第一名的那个网站\nhttps://pokerogue.net/\n可能会有朋友疑问，这样不会让自己的停留时间变少，导致谷歌不给排名吗？\n的确是有影响的，你看首页默认英文关键词，就几乎没有拿到多少点击。\n谷歌排名算法很复杂，会综合很多很多因素，停留时间是因素之一，但是关键词匹配和意图匹配更重要。\n关键词匹配和意图匹配，决定参与排名的网站有哪些。在韩语 포케로그 的搜索结果中，我们可以看到，真正提供游戏入口的，只有群友做的这一个网站。也就是参与排名的网站少，所以你条件差一点，也能够拿到排名。\n谷歌先根据关键词找到所有匹配的网页，之后对这些网页基于各种因素进行打分，最后根据打分得出排名。\n如果你的网页在第一步关键词匹配时，就没有被选上，那么就没有然后了。所以这也是哥飞一直强调的站内优化的重要性。\n而 pokerogue.net、pokerogue.io、pokerotuegame.io都没有做多语言，只要群友的网站做了多语言，刚好就拿下来韩语流量。\n现在大家知道做多语言有多香了吧，知道为什么要去做多语言了吧。因为很多网站并没有做多语言，那么我们做了多语言，在英语之外的搜索结果里，我们就能够分一杯羹。\n群友做的网站，甚至只有 26 个外链，就能够在三个月时间拿下 244 万的曝光，45 万的点击。\n可能又有朋友有疑问了，哥飞你不是说外链越多越好吗？\n这个还是要从竞争角度分析，当跟你竞争的网页没几个时，你很少的外链就能够拿下排名。举例群里另一位朋友做的网站，也是新词新站，当他拿下每日 10K 的 UV 时，依然只有 2 个外链。\n如果跟你竞争的网站很多，你为了能够脱颖而出，就需要在每一处细节都做到更好。举例，要有更多的外链，要有更高的停留时间。\n那么为什么我们分享开头提到的三个网站，需要有 200 多个外链呢？因为他们想让竞争者望而却步，他们想要形成绝对优势。\n最后再给大家看一张截图，看看流量曲线和内容曲线，会发现趋势是一致的。所以哥飞的建议就是，好好对待你的每一个网页，争取让绿色的网页越来越多，而灰色的网页越少越好。\n以上是群友的网站在各个不同国家流量排行榜。\n群友网站的韩国流量是 6 月份才拿下来的，之前主要是别的国家的流量。\n提问：\n博客文章是用哪个工具写的？GPT 辅助即可。\n这个新词是通过哪个方法发现的？\n在谷歌趋势的相关查询多点几下发现的。\n天天去看谷歌趋势，并且不要是看 AI 相关的，任何行业的词都可以去看看。\n查域名工具哪个快？\nhttps://query.domains",
    "scraped_at": "2025-09-03T15:13:51.622386",
    "original_title": "如何拿下大词？网站多语言的重要性",
    "date": "2024-06-25"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240626",
    "title": "如何找到更多的可以发外链的地方？",
    "description": "日期：2024-06-26",
    "content": "日期：2024-06-26\n关于如何找到更多的可以发外链的地方。\n之前跟大家说过方法，找到你的竞争对手的所有外链，你也去发一下。\n今天，哥飞把这个方法拓展一下。\n先收集 10 个左右的 AI 导航站，然后把这些导航站收录的 AI 网站域名都抓取下来，这一步你可能能够找到 1 万个域名。\n之后查询这 1 万个域名的外链都有哪些，假设平均每个网站有 10 个外链域名，你就得到了 10 万个外链域名了。\n之后你对这 10 万个外链域名分组统计，就能够知道哪些地方更容易发外链，更多人选择去发。去重处理后，你也能够得到一个能够发外链的域名大全列表。\n也许能够找到几千个域名。打包 99 美元来卖，我估计很多人愿意买。",
    "scraped_at": "2025-09-03T15:13:52.975878",
    "original_title": "如何找到更多的可以发外链的地方？",
    "date": "2024-06-26"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240627",
    "title": "为什么要去开一个谷歌广告账号？",
    "description": "日期：2024-06-27",
    "content": "日期：2024-06-27\n今天哥飞小课堂，提醒大家去开一个谷歌广告账号，并且真的投一点广告，花一些钱出去。\n为什么这么说呢，因为哥飞发现，你的不投广告的谷歌广告账号，看一个关键词的搜索量数据，是一个范围，如某个词搜索量是 10 万到 100 万每个月。\n我们知道谷歌趋势里只能看到相对值，看不到绝对值。想要看到绝对值，就需要用一个已知搜索量的关键词去对比。\n而 Keywords Everywhere 这个插件可以在谷歌趋势上显示绝对值，其实数据就来自谷歌广告后台。\n但是据我观察，他的账号是没有投过广告的账号，所以看到的也是一个范围，Keywords Everywhere 直接把范围的最大值 100 万给显示出来了。\n但如果用投过广告的账号去看，就会发现，真实的数据比 100 万还更大，而且差距还挺大的。所以真的值得去开一个广告账号。\n现在大家知道，在 Semrush、Similarweb、Ahrefs 等平台可以\u0000看到一个词的月搜索量。在谷歌广告后台也可以看到，在谷歌趋势里则只能看到相对值。同时在 GSC 后台也能够看到真实的搜索量，前提是你拿下了这个关键词的谷歌搜索前几名。\n如果从准确性、及时性、通用性角度考虑，哥飞最推荐的还是谷歌趋势查看。\n补充两点：\n谷歌广告后台看不到实时数据，只能看到截止到上个月的数据。\n目前测试，你投了广告就可以看到所有词，不是只能看到你投的词。\n谷歌趋势如何使用：\n谷歌趋势是一个相对值，跟绝对值无关。\n如果不和别的词对比，就只能看个趋势。\n如果要知道绝对值，可以找一个已知绝对值的词，对比来看。\n比如，目前 GTPs 每天数据大概 5000+，找的词根 GPTs 对比，假设 GPTs 值是 10，你找的词是 20，那么这个词当前每天数据大概是 10K。",
    "scraped_at": "2025-09-03T15:13:54.343280",
    "original_title": "为什么要去开一个谷歌广告账号？",
    "date": "2024-06-27"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240707",
    "title": "如何做好一个内容型工具站？",
    "description": "日期：2024-07-07",
    "content": "日期：2024-07-07\n今天的主题是，再聊内链和内页，以及如何做好一个内容型工具站。\n大家听过哥飞无数次在群里说，有些关键词，别人靠内页，就能够拿到排名，如果我们做一个网站专门做这个关键词，举全站之力去优化这个关键词，那么假以时日，我们的网站也能够拿到排名，甚至超过那些内页，拿下第一名都是有可能的。\n方法是什么呢？\n什么是举全站之力呢？\n这跟内页和内链又有什么关系呢？\n这就是今天要跟大家将清楚的问题。\nhttps://mp.weixin.qq.com/s/Jru9k4oGAyiZK1VYFFZRQQ\n大家先看下半年前，哥飞发在公众号的文章，当时解读了 2024 年谷歌排名算法。\n其中有几条，我摘出来：\n持续发布新引人的内容：权重 21%\n细分领域专长：权重 14%\n新鲜度：权重 6%\n可依赖性：权重 5%\n内部链接：权重 2%\n这五条，加起来权重是 48%\n哥飞为什么把这五条摘选出来？因为都是跟内页和内链相关的。\n只有持续发布新引人的内容，才能保持新鲜度，同时内页也就会越来越多，这时才需要合理的内链。只有你的网站积累下来了足够多的权威内容，才算得上是细分领域专长以及可信赖。\n以上是谷歌给我们的理论基础，那么基于这些基础，我们需要怎么去规划建设我们的网站呢？\n首先很明确的一点，你如果看中了一个关键词，只做了一个首页，就拿下来排名，那么只能说明目前这个关键词竞争程度不高。别人也做一个网站，花一些时间，是很有可能超过你的网站。因为你的基础不牢靠。\n打好基础第一步，就是多做内页，做扎实内容。\nhttps://mp.weixin.qq.com/s/VVC13q_rar8Qsbz_a7JcrA\n怎么做扎实内容，之前北京聚会的分享嘉宾 Henry 就给我们讲过了，哥飞也写了一篇解读的文章，大家可以看上文。\nHenry 去年 12 月做了一个网站，选择了一个有一定难度的关键词，靠着扎实的内容，在 4 月份时候流量开始起飞，之后每个月都在增长。刚才哥飞去看了下，6 月的访问量又涨了。\n他的网站 57%流量来自于自然搜索，35%来自于直接访问量，没有投过付费广告。一些核心关键词流量相比于上个月涨了 465%，这什么概念，流量翻了几倍。靠的是什么？靠的就是扎实的内容和内页，使得首页的核心关键词排名上升了。\n类似的例子还有很多，今天的分享不一一列出了。但是所有的例子都在说明一件事情，你想要拿下排名，仅仅靠外链是不够的的，你还需要有内页。\n但是，注意，千万\u0000\u0000注意，不是盲目的上几十万个几百万个跟你的核心关键词无关的内页，也不能你有什么内容，就上什么内页。相反，你需要有所取舍，有些内容，就不适合给谷歌看到，你最好一开始就不让谷歌爬。整个目录你都可以在 robots.txt里设置禁止抓取。\n在接下来的分享之前，大家可以再看看我之前分享的失败案例。\n我在上次分享时提到，确保我们网站上线的每一个页面都是精品网页。怎么定义精品网页呢，就是我们新发布的网页，能够在 GSC 里有曝光和点击。\n经过最近一段时间和各路 SEO 高手交流学习，更是坚定了我在这方面的想法。\n我先定义一个公式：\n哥飞网站权重 = GSC 后台里显示的能够拿到曝光和点击的网页数量/GSC里爬虫发现了的网页数量 x 100%\n接下来，我会解释这个看起来简单，但实际上不简单的公式。\n哥飞以 Woy.ai 和 AISong.ai 为例，给大家计算一下这个公式。\n先看 Woy.ai 的，GSC 后台，按照截图所示，下载所有的网页。Woy.ai 拿到了至少 1 个点击的网页数量是 692 个。\n未编入索引和已编入索引网页加起来个数是 13385。\n那么计算出来的 哥飞网站权重 = 692/13385x100% = 5.16%\n用同样的方法，我再计算另两个网站的数据\nAISong 的网站权重 = 52/300000x100% = 0.01733%\nChatGPT4o 的网站权重 = 23/27300x100% = 0.08424%\n整体数值有点小，我修正一下公式：\n网站权重 = GSC 后台里显示的能够拿到曝光和点击的网页数量/GSC里爬虫发现了的网页数量 x 10000‱\n解释一下，这个公式用来计算，你的网站高质量网页的万比值，也就是每 1 万个网页里，有多少个高质量网页。\n用修正后的公式来计算，得到三个网站数据：\nWoy.ai 网站权重 = 516‱\nAISong 网站权重 = 1.733‱\nChatGPT4o 网站权重 = 8.424‱\n我们实际使用时，可以去除‱符合，那么：\nWoy.ai 网站权重 = 516\nAISong 网站权重 = 1.733\nChatGPT4o 网站权重 = 8.424\n实际上，Woy.ai 因为一些代码的失误，导致分母变大了，如果从分母里减去 928+5297+1522，那么重新计算的权重分应该是 692/5638x10000‱ = 1227‱\n我现在能够拿来计算的网站样本还不够多，没办法直接告诉大家，这个数值应该多大更好。所以先拍脑袋说一个数吧，至少要超过 100‱，这是一个及格线，如果你发现你的网站数值小于 100‱，那么你就要反思一下，是不是你的生成内容策略有问题了。如果有问题，请及时停止生成新内容页面，然后处理老内容页面，再想新的生成策略。\n这个哥飞网站权重公式，为什么只选择 GSC 后台的这两个指标呢？\n一、当然是为了大家计算更方便，二是 GSC 后台的数据，就是谷歌官方的数据，这比所有任何第三方平台估算的数据更准确。\n用这个公式计算出来的数值越高，其实就直接表明你的网站在谷歌的受欢迎程度越高。\n那么，要怎么做页面，才能让这个数值更高呢？\n记住一句话，不是你有什么内容，你就做什么页面，而是用户在谷歌搜索什么，你才去做满足搜索需求的页面。\n之前哥飞以\nhttps://sticker.show\n为例，给群里朋友们讲解了如何做一个内容型工具站。当时提出的做法，后来实践证明，有一些不太通。\n所以今天哥飞要提出一套新的做内容型工具站的做法，目的是做出一个用“哥飞网站权重”公式计算出来得分高的网站。\n先来回顾一下当时的做法：\n做一个能够生成内\u0000\u0000容的工具站，提供免费额度给用户使用，让用户在使用过程中生成无限多的真实需求的内容（图片、文字、声音、视频等），再给每一条内容生成一个页面，这样就能够源源不断的生成无数页面了，而且这些页面都是基于用户的真实需求生成的。\n这个想法很美好，但是忽略了一个因素，大多数人生成的内容有重复，这就导致你可能会有很多个不同的页面，可能在抢同一个关键词的排名。同时呢，每一个页面都不是特别聚焦，文字内容不够，关键词密度不够，于是自然而然就拿不到排名。\n今天，哥飞要修正一下做法，不再给用户生成的每一个内容生成一个页面。而是去各种渠道挖掘可能会有搜索量的关键词，为每一个关键词生成一个页面，在这个页面里汇聚展示用户生成的相关内容。\n听起来好像很简单，实际做起来，还是有一些难度的。\n首先，你要怎么去挖掘尽可能多的有搜索量的关键词呢？\n深圳线下聚会，彪哥分享了一个方法，你先收集你的一些大流量竞对网站，然后用 Similarweb 或者 semrush 或者 ahrefs 找到这些网站能够拿到流量的页面，分析他们是通过什么关键词获取流量的，把这些关键词抓取过来。\n基于一些你已知的关键词，找到更多的相关网站，进而找到更多的关键词，不断循环，你就能够得到一个比较大的关键词库了。\n有了关键词库，你就可以基于关键词库，对用户生成的内容进行打标签，也就是把关键词和内容关联起来。具体的做法，你可以结合关键词搜索、向量相似度检索、GPT 打标签等方式去做。\n一旦某个关键词关联的内容超过3 个，你就可以为这个关键词生成页面了。\n在这个页面里，你要围绕着这个核心关键词来做优化，解释说明这个关键词，同时把相关的内容列出来。\n上面所的 3 是最少数量，其实更多更好，举例 5 或者 10.\n随着内容数量的增多，你还可以对内容进行分类，然后分门别类列出来。\n所以，上面就用到了我们讲过的两个原则：一个页面一个关键词，分门别类罗列。\n而做这些一个一个内页，又是为了：举全站之力优化。\n又因为 GSC 后台最多只能下载 1000 个网页，所以哥飞要修正一下这个公式的使用范围了：这个公式适合在你的网站刚上线没多久，有点击和曝光的页面数量小于 1000 时使用。\n也刚好，也就是说，最好是在你的网站网页数量在 1 万以内时，就要去试探谷歌，看看你的内容生成策略是否有效，不要一下子就上万几十万个页面。\n你可以在前 1 万个页面时调整好内容生成策略，调整好之后，就可以继续生成很多页面了。\n重新计算刚才的几个网站的得分：\nWoy.ai 有 1000+个网页拿到了点击和曝光，那就只能按照 1000 计算。\nWoy.ai 网站权重 = 1000/13385x10000‱ = 747‱\nAISong 网站权重 = 307/300000x10000‱ = 10.23‱\nChatGPT4o 网站权重 = 82/27300x10000‱ = 30‱\nsticker.show 网站权重 = 122/56993x10000‱ = 21.4‱\n那么最低分数，依然还是暂定 100‱，如果你连这个树都拿不到，那么你的网站内容策略一定是有问题的，就先别继续生成内容了。\n继续刚才的内容，我们要基于关键词，去生成质量可控的有可能能够拿到曝光和点击的页面，而不是有什么内容，就生成什么页面。\n这些关键词页面，才是我们的最终页面，而用户生成的内容，你可以结合实际考虑，是否生成页面，如果要生成页面，也可以设置为 noindex，并且 robots.txt里也设置禁止爬虫抓取这个页面，这样就不会生成大量的不可控的页面了。\n这些关键词页面，也是有层级关系的\u0000\u0000，你可以继续为它们生成不同层级的列表页面，拿下更多关键词的流量。\n页面多了之后，怎么组织好页面之间的关系，怎么做好内链呢？\n首先，页面之间，最好有上下级关系，这就是之前 Henry 分享时画出来的树状结构。从首页出发，可以不断的进入各级目录，各级页面。这就要做好面包屑导航，面包屑导航可以使得每一个内容，用户都知道，所有的上级有哪些。\n然后，树根直接出来的几个关键词，你可以做成全站顶部导航条，让用户在网页的任何一个页面，都可以快速切换到别的根部。这也相当于全站每一个页面都给这些重要的频道页面加了内链。\n同时，每一级页面，最好列出来同级的页面有哪些，下一级页面有哪些。\n对于重要的内页，可以在各个重要目录多给入口。\n这部分更具体的可以看深圳线下聚会，彪哥的分享：\nhttps://docs.google.com/presentation/d/1C_uBmggbFjasCZ0Iiv4flC8-TX1x-Kzq5YcToLx2G54/edit?usp=sharing",
    "scraped_at": "2025-09-03T15:13:56.734914",
    "original_title": "如何做好一个内容型工具站？",
    "date": "2024-07-07"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240716",
    "title": "为什么要满足用户搜索意图",
    "description": "日期：2024-07-16",
    "content": "日期：2024-07-16\n接着昨晚我们聊过的话题：\n用户想找什么，你就得给什么，即使不是你自己做的也行，只要能够帮助用户满足搜索意图。解决用户需求，并不一定要自己开发工具。\n今天的哥飞小课堂，给大家看一个实际的案例。\naimusicpreneur.com\n域名注册于 2023 年 8 月 18 日，第一版上线于 8 月 24 日，用的是 WordPress 建站，所以能够这么快。\n网站定位于 AI 音乐创作者杂志，也就是 AI 音乐创作者提供各种教程资讯的文章。\n从上线至今的流量曲线可以看出来，虽然即使到了 6 月份，月访问量也才 3.7 万，但是增长趋势是实打实的，一直在增长中。\n怎么做到的呢？靠的就是做扎实的内容。目前这个网站已经在多个音乐相关的关键词里拿到了谷歌首页的排名。\n从拿到流量的页面来看，都是一些 AI 音乐相关产品推荐文章，如拿下最高流量的页面\nhttps://aimusicpreneur.com/ai-tools-news/the-best-ai-stem-separation-tools-ai-stem-splitter\n，这篇文章的主题是：The best 4 AI stem separation tools in 2024\n文章发布于今年的 3 月 1 日，到现在也才 4 个半月时间，但获得的流量已经占全站总流量的 43%了。\n这个页面主打关键词 ai stem splitter，对应的需求是音轨分离。在谷歌搜索结果中，排名第 6 左右。\n这个网站并没有自己开发音轨分离工具产品，而且体验了市面上的各个产品之后，写了一篇推荐文章，文章结构如下：\nWhat is AI stem separation? 什么是 AI 音轨分离\nHow does AI stem separation work? AI 音轨分离如何工作的？\nAI tools for music stem separation 用于音乐音轨分离的 AI 工具\nApplications of AI stem separation AI 音轨分离的应用\nReal-wrold examples 实际案例\nChallenges and Limitations of AI stem separation technology AI 音轨分离技术的挑战和局限\nFrequently asked questions about AI stem splitter 关于 AI 音轨分离器的常见问题\n谷歌还是喜欢这样的推荐页面的，虽然排名不如工具页面高。\n总结一下，假如你现在发现一个词有一定搜索量，并且竞争程度也不是特别高，但是开发工具有需要时间，你就可以先上线一个内容推荐页面，先试试看是否可以拿到排名。\n而不是等待工具开发完成之后，再来上线页面。\n一定要快，在你发现词之后，就快速上线页面。\n很多时间谷歌排名，\u0000\u0000就是你早上线一天，你就更有优势。\n等你的内容推荐页面拿到排名后，等你的工具开发完成后，你完全可以把工具页面作为一个内页，然后在你的内容页面增加很多按钮，引导流量到你的工具页面。这样两个页面都能够参与谷歌排名。",
    "scraped_at": "2025-09-03T15:13:58.135912",
    "original_title": "为什么要满足用户搜索意图",
    "date": "2024-07-16"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240720",
    "title": "如何挑战高 KD 值的关键字",
    "description": "日期：2024-07-20",
    "content": "日期：2024-07-20\n今天的哥飞小课堂，我们来看一个搜索量还挺大的词 ai face swap 和 face swap ai，虽然看起来是两个次，并且搜索量实际是不一样的，但是因为意思相同，需求相同，并且谷歌趋势也把这两个词的热度值看成一样，所以我们也当做同一个词。\n如果单纯看 KD 的话，会觉得有一定的难度，我们通常就不会去做这个词了。但是哥飞想跟大家说，现在我们已经进入下一个阶段了，需要开始考虑 KD 为 50 到 70 之间的词了。\n这些词每天搜索量在 10 万以内，机会很多，我们只是吃到一点点，在本身流量很精准的情况下，其实收入会很不错。\n我们用 Ahrefs 查询关键词 KD 时，除了要看难度值，也要看右侧的外链网站数量。我们会发现，两个词一个需要 95 个外链，一个需要 60 个外链。这里是说，有了这些外链，就大约能够进入谷歌搜索第一页面。\n上周六 英文SEO 实战派 John 的线下分享会里说过，这些外链用来帮助我们拿下首页前 10 位置，但是决定谁排前三的，就不仅仅只是看外链了，更主要看你的网站，用户是否喜欢，是否能够满足用户的搜索需求。\n在 ai face swap 的搜索结果里，我们看到了一个网站 aifaceswap.io ，域名注册于 2024 年 2 月 19 日，目前外链网站数量 74 个，DR 才 7，但的确不仅拿下首页了，还进入前五了。\n从最近几个月的流量曲线可以看到，又是一条特别漂亮的曲线，而且每个月的增长率都比之前更高。\n上线至今，38.88%流量来自于自然搜索，而如果只看 6 月数据的话，40%来自于搜索，说明从搜索引擎来的流量是在增长的。\n2 月注册的域名，到现在也才 5 个月的时间，就拿下了 ai face swap 相关很多关键词的谷歌首页了。\n基于谷歌趋势数据和谷歌广告后台数据综合校验，我估算 face swap ai 每天搜索量两三万，而 ai face swap 每天搜索量一两万左右。这种词能够拿下谷歌前五，甚至以后还能更进一步的话，日入千刀不是梦。\n从谷歌搜索结果来看，直接首页排名里，.ai 域名结尾的 faceswapper.ai 排名最靠前，为什么呢？\n从外链网站数量就可以看出差距了，.ai结尾的有 1000 个外链网站，而 .io结尾的只有 74 个外链网站。\n但是，其实我们也可以看到一个好消息，这是一个很重要的信号，即使别人已经有 1000 个外链，我们只有 74 个，也是有可能能够拿下谷歌首页排名的。\n这能够给我们信心。这也是为什么今天的哥飞小课堂，会用这个 .io 网站当做案例来给大家讲解。\n第二个信号，我们开头已经说过了，即使那些看起来 KD 有点难度的关键词，也是可以去做的，花他三五个月时间，拿下首页不成问题。\n拿下首页之后，比拼的就是产品力了，谁的产品更好用，谁的产品更便宜，谁的产品效果更好。当然关键词密度也不要忘记了。\n从这两个网站案例来说，他们的密度其实都不高。如果我们做一个网站，外链有几百个，并且提供免费使用，密度还比他们高，那么也是有可能能够拿下谷歌首页的。\n最后总结一下，每天搜索量 10 万以内的词，我们都可以去考虑做一做了，不要被高 KD 和高外链吓跑。\n有一个小发现，aifaceswap.io完全免费使用，甚至连登录都不需要，这也许就是它能够在竞争这么激烈的关键词里，仅仅靠 74 个外链网站，只花了五个月拿到谷歌首页的原因。\n这个网站怎么变现呢，免费还没有广告？=> 先占排名再说",
    "scraped_at": "2025-09-03T15:13:59.553278",
    "original_title": "如何挑战高 KD 值的关键字",
    "date": "2024-07-20"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240722",
    "title": "分享一个快速找套壳网站的方法",
    "description": "日期：2024-07-22",
    "content": "日期：2024-07-22\n之前分享过通过看 checkout.stripe.com 的入站流量来分析不同网站的收入情况，今天哥飞小课堂，快速分享一个找套壳网站的方法。\n拿 hf.space来举例，在 Similarweb 可以看到所有给 hf.space导入流量的网站。\n这些网站有一部分是直接给 hf.space增加外链，还有一部分是用 iframe 嵌入了 hf space 。我们要做的就是从导入流量的网站列表里找出用 iframe 嵌入的网站。\n不仅可以直接查 hf.space 的，还可以查具体某一个 space 的，如 openai-openai-detector.hf.space。\n举一反三，除了 hf.space，还可以查什么呢？其实在我们的网站里引用别的网站的图片、视频等静态资源，也算是外链。\n所以，一些热门的 AI 产品的 CDN 域名，你也可以拿来查一查。这个点到为止，大家自己去实践。",
    "scraped_at": "2025-09-03T15:14:00.942034",
    "original_title": "分享一个快速找套壳网站的方法",
    "date": "2024-07-22"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240724",
    "title": "广告指标有哪些？",
    "description": "日期：2024-07-24",
    "content": "日期：2024-07-24\n今天哥飞小课堂聊聊一些大家目前用得上的广告指标。\n广告曝光\n你的广告被展示出来了，展示一次算一个曝光。\n广告点击\n有人看到了你的广告，点击了广告，打开了你的网页，就是一次广告点击。\n我们设置广告时，需要设置我们愿意出的每次点击最高单价。\n一般实际广告点击单价费用不会超过我们设置的最高单价，但也是会有例外情况发生。\n谷歌向我们收钱，其实是按照曝光算钱的，谷歌会综合曝光数据和点击数据，动态计算每一次的点击单价是多少钱。\n如果有别人跟我们竞争相同的关键词，那么如果你出价太低了，就拿不到广告曝光，这时就需要提高出价。\n广告落地页\n用户点击广告，打开了我们的网页，进入的这个页面，也叫落地页。\n有时候我们需要针对广告关键词，专门去设计制作落地页，目的是提高登录注册率、付费率等指标，不要浪费掉了广告费。\n如果有人看了广告点进来了，又关闭了，那么你的广告费就白花了，所以需要尽可能的把人留住。\n举例，可以提供免费试用机会，甚至是免登陆试用机会，因为登录本身也会挡住用户。\n用户\n看你怎么定义，可以是按照注册算，也可以按照设备算。简单处理可以按照注册算。\n客户\n当你的网站使用 Stripe 收款时，创建订单时，你需要传入邮箱，Stripe 会为每一个唯一邮箱创建一个客户 ID。\n所以，如果你的用户，没有点击付款，那么就不会成为 Stripe 的客户。\n也就是，这里有一个转化率的问题，不是每一个用户都会转化为客户。\n订阅客户成本\n不是每一个客户都会付费，这里还可以计算最终每一个订阅客户的成本。\n订阅客户成本 = 花掉的广告费/订阅客户数量\n举例，你今天花了 1000 美元，有 200 个客户尝试付款，有 100 个成功支付，那么订阅客户成本就是 10 美元一个。\n订阅留存率\n一般都是按月订阅的，所以会关注月留存率、三月留存率、六月留存率、一年留存率。\n假如有用户每个月都订阅，12 个月还没取消，那就真的是真爱了。\n通过订阅留存率可以大概判断平均每一个客户能够在未来给你的产品带来总共多少收入，这个就是 LTV\nLTV\n如果你的产品用 Stripe 收款，且是订阅制的话，Stripe 会根据你的订单金额、订阅流失率等信息综合估算你产品的 LTV（客户终身价值）。\n客户是一定会流失的，只是时间长短不同而已。\n你简单理解 LTV 就是每一个客户在你的产品里从注册到最终流失，在你的产品最终会付的钱。\n怎么算账\n只有 LTV 大于订阅客户成本，那么你才有可能能赚钱。\n下面的每一个环节，都可以计算转化率：\n广告曝光 -> 广告点击 -> 访客 -> 注册用户 -> 下单客户 -> 成功订阅客户\n最终你就可以反推，你愿意为每一次广告点击最多出多少钱。\n同时，你也能发现，提升各个环节的转化率，最终就能够提高收入。\n怎么归因\n判断每一个用户来自于具体的哪一个渠道，就是用户归因。\n通过对所有用户归因，我们可以计算出不同渠道的以上介绍的每一项指标数据，就能够知道每一个渠道的性价比。\n通常网站的归因很简单，通过给不同的渠道进来的用户添加不同的来源参数即可。\n既可以用谷歌分析等提供的能力实现用户归因，也可以自己代码里简单实现。\n归因有两种方式，一种是按照最后触达归因，一种是最早触达归因。\n下面是一个最早触达归因的简单实现：\njs 判断当前cookie 中是否存储了来源信息，如果有，则不作处理。\n如果没有，则判断当前访问网址中是否有来源参数，如果没有，则获取 HTTP referer 中的来源网址也可以当做来源信息。\n如果获取到了来源信息，则用 js 写入来源信息到 cookie，这里还可以设置 cookie 最大有效期 30 天，到期自动清空，等待下一次的来源信息。\n在用户登录、注册、付费等重要事件中，读取 cookie 中的来源信息，绑定到用户信息中。\n成本其实无处不在：\n域名注册\n网站服务器\nCDN 流量\nAPI 成本\n付费购买外链\n付费请人打榜\n订阅的一些工具服务\n你的时间\n有成本意识，才能最终算清楚账，知道做哪些事情，投资回报率高，不要在一些小事情小费用上浪费时间。",
    "scraped_at": "2025-09-03T15:14:02.347144",
    "original_title": "广告指标有哪些？",
    "date": "2024-07-24"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240730",
    "title": "Canva 网站拆解，落地页布局结构",
    "description": "日期：2024-07-30",
    "content": "日期：2024-07-30\n之前彪哥让我们看大站，学大站的 SEO，最近哥飞搜索好多关键词，在谷歌首页看到了 Canva.com 的身影，所以今晚的哥飞小课堂带着大家来了解学习一下 Canva。\n先看流量，月访问量 6.5 亿，年访问量 74.75 亿，的确是大站。\n再来看流量来源，直接打开占比了 67.87%，自然搜索占了 27.08%。每年从付费搜索获取 5800 万访问量，从展示广告获取 330 万访问量。\n自然搜索里，又有 82%来自于自然搜索，所以品牌可谓是深入人心了。一想到作图，就会想到 Canva.com。\n查看非品牌词，Similarweb 统计了 457 万个网址，拿下了 106 万个关键词的曝光。\n这些关键词，不乏一些有大搜索量的词，如 ai image generator，拿下了 330 万搜索量里的 67.2 万次点击。\n但是也不要忽略了那海量的长尾关键词，举个例子，house warming invitation(乔迁请柬)，这种算是小词了，他也有覆盖到。\n这个词每个月搜索量 4 万次，也就是每天 1300 次左右，不值得为这个词单独做一个网站，但可以作为一个内页。\nCanva.com 就是靠着大量这种中小长尾词，汇聚起来了海量的流量。\n再来看页面，即使是颜色相关的，Canva 就做了很多页面，覆盖了各种各样的关键词，而且流量都还挺高的。\n从这个搜索结果点进去，可以看到，Canva 做了一系列的颜色解释说明页面。\n面包屑导航起作用了，点击 Color meanings 就进入了上一层页面，这里列出来了常见的颜色名称。因为谷歌能够理解语义，所以你在一个主打关键词是“Color meanings” 的页面列出所有颜色名称，就可以拿到排名了。\n不过在谷歌搜索“Color meanings”，Canva 只拿到了第三名，排名第一的是\nhttps://www.color-meanings.com\n直接拿关键词做域名的网站。这个网站有点意思，最近 12 个月访问量 912 万，但是流量一直在下跌，上个月只剩 48 万了。\nCanva 甚至还做了一系列的 features 页面，把每一个功能都做成页面，就是为了获取这个功能搜索词的搜索流量。\n以 Background Remover 为例，大家可以学习一下，为了获取这个关键词的搜索流量，Canva 做了一个什么样的页面。\nhttps://www.canva.com/features/background-remover\n打开看看，是不是很像我们经常做的落地页模板？没错，如果你想获取某个关键词的排名和曝光，你就得围绕这个关键词做一个页面，把这个关键词相关的方方面面都用图文说清楚。其实谷歌爬虫看到的只是文字，图文排版是为了让我们真人用户看起来更好看。\n整个落地页有以下模块：\n工具名称和工具入口\nHow it works （remove form picture）\nFeatures\nHow it works (remove form image)\nFAQs\n用户证言\n相关功能链接列表\n工具入口\nSEO 从来没有简简单单的成功，如果你想获取某个词的流量，就得把这个词说透。\n之前哥飞介绍了一种内容策略，用标签聚合内容，靠标签页获取流量，如果这个标签页只是简简单单的放一下标签名称、标签说明、内容列表，是很难拿到排名的，你需要认真对待每一个页面，当然也包括标签页。",
    "scraped_at": "2025-09-03T15:14:03.730340",
    "original_title": "Canva 网站拆解，落地页布局结构",
    "date": "2024-07-30"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240801",
    "title": "挖掘需求的方法（下）",
    "description": "日期：2024-08-01",
    "content": "日期：2024-08-01\n第六种，挖掘需求关键词的方法。\n今天跟大家聊聊一些目前正在赚钱的 AI 产品。\n主要分成三部分：\n分享彪哥发现的通过看排行榜挖掘赚钱产品的方法\n从排行榜里找一些产品，分析流量来源，估算月收入\n总结下目前还能够获取到流量的一些渠道\n第一部分，如何找到这些目前正在赚钱的 AI 产品。\n如果是网站产品，可以看 Toolify.ai 的收入排行榜或者 IndieHackers.com 的收入排行榜。如果是 APP 产品可以看 SensorTower.com、DianDian.com、QiMai.cn、Data.ai 等产品。不过我对 APP 不是特别熟悉，所以我们今天只讲 web 形态的产品。\n我们先看下 Toolify.ai 收入排行榜的截图：\nhttps://www.toolify.ai/Best-AI-Tools-revenue\n注意这里虽然第一眼看起来是按照流量排序的，好像跟收入没关系，但其实只是因为一般来讲流量越大收入越高，所以前面一些产品刚好流量排名和收入排名重合了。看第 7 名和第 8 名就知道，这个榜单不是流量排行榜。\n那么这个榜单的收入是怎么来的呢？ 很简单，凭经验估算的。但也不是瞎估算，而是要有参考依据的。\n参考依据是什么呢？就是上面截图中哥飞用红色圈出来的，基于收款平台的数据。先说下原理，当一个网站，接入了 stripe 支付后，用户想要付费，就会从这个网站点击打开 stripe 的收银台页面，进行支付。\n我们拿 ChatGPT 网站升级 plus 套餐为例。\n当我们点击“Upgrade to Plus”按钮后，会打开下面的页面：\n可以看到，虽然打开的网站域名是 pay.openai.com，但从左下角的“Powered by Stripe” 可以知道，这其实是 Stripe 的页面。\n会显示为 pay.openai.com 是因为 OpenAI 在 Stripe 后台绑定了自定义域名。那么根据 pay.openai.com 这个域名的访问量，就可以算出 ChatGPT 的订单数量。\n在 Similarweb 可以查到这个域名的 3 月访问量是 658 万，其中有 450 万来自于外部链接。\n而外部链接里 99.9% 流量都来自于 chat.openai.com，所以我们就可以假设收银台页面在 3 月总共被打开了 450 万次，我们假设打开一次就是一个订单，也就是 450 万个订单。\n这里我再解释下，一般打开了 Stripe 的收银台页面，就是已经创建好订单了。用户打开这个订单后，有可能不输入任何信息，直接关闭，也有可能会输入信用卡信息，确认支付。这里就有两种结果，支付成功或者失败，失败的原因有可能有多种，如被限制了、卡余额不足、卡信息填错等等。\n也就是说订单数量不等同于支付成功数量，这里有一个转换比例，我自己的 AI 工具类产品，支付成功比例从 10%到 50%都有。\n我们假设 ChatGPT 订单支付成功率是 20%，也就是 90 万个订单，每个支付 20 美元，那么总营收就是 1800 万美元。\nChatGPT 的实际支付成功率估计不止 20%，具体多少，哥飞也不知道。\n但我们掌握了这个方法，至少可以大概判断一个产品的月收入是多少。\n有些产品没有在 Stripe 设置自定义域名，我们就没办法直接看收银台域名的流量来判断收入了。\n这时候其实也有办法的，观察会发现，点击支付后打开的 Stripe 收银台地址是 checkout.stripe.com，那我们就可以去看checkout.stripe.com的流量。\n可以看到这个域名每个月的访问量在两三千万，也就是说，所有接入了 Stripe 支付但没有设置自定义域名的网站，一共每个月有两三千万个订单。\n那要怎么分出来，每一个网站的订单数量呢？\n刚才我们说明，在接入了 Stripe 支付的网站点击就会打开 Stripe 的收银台页面，这个时候，【接入了 Stripe 支付的网站】就是【Stripe 收银台网站】的【外部链接网站】，所以就可以在 Similarweb 的热门外链网站模块看到每一个网站的数据。\n点击右下角链接，打开新页面，我们就得到了单点排行榜。\n举例，上面是 3 月份的订单数量排行榜，排名第一的是 roblox.com，是一个套了元宇宙概念的类 4399 网站，上面有很多各种各样的小游戏，3 月的网站访问量是 6.669 亿，其中订单量是 140 万，具体支付成功率哥飞没去估算，反正也不是 AI 产品，我们就跳过。\n再看第二个产品 Midjourney 就是典型的 AI 产品了，3 月份订单数量约为 67 万个。\nMidjourney 提供这么多套餐，我们假设平均每个订单 25 美元，假设支付成功率是 40%，那么算下来月收入是 67x25x0.4=670 万美元。\n而实际上 Midjourney 属于订阅制，用户订阅后如果不是主动取消，下个月还好自动扣款，所以这 670 万可以理解为新增收入，而每个月还有老用户的订阅收入，所以总收入肯定是不止我们计算的这些。\n查看科技媒体报告，说 Midjourney2023 年收入是 2 亿美元，算下来平均每个月是 1666 万美元。\n从这里我们可以看\u0000\u0000到，对于这种超级大的产品，我们其实并没有那么容易去估算真实的月收入。但是，其实很多时候我们也不需要知道真实的收入，只要知道订单数量，就能够判断出来，某一个 AI 产品到底有没有收入，进而去判断这个产品对应的需求大概有多大，我们是否值得进入这个市场。\n那么是不是就完全无法知道一个 AI 产品的月收入到底是多少呢？\n也不是。有一些开发者奉行 Build in Public 原则，会每个月公布自己产品的月收入，这也是他们宣传产品的一种方式。\n通过去 Twitter 关注这些开发者，就能够知道真实收入。\n甚至还可以去 Similarweb 看他的网站的流量情况，这样就能够倒推支付成功率等信息。\n另外 IndieHackers 网站，也有一个收入排行榜，数据都是真实的，来自于开发者授权 IndieHackers 网站读取的 Stripe 真实收入。\nhttps://www.indiehackers.com/products?category=ai&revenueVerification=stripe&sorting=highest-revenue\n总结一下，我们可以通过 Toolify 和 IndieHackers 的排行榜直接看目前正在赚钱的 AI 产品，也可以通过在 Similarweb 看 Stripe 收银台的流量数据来估算其他一些 AI 产品的收入。\nhttps://www.toolify.ai/Best-AI-Tools-revenue\nhttps://www.indiehackers.com/products?category=ai&revenueVerification=stripe&sorting=highest-revenue\n下面我们开始第二部分，找几个产品来实际具体分析一下。\n先看 Jenni AI，这是一个 AI 写作类产品，更准确地说是帮你写论文，写文献综述等各种各样内容的 AI 产品。\n论文写作，这个是用户付费意愿比较强的需求。从流量角度，过去一年流量没有特别大的变化，一直在 100 多万徘徊。\n28.9%流量来自于自然搜索，也就是通过 SEO，从各个搜索引擎免费获取的流量。 10%流量来自于付费广告，7.1%来自于社交媒体分享，3.9%来自于外部链接，剩下还有 49.4%来自于直接访问，说明这个网站的留存不错。\n按照刚才介绍的方法，我们可以看到，最近 12 个月，Jenni AI 跳转到 Stripe 的访问量是 13.18 万，也就是过去 12 个月产生了这么多订单。\n因为 IndieHackers 上显示的是 Mrr，也就是月度经常性收入，所以我们先看下 3 月的新增订单数量是 3.73 万，假设支付成功率是 10%，那么就有 3730 个成功支付订单。\n再看下 Jenni AI 的套餐是单月 20 美元，如果一次性支付 12 个月，就能优惠 40%，只需要 12 美元一个月，算下来就是要支付 144 美元。这里我们假设全部人都选择了年\u0000付套餐，那么新增收入就是 3730x144=537K。\n而 IndieHackers 上面显示的收入是 574K，看起来猜对了。\n但其实是错的，因为不可能所有人都选择年付，也就是有一部分人会选择 20 美元，这里假设 60%选择年付，40%选择月付。\n那么算下来，收入就是 3730x(144x0.6 + 20x0.4) = 352K。\n还差 574K - 352K = 222K，可以理解是之前用户订阅后的自动付款。\n那么上面这几个数字就算对了吗？\n其实我们也是用了大量假设，先假设付费成功率是 10%，再假设有 60%选择年付，40%选择月付，这么多假设凑出来的数字当然不可能反应真实情况。\n实际情况如何，就需要用上各种办法去调查，尽可能少假设，多用真实数据。但我们今天只是跟大家分享这个方法，所以就大胆假设了。\n好了，我们再去看看广告收入，基于 Similarweb 估算的数据，3 月 Jenni AI 的搜索广告投入是 9 万美元左右。\n这相比于每个月有 57 万美元收入来说，ROI 就很高了。\n刚才上面说过，这主要是得益于有 28.9%的来自于搜索引擎的流量。\n这部分流量完全不花钱，只要做好了 SEO 就能够得到，可以理解是谷歌的馈赠。\nJenni AI 还有 7.1%流量来自于社交媒体，主要来自于 YouTube 视频，排名第二的是 LinkedIn，WhatAPP 也来了不少流量。\n所以我们的 AI 产品，如果做好用户引导，让用户能够主动分享到社交平台上，也是能够获得不错的流量和关注度的。\n我们再来看一个产品 StealthGPT，这是一个生成“Undetectable AI Content”的 AI 工具，也就是说它生成出来的内容不太容易被 AI 检测工具检测出来。\n在 IndieHackers 上公布出来的，被验证的收入是 201K 美元。\n而这个网站的访问量目前才 26.4 万每个月，即使最高峰也才 33.8 万。这么一点流量，居然能够产生这么高的收入，这就是目前 AI 出海产品的魅力。\n差不多相当于每一个访问量可以产生 20.1/26.4=0.76美元的收入。\n查看导入到 Stripe 的订单大概是 9.6K 个，这里我们忽略支付成功率，假设成功率就是 100%，计算一下每个订单的金额大概是 20.9 美元。\n这个领域，目前流量更大的是另一个产品，谷歌搜索“Undetectable AI”可以找到，排名第一的就是。\n可以看到 Undetectable AI 直接用需求关键词注册域名，这样就把行业需求词变成了自己的品牌名称，在谷歌眼里，就相当于大家搜索 Undetectable AI 需求，想找的是 Undetectable AI 这个网站。这是很牛逼的一个策略。\n这个网站 3 月的访问量是 416.9 万，假设这是同一批潜在用户，那么按照每一个访问量 0.76 美元计算，这个网站的月收入是 316 万美元。不过实际肯定是没有那么多的。\n我们查到这个网站 3 月份导入到 Stripe 的订单大概是 60.5K。\n同样按照 100%支付成功率计算，得到的金额是 60.5x1000x20.9=126 万美元。我们去 126 万到 316 万的中间数，所以大概估算这个网站每个月的收入是 220 万美元。再次说明一下，以上估算我们用到了大量的拍脑袋想的经验值，不保证准确率。\nUndetectable AI 每一月的流量里有 47.74%来自于搜索引擎，这也是完全免费的流量，也就是几乎差不多有 100 万美元的收入来自于免费流量。\n3 月花出去的广告费是 22.7 万美元，敢话这么多钱出去，说明肯定是赚钱的，ROI 能够打正的。有 10.43%的流量来自于付费搜索，也即是大约能够产生 22.9 万美元收入。\n这样算起来，ROI 才刚刚打正，为什么他还愿意花这么多钱去打广告呢？\n从上面的付费关键词可以看到，核心关键词“Undetectable AI”上就花了 16 万的广告费，说明他需要靠着付费广告来把这个词的精准流量都拿下，之后再用这些量来拿到自然搜索的排名。\n好了，以上就是第二部分，我们找了几个产品分析了一下。列表里还有上百个产品，大家都可以按照这样的方式去分析。\n下面我们讲\u0000\u0000第三部分，目前还有效的流量获取渠道。\n目前海外获取流量，主要有以下几种方式：\n1、SEO + SEM\n免费 + 付费组合，尽可能拿下所有的精准流量，而且付费流量还可以进一步巩固免费流量的位置。\n2、Affiliate\n也就是通过真金白银的返佣机制，让很多中小流量渠道帮助我们推广。\n3、导航站\n目前全球有 300+ 个 AI 导航站，大部分是不需要花钱就能提交，或者他们会自动收录，但还有很多有流量的 AI 导航站需要花钱才能提交，不过一般化的钱也不多，目前最贵的是全球排名第一的 AI 导航站 theresanaiforthat.com ，单次提交费需要 300 多美元。\n而全球排名第二的 AI 导航站是杉木哥的 Toolify.ai，目前提交只需要 49 美元，价格很便宜了。\n另外有些 AI 导航站还会去注册 Affiliate，也就是所有从导航过来的付费用户，他们都要收佣金。\n4、Reddit\nReddit 类似于贴吧，有很多各种不同的频道，有些频道支持我们发布自己的产品的宣传帖子。\n老外比较喜欢分享创业故事、产品故事的帖子，所以可以软一点，千万不要扔下一个链接就跑，那样太硬了，很容易被删帖。\n5、YC Hacker News\nHacker News 上有一个 Show HN 频道，允许全球开发者发布自己的产品，可以直接留链接，然后写产品介绍。\n同样更建议软一点，讲故事的形式，这样可以引起讨论，获得更多曝光。\n6、ProductHunt\n这上面每天都有很多产品在打榜，我们中小团队，没什么特色的产品，其实也是可以发布，不为别的，能够拿到一个外链也是不错的。\n而如果你的产品有特色，能够吸引用户自发参与讨论，帮你投票，你再辅助一些付费投票，拿下前三名的话，可以带来很多二次传播。\n7、红人营销\n找到 Tik Tok、Instagram、YouTube 等平台上有一定粉丝的红人，请他们体验我们的产品后，制作一个视频发布到他们的账号上，也是可以带来不错热度和流量的\n8、社交媒体\nTwitter、Facebook 等传统社交媒体上面依然有挺大的流量，值得我们去挖掘，也可以找到一些达人帮我们发帖宣传。",
    "scraped_at": "2025-09-03T15:14:05.114833",
    "original_title": "挖掘需求的方法（下）",
    "date": "2024-08-01"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240802",
    "title": "挖掘需求的方法（上）",
    "description": "日期：2024-08-02",
    "content": "日期：2024-08-02\n今天的哥飞小课堂，把之前聊过的挖掘需求的方法再整理一次发一下。\n先介绍一下，在 SEO 领域，什么是【需求】？\n会有人搜索的关键词，就代表这需求。\n有些需求是资讯、信息，有些需求是工具、服务，有些需求是商品、店铺，还有些别的各种需求。\n我们目前主要聚焦在【出海】【AI】【工具站】领域。\n一个一个关键词来解释，先说【出海】，这个很容易理解，出海意味着给全球 70 亿人提供服务，而且可以快速上线，不需要备案，不需要审核。\n再来解释【工具站】，工具站通常都可以靠用户付费变现，比单纯靠广告变现收入会高很多。\n所以我们主要关注工具、服务相关的关键词，只要有人会搜索的关键词，都是我们的潜在目标。\n有些需求比较老，长期稳定存在，比如 PDF 编辑、转换、压缩等需求，这类需求已经很多网站霸占了谷歌前排的位置，我们短时间内很难做个新网站就拿到排名，获取曝光和点击。\n但是，如果是一个新出现的关键词，大家几乎都在同一个起跑线上竞争，我们懂 SEO，我们反应比别人快，就有可能赢得竞争。\n下面就要解释【AI】了，在 AI 领域，就诞生了很多新的需求，目前几乎可以实现 AI 生成一切，如 AI Image Generator、AI Music Generator、AI Video Generator 等，这些都是之前不曾出现的关键词，或者是老需求，加上了 AI 关键词，也变成了新关键词，新需求。\n所以我们群里目前主要聚焦在出海 AI 工具方向，这个方向已经被教育好了，用户知道需要付费才能使用，所以很愿意付钱，并且海外愿意付费的人群还很多。\n人在国内，赚美元，真的很香。\n所以总结一下，我们要做出海 AI 工具站，第一步就需要去挖掘海外工具的搜索需求关键词，然后做一个网站来满足这个搜索需求，之后通过科学的 SEO 方法，从谷歌等搜索引擎获取流量，最后讲流量变现为美元。\n所以，挖掘需求就是重中之重，是一切的基础，是美元之源。\n那么有哪些挖掘需求的方法呢？\n我们先准备好工具，需要用到谷歌搜索、谷歌趋势、谷歌广告、similarweb、semrush、ahrefs 等平台，用到了哪个工具，我都会说明。\n第一种挖掘需求的方法，我们从基础需求关键词出发，也就是所谓的词根出发，找到更多的关键词。这就需求配合哥飞之前发到公众号里的 51 个词根关键词\nhttps://mp.weixin.qq.com/s/pFi683ZoT_WJXO_t770vSQ\n我们今天先那 Generator 来演示，因为很多 AI 相关的需求关键词都包含 Generator 这个词。有很多工具都可以基于一个关键词来拓展更多关键词，先说完全免费，不需要登录也能使用的 Ahrefs Free Keyword Generator 工具，大家会发现，本身这个工具名就自带了 Generator 这个词。\n打开\nhttps://ahrefs.com/keyword-generator/\n，选择谷歌，输入关键词 Generator，选择美国，就能够看到拓展出来的一些关键词。\n可以看到，这个免费工具虽然可以看到一些关键词，但是默认给出来的都是搜索量比较大的关键词，KD 都很高。\n而如果登录注册 Ahrefs，套餐费又挺高的，所以我们一般不用这个工具。\n我们可以打开 Semrush，找到关键词研究功能，输入 Generator 就能够看到关于这个关键词的概览数据页面。\n我们此时不关心这个关键词本身的数据，所以需要点击下面衍生关键词列表下方按钮“查看全部关键词”。\n在这个 Keyword Magic Tool 页面，可以看到很多关键词，我们可以用筛选工具，选择搜索量 30000 以上，也就是平均每天 1000 以上的，KD 选择 60 一下的，CPC 选择大于 0.01 的，就得到了一些符合我们需求的关键词列表。\n还可以点击左侧的关键词群组，选择 AI，那么出来的就全都是带 AI 且带 Generator 的关键词了。\nSimilarweb 也有关键词拓展功能，在关键词研究 -> 关键词生成器里，同样输入一个关键词，就能够找到很\u0000\u0000多相关关键词。同样设置一些筛选条件，可以找到一些关键词。\n有了这些关键词列表，我们就可以进一步的筛选，举例你可以按照搜索量从高到低排序，也可以按照优化难度 KD 从低到高排序，也可以按照 CPC 从高到低排序。\n通过年趋势这一列，你甚至可以可视化的看出这个关键词是否是一个新词。\n很明显 headcanon generator 就是一个新词，之前都没啥搜索量，最近才有搜索量。为了判断是否是新词，我们还可以借助谷歌趋势来看。\n打开谷歌趋势\nhttps://trends.google.com/trends/explore?q=headcanon%20generator&hl=zh-CN\n时间选择最近 12 个月，很容易看出来，这个词是 5 月底才出现的。\n我们还可以借助谷歌广告后台进一步确认这个词的真实搜索量。\n打开谷歌广告后台，找到工具 -> 规划 -> 关键词规划工具 -> 选择获取搜索量和预测数据，输入我们想查询的关键词，把地理位置选择为全球，时间选择 5 月和 6 月，就看到了，6 月这个词的搜索量是 13.5 万，平均每天 4500 次搜索。\n有了关键词，我们就可以去谷歌实际搜索一下这个关键词，看看目前的第一页结果都是什么。\n目前可以看到，美国区，用英语搜索，出来的第 1、第 3 都是工具，不过是内页。第 2 是 Reddit 的讨论区。第 4 是一个 AI 导航站，这个站记起来，要考，属于是 SEO 做的比较好的网站，可以去上面提交我们的产品。\n补充一下，第一种方法，总共有 51 个关键词，刚才我们只看了第一个关键词，还剩下这么多关键词，大家都可以去看一看。做 SEO，你的数据敏锐度怎么训练出来的？就是靠多看，多研究，多分析。\n剩下的结果分析我们今天就不深入了。继续说挖掘需求。\n刚才介绍了基于某个基础关键词，去拓展找到更多关键词的方法。我们再说第二种方法，是基于某一个网站，找到这个网站的流量来源关键词。举例 canca.com 是 SEO 做的很好的大站，我们可以研究他从哪些关键词获得了流量，我们是否也可以从这些关键词获取流量呢。\n第二种，根据 SEO 大站来查关键词，依然有多个平台可以使用。如 Ahrefs 的 Website Traffic Checker（这里又一个词根 Checker）\nhttps://ahrefs.com/traffic-checker\n在这里可以免登录看到所查网站的流量数据，核心关键词数据，能够拿到大流量的页面数据。\n第二个平台是 Semrush，输入域名，就能够看到这个域名对应网站的数据。我们主要关注自然搜索流量和自然搜索关键词和能够获取流量的页面有哪些。\n先看关键词，点击“查看详情”，可以进入关键词列表，看到很多关键词。\n在排除掉品牌词之后，我们就能够看到 Canva 获取流量的关键词都有哪些了。可以看到第一名就是 color wheel 色轮，这是设计师经常用到的颜色选择工具。\n第二名是 im image generator，这个也算是 Canva 的核心功能之一。\n第四名 qr code generator 有点意思，这跟 Canva 主业好像不搭，不过也算是图片生成相关的。\n看关键词列表，我们还可以关注那些仅仅靠内页就拿下来了这个关键词搜索的绝大部分流量的词，这种词，既然别人仅仅靠一个内页就能够拿到排名，我们专门做一个网站，举全站之力去做，也很有可能拿到排名，拿到曝光和点击。\n第三个平台是 Similarweb，一样可以看到某个网站的关键词列表，一样可以按照一些条件去筛选关键词。\n除了关注大站的关键词，我们还需要关注他们的能够获取流量的页面，如 Similarweb 这里就可以看到所有能够获取自然流量的页面，都是通过哪些关键词获取的流量。\n而且还可以在点击量变化中选择“新点击量”，筛选那些最近才获得流量的页面。从这些页面，也可以发现一些新的需求关键词。\n举个例子，这个生日排队邀请函模板页面就获取到了很多新流量。不过这个词本身不新，可能是之前他们这个页面没有拿到排名，最近拿到排名了。\n谷歌一搜索，看到的确是\u0000\u0000排到了第一名。但是你仔细看会发现，这个词触发了谷歌商品搜索界面。明明是虚拟产品，怎么也会触发谷歌的这个商品搜索界面呢？\n很有可能是 Canva 发现这个词被谷歌认定是商品搜索相关词，于是就给自己的页面增加了商品的结构化数据或者在页面增加商品价格信息，让谷歌识别到了这是商品页面。\n具体什么情况，算是家庭作业，大家可以去研究一下。\n现在讲第三种挖掘需求关键词的方法。直接利用谷歌等搜索引擎的下拉推荐搜索词。\n比如在谷歌搜索 Birthday，你加一个空格之后，就会出现很多以 Birthday 开头的相关关键词。谷歌放出来的这些词，就是大家经常搜索的关键词。\n现在讲第四种挖掘需求关键词的方法，把以上三种方法组合起来使用。\n在谷歌随便搜索某个关键词，一般排到前三的都是 SEO 做的比较好的网站。\n点开这些网站，去 Similarweb 或者 semrush 继续研究这个网站，找出这个网站的更多关键词。\n有了关键词，又可以回到谷歌，继续找到三个做的比较好的网站。\n这样反反复复循环，就像是在流量的海洋里冲浪，看多了，你绝对能够得到升华。\n举例，你搜搜 qr code generator，就找到了\nqr-code-generator.com\n，这个网站月访问量 660 万，很大了。而且，最终能够向用户收钱，很香。\n一边靠大量的免费搜索流量，一边还投广告，说明这个生意很赚钱。\n最近 12 个月，这个网站花了 730 万美元的广告费，这种几乎没啥成本，ROI 应该会很高的，我们先按照最极端的，只赚回广告费来计算。790 万的访问量能够带回来 730 万收入，也就是大约 1 个访问量 1 美元。\n那么他每个月有 660 万的免费流量，即使每个访问量只赚 0.1 美元，也能赚 66 万美元。\n而实际上 ROI 肯定更高，也即是 790 万的访问量可能赚一千多万美元。那么 660 万的免费流量，是不是也能赚回几百万美元呢？\n没人能想到不起眼的二维码生成器，这么赚钱吧。\n继续去看这个关键词的付费流量，我们去看看买量第一名 qrfy.com 的数据。\n这个网站最近 12 个月，花了 1530 万美元广告费。没有哪个傻子会在不赚钱的情况下持续不断的投广告。答案只有一个，能够赚回来。\n所以，这又引出了第五种挖掘需求的方法，我们去看那些大量在投广告的关键词，就能够找到财富密码。\n方法是在 Similarweb 的关键词浏览工具 -> 竞争对手页面，输入关键词，选择付费流量，看看正在投广告的网站。再去看看这个网站花了多少广告费，都花在哪些关键词里。\n这是最直接的可以抄作业的方式，因为别人在一直投广告，说明就是一直在赚钱的需求。\n第六种挖掘需求的方法看上面的分享，这也是一种直接可以抄作业的方式，从流量变现的角度，找出那些正在赚钱的网站，分析他们的需求。\n实际还有很多挖需求的方法，用到的工具就是上面提到的这些功能，组合起来使用，举一反三，就能够发现更多的方法。\n今天的哥飞小课堂就到这里了，整整 2 个小时，很精彩。",
    "scraped_at": "2025-09-03T15:14:06.560031",
    "original_title": "挖掘需求的方法（上）",
    "date": "2024-08-02"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240803",
    "title": "如何锻炼 SEO 思维能力",
    "description": "日期：2024-08-03",
    "content": "日期：2024-08-03\n分享 Ahrefs 的一个公开页面，里面列出来了一个流量排行榜，和两个趋势变化榜，今天带大家看看流量增长趋势榜。\nhttps://ahrefs.com/top#trending\n第一名 TG 不用说了，第二名 mayoclinic.org点开看一下，哥飞一下就看到了这一排字母顺序的入口，我就知道，这个网站绝对不简单。看下流量，果然不简单，月访问量 1.24 亿，85%流量来自于自然搜索。\n为什么在首页看到 A-Z 的入口就觉得不简单呢？因为只有很注重 SEO 的网站，才会有这个觉悟，要把这样的入口放出来。\n一个产品经理学 10 年的产品课，也没人告诉你要有这样的入口。\n这个入口即是给别人看的，但更主要是给搜索引擎爬虫看的。\n看左侧，搜索关键词里，只有 21%是品牌词，剩下 79%都是各类需求关键词。\n看右侧，每一个关键词的流量占比都不高，说明这个网站有大量关键词能够获取流量。\n6 月，总共有 860 万个网页通过 176 万个关键词获取到了 1 亿的搜索流量。\n排名靠前的关键词，一个关键词就能够带来 30 多万的月访问量，算下来一年 400 万访问量肯定是有的。\n拿 calorie calculator 这个关键词来说，6 月有 287 万搜索量。\n排名第一的 calculator.net每周能够拿下 33 万搜索流量。\n第二名就是 mayoclinic.org，每周拿下 7 万，4 周大约是 28 万，不过 4 周不一定等于 一个月，所以 similarweb 显示 6 月拿下了 35.7 万。\n大家会发现，我们刚才从一个网站 mayoclinic.org出发，看到了很多关键词。又从 calorie calculator 这个关键词出发，看到了很多能够拿到流量的网页。这些网页，有些是首页，有些是内页。\n不管是首页还是内页，都可以研究一下，这个页面为什么能够拿下这个关键词的排名。尤其对于内页，我们需要仔细去研究，这个网站如果仅仅凭借一个内页就拿到了排名，我们是否可以做一个网站举全站之力拿下这个关键词的某些排名。\n大站吃肉，我们跟着喝点汤也行。\n注意，我会反复提及几个原则：\n举全站之力拿下某个关键词的排名\n分门别类罗列\n一个关键词一个页面\nhttps://www.mayoclinic.org/disease-conditions/index?letter=A\nhttps://www.mayoclinic.org/disease-conditions/index?letter=C\n...\nhttps://www.mayoclinic.org/disease-conditions/index?letter=Z\n这种页面，作用是索引页，而不是排名页，索引列出来的，才是排名页。\n也就是这些 A 到 Z 的页面，目的仅仅是把我们需要拿去排名的页面给列出来，方便谷歌的爬虫来爬取我们的网站的排名页面。\n这里涉及到怎么做海量页面 SEO，可以看我们 630 深圳大会时，彪哥的分享视频\nhttps://new.web.cafe/tutorial/detail/82ea980d818446bfbee3daea735126ea\n回到刚才的 mayoclinic.org 网站的流量页面，可以看到，6 月有一个页面带来了 69 万的访问量，主要关键词就是 calorie calculator。\n那你可能就奇怪了，刚才不是说这个关键词带来了35.7 万吗？怎么又变成了 69 万？\n我们点击“所有关键词”，展开一个新的表格就能\u0000够发现，原来一个页面，能够覆盖到多个关键词，排名第一的关键词的确是 35.7 万。剩下还有很多关键词，加起来又有 34 万，所以总共 69 万。\n那么问题又来了，哥飞你不是说“一个关键词一个页面”原则吗？这个页面明明有多个关键词，不符合你说的原则呀\n这是很多朋友有疑问的点。答案是，因为同一个关键词，不同的人有不同的说法，而谷歌能够准确识别到不同的说法，其实是同一个意思，同一个需求，所以会给出同一个页面的结果。\n这同样是符合一个关键词一个页面原则的，这个页面并没有写其他内容，而是围绕这“calorie calculator” 做文章。\n看截图就会发现，单数 calorie 复数 calories 都有覆盖到。而 maintenance calorie calculator 意思是维持一定卡路里所需计算器的意思，跟卡路里计算器是同一个需求。\n总结就是，你为某个需求做了一个页面，在这个页面其实可用覆盖同一个需求的多种不同说法。\n那么对于我们来讲，其实也可以避开这个需求的大多数人会用的说法，找一个更少人用的说法，专门去优化这个关键词，也不是不能拿到排名和曝光的。\n看上面的三张截图，分别是同一个需求的三个不同的说法，前四个谷歌搜索结果其实并不完全一样。\nhttps://www.calculator.net/calorie-calculator.html\n稳稳拿下来了第一名，但是二三四名就各不一样了。\n好了，今晚的哥飞小课堂就到这里了。我们总结一下：\n先根据 Ahrefs 提供的趋势排名榜，找到一些值得研究的网站。\n然后，去看这些网站的流量数据、关键词数据、页面数据。\n再拿一些关键词来研究，找到更多的网站，去研究这些网站怎么获取的流量。\n通过这些网站，我们又能够得到更多的关键词。\n周而复始，你看过的 SEO 世界流量数据就会越来越多，能够很好的锻炼你的 SEO 思维能力。\n最后还讲了三个原则，用一句话串起来就是：\n举全站之力优化一个关键词，就需要坚持一个关键词一个页面原则，布局核心关键词下的很多细分关键词，然后在页面里分门别类罗列出来。",
    "scraped_at": "2025-09-03T15:14:08.316322",
    "original_title": "如何锻炼 SEO 思维能力",
    "date": "2024-08-03"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240804",
    "title": "内容型工具站的页面结构",
    "description": "日期：2024-08-04",
    "content": "日期：2024-08-04\n当你看多网站之后，很多网站你只要看一眼，就能够猜到这些网站主要靠 SEO 从搜索引擎获取流量。\ngrowjo.com 就是这样一个典型的网站，现在哥飞考考大家，打开这个网站，不用任何流量查询工具，只是看首页的内容，看看哪些是为了 SEO 而做的？\n我们实际看一下 growjo.com 在 Similarweb 上的数据，主要流量来自于欧美等发达国家，流量值钱。\n76%流量来自于自然搜索，20% 来自于直接访问，这两项加起来就是 96%了，所以可以认为这就是一个主要靠 SEO 从搜索引擎获取流量的网站。\n从能够拿到流量的\u0000关键词来看，目前主要满足的需求关键词是“XXX Revenue”，也就是有很多用户在谷歌搜索 XXX 产品的收入，XXX 公司的收入，这个网站通过一些数据页面满足了这些搜索意图。\n再看页面，主要获取流量的是 /company/xxx 页面，这些页面上有 xxx 公司的介绍、收入、员工、竞品等信息。\n还有些城市页面 /city/xxx 也拿到了流量，这是把公司信息，按照所在城市分组了，列出来了该城市下的公司列表。满足的是用户在谷歌搜索 xxx 地方的初创公司等搜索需求。\n再然后是行业页面 /industry/xxx，把公司按照行业划分，列出每一个行业下的公司信息。\n还有两类页面是按照州划分的 /state/xxx 和公司人员信息页面 /employee/xxx。\n梳理一下之后，我们就会发现，growjo.com 这个网站的最小信息单位是公司，做一个 /company/ 页面模板，再收集好公司信息存到数据库里去，就可以生成很多的公司页面。\n公司下面目前只有一层信息，是雇员 /employee/ 页面。\n而 /state/、/city/ 和 /industry/ 都是公司的属性，信息可以存储在公司表里，然后使用同一个页面模板，也就是公司\u0000\u0000列表页面，就可以把这几类页面给渲染出来。\n哥飞想给这个网站提一个建议，有时候公司名称和产品名称并不相同，最好可以增加产品信息数据，就放在公司的下一级，跟雇员信息是同级的关系。\n举例 OpenAI 公司的产品有 ChatGPT 和 GPT 模型，有人可能会想知道 ChatGPT 的收入信息。\n目前这个网站通过把 ChatGPT 当做一家公司名称，勉强能够覆盖到相关搜索词，但是这样的实现不优雅。\nhttps://growjo.com/company/OpenAI\nhttps://growjo.com/company/ChatGPT\n梳理好这个网站的页面结构之后，我们再回头看看首页，是不是就是很简单直接把所有的页面入口在首页列出来就行了。\n这里有什么好处呢？谷歌是懂语义分析的，你把这些列出来了，它就知道你这个网站主要是用来做什么的，就能够在用户搜索相关关键词时，给你的网站曝光机会。\n你会发现，梳理清除之后，这套方法我们可以用在很多内容查询类网站上。\n甚至于，内容型工具站，也可以用这套方法：\n选定最小数据单元，做数据详情页面\n按照各种属性维度列出最小数据单元，也就是做列表页面，上面很多链接都是指向到最小单元详情页面；\n如果有必要，给最小数据单元增加下级数据，为每一个下级数据做一个详情页面，覆盖更细分的关键词。\n好了，今天的哥飞小课堂就到这里了，告诉大家了，如何简单分析一个网站的页面架构。多多学习别人的架构，就能够更好的为我们的网站做好页面架构。\n如果你立项做一个新项目，那么第一件事，就是去调研需求关键词，然后对这些关键词进行分类\u0000\u0000，做好页面架构规划。\n你不一定需要第一版全部页面都做完，你有了规划之后，后面只需要按部就班的不断上页面就行。",
    "scraped_at": "2025-09-03T15:14:09.801200",
    "original_title": "内容型工具站的页面结构",
    "date": "2024-08-04"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240805",
    "title": "如何使用模型批量上站",
    "description": "日期：2024-08-05",
    "content": "日期：2024-08-05\n今天的哥飞小课堂很短，但价值很大：\n大家可以把 Replicate.com、Fal.ai、HuggingFace.co 上的模型都抓取下来，把功能整理出来。\n然后再抓取所有 AI 相关的需求关键词。\n然后就是一个一个关键词，都拿去让 GPT 分析，有哪些模型可以解决这个需求。\n最后，你就得到了需求关键词与模型的对应关系表。\n再然后，你就可以批量上站了。\n以上方法，如果你去执行了，大概率可以赚取。\n早上的那堂写得很短小，但其实价值很大，估计get到的人不多，希望大家回看一下，多多思考，多多实践。",
    "scraped_at": "2025-09-03T15:14:11.204536",
    "original_title": "如何使用模型批量上站",
    "date": "2024-08-05"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240806",
    "title": "如何覆盖小词，如何布局页面结构",
    "description": "日期：2024-08-06",
    "content": "日期：2024-08-06\n给大家看两个例子，这个网站是怎么覆盖小词的。他为每一个词都做了一个功能页面，打开就是落地页，也是功能页。\nhttps://online-video-cutter.com/remove-logo\nhttps://online-video-cutter.com/add-image-to-video\n这个网站月访问量是 600 万，60%流量来自于自然搜索，也就是每个月有 360 万左右从搜索引擎免费获得的。\n用 15 万个页面，覆盖了 2.6 万个关键词。各种各样的小词都覆盖到了，如“increase volume of video”，这是提高视频音量需求。\n大家可以学习这个站的页面布局，为了拿到一个关键词的搜索量，每个页面都放了哪些内容。\nhttps://online-video-cutter.com/volume\n最重要一点，大家会发现，拿流量的页面，跟美丑其实没多大关系，直接朴实无华的，放很多文字介绍也是可以的，只要简单排班一下即可。\n学习这些页面结构，丰富我们自己网站内容。好酒也怕巷子深，放在 SEO 领域，就是好功能也怕你不写文字介绍。谷歌不怕你文字多，就怕你没文字。没文字，我怎么知道你的这个页面到底是关于什么内容的呢？\n再一个，以后 AI 搜索引擎越来越多，他们怎么判断要不要推荐你的网页？还不是靠你的网页写的内容来判断。",
    "scraped_at": "2025-09-03T15:14:12.593880",
    "original_title": "如何覆盖小词，如何布局页面结构",
    "date": "2024-08-06"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240807",
    "title": "如何快速上站，如何优化页面收录数",
    "description": "日期：2024-08-07",
    "content": "日期：2024-08-07\n先给大家讲讲故事，去年 9 月份到今年 3 月，我受邀到生财有术社群当了几次出海航海教练。今天的案例网站\ndescribepicture.org\n就是去年 12 月航海时，其中一名学员 Andy Leo 做出来的。在航海的第三天，Andy Leo 经过朋友的提示，找到了解析图片这个需求，然后在 1 月 9 日注册了域名，1 月 13 日上线了第一版。之后故事就开始了。\n这就是 1 月 13 日上线的第一版，为什么我上午看一眼就说是我教出来的人做的网站呢？因为这个模板我太熟悉了，是一个 Astro 的博客模板，我当时在我们社群，也在航海群里将了，这是一个 SEO 友好的模板。在这里可以一键部署：\nhttps://vercel.com/templates/astro/astro-paper\n，这里有一个演示站：\nhttps://astro-paper.pages.dev/\n。\n这是模板原样，Andy Leo 修改了红色框起来的部分，其他地方没动，就快速上线了一个网站了。\n为什么当时 Andy Leo 听朋友提到了这个需求，就决定做这个需求呢？因为做了以下事情和判断：\n找到能够准确描述这个需求的相关关键词；\n通过谷歌趋势去看这些需求关键词的趋势，发现是长期需求，并且有一定搜索量；\n通过\nhttps://ahrefs.com/keyword-difficulty\n判断了关键词优化难度，当时属于不难的词。（以上步骤，咱们社群里都讲过了，今天不展开说明了）。\n基于以上判断，Andy Leo 就直接用关键词注册了域名 describepicture.org，然后快速上线网站。\n做好了站内基本的优化之后，就开始提交外链了，V2EX、Hacker News 等所有能提交的都提交了一遍。\n航海时间是 3 周，结果航海还没结束，他的网站就进入了谷歌搜索十几名。\n上面可以看到，其实目前他的外链数量并不多，外链网站才 57 个。这里大家要有信心，拿下关键词排名，其实需要的外链并不用特别多。也就是说，高外链这件事情，并没有大家想象中的那么难。\n有一个很好的外链技巧，就是用你想做的关键词，去谷歌搜索，找到那些你的竞品网站，看看他们有哪些外链，既然他们能够获取到这些外链，你也可以的，你也去提交。\n接下来先给大家按照月份看看每个月的关键词排名和点击率如何变化。这是 1 月份的，网站上线半个月的数据，可以看到，有好多关键词已经在十几名开外了。\n2 月份，可以明显看到，排名前进了好多，有些关键词进入谷歌首页了，有些关键词进入第二页了。\n进入到 3 月，大家可以看到，点击率直接翻倍了，有的还翻了好几倍。原因就是排名进一步前进。\n有些关键词进入了前三，有些是前五，截图中的关键词都进入了首页。\n4 月，排名继续上升，有些显示排名 1.4，其实可以认为就是在某些国家拿到了第一名，在别的国家是第二三名，综合平均一下，就是 1.4 名。\n后面的排名就不看了，基本都是类似，反正就是不断上升，点击率越来越高，从谷歌获取的点击数也越来越多。\n打开网站看一眼，广告还是有点多的，这个网站可以免费试用，还可以付费购买更多次数和更好的模型。我问过 Andy Leo ，目前每个月广告收入多少，他说 200 美元左右。那么基于我的判断，其实完全可以关闭广告了，算下来，每天六七美元左右，还不如好好提示体验，提高付费转化率，每天的付费收入都可以增加不少。\n这个网站，目前只做了英文，如果做好一下几个改进，那么月入万刀都是有可能的：\n增加外链，增加内页，巩固目前各个关键词在各个国家的排名，争取拿下第一名；\n增加多语言，获取更多国家的流量\n图片生成文字，其实还有其他更多说法，可以考虑覆盖更多说法，获取更多关键词流量；\n增加图片相关的更多功能，如目前图片生成文字之后，还可以用文字帮助用户生成图片，或者生成视频，也就是文生图、文生视频，图生图，图生视频，都可以探索一下。\n从 GSC 后台可以看到，其实这个网站被收录的网页并不多，才 19 个。还有一些未收录的页面，下面给大家分析一下，未被收录的页面要怎么处理。\n先看“备用网页（有适当的规范标记）”，我们打开第一个网址\nhttps://describepicture.org/?utm_source=aitoolreport.beehiiv.com&utm_medium=newsletter&utm_campaign=the-fcc-to-make-ai-generated-robocalls-illegal\n，这个地址其实就是首页，只不过加了一些流量来源参数，那么正确的做法就是在 Canonical 中设置好，规范网页是什么，这一点，网站是做好了的。\n再看这个网址，区别是有没有最后的斜杠。打开的是：\nhttps://describepicture.org/posts/describe-picture-v1.0\n，而 Canonical 标记的是有斜杠的：\nhttps://describepicture.org/posts/describe-picture-v1.0/\n，而打开带斜杠的网址，也是可以打开的。这就有问题了，你两个网址打开了同一个网页。正确做法是，保持 Canonical 的标记，然后在服务器里或者代码里把没斜杠的地址通过 301 跳转到有斜杠的地址。\n还有重要的一点，在网站的任何地方，当你要给这个页面加外链时，都写成带斜杠的规范化地址。\n上面写的比较复杂，但大家理解一下，其实不难。\n再看“网页会自动重定向”的相关网页，第一个是 http 自动跳转到 https，这是在我们预期内的，这种可以不用处理。\n但是第二个网址，就有问题了，谷歌发现你的网站出现了这个不带斜杠的网址\nhttps://describepicture.org/image-to-prompt\n，打开之后会自动跳转到带斜杠的网址去。\n可以看到 Canonical 写的是没问题，那为什么谷歌还会报那个错误呢？\n答案就在网站代码里，既然你的规范化网址是带了斜杠的，那么你写的链接就要写带斜杠的版本。否则，谷歌就会根据你写的链接，抓取到不带斜杠的网址，最后发现这个网址会重定向到另一个网址，于是谷歌在 GSC 后台提醒你，这里有重定向问题。这个解决办法也简单，把你代码里写的不带斜杠的网址改成带斜杠就行。\n再看 404 页面，这就简单了，要么是站长，要么是别的用户，写网址时，把 url 写成了大写的，导致页面打不开，404 了。这个可以向谷歌申请删除。\n继续看，这也是比较典型的问题，一般出现在分页列表里。如果没有处理好，就容易出现这个问题，谷歌选择的规范网页与站长指定的不一样。\n上面两个页面，大家可以看到，除了网址不一样，整个页面内容是完全一样的。但是，你完全一样的页\u0000\u0000面，却用Canonical 标记了两个不一样的规范网址：\nhttps://describepicture.org/tags/release/\n，\nhttps://describepicture.org/tags/release/1/\n,最终谷歌根据自己的算法，选择了正确的网址：\nhttps://describepicture.org/tags/release/\n，同时告诉你，下面后者网址有问题。\n这种分页一般我们称之为索引页，用来告诉谷歌，这个页面列出来了很多其他页面，你快来抓取。索引页的用途就是列出更多的其他用于排名的内页（称为排名页），或者列出其他索引页。\n这种页面，一般还会有翻页，也就是多个页面，除了列出来的内页不一样，其他都是一样的，包括网页标题描述也是一样的。\n这种情况要怎么处理呢？哥飞通常会这样处理：\n确定第一页的 url，拿刚才的例子举例，第一页是不带页码的：\nhttps://describepicture.org/tags/release/\n第一页统一用规范的网址，而不用带页码 1 的网址，也就是\nhttps://describepicture.org/tags/release/\n，而不是\nhttps://describepicture.org/tags/release/1/\n不管页码多少，统一所有页面的 Canonical 都设置为第一页不带页面的 url，举例，第二页\nhttps://describepicture.org/tags/release/2/\n，的 Canonical 也设置为：\nhttps://describepicture.org/tags/release/\n从第二页开始，页面标题里加上页面，如“第 2 页”\n拿 Woy.ai 的 Discover 页面举例，第一页一定是\nhttps://woy.ai/discover\n而不是\nhttps://woy.ai/discover/1\n.\n甚至当用户输入\nhttps://woy.ai/discover/1\n时，会直接用 308 跳转到\nhttps://woy.ai/discover\n。\n注意看标题的变化。不过我刚发现第 2 页的 Canonical 没设置对，最好设置为\nhttps://woy.ai/discover\n。\n其他的如“已抓取-尚未编入索引”和“已发现-尚未编入索引”，一般就是谷歌认为你这个页面没啥值得收录的内容，换句话说，内容质量不高。我们要做的是改进页面内容，或者本来就是没必要被收录的页面，那么直接设置 noindex 就好了。\n核心页面指标，这里谷歌给你提示，欠佳和需要改进的页面，需要引起重视。能改则改，尽量优化好。因为这里的\u0000指标也会影响排名的。\n今天的哥飞小课堂就结束了。\n提问：\nCanonical 的网址末尾要加 / 吗？\n只要统一就好了，一般情况下，如果是页面不加，如果是目录就加。\n下面是第二个小课堂分享\nsynthesia.app 2018 年注册的域名，一个在线钢琴教程，7 月强势增长 3808%，进入了 Stripe 入站流量第 10 名。\n这个网站的流量，7 月并没有增长多少，甚至还是下降趋势，那么只有一种可能，之前用的别的收款平台，7 月切到了 Stripe，才有可能有那么大的增长幅度。\nStripe 7 月入站流量排名榜前 100 名网站列表\nhttps://new.web.cafe/topic/uqzVwMWnrRpHcSfNrXWGPw\n，哥飞 8 月 7 日 22 点首发，Similarweb 统计的 2024 年 7 月 Checkout.Stripe.com 的入站流量排行榜前 100 个网站列表，分享给大家了。\ndragganaitool.com 就是一个比较典型的这类网站，大家打开首页会发现介绍的是 DragGan AI Tool 这个 AI 图片编辑工具。但是如果去看 Sitemap 就会发现，这个网站拓展了好多新页面。\n看他拿到点击的关键词列表和内页就知道，他做了很多页面了。\n但是因为当初他的首页做的是 DragGan AI Tool 这个词，所以后面就只能一直用这个词。然后在导航栏增加了很多其他页面的入口。",
    "scraped_at": "2025-09-03T15:14:14.104003",
    "original_title": "如何快速上站，如何优化页面收录数",
    "date": "2024-08-07"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240809",
    "title": "如何预估网站收入",
    "description": "日期：2024-08-09",
    "content": "日期：2024-08-09\n今天的哥飞小课堂，跟大家分享下我最近使用的一个预估网站收入的方法，不一定准确，也是仅供参考。\n这个方法只能用在那些正在投放付费搜索广告的网站上。大概的原理是，看他花了多少钱投广告，带来了多少流量。\n既然他愿意长期花这么多钱去投广告来带来这些流量，那么我们可以认为投放广告至少是能回本的。\n然后，我们也可以简单认为，从自然搜索过来的流量，也是精准流量，也能够产生差不多的收益。\n我们拿 ChatPDF 来测试下，过去 12 个月，自然搜索流量占比 35.74%，访问量是 24.5M。付费搜索流量占比 11.77%，访问量是 8.1M。\n过去 12 个月，花了 3.2M 广告费。可以简单认为，8.1M 的访问量，至少可以带回来 3.2M 的收入，这样就刚好回本。那么自然搜索带来的 24.5M 流量，大概\u0000价值 3.2x(24.5/8.1) = 9.68M。\n实际这个估算准不准呢？我们去找 ChatPDF 创始人的推特看看。\n有个小问题，ChatPDF 的创始人@xathis 好像没公布多 MRR。那我们就按照他广告能够回本来推算吧，广告投放部分刚好回本，自然搜索部分纯赚，过去 12 个月的收入是 9.68M，差不多 1 千万美元。\n不过这里有点小问题，自然流量真的带来那么多收入吗？我们无法知道实际的转化率，即使按照打五折算，过去 12 个月也有 500 万美元的收入。\n所以收入规模我们按照 5M~10M 之间估算吧，取个中间值，750 万美元。\n这里还有一个问题，这些产品都是订阅制的，老用户的收入可以不断累计，不断有新增的订阅。计算 ROI ，不能只看广告投放当月的收入，还需要看续订率，看未来几个月的收入。但至少我们可以简单的认为，用户 LTV 可以覆盖广告成本。\n所以我们可以算一下，每一个访问量的 LTV，这个计算不正规，正确的算法是按照注册用户计算哈，但假如注册率是稳定的，那么也可以去算访问量的 LTV。\n8.1M 访问量，花了 3.2M 的广告费，那么每一个访问量的成本是 0.39 美金。我们前面假设过他能够回本，那么也就是说，平均每个访问量至少价值 0.39 美金。\n事实上，之前我自己产品，我算过，一个新访问量的价值大概是 0.1 美金，也就是说，他的 0.39 美金是有可能的。",
    "scraped_at": "2025-09-03T15:14:15.484922",
    "original_title": "如何预估网站收入",
    "date": "2024-08-09"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240815",
    "title": "图片类关键词分析",
    "description": "日期：2024-08-15",
    "content": "日期：2024-08-15\n今天跟大家聊聊一些图片类关键词的数据怎么看，怎么判断能不能做，要不要做。\n我们拿 sky background 这个关键词来说，PC 端使用谷歌搜索，会发现谷歌能够识别到这是图片搜索需求，所以直接出现了“images”模块，直接给你显示了一些图片。\n这时候大部分人可能直接就会点击图片列表，进入谷歌图片搜索了。少部分人会点击下面的网站。\n那我们就来判断一下，这个关键词，点击下面网站的比例大概是多少。换句话说，我们看一看，假如你做了一个网站，拿到了这个词的第一名，能够获取多少流量。\n先在 Similarweb 看这个关键词的概况，Similarweb 估算，这个词的月曝光量在 109.9K，月点击量在 51.9K。其中排名第一的 pexels.com拿到了 24.7K 点击量。\n注意，这里的 24.7K 可能包含了 pexels.com多个页面拿到的点击量。如果只看\nhttps://www.pexels.com/search/sky%20background/\n这个页面，会发现从 sky background 这个关键词只拿到了 6.8K 的点击。\n现在，我们就可以计算一下比例了，如果是在“Images”模块下的第一名，能够拿到曝光量中的(6.8/109.9)x100% = 6.18%。\n也就是说，你别看这个关键词每个月有 109K 的搜索量（曝光量 = 搜索量），但是即使你排到了首页，点击率也才 6.18%。\n那么这种词，如果我们要去做网站，就有点吃力不讨好了。除非你真的没别的词可以去做了，否则别选择这种词。\n所以哥飞在判断一个词是否能做时，最重要的一步是直接谷歌搜索看看搜索结果长啥样。图片类、视频类、商品类、数学公式计算类关键词等等，所有这种谷歌直接在搜索结果最前面直接把用户想要的给呈现出来的关键词，都要慎重考虑。\n如果你在 Ahrefs 查询关键词难度，会发现难度很低，只要几个外链就能够让你的网站进入首页。但其实这是 Ahrefs 的算法局限性导致的计算失误，实际上难度并没有这么低。看看搜索结果，一个个都是大站的内页。我们一个新网站，还是比较难突破这些大站的封锁，进入前三名的。\n好了，今天的小课堂就到这里了。",
    "scraped_at": "2025-09-03T15:14:16.944450",
    "original_title": "图片类关键词分析",
    "date": "2024-08-15"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240822",
    "title": "如何挖掘 APP 需求？",
    "description": "日期：2024-08-22",
    "content": "日期：2024-08-22\n今天哥飞小课堂教一个挖 APP 需求的方法。原理很简单，依然是抄作业，看哪些 APP 在投谷歌关键词广告。\n怎么看呢？打开 Similarweb，输入 App Store 的域名 apps.apple.com，在自然搜索的下面找到付费搜索，点击下面的链接，查看全部广告，就能够到达广告列表页面。\n在这个页面，你可以分桌面端和移动端分别看都有哪些 APP 在投广告。\n举例，排名第一的，投的好像比较猛，我们看到他的 APP 地址是 [apps. Apple. Com/br/app/ia-chat-inteligente-chatbot/id 6447419372](apps. Apple. Com/br/app/ia-chat-inteligente-chatbot/id 6447419372) 记住这个数字 ID 6447419372 ，自己构造一个 SensorTower 的网页地址\nhttps://app.sensortower.com/overview/6447419372\n，打开网页，得到这个 APP 在 SensorTower 的名称是 AI Chat-Ask Chatbot Assistant。为什么需要这一步呢？因为有些 APP 会时不时改名字，我们在 App Store 看到的名字，在 SensorTower 不一定能够搜索到。\n从这两张图就可以看到，的确名字不一样，但是 ID 是一样的，那就没问题了。\n接下来，你拿着 AI Chat-Ask Chatbot Assistant 这个名字，打开\nhttps://app.sensortower.com/\n首页，在右上角输入粘贴名字，就会有一个下拉的即时搜索结果。确认一下开发商，对得上，那么没问题，就是这个 APP，可以看到月下载量是 400 K，月收入 100 万刀。\n同样的方法，我们又看到了一个 APP，在 iOS App Store 里月下载量 200 万，月收入 70 万刀，在 Google Play 里月下载量 70 万，月收入 100 万。\n通过这些高收入 APP，我们就可以大概知道，哪些需求能赚钱，而且即使投广告也能赚。这些都是信号，能够指引方向，也能够增强信息。\n除了在 Similarweb 看 apps.apple.com 广告 APP，还可以看广告的关键词。这些词，有些是品牌词，有些是需求词。如果你发现有人做了一个 APP 叫做 ABC，需求关键词是 DEF，那么甚至你可以立马做一个名字叫做 DEF 的 APP。能蹭一点是一点。\n这跟我们分析网站，找到值得做的业务需求关键词，然后用关键词注册域名，做个网站的原理是一样的。\n总结一下，正在投广告的产品是风向标，可以帮助我们发现需求，分析需求加载。\n好了，今天的小课堂就到这里了。",
    "scraped_at": "2025-09-03T15:14:18.404249",
    "original_title": "如何挖掘 APP 需求？",
    "date": "2024-08-22"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240828",
    "title": "分享一个被动获取外链的方法",
    "description": "日期：2024-08-28",
    "content": "日期：2024-08-28\n看到个从老外推文学到的被动获取外链的方法。今天的哥飞小课堂，哥飞根据自己的经验补充完善如下。\n其实跟我们做导航站思路是一致的。\n在你的网站里写一些最好的 XXX 相关主题文章，里面列出 N 个 XXX 类产品，并且给出链接。其中，还可以把你自己的产品也放到列表里去。\n文章底部留一个邮箱，让别人可以联系到你。\n然后去专门优化这个页面，让这个页面至少进去谷歌搜索前两页。\n怎么优化呢？\n你可以到各个平台去发布相同的文章，文章底部留下你的原文链接。\n拿国内平台举例，你写一篇最好的中国文字生成图片 AI 工具，先发到你的网站里，后发到知乎、掘金、公众号、即刻等平台。\n这样既能够让你的品牌被更多人看到，又能够给这\u0000篇文章获得更多外链，进而得到更高排名。\n之后就守株待兔，有人做了一个新的 XXX 类产品，可能会通过邮箱联系你，请求你评测后收录他的产品。\n你就可以回复邮件说，收录可以，但你需要写一篇文章发到你的网站里，提到你的产品被我的这个列表收录了，并且给我这篇文章加一个链接。\n这种能能够被对方当做荣誉的事情，对方很愿意做的。\n然后，你的最好的 XXX 列表文章就会获得越来越多的外链。\n好，以上是用文章来做的思路，是否可以改一下，改成用导航站来做？\n专门出一些最好的 XXX 列表页面，然后让用户可以自助提交。\n好了，以上就是今天的哥飞小课堂。",
    "scraped_at": "2025-09-03T15:14:19.876888",
    "original_title": "分享一个被动获取外链的方法",
    "date": "2024-08-28"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240830",
    "title": "meme 相关关键词分析",
    "description": "日期：2024-08-30",
    "content": "日期：2024-08-30\n2024 年 3 月分享：流行热梗里也许就会有 AI 工具的需求，我不多说，大家去挖掘吧\nhttps://trending.knowyourmeme.com/trending\n。\n3 月份，我们介绍过一个 meme 解释网站\nhttps://knowyourmeme.com\n，刚才搜索某个小工具时，又搜索到了。\n给大家还原一下哥飞的探索全过程。\n第一步，出于好奇，想看看做图片尺寸放大的有哪些网站，于是在谷歌里输入 image resize，结果发现被谷歌纠正了，原来大家会搜索的是 image resizer。\n于是选择了 image resizer，敲下回车，第一个结果就是直接用这个关键词做域名的网站\nhttps://imageresizer.com/\n。\n这么一个看起来平平无奇的网站，大家猜猜 Similarweb 显示的月访问量是多少？\n揭秘网站流量之前，我们先看看相关关键词的搜索量。谷歌广告后台显示，image resizer 系列关键词，2024 年 7 月的搜索量是 274 万，平均每天 9 万。\n大家猜测的相对保守，实际 7 月访问量是 673 万，最近 12 个月累计访问量 4963 万，平均每个月 413 万。\n从流量曲线可以看到，3 月之前的月访问量其实是小于 400 万的，从 3 月开始发力，超过了 400 万，一直到 6 月都还是 400 多，到了 7 月直接就上升到了 673 万。7 月的流量暴涨，跟刚才我们看到的谷歌广告后台显示的搜索量上涨趋势是一致的。\n我们再去看\nhttps://imageresizer.com\n拿到了流量的关键词列表。可以看到这个需求，的确有不同的说法，而每一个说法，都拿下了不过的位置。\n筛选过滤里边的 Trending 这个控件，很值得使用。可以按照三种方式筛选关键词：\n1、不再流行。选定的时间段相比于上一个时间段，点击下降至少 10%。简单来说就是流量下降的\u0000\u0000关键词。\n2、点击丢失。选定的时间段没有拿到点击，但是上个阶段拿到了点击。简单说就是完全失去了排名和曝光的关键词。\n3、全新点击。选定的时间段获得了点击，但是上个时间段没有点击。简单说就是网站上的新页面，覆盖了新的关键词，拿到了点击。\n这个可以帮助我们发现新词。\n修正一下，是 clicks change 这个控件，而 trending 是其中一个选项，代表的是目前正在拿到点击的关键词。\n切换到落地页这里，也有 clicks change 控件，依然可以筛选。\n落地页选择新点击量，就可以看到这个网站上线的新页面。其中一个页面\nhttps://imageresizer.com/meme-generator/edit/another-20-trillion\n，就是我们开头说的，某个 meme 火了，他就可以快速上线一个 meme 生成器，来搞流量。\n我们拿 Another 20 Trillion meme 去谷歌搜索，可以看到第一名就是这个 meme 生成器，第二名则是我们开头说到的 meme 解释网站。\n好，现在知道\nhttps://trending.knowyourmeme.com/trending\n的用途了吧。\n找到正在流行的 meme，然后去做一个生成器，获取谷歌搜索流量。\n这些流行的 meme 还有个作用，大家可以拿去发到 Reddit 或者 Hacker news，来养号，赚 karma。\n注意看这个网站的 URL 结构：\nhttps://imageresizer.com/meme-generator/\n是 meme 生成器；\nhttps://imageresizer.com/meme-generator/edit/distracted-boyfriend\n是某一个 meme 的生成器。\n也就是说，任何一个有人搜索的 meme，他都可以快速基于生成器，只做一个落地页，来承接这个 meme 的搜索流量。",
    "scraped_at": "2025-09-03T15:14:21.288153",
    "original_title": "meme 相关关键词分析",
    "date": "2024-08-30"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240905",
    "title": "分析一个年收入 4000 万美金的小网站",
    "description": "日期：2024-09-15",
    "content": "日期：2024-09-15\n今天给大家分享一个家年收入 4000 万美金的小网站，就上面这个截图，任谁也看不出来他一年能赚这么多是吧。\nhttps://companieslogo.com/\n大家可以先打开这个网站看看，研究一下，他到底怎么赚钱的。\n先说下收入数据来源，是 LinkCloud 的 JK 老师在 8.24 的线下分享时提到的数据。我刚才算了一下，假如按照大家都购买 199 美元的套餐计算，并且每一位客户都会购买 12 个月，那么需要 16750 个客户，才能达到 4000 万美元的年收入。我刚才在谷歌搜索了一下，没有找到 4000 万收入的信源，所以又去问了 JK 老师，等他回复中。\n我们先忽略具体的收入数据，先分析一下网站流量数据，以及卖点是什么，什么客户\u0000会愿意购买。说这个网站之前，得先说这家公司的另一个网站\nhttps://companiesmarketcap.com\n。\n这个网站的年访问量是 3360 万，7 月访问量是 366 万。\n主要流量来自于自然搜索，占比 60%。用户主要搜索某某公司市值时能够找到这个网站。如搜索 nvidia market cap，结果前面是谷歌直接给出数据和相关新闻，这两部分之后，第一个网页就是\nhttps://companiesmarketcap.com/nvidia/marketcap/\n。\n在显示公司市值时，就需要用到相关公司的 Logo。而\nhttps://companiesmarketcap.com\n在网站底部说明了，Logo 来自于\nhttps://companieslogo.com\n。\n而\nhttps://companieslogo.com\n提供的主要服务，就是卖各大公司的高清 Logo API，注意他不是提供 Logo 设计服务，仅仅是提供他们收集整理的 PNG 和 SVG 格式的 Logo 文件。通过 API 可以列表形式下载全部 Logo，也可以用公司域名或者股票代码搜索 Logo。\n客户是谁呢？是哪些各种券商或者一些机构。他们会定期出各种研究报告，在报告里需要用到公司 Logo，但是收集\u0000\u0000整理很麻烦，于是就去购买这个 Logo API 服务。\n我们现在回过头来看看这个网站的流量，会发现访问量特别小，最近 12 月总的访问量才 118 万，而 7 月访问量是 8 万多。\n具体的收入数据来源，我还在等 JK 老师的回复。不过我们可以先大概估算一下，去重后的访客才不到 5 万，如果要积累下来一年 1.67 万个客户，那么转化率需要 33%。这个转化率太恐怖了，不太可能达到的数字。\n忽略收入数据，这个网站对我们有什么启发呢？他的卖点其实是方便快捷的 API，帮助那些不想浪费时间的人节省时间，顺便赚他们的钱。那么还有其他什么服务，也是能够帮助别人节省时间的呢？我们去收集整理这些资料，然后一份资料卖个多个人。\n举例来说，卖 Leads 就是这样的服务，你到处收集整理的邮箱等联系方式，就会有想要来购买。广州的探迹 tungee.com 就是这么一家卖外贸线索起家的公司，不过现在他们不仅仅只卖线索，已经是一家 SaaS 公司了。\n关于今天分享的\nhttps://companieslogo.com\n年收入 4000 万美金的数据，跟 JK 核对了一下，来自于他在纽约的投资人朋友说的。\n这个网站卖的是 API，所以用户量不太容易在 Similarweb 上体现出来。不过，即使这个金额打个超级打折扣，一年 40 万美金，也很多了。卖水这件事情，还是很值得做的。",
    "scraped_at": "2025-09-03T15:14:22.679459",
    "original_title": "分析一个年收入 4000 万美金的小网站",
    "date": "2024-09-15"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240913",
    "title": "如何使用程序化 SEO 生成海量页面获取流量",
    "description": "日期：2024-09-13",
    "content": "日期：2024-09-13\n今天的哥飞小课堂，用几个案例来讲解程序化 SEO 生成海量页面获取流量的方式。\n先看流量，Similarweb 上面几个网站的最近 12 个月访问量，最大的\ndistance. To\n访问量 1297 万。\n这些网站解决的需求是什么呢？其实是特别小的一个需求，甲地到乙地的距离是多少。如阿斯拜疆到德国距离是多少。Distance from Azerbaijan to Germany\n这样两个地点，两两组合，就会有 N 多问题。仅仅从国家层面，全球 200 多个国家，就有四万多个问题了。再到省市区不同级别的地区，各自两两组合，几百万个问题都有了。\n甚至离开地球，在宇宙尺度，也是有人会问问题的。\n每一个地区，到另一个地区，都会有人好奇，距离是多少。\n我们拿\ndistance.to\n这个网站来说，页面很好做，主体部分是地图，标记一下两个地区，连上线，再在地图上方浮层显示一些文字信息，整个页面就做好了。\nhttps://www.distance.to/Germany/Azerbaijan\n.\n谷歌收录了\ndistance.to\n129 万个页面。注意，并不是说这个网站服务器里有 129 万个 html 文件。这样的页面，都是统一的模板页面，只需要从数据库里取出地理位置数据，计算一下距离，然后把数据填充到模板里，每次用户访问时动态渲染出来就好了。\n从前面的 site 结果看到，这个网站还做了多语言支持，并且用的是子域名的方式实现的。我们之前提到的多语言方式都是用子目录来实现的。两种方法都可以，但是哥飞建议，你一个新网站刚上线时，最好用子目录方式来实现，这样冷启动的成本更低。\n即使是 canvas 这样的大站，也是用的子目录形式实现的多语言。\nhttps://www.canva.com/ai-image-generator/\nhttps://www.canva.com/ja_jp/ai-image-generator/\nhttps://www.canva.com/fr_fr/generateur-image-ia/\n所以不要因为我们今天分享了 distance.to，就觉得子域名形式更好。\n两个地点之间，其实有很多需求，距离只是其中一个特别小的需求，但是你盯住这个这么小的需求，也能做出百万月访问量的网站。原因就是这类需求都可以做出海量页面。虽然每一个页面可能每一天只有几个几十个访问量，但是所有页面加起来，访问量就多了。\n两地之间，更值钱的需求是交通，飞机、公路、轮船、铁路等等各种交通方式，直接卖票就是旅游网站的赚钱方式之一。\n不知道大家发现没有，今天分享的 distance.to 生成页面的方式，跟之前大家理解的海量页面方式还不太一样。尤其是有了 AI 的加持后，大家以为的海量页面生成方式，就是让 AI 去回答海量的问题。但其实，不用 AI，也可以生成海量页面。\n只需要你的数据库里有结构化的数据，就可以做成各种各样的模板，生成各种各样的页面。每一个页面都是盯着某一个真会有人搜索的需求去创建的。\n结构化数据，这里划重点。如果你存储的都是纯文本数据，那么没有用的，一定要拆成结构化的数据，才能够按需组合，任意组合，生成各种各样的页面。\n阿彪谈谈海量 SEO 页面以及最近的一些收获\nhttps://new.web.cafe/tutorial/detail/82ea980d818446bfbee3daea735126ea\n听完今天的小课堂，现在大家再去听彪哥将的海量页面 SEO 经验，可能就会更能听懂，更有收获了。\n彪哥在演讲中给我们分享了一个找人找公司的网站，里边就有大量的页面，从人的维度，从公司的维度，从地点的维度，都能够生成海量页面。\n这些页面是随便乱生成的吗？\n不是的，是因为有人会这样搜索，所以才去生成相关的页面，期望我们的页面能够出现在真实用户搜索结果里，从而获得访问量。\n之前有一次小课堂，哥飞分享的\ngrowjo.com\n，也是这类网站。\n好，既然数据这么重要，那么数据怎么来呢？当然是从互联网中来。但是，没有哪个地方刚好就有你需要的一模一样的数据。所以一般都是你自己先分析好需求，规划好数据结构，然后按照需要，去找哪里可能有相关数据，你用爬虫去抓取，然后解析结构化数据。不过，这里注意一下，非公开数据，有版权数据，不要去抓取。\n有时候一个地方不会有你需要的全部数据，你还需要去多个地方抓取，最后整合数据。\n一般，如果我们去外部分享，提到了海量页面，一定会有人杠，你这不是垃圾网站吗？\n我的回答是，只要能够帮助一部分人群解决某些特定需求，就不是垃圾网站。\n他们会这么说，只是因为这个网站不是他的。吃不到的葡萄，都说是酸的。\n谷歌有一个反垃圾机制，你不提供价值的网站，很难获取到流量了。能够拿到流量的网站，尤其是拿到大流量的网站，一定是能够给一部分人群提供价值的。\n新站搞海量页面会分散权重吗？最后每个页面排名都很低吗？恰恰相反，因为有了海量有价值的页面的支撑，才会让你的新网站权重更高。注意，一定是有价值的网页。就是这些你上线的网页，需要能够在谷歌拿到排名，拿到曝光，获取到点击。\n之前 6 月北京线下聚会时，Henry 分享了他的网站的案例，首页瞄准有一定优化难度的大搜索量关键词，然后通过二级页面和大量的三级页面，不断的获取小词的排名、曝光、点击，进而带动了上一级页面的权重，最后让首页拿到了相关关键词的排名。下面的这条流量增长曲线就说明了，这个内容策略是有效的。\nhttps://mp.weixin.qq.com/s/Dgf_3fJmNrBWj6u76essUw\n怎么让搜索引擎爬虫能够爬取到你的海量页面，可以看看上面这篇文章。\n还有个问题，大家很关心，现在还可以做这样的网站吗？\n那么你就要去挖掘相关需求了，而不是仅仅盯着哥飞今天分享的两地距离这个需求去做。重要的是学会这种建站思路，然后再去挖掘可以用这个建站思路做站的需求。\n提问环节：\n1、这种海量页面，新站的话，一天上多少个页面合适？\n回答：每一个站的情况都不同，一般来讲，前期少量测试，每天 10 个页面，看看爬虫是否能够全部抓取，以及抓了之后是否会出词。这一步目的是测试你的模板页面 SEO 做得到底好不好。根据 GSC 后台反馈的数据，不断调整页面。直到你给出的页面，谷歌爬虫都能够抓取，并且都出词了，那就说明你的页面调整得差不多了。\n接下来，就可以增大生成页面的数量，每天 100 个看看谷歌爬虫是否吃得下。\n如果也是能吃下去，并且也有出词，那就改成每天 200 个，300 个，500 个，1000 个。\n2、判断一个页面需不需要生成，数据来源和依据一般是什么？是不是当前站点的搜索后台的搜索情况，或者按照以前的搜索意图去分析？\n回答：刚才课堂里已经讲了，因为有人会在搜索引擎搜索相关关键词，我们才去做相关的页面。\n3、像这种海量页面，做多语言的时候进行翻译有什么低成本的方法不？\n回答：拿距离网站举例，多语言分两部分：1 界面 UI 文案多语言，这里一次翻译，多次可用，不用多说；2 数据多语言，一般是在录入数据时，就自动调用相关翻译接口，生成多语言数据。\n4、类似 lobe-chat 这种开源的聊天助理软件，怎么赚钱？\n回答：给个人免费使用，商用要付费的。\n5、距离的这个网站用是什么数据结构？怎么去切分字段更加高效呢？\n回答：大概猜测，需要有一个地点数据表，记录了全球各个国家各个地区的基本信息、从属关系，以及每一个地区的中心点的 GPS 坐标。然后还可以有一张表，存储计算好的两地之间的距离数据，不过这张表也可以不要，临时计算也可以。",
    "scraped_at": "2025-09-03T15:14:24.068223",
    "original_title": "如何使用程序化 SEO 生成海量页面获取流量",
    "date": "2024-09-13"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240919",
    "title": "分析一个网站的 SEO优化情况",
    "description": "日期：2024-09-19",
    "content": "日期：2024-09-19\n今天哥飞小课堂拿某位群里朋友的一个比较典型的，SEO 没做好的网站当作案例，跟大家分析一下，有哪些点没做好，以及要怎么改进。\n这个网站域名是\nhttps://c2story.com/\n，上线于 6 月份，到现在也三个月时间了。其实只看界面的话，这个网站 UI 还是挺漂亮的。但是很多 SEO 细节，的确是没做好。\n我们看下 GSC 数据，三个多月的时间，总共才拿到 99 个曝光，35 个点击。可以说几乎没曝光了。\n原因是为什么呢？很重要的一点，网站内容没有突出核心关键词，也就是关键词的密度不够。换句话说，一是没有围绕核心关键词去写网页内容，二是让 UGC 和 AIGC 的内容冲淡了关键词密度。\n拿首页来说，网站要瞄准的关键词是 ai story generator，但是首页出现最多的单词是 geaiy62jsv65s，这是一个作者的昵称，因为首页出现了这位作者的 74 篇内容，所以 geaiy62jsv65s 就出现了 74 次。\n所以当你在谷歌搜索 geaiy62jsv65s 时，这个网站就排在了第一名。所以你看，你想拿某个关键词的排名，就让你的网页多出现几次这个关键词就行。\n原理就是这么简单。\n不过，geaiy62jsv65s 这个词没人竞争，而我们做的很多词，通常有很多网站竞争，所以除了内容要出现，外链也要做好，提升网站权重，才能让自己网站出现在前面位置。\n对于这个网站来说，上面说的原因还不是最严重的。目前最致命的原因是，网站是前端渲染的。这就导致谷歌抓取不到你的网页内容到底是关于什么的。既然不知道是干什么的，当然也无法给你排名和曝光。\n所有，大家记住，第一大忌，不要前端渲染。第二大忌，不要让无关的内容冲淡你的核心关键词密度。\n我们假设，这个网站改成了后端渲染，那么目前首页这些内容，也是有害而无益的。因为你首页出现了太多跟你的核心关键词无关的文字。\n不知道大家记得不记得我们之前聊过的“分门别类罗列”，这个原则，你要罗列的内容，需要是谷歌能够理解的知道是什么类型，且跟你的主题相关的内容。\n举个例子来说，你的网站是关于 AI Story Generator 的，那么你可以分析一下，有\u0000哪些 story 类型，然后首页把很多不同的 story 类型都列出来，每一个类型都有一个生成器，并且有这个类型下的几篇相关内容。注意，内容这里只要出现个标题就行，不要出现太多无关的内容。\n如果你的网页上实在是需要显示一些跟核心关键词无关的内容，举例作者名称、内容简介，那么可以考虑把这部分内容前端渲染出来，也就是后端不返还内容，而是前端请求之后再填充进去。\n刚才这张首页截图可以看到，首页有 2729 个单词，而这些词都是废词，对于你的排名没有任何帮助。\n再看内页，也是很多问题：\n1、URL 没有带关键词，而是用了数字 ID，并且还有没用的参数 type；\n2、内页也是用的前端渲染，而没有用后端渲染\n3、Heading 结构太简单了，只写了一个 H1；\n4、内页的 title、description 没有根据内页的内容去书写，而是直接用了首页的文案；\nTDK 都超长了，并且其实 K 没必要写。\nhttps://mp.weixin.qq.com/s/41O1gg8bfU5MdmKkann8Aw\n有些页面给用户看的，不是用来从谷歌拿排名获取流量的，那么这些页面，可以设置 noindex，就是不给谷歌抓取。\n有些页面就是用来从谷歌获取排名和流量的，就需要遵循“一个关键词一个页面”原则，你有多少个想要拿到排名和流量的关键词，就需要去做多少页面。\n并且每一个页面都需要设置好自己的 TDH，而不是跟首页公用 TDH。\nhttps://mp.weixin.qq.com/s/aCNzWnu09jQxPcPHMcswMA\n这里有一篇贴纸网站 stickerbaker.com 的评测，大家可以跟着去查查自己网站的问题。\n问：怎么看出是前端渲染的\n答：谷歌浏览器查看源码 view-source，c2story.com 里边只有 html 结构，没有内容，就是前端渲染。\n问：怎么合理的提升关键词密度呢？提升到什么数值区间为佳呢？\n答：围绕着核心关键词去拓展更多关键词和更多问题，然后去写内容。每个页面的核心关键词密度在 3% - 5%左右更合理。",
    "scraped_at": "2025-09-03T15:14:25.437387",
    "original_title": "分析一个网站的 SEO优化情况",
    "date": "2024-09-19"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240923",
    "title": "0代码做在线网页游戏搞流量",
    "description": "日期：2024-09-23",
    "content": "日期：2024-09-23\nhttps://scratch.mit.edu/\n是儿童可视化编程 scratch 平台的官网，目前月访问量 21.46 万，最近 12 个月访问量 3.13 亿。\n在这个网站的发现栏目，有大量的热门作品，都是用 scratch 做出来的，可以在线使用的。\nhttps://scratch.mit.edu/explore/projects/all/\n，其中，就有一个游戏分类，有大量的游戏\nhttps://scratch.mit.edu/explore/projects/games/\n。\n这里的每一个游戏，都可以在线体验，还\u0000\u0000可以查看 scratch 代码，你可以基于这些代码继续修改，做出你自己的游戏逻辑。\n拿刚才的飞机大站游戏来说，网址是：\nhttps://scratch.mit.edu/projects/745602957/\n对应的编辑器地址是：\nhttps://scratch.mit.edu/projects/745602957/editor/\n有一个第三方工具，叫做 TurboWrap Packager，可以把 scratch.mit.edu 上面的每一个 project，都打包成可以独立部署的单 html 文件\nhttps://packager.turbowarp.org/\n。\n刚才给大家看的\nhttps://seo.box/game/AIRPLANE-SHOOTER-V1.html\n就是用这个工具打包之后，我再部署到 Vercel 上的。\n因为游戏文件比较大，其实更建议大家放到对象存储里去，再套一层 CDN。\n放到 CDN 之后，你就得到了一个可以直接玩的游戏地址，但是这个页面其实不利于 SEO，所以我们还需要用之前的小课堂里分享的方法，再做一个落地页，然后用 iframe 把游戏给嵌入进来。\n你看，这就回到了大家的熟悉领域，怎么快速制作落地页，做好站内优化，做好外链，拿排名搞流量，都是大家很擅长的。\n我们还可以用 Similarweb 或者 Semrush 来分析 scratch.mit.edu 上面能够拿到搜索量的游戏。这又回到了我们熟悉的领域，分析需求，挖掘需求。\n找到合适的游戏之后，单独做个网站来嵌入游戏，就可以放广告赚美元了。\n不过，这里需要注意版权问题，某一个游戏到底能不能用，需要具体去看 project 页面的介绍说明。\n除了直接在上面找游戏，我们也可以用 scratch 来做游戏。就相当于，你有了一个现在的在线游戏开发平台，不需要自己去搭建游戏开发环境。而且自己做出来的游戏，也一样能够用刚才介绍的工具导出 html，部署到自己网站里。\n一些经典的游戏，上面都能找到别人的作品，我们可以去学习别人的代码，进而学会自己做游戏。比如，\nhttps://scratch.mit.edu/search/projects?q=2048\n。\n游戏流量还是很赚钱的，已经不止一个人跟我说，想收 H5 流量，之后通过游戏变现。\n游戏网站之间还可以相互导流量，随着你做的游戏越来越多，只要哪个游戏火了，就能够带动别的游戏也有用户使用。我们之前也分享过一些游戏站，基本都是一个关键词一个域名做一个网站的思路。但是在页面上，会显示其他游戏列表，让来的流量都别浪费。\n游戏里的皮肤，是可以自己更换的。你也可以让 AI 生成图片，制作皮肤。\n好了，今天的哥飞小课堂就到这里了，主要是给大家分享了一个能够在线制作游戏的平台，其他的 SEO 搞流量挖掘需求，都是我们之\u0000前讲过的，也是大家熟悉的领域，就不过多展开了。\n问答：\n这个游戏网站的作者太猛了，搞了很多类似的网站，一套模板\nhttps://wordly.org/\n。",
    "scraped_at": "2025-09-03T15:14:26.850960",
    "original_title": "0代码做在线网页游戏搞流量",
    "date": "2024-09-23"
  },
  {
    "url": "https://www.lummstudio.com/docs/20240924",
    "title": "sitelinks 和 mini sitelinks",
    "description": "日期：2024-09-24",
    "content": "日期：2024-09-24\nsitelinks 和 mini sitelinks 的区别\n上面这张图里，搜索结果下方出现的 explore 等链接，就是 sitelinks。sitelinks 有可能单列，也有可能双列。\nsitelinks 通常出现在你搜索某个网站的品牌词时，谷歌会在这个网站的正常搜索结果下方显示 sitelinks。\n所谓 sitelinks，其实就是谷歌挑选的该网站比较重要的一些内链。可能是这个页面比较多人访问，也可能是比较多人搜索，又或者谷歌觉得这个页面比较重要，有必要让搜索用户看到。\n因为 sitelinks 占用的页面高度比较多，比较浪费空间，谷歌又在 2009 年引入了 mini sitelinks。同样是被谷歌挑选出来的一些链接，不同的是，mini sitelinks 只会显示一行，这样占用的页面高度就不多了，很节省空间。\nsitelinks 通常出现在品牌词搜索结果中，并且通常只有第一名才会出现。一般，我们看到一个词的搜索结果里出现了 sitelinks，就可以认为，谷歌已经把这个词跟这个网站绑定了，谷歌认为这个词就是这个网站的品牌词。\n注意，这很重要，一个词成为你网站的品牌词之后，一般情况下，别人就很难抢走你的排名了。\n经典案例，就是 undetectable ai 这个词，有人用这个词注册了域名 undetectable.ai，经过一段时间的努力，现在谷歌已经把 undetectable ai 这个词当成了 undetectable.ai 的品牌词了。\n成为品牌词有什么好处呢？\n一是出现 sitelinks 之后，几乎搜索结果第一屏被你的网站霸屏了，你能够拿到这个关键词的绝大多数点击。\n二是别人比较难跟你抢这个关键词的排名了，你可以任务高枕无忧了。\n那么怎么才能让自己的网站出现 sitelinks 呢？或者说，怎么控制哪些链接出现在 sitelinks 里边呢？\n通常大家认为，这里的链接是无法站长直接控制的，只能谷歌去自动抓取，自动识别，自动判断。\n但是，有一些方法，可以辅助谷歌识别到你的哪些网页更重要，从而增加被谷歌选中的概率。\n举例，你的网站需要有全站导航条，那么在导航条例出现的链接，就更容易被谷歌选中放到 sitelinks 里去。\n举例，你的网站里有些页面，假设有很多内链，或者很多外链，或者被很多人在谷歌搜索直接查找，也会更容易出现在 sitelinks。\n举个例子，你做了一个 AI 工具，品牌词是 xxx，你有一个价格页面，很多人会在谷歌里搜索 xxx pricing 来看你的定价，那\u0000\u0000么当用户搜索 xxx 时，谷歌很大概率就会把 pricing 页面放到 sitelinks 里。\n好了，今天的小课堂就到这里了。",
    "scraped_at": "2025-09-03T15:14:28.424931",
    "original_title": "sitelinks 和 mini sitelinks",
    "date": "2024-09-24"
  },
  {
    "url": "https://www.lummstudio.com/docs/seo/miniclass",
    "title": "简介",
    "description": "哥飞小课堂，是哥飞在「哥飞的朋友们」微信群里，不定期进行的主题分享。一次分享一个主题，都是围绕 SEO 优化的干货。从 2024 年 1 月开始记录，按时间先后排序。",
    "content": "哥飞小课堂，是哥飞在「哥飞的朋友们」微信群里，不定期进行的主题分享。一次分享一个主题，都是围绕 SEO 优化的干货。从 2024 年 1 月开始记录，按时间先后排序。\n📄️\n蜘蛛池是什么？如何利用？\n日期：2024-01-02\n📄️\n分享一个错过的机会\n日期：2024-01-19\n📄️\n如何覆盖更多关键词？\n日期：2024-02-20\n📄️\n为什么新词可以快速拿到结果？\n日期：2024-02-27\n📄️\nGoogle 的高权重域名是什么，如何利用？\n日期：2024-03-04\n📄️\n同一个页面，不要同时有大词和小词\n日期：2024-04-16\n📄️\n做有人会搜索相关关键词的页面\n日期：2024-04-21\n📄️\n一个关键词一个页面原则\n日期：2024-05-09\n📄️\n为什么说谷歌的最小排序粒度是网页，而不是网站？\n日期：2024-05-14\n📄️\n如何查看 checkout.stripe.com 导入流量的 100 名外的网站？\n日期：2024-05-15\n📄️\n如何获取某个网站的 icon？\n日期：2024-05-16\n📄️\n如何找到优秀的文章模板？\n日期：2024-05-23\n📄️\n用户归因是什么？如何做？\n日期：2024-05-29\n📄️\n如何使用谷歌趋势找新词？\n日期：2024-06-03\n📄️\n你也许能学到更多，两个SEO优化的失败案例\n日期：2024-06-04\n📄️\nAhrefs DR 值计算的小漏洞\n日期：2024-06-06\n📄️\nHenry 分享：如何通过内容运营，拿下主词？\n日期：2024-06-09\n📄️\n为什么你需要关注未编入索引网页数量？\n日期：2024-06-11\n📄️\nSEO三原则：什么是“分门别类罗列“和“一个关键词一个页面”\n日期：2024-06-13\n📄️\n如何拿下大词？网站多语言的重要性\n日期：2024-06-25\n📄️\n如何找到更多的可以发外链的地方？\n日期：2024-06-26\n📄️\n为什么要去开一个谷歌广告账号？\n日期：2024-06-27\n📄️\n如何做好一个内容型工具站？\n日期：2024-07-07\n📄️\n为什么要满足用户搜索意图\n日期：2024-07-16\n📄️\n如何挑战高 KD 值的关键字\n日期：2024-07-20\n📄️\n分享一个快速找套壳网站的方法\n日期：2024-07-22\n📄️\n广告指标有哪些？\n日期：2024-07-24\n📄️\nCanva 网站拆解，落地页布局结构\n日期：2024-07-30\n📄️\n挖掘需求的方法（下）\n日期：2024-08-01\n📄️\n挖掘需求的方法（上）\n日期：2024-08-02\n📄️\n如何锻炼 SEO 思维能力\n日期：2024-08-03\n📄️\n内容型工具站的页面结构\n日期：2024-08-04\n📄️\n如何使用模型批量上站\n日期：2024-08-05\n📄️\n如何覆盖小词，如何布局页面结构\n日期：2024-08-06\n📄️\n如何快速上站，如何优化页面收录数\n日期：2024-08-07\n📄️\n如何预估网站收入\n日期：2024-08-09\n📄️\n图片类关键词分析\n日期：2024-08-15\n📄️\n如何挖掘 APP 需求？\n日期：2024-08-22\n📄️\n分享一个被动获取外链的方法\n日期：2024-08-28\n📄️\nmeme 相关关键词分析\n日期：2024-08-30\n📄️\n分析一个年收入 4000 万美金的小网站\n日期：2024-09-15\n📄️\n如何使用程序化 SEO 生成海量页面获取流量\n日期：2024-09-13\n📄️\n分析一个网站的 SEO优化情况\n日期：2024-09-19\n📄️\n0代码做在线网页游戏搞流量\n日期：2024-09-23\n📄️\nsitelinks 和 mini sitelinks\n日期：2024-09-24\n📄️\n简介\n哥飞小课堂，是哥飞在「哥飞的朋友们」微信群里，不定期进行的主题分享。一次分享一个主题，都是围绕 SEO 优化的干货。从 2024 年 1 月开始记录，按时间先后排序。",
    "scraped_at": "2025-09-03T15:14:30.022028",
    "original_title": "简介",
    "date": "哥飞小课堂，是哥飞在「哥飞的朋友们」微信群里，不定期进行的主题分享。一次分享一个主题，都是围绕 SEO 优化的干货。从 2024 年 1 月开始记录，按时间先后排序。"
  },
  {
    "url": "https://www.lummstudio.com/docs/seo",
    "title": "SEO 笔记",
    "description": "本页面记录我自己学习 SEO 优化过程中的笔记，SEO 包含很多细节，这里留下记录，方便回顾和查找。",
    "content": "本页面记录我自己学习 SEO 优化过程中的笔记，SEO 包含很多细节，这里留下记录，方便回顾和查找。",
    "scraped_at": "2025-09-03T15:14:31.433114",
    "original_title": "SEO",
    "date": ""
  },
  {
    "url": "https://www.lummstudio.com/docs/skill",
    "title": "技术笔记",
    "description": "本页面为个人学习中所涉及相关技术栈的笔记汇总，包含但不限于",
    "content": "本页面为个人学习中所涉及相关技术栈的笔记汇总，包含但不限于\n前端\nVue\nReact\nJavaScript & TypeScript\nNextjs\nVercel",
    "scraped_at": "2025-09-03T15:14:32.829757",
    "original_title": "笔记",
    "date": ""
  },
  {
    "url": "https://www.lummstudio.com/docs/tools",
    "title": "工具推荐",
    "description": "推荐好用的 Mac 软件，手机软件等等",
    "content": "推荐好用的 Mac 软件，手机软件等等",
    "scraped_at": "2025-09-03T15:14:34.240547",
    "original_title": "工具推荐",
    "date": ""
  },
  {
    "url": "https://www.lummstudio.com/docs/seo/dailyshare",
    "title": "简介",
    "description": "日常分享，是哥飞在「哥飞的朋友们」微信群里，每天分享的 SEO 的方方面面，包括工具的使用，案例的分析，SEO 优化的细节，成功案例等等。按分享主题分类。",
    "content": "日常分享，是哥飞在「哥飞的朋友们」微信群里，每天分享的 SEO 的方方面面，包括工具的使用，案例的分析，SEO 优化的细节，成功案例等等。按分享主题分类。\n📄️\nnextjs 全栈开发学习资源汇总\nnextjs 全栈开发，学习资源汇总。包括 nextjs、登录授权、stripe 支付、国际化、第三方 AI 接口调用等\n📄️\nSaaS 网站模板推荐\n建站模板推荐，用于快速建站。\n📄️\n可选的建站方向\n可选的建站方向。\n📄️\n练手网站\n有朋友问，看到别人很优秀，我比较焦虑怎么办？\n📄️\n简介\n日常分享，是哥飞在「哥飞的朋友们」微信群里，每天分享的 SEO 的方方面面，包括工具的使用，案例的分析，SEO 优化的细节，成功案例等等。按分享主题分类。",
    "scraped_at": "2025-09-03T15:14:35.596792",
    "original_title": "日常分享",
    "date": ""
  },
  {
    "url": "https://www.lummstudio.com/docs/seo/newwords",
    "title": "简介",
    "description": "路漫漫的个人博客",
    "content": "📄️\ncursive 草书\nSEO 三原则：\n📄️\n简介\n📄️\nshades",
    "scraped_at": "2025-09-03T15:14:36.983955",
    "original_title": "新词分析",
    "date": ""
  },
  {
    "url": "https://www.lummstudio.com/docs/seo/newwebsites",
    "title": "简介",
    "description": "路漫漫的个人博客",
    "content": "📄️\n简介",
    "scraped_at": "2025-09-03T15:14:38.340355",
    "original_title": "新站测评",
    "date": ""
  }
]