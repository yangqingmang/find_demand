#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å»ºç«™å»ºè®®åŠŸèƒ½æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•åŸºäºæœç´¢æ„å›¾çš„å»ºç«™å»ºè®®åŠŸèƒ½
"""

import sys
import os
import pandas as pd

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_website_recommendations():
    """æµ‹è¯•å»ºç«™å»ºè®®åŠŸèƒ½"""
    print("=== æµ‹è¯•å»ºç«™å»ºè®®åŠŸèƒ½ ===")
    
    try:
        from src.demand_mining.analyzers.intent_analyzer import IntentAnalyzer
        from src.demand_mining.analyzers.website_recommendation import WebsiteRecommendationEngine
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'query': [
                'best ai writing tools',
                'how to use chatgpt',
                'ai image generator free',
                'chatgpt login',
                'ai tool not working',
                'ai tools near me',
                'buy ai software',
                'ai vs human writing',
                'download stable diffusion',
                'ai coding assistant'
            ],
            'volume': [5000, 3000, 4000, 2000, 1500, 800, 2500, 1800, 3500, 2800],
            'growth': [120, 80, 200, 50, 30, 60, 150, 90, 180, 110]
        })
        
        print(f"æµ‹è¯•æ•°æ®åŒ…å« {len(test_data)} ä¸ªå…³é”®è¯:")
        for idx, row in test_data.iterrows():
            print(f"  {idx+1}. {row['query']} (æœç´¢é‡: {row['volume']})")
        
        # æµ‹è¯•1: ä½¿ç”¨é›†æˆçš„æ„å›¾åˆ†æå™¨ï¼ˆåŒ…å«å»ºç«™å»ºè®®ï¼‰
        print("\n=== æµ‹è¯•1: é›†æˆæ„å›¾åˆ†æ + å»ºç«™å»ºè®® ===")
        analyzer = IntentAnalyzer(
            use_serp=False, 
            use_v2=False, 
            enable_website_recommendations=True
        )
        
        result_df = analyzer.analyze_keywords(test_data, keyword_col='query')
        
        # æ˜¾ç¤ºç»“æœ
        print("\næ„å›¾åˆ†æ + å»ºç«™å»ºè®®ç»“æœ:")
        display_columns = [
            'query', 'intent', 'intent_description', 
            'website_type', 'ai_tool_category', 'development_priority'
        ]
        
        for idx, row in result_df.iterrows():
            print(f"\n{idx+1}. {row['query']}")
            print(f"   æ„å›¾: {row['intent']} - {row.get('intent_description', '')}")
            print(f"   å»ºè®®ç½‘ç«™ç±»å‹: {row.get('website_type', 'æœªçŸ¥')}")
            print(f"   AIå·¥å…·ç±»åˆ«: {row.get('ai_tool_category', 'æœªçŸ¥')}")
            
            # æ˜¾ç¤ºå¼€å‘ä¼˜å…ˆçº§
            priority_info = row.get('development_priority', {})
            if isinstance(priority_info, dict):
                priority = priority_info.get('level', 'æœªçŸ¥')
                timeline = priority_info.get('timeline', 'æœªçŸ¥')
                print(f"   å¼€å‘ä¼˜å…ˆçº§: {priority} ({timeline})")
            
            # æ˜¾ç¤ºåŸŸåå»ºè®®
            domains = row.get('domain_suggestions', [])
            if isinstance(domains, list) and domains:
                print(f"   åŸŸåå»ºè®®: {', '.join(domains[:3])}")
            
            # æ˜¾ç¤ºå˜ç°ç­–ç•¥
            monetization = row.get('monetization_strategy', [])
            if isinstance(monetization, list) and monetization:
                print(f"   å˜ç°ç­–ç•¥: {', '.join(monetization[:2])}")
        
        # æµ‹è¯•2: å•ç‹¬æµ‹è¯•å»ºç«™å»ºè®®å¼•æ“
        print("\n=== æµ‹è¯•2: å•ç‹¬å»ºç«™å»ºè®®å¼•æ“ ===")
        
        # å…ˆè¿›è¡Œç®€å•çš„æ„å›¾åˆ†æ
        simple_intent_data = test_data.copy()
        simple_intent_data['intent'] = ['C', 'I', 'E', 'N', 'B', 'L', 'E', 'C', 'N', 'E']
        
        # åˆ›å»ºå»ºç«™å»ºè®®å¼•æ“
        recommender = WebsiteRecommendationEngine()
        
        # ç”Ÿæˆå»ºç«™å»ºè®®
        recommendations_df = recommender.generate_website_recommendations(
            simple_intent_data, 
            keyword_col='query', 
            intent_col='intent'
        )
        
        print("\nå•ç‹¬å»ºç«™å»ºè®®ç»“æœ:")
        for idx, row in recommendations_df.iterrows():
            print(f"\n{idx+1}. {row['query']} (æ„å›¾: {row['intent']})")
            print(f"   ç½‘ç«™ç±»å‹: {row.get('website_type', 'æœªçŸ¥')}")
            print(f"   AIç±»åˆ«: {row.get('ai_tool_category', 'æœªçŸ¥')}")
            
            # æ˜¾ç¤ºæŠ€æœ¯è¦æ±‚
            tech_reqs = row.get('technical_requirements', [])
            if isinstance(tech_reqs, list) and tech_reqs:
                print(f"   æŠ€æœ¯è¦æ±‚: {', '.join(tech_reqs[:3])}")
            
            # æ˜¾ç¤ºç«äº‰åˆ†æ
            competition = row.get('competition_analysis', {})
            if isinstance(competition, dict):
                level = competition.get('level', 'æœªçŸ¥')
                advice = competition.get('advice', '')
                print(f"   ç«äº‰ç¨‹åº¦: {level} - {advice}")
        
        # æµ‹è¯•3: ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        print("\n=== æµ‹è¯•3: æ‘˜è¦æŠ¥å‘Šç”Ÿæˆ ===")
        
        summary_report = recommender.generate_summary_report(recommendations_df)
        
        print("\næ‘˜è¦æŠ¥å‘Š:")
        print(f"æ€»å…³é”®è¯æ•°: {summary_report.get('total_keywords', 0)}")
        
        print("\nç½‘ç«™ç±»å‹åˆ†å¸ƒ:")
        for website_type, count in summary_report.get('website_type_distribution', {}).items():
            print(f"  {website_type}: {count}")
        
        print("\nAIå·¥å…·ç±»åˆ«åˆ†å¸ƒ:")
        for ai_category, count in summary_report.get('ai_category_distribution', {}).items():
            print(f"  {ai_category}: {count}")
        
        print("\nå¼€å‘ä¼˜å…ˆçº§åˆ†å¸ƒ:")
        for priority, count in summary_report.get('priority_distribution', {}).items():
            print(f"  {priority}: {count}")
        
        print("\né«˜ä¼˜å…ˆçº§é¡¹ç›®:")
        for project in summary_report.get('high_priority_projects', []):
            print(f"  - {project.get('query', '')}: {project.get('website_type', '')}")
        
        print("\nç«‹å³è¡ŒåŠ¨å»ºè®®:")
        for recommendation in summary_report.get('recommendations', {}).get('immediate_action', []):
            print(f"  â€¢ {recommendation}")
        
        print("\nå¸‚åœºæœºä¼š:")
        for opportunity in summary_report.get('recommendations', {}).get('market_opportunities', []):
            print(f"  â€¢ {opportunity}")
        
        print("\næŠ€æœ¯é‡ç‚¹:")
        for focus in summary_report.get('recommendations', {}).get('technical_focus', []):
            print(f"  â€¢ {focus}")
        
        print("\nâœ“ å»ºç«™å»ºè®®åŠŸèƒ½æµ‹è¯•å®Œæˆ!")
        return True
        
    except ImportError as e:
        print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_ai_tool_detection():
    """æµ‹è¯•AIå·¥å…·ç±»åˆ«æ£€æµ‹"""
    print("\n=== æµ‹è¯•AIå·¥å…·ç±»åˆ«æ£€æµ‹ ===")
    
    try:
        from src.demand_mining.analyzers.website_recommendation import WebsiteRecommendationEngine
        
        recommender = WebsiteRecommendationEngine()
        
        test_keywords = [
            'chatgpt alternative',
            'ai image generator',
            'code completion tool',
            'voice synthesis ai',
            'video editing ai',
            'business automation tool',
            'research assistant ai',
            'writing helper tool',
            'regular calculator',  # éAIå·¥å…·
            'weather forecast'     # éAIå·¥å…·
        ]
        
        print("AIå·¥å…·ç±»åˆ«æ£€æµ‹ç»“æœ:")
        for keyword in test_keywords:
            category = recommender._detect_ai_tool_category(keyword.lower())
            print(f"  {keyword}: {category}")
        
        return True
        
    except Exception as e:
        print(f"âœ— AIå·¥å…·æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_domain_suggestions():
    """æµ‹è¯•åŸŸåå»ºè®®ç”Ÿæˆ"""
    print("\n=== æµ‹è¯•åŸŸåå»ºè®®ç”Ÿæˆ ===")
    
    try:
        from src.demand_mining.analyzers.website_recommendation import WebsiteRecommendationEngine
        
        recommender = WebsiteRecommendationEngine()
        
        test_cases = [
            ('ai writing tool', 'AIå†™ä½œå·¥å…·'),
            ('best chatgpt alternative', 'AIå¯¹è¯å·¥å…·'),
            ('image generator free', 'AIå›¾åƒç”Ÿæˆ'),
            ('code assistant', 'AIç¼–ç¨‹å·¥å…·'),
            ('business automation', 'AIå•†ä¸šå·¥å…·')
        ]
        
        print("åŸŸåå»ºè®®ç”Ÿæˆç»“æœ:")
        for keyword, ai_category in test_cases:
            domains = recommender._generate_domain_suggestions(keyword.lower(), ai_category)
            print(f"\n{keyword} ({ai_category}):")
            for i, domain in enumerate(domains[:5], 1):
                print(f"  {i}. {domain}")
        
        return True
        
    except Exception as e:
        print(f"âœ— åŸŸåå»ºè®®æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å»ºç«™å»ºè®®åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•ç»“æœ
    results = []
    
    # 1. æµ‹è¯•å»ºç«™å»ºè®®åŠŸèƒ½
    results.append(test_website_recommendations())
    
    # 2. æµ‹è¯•AIå·¥å…·æ£€æµ‹
    results.append(test_ai_tool_detection())
    
    # 3. æµ‹è¯•åŸŸåå»ºè®®
    results.append(test_domain_suggestions())
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ€»ç»“:")
    print(f"  å»ºç«™å»ºè®®åŠŸèƒ½: {'âœ“ é€šè¿‡' if results[0] else 'âœ— å¤±è´¥'}")
    print(f"  AIå·¥å…·æ£€æµ‹: {'âœ“ é€šè¿‡' if results[1] else 'âœ— å¤±è´¥'}")
    print(f"  åŸŸåå»ºè®®: {'âœ“ é€šè¿‡' if results[2] else 'âœ— å¤±è´¥'}")
    
    if all(results):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å»ºç«™å»ºè®®åŠŸèƒ½å·²æˆåŠŸé›†æˆï¼")
        print("\nåŠŸèƒ½ç‰¹æ€§:")
        print("âœ“ åŸºäºæœç´¢æ„å›¾çš„ç½‘ç«™ç±»å‹æ¨è")
        print("âœ“ AIå·¥å…·ç±»åˆ«è‡ªåŠ¨è¯†åˆ«")
        print("âœ“ æ™ºèƒ½åŸŸåå»ºè®®ç”Ÿæˆ")
        print("âœ“ å˜ç°ç­–ç•¥æ¨è")
        print("âœ“ æŠ€æœ¯è¦æ±‚åˆ†æ")
        print("âœ“ ç«äº‰ç¨‹åº¦è¯„ä¼°")
        print("âœ“ å¼€å‘ä¼˜å…ˆçº§è¯„ä¼°")
        print("âœ“ å†…å®¹ç­–ç•¥å»ºè®®")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("```python")
        print("from src.demand_mining.analyzers.intent_analyzer import IntentAnalyzer")
        print("analyzer = IntentAnalyzer(enable_website_recommendations=True)")
        print("result = analyzer.analyze_keywords(df)")
        print("# ç»“æœå°†åŒ…å«å®Œæ•´çš„å»ºç«™å»ºè®®")
        print("```")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()