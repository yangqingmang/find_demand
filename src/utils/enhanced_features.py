#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºåŠŸèƒ½æ¨¡å—
ä¸ºä¸»ç¨‹åºæä¾›é¢å¤–çš„å¢å¼ºåŠŸèƒ½
"""

from datetime import datetime
from typing import List, Dict, Any

def monitor_competitors(sites: List[str], output_dir: str = None) -> Dict[str, Any]:
    """ç›‘æ§ç«å“å…³é”®è¯å˜åŒ–"""
    raise RuntimeError("ç«å“ç›‘æ§åŠŸèƒ½éœ€è¦æ¥å…¥çœŸå®ç›‘æ§æ•°æ®æºï¼Œç›®å‰æœªå®ç°")

def predict_keyword_trends(timeframe: str = "30d", output_dir: str = None, keywords: List[str] = None, use_real_data: bool = True) -> Dict[str, Any]:
    """é¢„æµ‹å…³é”®è¯è¶‹åŠ¿
    
    Args:
        timeframe: é¢„æµ‹æ—¶é—´èŒƒå›´
        output_dir: è¾“å‡ºç›®å½•
        keywords: è¦åˆ†æçš„å…³é”®è¯åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å…³é”®è¯
        use_real_data: æ˜¯å¦ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡Œé¢„æµ‹ï¼ŒFalseæ—¶è¿”å›æ¼”ç¤ºæ•°æ®
    
    Returns:
        è¶‹åŠ¿é¢„æµ‹ç»“æœ
    """
    print(f"ğŸ“ˆ å¼€å§‹é¢„æµ‹æœªæ¥ {timeframe} çš„å…³é”®è¯è¶‹åŠ¿...")
    
    if not use_real_data:
        raise RuntimeError("è¶‹åŠ¿é¢„æµ‹ä¸å†æ”¯æŒæ¼”ç¤ºæ•°æ®æ¨¡å¼ï¼Œè¯·å…ˆæ¥å…¥çœŸå®æ•°æ®æº")

    print("âœ… ä½¿ç”¨çœŸå®Google Trendsæ•°æ®è¿›è¡Œé¢„æµ‹")
    predictions = _predict_with_real_data(keywords, timeframe)

    # ä¿å­˜é¢„æµ‹ç»“æœ
    if output_dir:
        _save_trend_predictions(predictions, output_dir)

    return predictions

def _predict_with_real_data(keywords: List[str] = None, timeframe: str = "30d") -> Dict[str, Any]:
    """ä½¿ç”¨çœŸå®Google Trendsæ•°æ®è¿›è¡Œè¶‹åŠ¿é¢„æµ‹"""
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        import sys
        import os
        import pandas as pd
        
        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(current_dir))
        if project_root not in sys.path:
            sys.path.insert(0, project_root)
        
        from src.demand_mining.managers.trend_manager import TrendManager
        from src.demand_mining.analyzers.timeliness_analyzer import TimelinessAnalyzer
        
        # å¦‚æœæ²¡æœ‰æä¾›å…³é”®è¯ï¼Œä½¿ç”¨é»˜è®¤çš„AIç›¸å…³å…³é”®è¯
        if not keywords:
            keywords = [
                'ai tools', 'chatgpt', 'claude ai', 'gemini ai', 
                'ai generator', 'ai assistant', 'machine learning',
                'artificial intelligence', 'ai image generator', 'ai code assistant'
            ]
        
        print(f"ğŸ” åˆ†æ {len(keywords)} ä¸ªå…³é”®è¯çš„çœŸå®è¶‹åŠ¿æ•°æ®...")
        
        # ä½¿ç”¨å®æ—¶æ€§åˆ†æå™¨è·å–çœŸå®è¶‹åŠ¿æ•°æ®
        analyzer = TimelinessAnalyzer()
        df = pd.DataFrame({'query': keywords})
        
        # æ‰§è¡Œå®æ—¶æ€§åˆ†æ
        result_df = analyzer.analyze_timeliness(df)
        
        # åŸºäºåˆ†æç»“æœè¿›è¡Œé¢„æµ‹åˆ†ç±»
        predictions = {
            'prediction_date': datetime.now().isoformat(),
            'timeframe': timeframe,
            'data_source': 'google_trends_real_data',
            'analysis_method': 'timeliness_based_prediction',
            'total_keywords_analyzed': len(keywords),
            'rising_keywords': [],
            'stable_keywords': [],
            'declining_keywords': []
        }
        
        for _, row in result_df.iterrows():
            keyword_data = {
                'keyword': row['query'],
                'timeliness_score': float(row.get('timeliness_score', 0)),
                'trend_direction': row.get('trend_direction', 'stable'),
                'growth_rate': f"{row.get('growth_rate', 0):+.1f}%",
                'confidence': min(0.95, max(0.3, float(row.get('timeliness_score', 50)) / 100)),
                'current_interest': float(row.get('current_interest', 0)),
                'peak_interest': float(row.get('peak_interest', 0))
            }
            
            # æ ¹æ®è¶‹åŠ¿æ–¹å‘åˆ†ç±»
            if row.get('trend_direction') == 'rising':
                predictions['rising_keywords'].append(keyword_data)
            elif row.get('trend_direction') == 'falling':
                predictions['declining_keywords'].append(keyword_data)
            else:
                predictions['stable_keywords'].append(keyword_data)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        predictions['rising_keywords'].sort(key=lambda x: x['confidence'], reverse=True)
        predictions['declining_keywords'].sort(key=lambda x: x['confidence'], reverse=True)
        predictions['stable_keywords'].sort(key=lambda x: x['confidence'], reverse=True)
        
        print(f"âœ… é¢„æµ‹å®Œæˆ: {len(predictions['rising_keywords'])} ä¸Šå‡, {len(predictions['stable_keywords'])} ç¨³å®š, {len(predictions['declining_keywords'])} ä¸‹é™")

        return predictions

    except Exception as e:
        raise RuntimeError(f"è°ƒç”¨çœŸå®è¶‹åŠ¿é¢„æµ‹å¤±è´¥: {e}") from e

def generate_seo_audit(domain: str, keywords: List[str] = None) -> Dict[str, Any]:
    """ç”ŸæˆSEOä¼˜åŒ–å»ºè®®"""
    raise RuntimeError("SEO å®¡è®¡åŠŸèƒ½éœ€è¦æ¥å…¥çœŸå®ç«™ç‚¹/SEO æ•°æ®ï¼Œç›®å‰æœªå®ç°")

def batch_build_websites(top_keywords: int = 10) -> Dict[str, Any]:
    """æ‰¹é‡ç”Ÿæˆç½‘ç«™"""
    raise RuntimeError("æ‰¹é‡å»ºç«™åŠŸèƒ½éœ€è¦æ¥å…¥çœŸå®å»ºç«™æµæ°´çº¿ï¼Œç›®å‰æœªå®ç°")

def _scheduled_task(action: str, **kwargs):
    """æ‰§è¡Œå®šæ—¶ä»»åŠ¡"""
    print(f"ğŸ¤– æ‰§è¡Œå®šæ—¶ä»»åŠ¡: {action} at {datetime.now()}")
    
    try:
        if action == 'discover':
            raw_terms = kwargs.get('search_terms')
            seed_profile = kwargs.get('seed_profile')
            seed_limit = kwargs.get('seed_limit')
            min_seed_terms = kwargs.get('min_seed_terms')
            if isinstance(seed_limit, int) and seed_limit <= 0:
                seed_limit = None
            if isinstance(min_seed_terms, int) and min_seed_terms <= 0:
                min_seed_terms = None
            from src.demand_mining.tools.multi_platform_keyword_discovery import MultiPlatformKeywordDiscovery
            discoverer = MultiPlatformKeywordDiscovery()
            search_terms = discoverer.prepare_search_terms(
                seeds=raw_terms,
                profile=seed_profile,
                limit=seed_limit,
                min_terms=min_seed_terms
            )
            if not search_terms:
                print("âš ï¸ å®šæ—¶ä»»åŠ¡: æœªè·å–åˆ°æœ‰æ•ˆç§å­å…³é”®è¯ï¼Œè·³è¿‡å¤šå¹³å°å‘ç°")
                return
            df = discoverer.discover_all_platforms(search_terms)
            if not df.empty:
                analysis = discoverer.analyze_keyword_trends(df)
                print(f"âœ… å®šæ—¶å‘ç°å®Œæˆ: {analysis['total_keywords']} ä¸ªå…³é”®è¯")
        
        elif action == 'monitor':
            sites = kwargs.get('sites', ['canva.com', 'midjourney.com'])
            result = monitor_competitors(sites)
            print(f"âœ… å®šæ—¶ç›‘æ§å®Œæˆ: {len(result['competitors'])} ä¸ªç«å“")
            
    except Exception as e:
        print(f"âŒ å®šæ—¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")

def _save_competitor_monitoring_results(results: Dict, output_dir: str):
    """ä¿å­˜ç«å“ç›‘æ§ç»“æœ"""
    from src.utils.file_utils import save_results_with_timestamp
    
    file_path = save_results_with_timestamp(results, output_dir, 'competitor_monitoring')
    
    print(f"ğŸ“ ç«å“ç›‘æ§ç»“æœå·²ä¿å­˜: {file_path}")

def _save_trend_predictions(predictions: Dict, output_dir: str):
    """ä¿å­˜è¶‹åŠ¿é¢„æµ‹ç»“æœ"""
    from src.utils.file_utils import save_results_with_timestamp
    
    file_path = save_results_with_timestamp(predictions, output_dir, 'trend_predictions')
    
    print(f"ğŸ“ è¶‹åŠ¿é¢„æµ‹ç»“æœå·²ä¿å­˜: {file_path}")
