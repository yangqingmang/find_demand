
"""
è‡ªå®šä¹‰Google Trendsæ•°æ®é‡‡é›†å™¨
æ›¿ä»£pytrendsåº“ï¼Œæä¾›æ›´çµæ´»çš„æ§åˆ¶å’Œæ›´æ–°èƒ½åŠ›
"""

import requests
import json
import time
import random
from typing import List, Dict, Optional, Callable, TypeVar, Any, Union
import pandas as pd
import logging
from functools import wraps
import hashlib

logger = logging.getLogger(__name__)

from .google_trends_session import GoogleTrendsSession, get_global_session
from .request_rate_limiter import wait_for_next_request, get_rate_limiter_stats, register_rate_limit_event

# ç±»å‹å˜é‡å®šä¹‰
T = TypeVar('T')
DataFrame = pd.DataFrame
JsonDict = Dict[str, Any]

class TrendsAPIClient:
    """Google Trends APIå®¢æˆ·ç«¯åŸºç±»"""
    
    # Google Trends API endpoints
    GENERAL_URL = 'https://trends.google.com/trends/api/explore'
    INTEREST_OVER_TIME_URL = 'https://trends.google.com/trends/api/widgetdata/multiline'
    INTEREST_BY_REGION_URL = 'https://trends.google.com/trends/api/widgetdata/comparedgeo'
    RELATED_TOPICS_URL = 'https://trends.google.com/trends/api/widgetdata/relatedsearches'
    TRENDING_SEARCHES_URL = 'https://trends.google.com/trends/hottrends/visualize/internal/data'
    TOP_CHARTS_URL = 'https://trends.google.com/trends/api/topcharts'
    SUGGESTIONS_URL = 'https://trends.google.com/trends/api/autocomplete'
    CATEGORIES_URL = 'https://trends.google.com/trends/api/explore/pickers/category'
    REALTIME_TRENDING_URL = 'https://trends.google.com/trends/api/realtimetrends'
    TODAY_SEARCHES_URL = 'https://trends.google.com/trends/api/dailytrends'

    # ä½¿ç”¨å…¬å…±sessionç®¡ç†ï¼Œä¸å†éœ€è¦DEFAULT_HEADERS
    pass
    
    def __init__(
        self,
        hl: str = 'en-US',
        tz: int = 360,
        timeout: tuple[float, float] = (3, 7),
        proxies: Optional[Dict[str, str]] = None,
        retries: int = 3,
        backoff_factor: float = 0.3,
        initial_retry_delay: float = 8.0,
        max_retry_backoff: float = 180.0,
    ):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯

        Args:
            hl: è¯­è¨€è®¾ç½® (é»˜è®¤: 'en-US')
            tz: æ—¶åŒºåç§» (é»˜è®¤: 360)
            timeout: è¯·æ±‚è¶…æ—¶è®¾ç½®ï¼Œæ ¼å¼ä¸º (è¿æ¥è¶…æ—¶ç§’æ•°, è¯»å–è¶…æ—¶ç§’æ•°)
            proxies: ä»£ç†è®¾ç½®
            retries: è¯·æ±‚å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°
            backoff_factor: é‡è¯•é—´éš”çš„é€€é¿å› å­ï¼ˆç”¨äºç½‘ç»œå¼‚å¸¸ï¼‰
            initial_retry_delay: æŒ‡æ•°é€€é¿çš„åˆå§‹ç­‰å¾…ç§’æ•°
            max_retry_backoff: æŒ‡æ•°é€€é¿çš„æœ€å¤§ç­‰å¾…ä¸Šé™
        """
        self.hl = hl
        self.tz = tz
        self.timeout = timeout  # (connect_timeout, read_timeout)
        self.proxies = proxies
        self.retries = max(int(retries), 0)
        self.backoff_factor = max(float(backoff_factor), 0.1)
        self.initial_retry_delay = max(float(initial_retry_delay), 3.0)
        self.max_retry_backoff = max(float(max_retry_backoff), self.initial_retry_delay)
        self.initialized = False
        self._retry_multiplier = 2.0
        self._retry_jitter = (0.75, 1.25)

        # ä¼šè¯ç®¡ç† - ä½¿ç”¨å…¨å±€sessioné¿å…é‡å¤åˆå§‹åŒ–
        from .google_trends_session import get_global_session
        self.trends_session = get_global_session()
        self.session = self.trends_session.get_session()

        # ç®€å•çš„å†…å­˜ç¼“å­˜
        self._cache: Dict[str, Any] = {}

    
    # _init_session æ–¹æ³•å·²ç§»è‡³ GoogleTrendsSession ç±»ä¸­ç»Ÿä¸€ç®¡ç†
    
    def _calculate_retry_delay(self, attempt: int, base_delay: Optional[float] = None) -> float:
        """è®¡ç®—æŒ‡æ•°é€€é¿ç­‰å¾…æ—¶é—´"""
        if attempt <= 0:
            return 0.0
        base = max(base_delay if base_delay is not None else self.initial_retry_delay, 0.5)
        delay = base * (self._retry_multiplier ** (attempt - 1))
        jitter_min, jitter_max = self._retry_jitter
        jitter = random.uniform(jitter_min, jitter_max)
        return min(delay * jitter, self.max_retry_backoff)


    def _get_data(
        self,
        url: str,
        method: str = 'get',
        trim_chars: int = 0,
        use_cache: bool = True,
        **kwargs,
    ) -> Union[dict[Any, Any], None, Any]:
        """å‘é€è¯·æ±‚è·å–æ•°æ®"""
        cache_key = None
        if use_cache:
            cache_data = {
                'url': url,
                'method': method,
                'kwargs': kwargs
            }
            cache_key = hashlib.md5(json.dumps(cache_data, sort_keys=True).encode()).hexdigest()
            if cache_key in self._cache:
                logger.debug(f"ä½¿ç”¨ç¼“å­˜æ•°æ®: {url}")
                return self._cache[cache_key]

        for attempt in range(self.retries + 1):
            if attempt > 0:
                backoff_delay = self._calculate_retry_delay(attempt)
                logger.debug(f"â³ ç¬¬{attempt}æ¬¡é‡è¯•æŒ‡æ•°é€€é¿ {backoff_delay:.1f} ç§’")
                time.sleep(backoff_delay)

            try:
                stats = get_rate_limiter_stats()
                logger.debug(f"ğŸ“Š è¯·æ±‚å‰ç»Ÿè®¡: {stats}")
                wait_for_next_request()
            except RuntimeError as quota_error:
                logger.error(f"âŒ è¯·æ±‚è¢«é…é¢å®ˆå«é˜»æ­¢: {quota_error}")
                return {}
            except Exception as limiter_error:
                logger.warning(f"âš ï¸ é¢‘ç‡æ§åˆ¶å™¨æ£€æŸ¥å¤±è´¥: {limiter_error}")

            try:
                self.session = self.trends_session.get_session()
            except Exception as session_error:
                logger.error(f"âŒ è·å–Google Trends sessionå¤±è´¥: {session_error}")
                if attempt < self.retries:
                    penalty = register_rate_limit_event('medium')
                    logger.debug(f"Sessionæ¢å¤ï¼Œå»ºè®®é¢å¤–ç­‰å¾… {penalty:.1f} ç§’")
                    continue
                return {}

            s = self.session
            s.headers.update({'accept-language': self.hl})
            if self.proxies:
                s.proxies.update(self.proxies)

            try:
                response = self.trends_session.make_request(
                    method.upper(),
                    url,
                    timeout=self.timeout,
                    **kwargs
                )
            except requests.exceptions.RequestException as request_error:
                logger.warning(f"è¯·æ±‚å¼‚å¸¸: {request_error}")
                if attempt < self.retries:
                    penalty = register_rate_limit_event('medium')
                    logger.debug(f"è¯·æ±‚å¼‚å¸¸åç­‰å¾…å»ºè®® {penalty:.1f} ç§’")
                    continue
                logger.error(f"è¯·æ±‚æœ€ç»ˆå¤±è´¥: {request_error}")
                return {}

            if response.status_code == 429:
                if attempt < self.retries:
                    logger.warning(f"âš ï¸ é‡åˆ°429é”™è¯¯ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•")
                    logger.warning(f"ğŸ”— è¯·æ±‚URL: {url}")
                    penalty = register_rate_limit_event('high')
                    logger.warning(f"â³ èŠ‚æµæç¤ºï¼Œé¢å¤–ç­‰å¾… {penalty:.1f} ç§’")
                    try:
                        from .google_trends_session import reset_global_session
                        reset_global_session()
                        self.trends_session = get_global_session()
                        self.session = self.trends_session.get_session()
                    except Exception as reset_error:
                        logger.error(f"âŒ é‡ç½®Sessionå¤±è´¥: {reset_error}")
                    continue

                register_rate_limit_event('high')
                logger.error("âŒ å¤šæ¬¡é‡åˆ°429é”™è¯¯ï¼Œè¯·æ±‚å¤±è´¥")
                return {}

            try:
                response.raise_for_status()
            except requests.exceptions.HTTPError as http_error:
                logger.warning(f"HTTPé”™è¯¯: {http_error}")
                if attempt < self.retries:
                    penalty = register_rate_limit_event('medium')
                    logger.debug(f"HTTPé”™è¯¯åç­‰å¾…å»ºè®® {penalty:.1f} ç§’")
                    continue
                logger.error(f"è¯·æ±‚æœ€ç»ˆå¤±è´¥: {http_error}")
                return {}

            content = response.text[trim_chars:] if trim_chars > 0 else response.text

            try:
                result = json.loads(content)
                if cache_key:
                    self._cache[cache_key] = result
                return result
            except json.JSONDecodeError:
                logger.warning(f"æ— æ³•è§£æJSONå“åº”: {content[:100]}...")
                return {}

        return {}


    def clear_cache(self) -> None:
        """æ¸…é™¤è¯·æ±‚ç¼“å­˜"""
        self._cache.clear()
        logger.info("è¯·æ±‚ç¼“å­˜å·²æ¸…é™¤")
    
    def reset_session(self) -> None:
        """é‡ç½®ä¼šè¯"""
        try:
            from .google_trends_session import reset_global_session
            reset_global_session()
            self.trends_session = get_global_session()
            self.session = self.trends_session.get_session()
            logger.info("ä¼šè¯å·²é‡ç½®")
        except Exception as e:
            logger.error(f"é‡ç½®ä¼šè¯å¤±è´¥: {e}")
    
    def __enter__(self) -> 'TrendsAPIClient':
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        try:
            self.session.close()
        except:
            pass
    
    def __del__(self) -> None:
        """ææ„å‡½æ•°"""
        try:
            self.session.close()
        except:
            pass


def error_handler(default_return: Any = None) -> Callable:
    """é”™è¯¯å¤„ç†è£…é¥°å™¨"""
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        def wrapper(*args, **kwargs) -> T:
            try:
                return func(*args, **kwargs)
            except Exception as e:
                logger.error(f"{func.__name__} å¤±è´¥: {e}")
                return default_return() if callable(default_return) else default_return
        return wrapper
    return decorator


class CustomTrendsCollector(TrendsAPIClient):
    """è‡ªå®šä¹‰Google Trendsæ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self, hl: str = 'en-US', tz: int = 360, geo: str = '', 
                 timeout: tuple = (5, 20), proxies: Optional[Dict[str, str]] = None, 
                 retries: int = 1, backoff_factor: float = 0.5):
        """åˆå§‹åŒ–é‡‡é›†å™¨"""
        super().__init__(hl, tz, timeout, proxies, retries, backoff_factor)
        
        # è¯·æ±‚å‚æ•°
        self.kw_list: List[str] = []
        self.cat: int = 0
        self.timeframe: str = 'today 12-m'
        self.geo: str = geo
        self.gprop: str = ''
    
    def build_payload(self, kw_list: List[str], cat: int = 0, timeframe: str = 'today 12-m', 
                     geo: str = '', gprop: str = '') -> JsonDict:
        """æ„å»ºè¯·æ±‚è½½è·"""
        self.kw_list = kw_list
        self.cat = cat
        self.timeframe = timeframe
        self.geo = geo
        self.gprop = gprop
        
        # æ ‡å‡†åŒ–æ—¶é—´æ ¼å¼
        normalized_timeframe = self._normalize_timeframe(timeframe)
        
        # æ„å»ºæ¯”è¾ƒæ•°æ®ç»“æ„
        comparisonItem = [{'keyword': kw, 'geo': geo, 'time': normalized_timeframe} for kw in kw_list]
        
        return {
            'comparisonItem': comparisonItem,
            'category': cat,
            'property': gprop
        }
    
    def _normalize_timeframe(self, timeframe: str) -> str:
        """æ ‡å‡†åŒ–æ—¶é—´æ ¼å¼ä¸ºGoogle Trends APIæ¥å—çš„æ ¼å¼"""
        # ç§»é™¤ç©ºæ ¼å¹¶è½¬æ¢ä¸ºå°å†™
        timeframe = timeframe.strip().lower()
        
        # æ—¶é—´æ ¼å¼æ˜ å°„è¡¨
        timeframe_mapping = {
            '1d': 'now 1-d',
            '7d': 'now 7-d', 
            '30d': 'today 1-m',
            '90d': 'today 3-m',
            '12m': 'today 12-m',
            '5y': 'today 5-y',
            # ä¿æŒåŸæœ‰æ ¼å¼
            'now 1-d': 'now 1-d',
            'now 7-d': 'now 7-d',
            'today 1-m': 'today 1-m',
            'today 3-m': 'today 3-m', 
            'today 12-m': 'today 12-m',
            'today 5-y': 'today 5-y',
            'all': 'all'
        }
        
        # å¦‚æœåœ¨æ˜ å°„è¡¨ä¸­æ‰¾åˆ°ï¼Œä½¿ç”¨æ˜ å°„å€¼
        if timeframe in timeframe_mapping:
            normalized = timeframe_mapping[timeframe]
            logger.debug(f"æ—¶é—´æ ¼å¼æ ‡å‡†åŒ–: {timeframe} -> {normalized}")
            return normalized
        
        # å¦‚æœå·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if timeframe.startswith(('now ', 'today ')) or timeframe == 'all':
            return timeframe
        
        # é»˜è®¤è¿”å›åŸæ ¼å¼ï¼Œä½†è®°å½•è­¦å‘Š
        logger.warning(f"æœªè¯†åˆ«çš„æ—¶é—´æ ¼å¼: {timeframe}ï¼Œä½¿ç”¨åŸæ ¼å¼")
        return timeframe
    
    def _get_token_response(self) -> JsonDict:
        """è·å–tokenå“åº”"""
        if not self.kw_list:
            raise ValueError("è¯·å…ˆè®¾ç½®å…³é”®è¯åˆ—è¡¨")
        
        payload = self.build_payload(self.kw_list, self.cat, self.timeframe, self.geo, self.gprop)
        
        token_payload = {
            'hl': self.hl,
            'tz': self.tz,
            'req': json.dumps(payload)
        }
        
        return self._get_data(
            self.GENERAL_URL,
            method='get',
            params=token_payload,
            trim_chars=4
        )
    
    def _find_widget(self, token_response: JsonDict, widget_id: str) -> Optional[JsonDict]:
        """æŸ¥æ‰¾ç‰¹å®šIDçš„widget"""
        if not token_response or 'widgets' not in token_response:
            return None
            
        for widget in token_response['widgets']:
            if widget.get('id') == widget_id:
                return widget
                
        return None
    
    def _get_widget_data(self, widget: JsonDict, url: str) -> JsonDict:
        """è·å–widgetæ•°æ®"""
        data_payload = {
            'hl': self.hl,
            'tz': self.tz,
            'req': json.dumps(widget['request']),
            'token': widget['token']
        }
        
        return self._get_data(
            url,
            method='get',
            params=data_payload,
            trim_chars=5
        )
    
    def _with_temp_settings(self, func: Callable[[], T], **kwargs) -> T:
        """ä½¿ç”¨ä¸´æ—¶è®¾ç½®æ‰§è¡Œå‡½æ•°"""
        # ä¿å­˜åŸå§‹è®¾ç½®
        original_settings = {
            'kw_list': self.kw_list,
            'timeframe': self.timeframe,
            'geo': self.geo,
            'cat': self.cat,
            'gprop': self.gprop
        }
        
        # åº”ç”¨ä¸´æ—¶è®¾ç½®
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)
        
        try:
            # æ‰§è¡Œå‡½æ•°
            return func()
        finally:
            # æ¢å¤åŸå§‹è®¾ç½®
            for key, value in original_settings.items():
                setattr(self, key, value)
    
    @error_handler(pd.DataFrame)
    def interest_over_time(self) -> DataFrame:
        """è·å–å…³é”®è¯éšæ—¶é—´å˜åŒ–çš„å…´è¶£åº¦"""
        token_response = self._get_token_response()
        
        # æ‰¾åˆ°æ—¶é—´åºåˆ—widget
        widget = self._find_widget(token_response, 'TIMESERIES')
        
        if not widget:
            logger.error("æœªæ‰¾åˆ°æ—¶é—´åºåˆ—widget")
            return pd.DataFrame()
        
        # è·å–å®é™…æ•°æ®
        data_response = self._get_widget_data(widget, self.INTEREST_OVER_TIME_URL)
        
        if not data_response or 'default' not in data_response:
            logger.error("æ— æ³•è·å–æ—¶é—´åºåˆ—æ•°æ®")
            return pd.DataFrame()
        
        # è§£ææ•°æ®
        timeline_data = data_response['default']['timelineData']
        
        # æ„å»ºDataFrame
        df_data = []
        for point in timeline_data:
            row = {'date': point['formattedTime']}
            for i, value in enumerate(point['value']):
                if i < len(self.kw_list):
                    row[self.kw_list[i]] = value
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        if not df.empty:
            try:
                df['date'] = pd.to_datetime(df['date'], format='mixed', errors='coerce')
                df.set_index('date', inplace=True)
            except:
                logger.warning("æ—¥æœŸæ ¼å¼è½¬æ¢å¤±è´¥")
        
        return df
    
    @error_handler(pd.DataFrame)
    def interest_by_region(self, resolution: str = 'COUNTRY', inc_low_vol: bool = True, 
                          inc_geo_code: bool = False) -> DataFrame:
        """è·å–æŒ‰åœ°åŒºåˆ†å¸ƒçš„å…´è¶£åº¦"""
        token_response = self._get_token_response()
        
        # æ‰¾åˆ°åœ°åŒºwidget
        widget = self._find_widget(token_response, 'GEO_MAP')
        
        if not widget:
            logger.error("æœªæ‰¾åˆ°åœ°åŒºwidget")
            return pd.DataFrame()
        
        # ä¿®æ”¹è¯·æ±‚å‚æ•°
        widget['request']['resolution'] = resolution
        widget['request']['includeLowSearchVolumeGeos'] = inc_low_vol
        
        # è·å–å®é™…æ•°æ®
        data_response = self._get_widget_data(widget, self.INTEREST_BY_REGION_URL)
        
        if not data_response or 'default' not in data_response:
            logger.error("æ— æ³•è·å–åœ°åŒºæ•°æ®")
            return pd.DataFrame()
        
        # è§£ææ•°æ®
        geo_data = data_response['default']['geoMapData']
        
        df_data = []
        for item in geo_data:
            row = {
                'geoName': item['geoName'],
                'geoCode': item['geoCode'] if inc_geo_code else None
            }
            for i, value in enumerate(item['value']):
                if i < len(self.kw_list):
                    row[self.kw_list[i]] = value
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        if not inc_geo_code and 'geoCode' in df.columns:
            df.drop('geoCode', axis=1, inplace=True)
        
        return df
    
    def _process_ranked_list(self, ranked_list: JsonDict, is_topic: bool = True) -> DataFrame:
        """å¤„ç†æ’ååˆ—è¡¨æ•°æ®"""
        items = []
        for item in ranked_list.get('rankedKeyword', []):
            if is_topic:
                topic_data = item.get('topic', {})
                items.append({
                    'topic_title': topic_data.get('title', ''),
                    'topic_type': topic_data.get('type', ''),
                    'value': item.get('value', 0)
                })
            else:
                items.append({
                    'query': item.get('query', ''),
                    'value': item.get('value', 0)
                })
        
        return pd.DataFrame(items)
    
    @error_handler(dict)
    def related_topics(self) -> Dict[str, Dict[str, DataFrame]]:
        """è·å–ç›¸å…³ä¸»é¢˜"""
        token_response = self._get_token_response()
        results: Dict[str, Dict[str, DataFrame]] = {}
        
        # æŸ¥æ‰¾ç›¸å…³ä¸»é¢˜widgets
        for widget in token_response.get('widgets', []):
            if widget.get('id') == 'RELATED_TOPICS':
                data_response = self._get_widget_data(widget, self.RELATED_TOPICS_URL)
                
                if data_response and 'default' in data_response:
                    # è§£æç›¸å…³ä¸»é¢˜æ•°æ®
                    related_data = data_response['default']
                    
                    # å¤„ç†topå’Œrisingæ•°æ®
                    for kw in self.kw_list:
                        if kw not in results:
                            results[kw] = {}
                        
                        if 'rankedList' in related_data:
                            for ranked_list in related_data['rankedList']:
                                list_type = 'top' if ranked_list.get('rankedKeyword', [{}])[0].get('topic', {}).get('type') == 'ENTITY' else 'rising'
                                results[kw][list_type] = self._process_ranked_list(ranked_list, is_topic=True)
        
        return results
    
    @error_handler(dict)
    def related_queries(self) -> Dict[str, Dict[str, DataFrame]]:
        """è·å–ç›¸å…³æŸ¥è¯¢"""
        token_response = self._get_token_response()
        results: Dict[str, Dict[str, DataFrame]] = {}
        
        # æŸ¥æ‰¾ç›¸å…³æŸ¥è¯¢widgets
        for widget in token_response.get('widgets', []):
            if widget.get('id') == 'RELATED_QUERIES':
                data_response = self._get_widget_data(widget, self.RELATED_TOPICS_URL)
                
                if data_response and 'default' in data_response:
                    related_data = data_response['default']
                    
                    for kw in self.kw_list:
                        if kw not in results:
                            results[kw] = {}
                        
                        if 'rankedList' in related_data:
                            for ranked_list in related_data['rankedList']:
                                list_type = 'top' if 'top' in str(ranked_list) else 'rising'
                                results[kw][list_type] = self._process_ranked_list(ranked_list, is_topic=False)
        
        return results

    @error_handler(dict)
    def batch_related_queries(
        self,
        keywords: List[str],
        timeframe: str = 'today 3-m',
        geo: str = '',
        cat: int = 0,
        gprop: str = '',
        delay_per_batch: int = 5
    ) -> Dict[str, Dict[str, DataFrame]]:
        """ä¸ºå¤§é‡å…³é”®è¯è‡ªåŠ¨åˆ†æ‰¹è·å–å…¶'ç›¸å…³æŸ¥è¯¢'"""
        final_results: Dict[str, Dict[str, DataFrame]] = {}
        batch_size = 5  # Google Trends API é™åˆ¶

        logger.info(f"å¼€å§‹ä¸º {len(keywords)} ä¸ªå…³é”®è¯æ‰¹é‡è·å–ç›¸å…³æŸ¥è¯¢...")

        for i in range(0, len(keywords), batch_size):
            batch = keywords[i:i + batch_size]
            logger.info(f"æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}ï¼Œå…³é”®è¯: {batch}")

            # è®¾ç½®å½“å‰æ‰¹æ¬¡çš„å…³é”®è¯
            self.build_payload(batch, cat=cat, timeframe=timeframe, geo=geo, gprop=gprop)
            
            # è·å–ç›¸å…³æŸ¥è¯¢æ•°æ®
            batch_result = self.related_queries()

            if batch_result:
                final_results.update(batch_result)
            else:
                logger.warning(f"æ‰¹æ¬¡ {i//batch_size + 1} æœªè¿”å›ä»»ä½•æ•°æ®ã€‚")

            # åœ¨æ‰¹æ¬¡ä¹‹é—´æ·»åŠ å»¶è¿Ÿ
            if i + batch_size < len(keywords):
                logger.info(f"æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œæš‚åœ {delay_per_batch} ç§’...")
                time.sleep(delay_per_batch)
        
        logger.info(f"æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œå…±è·å–äº† {len(final_results)} ä¸ªå…³é”®è¯çš„ç›¸å…³æŸ¥è¯¢ã€‚")
        return final_results
    
    @error_handler(pd.DataFrame)
    def trending_searches(self, pn: str = 'united_states') -> DataFrame:
        """è·å–çƒ­é—¨æœç´¢"""
        params = {
            'hl': self.hl,
            'tz': self.tz,
            'geo': pn,
            'ns': 15
        }
        
        response = self._get_data(
            self.TRENDING_SEARCHES_URL,
            method='get',
            params=params
        )
        
        if not response:
            return pd.DataFrame()
        
        # è§£æçƒ­é—¨æœç´¢æ•°æ®
        trending_data = []
        if isinstance(response, dict) and 'default' in response:
            for item in response['default'].get('trendingSearchesDays', []):
                for search in item.get('trendingSearches', []):
                    trending_data.append({
                        'title': search.get('title', {}).get('query', ''),
                        'traffic': search.get('formattedTraffic', ''),
                        'date': item.get('date', '')
                    })
        
        return pd.DataFrame(trending_data)
    
    @error_handler(list)
    def suggestions(self, keyword: str) -> List[Dict[str, str]]:
        """è·å–å…³é”®è¯å»ºè®®"""
        params = {
            'hl': self.hl,
            'tz': self.tz
        }
        
        response = self._get_data(
            self.SUGGESTIONS_URL + '/' + keyword,
            method='get',
            params=params,
            trim_chars=5
        )
        
        if not response or 'default' not in response:
            return []
        
        suggestions = []
        for item in response['default'].get('topics', []):
            suggestions.append({
                'title': item.get('title', ''),
                'type': item.get('type', ''),
                'mid': item.get('mid', '')
            })
        
        return suggestions
    
    def get_historical_interest(self, keyword: str, start_date: Optional[str] = None, 
                               end_date: Optional[str] = None) -> DataFrame:
        """è·å–å†å²å…´è¶£æ•°æ®"""
        timeframe = f"{start_date} {end_date}" if start_date and end_date else self.timeframe
        
        # ä½¿ç”¨ä¸´æ—¶è®¾ç½®æ‰§è¡Œ
        return self._with_temp_settings(
            self.interest_over_time,
            kw_list=[keyword],
            timeframe=timeframe
        )
    
    @error_handler(dict)
    def get_search_volume_estimate(self, keyword: str, timeframe: str = 'today 12-m') -> JsonDict:
        """è·å–æœç´¢é‡ä¼°ç®—ï¼ˆåŸºäºè¶‹åŠ¿æ•°æ®ï¼‰"""
        df = self._with_temp_settings(
            self.interest_over_time,
            kw_list=[keyword],
            timeframe=timeframe
        )
        
        if df.empty:
            return {'keyword': keyword, 'estimate': 'No data', 'trend': 'Unknown'}
        
        # è®¡ç®—åŸºæœ¬ç»Ÿè®¡
        values = df[keyword].dropna()
        if values.empty:
            return {'keyword': keyword, 'estimate': 'No data', 'trend': 'Unknown'}
        
        avg_interest = values.mean()
        max_interest = values.max()
        min_interest = values.min()
        
        # è®¡ç®—è¶‹åŠ¿æ–¹å‘
        if len(values) >= 2:
            recent_avg = values.tail(4).mean()  # æœ€è¿‘4ä¸ªæ•°æ®ç‚¹
            earlier_avg = values.head(4).mean()  # æœ€æ—©4ä¸ªæ•°æ®ç‚¹
            
            if recent_avg > earlier_avg * 1.1:
                trend = 'Rising'
            elif recent_avg < earlier_avg * 0.9:
                trend = 'Declining'
            else:
                trend = 'Stable'
        else:
            trend = 'Unknown'
        
        # ä¼°ç®—æœç´¢é‡çº§åˆ«
        if avg_interest >= 80:
            volume_estimate = 'Very High'
        elif avg_interest >= 60:
            volume_estimate = 'High'
        elif avg_interest >= 40:
            volume_estimate = 'Medium'
        elif avg_interest >= 20:
            volume_estimate = 'Low'
        else:
            volume_estimate = 'Very Low'
        
        return {
            'keyword': keyword,
            'estimate': volume_estimate,
            'trend': trend,
            'avg_interest': round(avg_interest, 2),
            'max_interest': max_interest,
            'min_interest': min_interest,
            'data_points': len(values)
        }
    
    @error_handler(pd.DataFrame)
    def get_trends_data(self, keywords, timeframe='today 12-m', geo=''):
        """è·å–å…³é”®è¯çš„è¶‹åŠ¿æ•°æ® (å…¼å®¹æ–¹æ³•)"""
        # æ„å»ºpayloadå¹¶è·å–æ•°æ®
        self.build_payload(keywords, timeframe=timeframe, geo=geo)
        return self.interest_over_time()
    
    @error_handler(dict)
    def get_keyword_trends(self, keyword, timeframe='today 12-m', geo=''):
        """è·å–å…³é”®è¯è¶‹åŠ¿æ•°æ® - ä¸ºroot_word_trends_analyzeræä¾›çš„æ¥å£

        Args:
            keyword: å…³é”®è¯ï¼ˆå­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            timeframe: æ—¶é—´èŒƒå›´
            geo: åœ°ç†ä½ç½®

        Returns:
            åŒ…å«è¶‹åŠ¿æ•°æ®å’Œç›¸å…³æŸ¥è¯¢çš„å­—å…¸
        """
        try:
            # ç¡®ä¿keywordæ˜¯åˆ—è¡¨æ ¼å¼
            if isinstance(keyword, str):
                keywords = [keyword]
            else:
                keywords = keyword

            # æ„å»ºpayload
            self.build_payload(keywords, timeframe=timeframe, geo=geo)

            # è·å–è¶‹åŠ¿æ•°æ®
            interest_data = self.interest_over_time()

            # è·å–ç›¸å…³æŸ¥è¯¢
            related_queries = self.related_queries()

            # æ„å»ºè¿”å›æ•°æ®
            result = {
                'interest_over_time': interest_data,
                'related_queries': related_queries,
                'keyword': keywords[0] if len(keywords) == 1 else keywords,
                'timeframe': timeframe,
                'geo': geo
            }

            return result

        except Exception as e:
            logger.error(f"è·å–å…³é”®è¯è¶‹åŠ¿å¤±è´¥: {e}")
            return {}

# å…¨å±€sessionå®ä¾‹
_global_session = None

def get_global_session() -> GoogleTrendsSession:
    """è·å–å…¨å±€sessionå®ä¾‹"""
    global _global_session
    if _global_session is None:
        _global_session = GoogleTrendsSession()
    return _global_session

def reset_global_session() -> None:
    """é‡ç½®å…¨å±€session"""
    global _global_session
    if _global_session:
        _global_session.reset_session()
    else:
        _global_session = GoogleTrendsSession()

