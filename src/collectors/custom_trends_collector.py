"""
è‡ªå®šä¹‰Google Trendsæ•°æ®é‡‡é›†å™¨
æ›¿ä»£pytrendsåº“ï¼Œæä¾›æ›´çµæ´»çš„æ§åˆ¶å’Œæ›´æ–°èƒ½åŠ›
"""

import requests
import json
import time
import random
import threading
from typing import List, Dict, Optional, Callable, TypeVar, Any, Union
import pandas as pd
import logging
from functools import wraps
import hashlib

logger = logging.getLogger(__name__)

# ç±»å‹å˜é‡å®šä¹‰
T = TypeVar('T')
DataFrame = pd.DataFrame
JsonDict = Dict[str, Any]

class TrendsAPIClient:
    """Google Trends APIå®¢æˆ·ç«¯åŸºç±»"""
    
    # Google Trends API endpoints
    GENERAL_URL = 'https://trends.google.com/trends/api/explore'
    INTEREST_OVER_TIME_URL = 'https://trends.google.com/trends/api/widgetdata/multiline'
    INTEREST_BY_REGION_URL = 'https://trends.google.com/trends/api/widgetdata/comparedgeo'
    RELATED_TOPICS_URL = 'https://trends.google.com/trends/api/widgetdata/relatedsearches'
    TRENDING_SEARCHES_URL = 'https://trends.google.com/trends/hottrends/visualize/internal/data'
    TOP_CHARTS_URL = 'https://trends.google.com/trends/api/topcharts'
    SUGGESTIONS_URL = 'https://trends.google.com/trends/api/autocomplete'
    CATEGORIES_URL = 'https://trends.google.com/trends/api/explore/pickers/category'
    REALTIME_TRENDING_URL = 'https://trends.google.com/trends/api/realtimetrends'
    TODAY_SEARCHES_URL = 'https://trends.google.com/trends/api/dailytrends'
    
    # é»˜è®¤è¯·æ±‚å¤´
    DEFAULT_HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'application/json, text/plain, */*',
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
        'Referer': 'https://trends.google.com/',
        'Origin': 'https://trends.google.com',
        'Sec-Fetch-Dest': 'empty',
        'Sec-Fetch-Mode': 'cors',
        'Sec-Fetch-Site': 'same-origin',
        'Cache-Control': 'no-cache',
        'Pragma': 'no-cache'
    }
    
    def __init__(self, hl: str = 'en-US', tz: int = 360, 
                 timeout: tuple[float, float] = (3, 7), proxies: Optional[Dict[str, str]] = None, 
                 retries: int = 2, backoff_factor: float = 0.3):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        
        Args:
            hl: è¯­è¨€è®¾ç½® (é»˜è®¤: 'en-US')
            tz: æ—¶åŒºåç§» (é»˜è®¤: 360)
            timeout: è¯·æ±‚è¶…æ—¶è®¾ç½®ï¼Œæ ¼å¼ä¸º (è¿æ¥è¶…æ—¶ç§’æ•°, è¯»å–è¶…æ—¶ç§’æ•°)
            proxies: ä»£ç†è®¾ç½®
            retries: è¯·æ±‚å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°
            backoff_factor: é‡è¯•é—´éš”çš„é€€é¿å› å­
        """
        self.hl = hl
        self.tz = tz
        self.timeout = timeout  # (connect_timeout, read_timeout)
        self.proxies = proxies
        self.retries = retries
        self.backoff_factor = backoff_factor
        self.initialized = False
        
        # ä¼šè¯ç®¡ç†
        self.session = requests.Session()
        self.session.headers.update(self.DEFAULT_HEADERS)
        
        # å¼‚æ­¥åˆå§‹åŒ–ä¼šè¯ï¼Œä¸é˜»å¡ä¸»æµç¨‹
        self._init_session()
        
        # ç®€å•çš„å†…å­˜ç¼“å­˜
        self._cache: Dict[str, Any] = {}
    
    def _init_session(self) -> None:
        """åˆå§‹åŒ–ä¼šè¯ï¼Œè·å–å¿…è¦çš„cookies"""
        try:
            # è®¿é—®Google Trendsä¸»é¡µè·å–å¿…è¦çš„cookies
            logger.info("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–Google Trendsä¼šè¯...")
            
            # å…ˆè®¿é—®ä¸»é¡µè·å–cookies
            main_page_url = 'https://trends.google.com/'
            response = self.session.get(main_page_url, timeout=self.timeout)
            
            if response.status_code == 200:
                self.initialized = True
                logger.info("âœ… Google Trendsä¼šè¯åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning(f"âš ï¸ ä¸»é¡µè®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                self.initialized = False
                
        except Exception as e:
            logger.error(f"âŒ ä¼šè¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.initialized = False
    
    def _get_data(self, url: str, method: str = 'get', trim_chars: int = 0, 
                  use_cache: bool = True, **kwargs) -> Union[dict[Any, Any], None, Any]:
        """å‘é€è¯·æ±‚è·å–æ•°æ®"""
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = None
        if use_cache:
            cache_data = {
                'url': url,
                'method': method,
                'kwargs': kwargs
            }
            cache_key = hashlib.md5(json.dumps(cache_data, sort_keys=True).encode()).hexdigest()
            if cache_key in self._cache:
                logger.debug(f"ä½¿ç”¨ç¼“å­˜æ•°æ®: {url}")
                return self._cache[cache_key]
        
        # ç›´æ¥å‘é€è¯·æ±‚ï¼Œæ— é”
        s = self.session
        s.headers.update({'accept-language': self.hl})
        
        if self.proxies:
            s.proxies.update(self.proxies)
        
        # åœ¨æ¯ä¸ªè¯·æ±‚å‰æ·»åŠ å›ºå®šå»¶è¿Ÿï¼Œé¿å…å¹¶å‘è¯·æ±‚
        time.sleep(1)
        
        for attempt in range(self.retries + 1):
            try:
                # æ·»åŠ éšæœºå»¶è¿Ÿé¿å…429é”™è¯¯
                if attempt > 0:
                    delay = random.uniform(5, 10) + (attempt * 3)
                    time.sleep(delay)
                
                response = s.get(url, timeout=self.timeout, **kwargs) if method.lower() == 'get' else s.post(url, timeout=self.timeout, **kwargs)
                
                # ç‰¹æ®Šå¤„ç†429é”™è¯¯
                if response.status_code == 429:
                    if attempt < self.retries:
                        wait_time = 20 + (attempt * 10) + random.uniform(5, 15)
                        logger.warning(f"é‡åˆ°429é”™è¯¯ï¼Œç­‰å¾…{wait_time:.1f}ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                        continue
                    else:
                        logger.error("å¤šæ¬¡é‡åˆ°429é”™è¯¯ï¼Œè¯·æ±‚å¤±è´¥")
                        return {}
                
                response.raise_for_status()
                
                # å¤„ç†å“åº”æ•°æ®
                content = response.text[trim_chars:] if trim_chars > 0 else response.text
                
                # å°è¯•è§£æJSON
                try:
                    result = json.loads(content)
                    # ç¼“å­˜ç»“æœ
                    if cache_key:
                        self._cache[cache_key] = result
                    return result
                except json.JSONDecodeError:
                    logger.warning(f"æ— æ³•è§£æJSONå“åº”: {content[:100]}...")
                    return {}
                    
            except requests.exceptions.RequestException as e:
                if attempt < self.retries:
                    wait_time = self.backoff_factor * (2 ** attempt) + random.uniform(1, 3)
                    logger.warning(f"è¯·æ±‚å¤±è´¥ï¼Œç­‰å¾…{wait_time:.1f}ç§’åé‡è¯•: {e}")
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(f"è¯·æ±‚æœ€ç»ˆå¤±è´¥: {e}")
                    return {}
    
    def clear_cache(self) -> None:
        """æ¸…é™¤è¯·æ±‚ç¼“å­˜"""
        self._cache.clear()
        logger.info("è¯·æ±‚ç¼“å­˜å·²æ¸…é™¤")
    
    def reset_session(self) -> None:
        """é‡ç½®ä¼šè¯"""
        try:
            self.session.close()
            self.session = requests.Session()
            self.session.headers.update(self.DEFAULT_HEADERS)
            self._init_session()
            logger.info("ä¼šè¯å·²é‡ç½®")
        except Exception as e:
            logger.error(f"é‡ç½®ä¼šè¯å¤±è´¥: {e}")
    
    def __enter__(self) -> 'TrendsAPIClient':
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        try:
            self.session.close()
        except:
            pass
    
    def __del__(self) -> None:
        """ææ„å‡½æ•°"""
        try:
            self.session.close()
        except:
            pass


def error_handler(default_return: Any = None) -> Callable:
    """é”™è¯¯å¤„ç†è£…é¥°å™¨"""
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        def wrapper(*args, **kwargs) -> T:
            try:
                return func(*args, **kwargs)
            except Exception as e:
                logger.error(f"{func.__name__} å¤±è´¥: {e}")
                return default_return() if callable(default_return) else default_return
        return wrapper
    return decorator


class CustomTrendsCollector(TrendsAPIClient):
    """è‡ªå®šä¹‰Google Trendsæ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self, hl: str = 'en-US', tz: int = 360, geo: str = '', 
                 timeout: tuple = (5, 20), proxies: Optional[Dict[str, str]] = None, 
                 retries: int = 1, backoff_factor: float = 0.5):
        """åˆå§‹åŒ–é‡‡é›†å™¨"""
        super().__init__(hl, tz, timeout, proxies, retries, backoff_factor)
        
        # è¯·æ±‚å‚æ•°
        self.kw_list: List[str] = []
        self.cat: int = 0
        self.timeframe: str = 'today 12-m'
        self.geo: str = geo
        self.gprop: str = ''
    
    def build_payload(self, kw_list: List[str], cat: int = 0, timeframe: str = 'today 12-m', 
                     geo: str = '', gprop: str = '') -> JsonDict:
        """æ„å»ºè¯·æ±‚è½½è·"""
        self.kw_list = kw_list
        self.cat = cat
        self.timeframe = timeframe
        self.geo = geo
        self.gprop = gprop
        
        # æ„å»ºæ¯”è¾ƒæ•°æ®ç»“æ„
        comparisonItem = [{'keyword': kw, 'geo': geo, 'time': timeframe} for kw in kw_list]
        
        return {
            'comparisonItem': comparisonItem,
            'category': cat,
            'property': gprop
        }
    
    def _get_token_response(self) -> JsonDict:
        """è·å–tokenå“åº”"""
        if not self.kw_list:
            raise ValueError("è¯·å…ˆè®¾ç½®å…³é”®è¯åˆ—è¡¨")
        
        payload = self.build_payload(self.kw_list, self.cat, self.timeframe, self.geo, self.gprop)
        
        token_payload = {
            'hl': self.hl,
            'tz': self.tz,
            'req': json.dumps(payload)
        }
        
        return self._get_data(
            self.GENERAL_URL,
            method='get',
            params=token_payload,
            trim_chars=4
        )
    
    def _find_widget(self, token_response: JsonDict, widget_id: str) -> Optional[JsonDict]:
        """æŸ¥æ‰¾ç‰¹å®šIDçš„widget"""
        if not token_response or 'widgets' not in token_response:
            return None
            
        for widget in token_response['widgets']:
            if widget.get('id') == widget_id:
                return widget
                
        return None
    
    def _get_widget_data(self, widget: JsonDict, url: str) -> JsonDict:
        """è·å–widgetæ•°æ®"""
        data_payload = {
            'hl': self.hl,
            'tz': self.tz,
            'req': json.dumps(widget['request']),
            'token': widget['token']
        }
        
        return self._get_data(
            url,
            method='get',
            params=data_payload,
            trim_chars=5
        )
    
    def _with_temp_settings(self, func: Callable[[], T], **kwargs) -> T:
        """ä½¿ç”¨ä¸´æ—¶è®¾ç½®æ‰§è¡Œå‡½æ•°"""
        # ä¿å­˜åŸå§‹è®¾ç½®
        original_settings = {
            'kw_list': self.kw_list,
            'timeframe': self.timeframe,
            'geo': self.geo,
            'cat': self.cat,
            'gprop': self.gprop
        }
        
        # åº”ç”¨ä¸´æ—¶è®¾ç½®
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)
        
        try:
            # æ‰§è¡Œå‡½æ•°
            return func()
        finally:
            # æ¢å¤åŸå§‹è®¾ç½®
            for key, value in original_settings.items():
                setattr(self, key, value)
    
    @error_handler(pd.DataFrame)
    def interest_over_time(self) -> DataFrame:
        """è·å–å…³é”®è¯éšæ—¶é—´å˜åŒ–çš„å…´è¶£åº¦"""
        token_response = self._get_token_response()
        
        # æ‰¾åˆ°æ—¶é—´åºåˆ—widget
        widget = self._find_widget(token_response, 'TIMESERIES')
        
        if not widget:
            logger.error("æœªæ‰¾åˆ°æ—¶é—´åºåˆ—widget")
            return pd.DataFrame()
        
        # è·å–å®é™…æ•°æ®
        data_response = self._get_widget_data(widget, self.INTEREST_OVER_TIME_URL)
        
        if not data_response or 'default' not in data_response:
            logger.error("æ— æ³•è·å–æ—¶é—´åºåˆ—æ•°æ®")
            return pd.DataFrame()
        
        # è§£ææ•°æ®
        timeline_data = data_response['default']['timelineData']
        
        # æ„å»ºDataFrame
        df_data = []
        for point in timeline_data:
            row = {'date': point['formattedTime']}
            for i, value in enumerate(point['value']):
                if i < len(self.kw_list):
                    row[self.kw_list[i]] = value
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        if not df.empty:
            try:
                df['date'] = pd.to_datetime(df['date'])
                df.set_index('date', inplace=True)
            except:
                logger.warning("æ—¥æœŸæ ¼å¼è½¬æ¢å¤±è´¥")
        
        return df
    
    @error_handler(pd.DataFrame)
    def interest_by_region(self, resolution: str = 'COUNTRY', inc_low_vol: bool = True, 
                          inc_geo_code: bool = False) -> DataFrame:
        """è·å–æŒ‰åœ°åŒºåˆ†å¸ƒçš„å…´è¶£åº¦"""
        token_response = self._get_token_response()
        
        # æ‰¾åˆ°åœ°åŒºwidget
        widget = self._find_widget(token_response, 'GEO_MAP')
        
        if not widget:
            logger.error("æœªæ‰¾åˆ°åœ°åŒºwidget")
            return pd.DataFrame()
        
        # ä¿®æ”¹è¯·æ±‚å‚æ•°
        widget['request']['resolution'] = resolution
        widget['request']['includeLowSearchVolumeGeos'] = inc_low_vol
        
        # è·å–å®é™…æ•°æ®
        data_response = self._get_widget_data(widget, self.INTEREST_BY_REGION_URL)
        
        if not data_response or 'default' not in data_response:
            logger.error("æ— æ³•è·å–åœ°åŒºæ•°æ®")
            return pd.DataFrame()
        
        # è§£ææ•°æ®
        geo_data = data_response['default']['geoMapData']
        
        df_data = []
        for item in geo_data:
            row = {
                'geoName': item['geoName'],
                'geoCode': item['geoCode'] if inc_geo_code else None
            }
            for i, value in enumerate(item['value']):
                if i < len(self.kw_list):
                    row[self.kw_list[i]] = value
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        if not inc_geo_code and 'geoCode' in df.columns:
            df.drop('geoCode', axis=1, inplace=True)
        
        return df
    
    def _process_ranked_list(self, ranked_list: JsonDict, is_topic: bool = True) -> DataFrame:
        """å¤„ç†æ’ååˆ—è¡¨æ•°æ®"""
        items = []
        for item in ranked_list.get('rankedKeyword', []):
            if is_topic:
                topic_data = item.get('topic', {})
                items.append({
                    'topic_title': topic_data.get('title', ''),
                    'topic_type': topic_data.get('type', ''),
                    'value': item.get('value', 0)
                })
            else:
                items.append({
                    'query': item.get('query', ''),
                    'value': item.get('value', 0)
                })
        
        return pd.DataFrame(items)
    
    @error_handler(dict)
    def related_topics(self) -> Dict[str, Dict[str, DataFrame]]:
        """è·å–ç›¸å…³ä¸»é¢˜"""
        token_response = self._get_token_response()
        results: Dict[str, Dict[str, DataFrame]] = {}
        
        # æŸ¥æ‰¾ç›¸å…³ä¸»é¢˜widgets
        for widget in token_response.get('widgets', []):
            if widget.get('id') == 'RELATED_TOPICS':
                data_response = self._get_widget_data(widget, self.RELATED_TOPICS_URL)
                
                if data_response and 'default' in data_response:
                    # è§£æç›¸å…³ä¸»é¢˜æ•°æ®
                    related_data = data_response['default']
                    
                    # å¤„ç†topå’Œrisingæ•°æ®
                    for kw in self.kw_list:
                        if kw not in results:
                            results[kw] = {}
                        
                        if 'rankedList' in related_data:
                            for ranked_list in related_data['rankedList']:
                                list_type = 'top' if ranked_list.get('rankedKeyword', [{}])[0].get('topic', {}).get('type') == 'ENTITY' else 'rising'
                                results[kw][list_type] = self._process_ranked_list(ranked_list, is_topic=True)
        
        return results
    
    @error_handler(dict)
    def related_queries(self) -> Dict[str, Dict[str, DataFrame]]:
        """è·å–ç›¸å…³æŸ¥è¯¢"""
        token_response = self._get_token_response()
        results: Dict[str, Dict[str, DataFrame]] = {}
        
        # æŸ¥æ‰¾ç›¸å…³æŸ¥è¯¢widgets
        for widget in token_response.get('widgets', []):
            if widget.get('id') == 'RELATED_QUERIES':
                data_response = self._get_widget_data(widget, self.RELATED_TOPICS_URL)
                
                if data_response and 'default' in data_response:
                    related_data = data_response['default']
                    
                    for kw in self.kw_list:
                        if kw not in results:
                            results[kw] = {}
                        
                        if 'rankedList' in related_data:
                            for ranked_list in related_data['rankedList']:
                                list_type = 'top' if 'top' in str(ranked_list) else 'rising'
                                results[kw][list_type] = self._process_ranked_list(ranked_list, is_topic=False)
        
        return results

    @error_handler(dict)
    def batch_related_queries(
        self,
        keywords: List[str],
        timeframe: str = 'today 3-m',
        geo: str = '',
        cat: int = 0,
        gprop: str = '',
        delay_per_batch: int = 5
    ) -> Dict[str, Dict[str, DataFrame]]:
        """ä¸ºå¤§é‡å…³é”®è¯è‡ªåŠ¨åˆ†æ‰¹è·å–å…¶'ç›¸å…³æŸ¥è¯¢'"""
        final_results: Dict[str, Dict[str, DataFrame]] = {}
        batch_size = 5  # Google Trends API é™åˆ¶

        logger.info(f"å¼€å§‹ä¸º {len(keywords)} ä¸ªå…³é”®è¯æ‰¹é‡è·å–ç›¸å…³æŸ¥è¯¢...")

        for i in range(0, len(keywords), batch_size):
            batch = keywords[i:i + batch_size]
            logger.info(f"æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}ï¼Œå…³é”®è¯: {batch}")

            # è®¾ç½®å½“å‰æ‰¹æ¬¡çš„å…³é”®è¯
            self.build_payload(batch, cat=cat, timeframe=timeframe, geo=geo, gprop=gprop)
            
            # è·å–ç›¸å…³æŸ¥è¯¢æ•°æ®
            batch_result = self.related_queries()

            if batch_result:
                final_results.update(batch_result)
            else:
                logger.warning(f"æ‰¹æ¬¡ {i//batch_size + 1} æœªè¿”å›ä»»ä½•æ•°æ®ã€‚")

            # åœ¨æ‰¹æ¬¡ä¹‹é—´æ·»åŠ å»¶è¿Ÿ
            if i + batch_size < len(keywords):
                logger.info(f"æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œæš‚åœ {delay_per_batch} ç§’...")
                time.sleep(delay_per_batch)
        
        logger.info(f"æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œå…±è·å–äº† {len(final_results)} ä¸ªå…³é”®è¯çš„ç›¸å…³æŸ¥è¯¢ã€‚")
        return final_results
    
    @error_handler(pd.DataFrame)
    def trending_searches(self, pn: str = 'united_states') -> DataFrame:
        """è·å–çƒ­é—¨æœç´¢"""
        params = {
            'hl': self.hl,
            'tz': self.tz,
            'geo': pn,
            'ns': 15
        }
        
        response = self._get_data(
            self.TRENDING_SEARCHES_URL,
            method='get',
            params=params
        )
        
        if not response:
            return pd.DataFrame()
        
        # è§£æçƒ­é—¨æœç´¢æ•°æ®
        trending_data = []
        if isinstance(response, dict) and 'default' in response:
            for item in response['default'].get('trendingSearchesDays', []):
                for search in item.get('trendingSearches', []):
                    trending_data.append({
                        'title': search.get('title', {}).get('query', ''),
                        'traffic': search.get('formattedTraffic', ''),
                        'date': item.get('date', '')
                    })
        
        return pd.DataFrame(trending_data)
    
    @error_handler(list)
    def suggestions(self, keyword: str) -> List[Dict[str, str]]:
        """è·å–å…³é”®è¯å»ºè®®"""
        params = {
            'hl': self.hl,
            'tz': self.tz,
            'q': keyword
        }
        
        response = self._get_data(
            self.SUGGESTIONS_URL,
            method='get',
            params=params,
            trim_chars=5
        )
        
        if not response or 'default' not in response:
            return []
        
        suggestions = []
        for item in response['default'].get('topics', []):
            suggestions.append({
                'title': item.get('title', ''),
                'type': item.get('type', ''),
                'mid': item.get('mid', '')
            })
        
        return suggestions
    
    def get_historical_interest(self, keyword: str, start_date: Optional[str] = None, 
                               end_date: Optional[str] = None) -> DataFrame:
        """è·å–å†å²å…´è¶£æ•°æ®"""
        timeframe = f"{start_date} {end_date}" if start_date and end_date else self.timeframe
        
        # ä½¿ç”¨ä¸´æ—¶è®¾ç½®æ‰§è¡Œ
        return self._with_temp_settings(
            self.interest_over_time,
            kw_list=[keyword],
            timeframe=timeframe
        )
    
    @error_handler(dict)
    def get_search_volume_estimate(self, keyword: str, timeframe: str = 'today 12-m') -> JsonDict:
        """è·å–æœç´¢é‡ä¼°ç®—ï¼ˆåŸºäºè¶‹åŠ¿æ•°æ®ï¼‰"""
        df = self._with_temp_settings(
            self.interest_over_time,
            kw_list=[keyword],
            timeframe=timeframe
        )
        
        if df.empty:
            return {'keyword': keyword, 'estimate': 'No data', 'trend': 'Unknown'}
        
        # è®¡ç®—åŸºæœ¬ç»Ÿè®¡
        values = df[keyword].dropna()
        if values.empty:
            return {'keyword': keyword, 'estimate': 'No data', 'trend': 'Unknown'}
        
        avg_interest = values.mean()
        max_interest = values.max()
        min_interest = values.min()
        
        # è®¡ç®—è¶‹åŠ¿æ–¹å‘
        if len(values) >= 2:
            recent_avg = values.tail(4).mean()  # æœ€è¿‘4ä¸ªæ•°æ®ç‚¹
            earlier_avg = values.head(4).mean()  # æœ€æ—©4ä¸ªæ•°æ®ç‚¹
            
            if recent_avg > earlier_avg * 1.1:
                trend = 'Rising'
            elif recent_avg < earlier_avg * 0.9:
                trend = 'Declining'
            else:
                trend = 'Stable'
        else:
            trend = 'Unknown'
        
        # ä¼°ç®—æœç´¢é‡çº§åˆ«
        if avg_interest >= 80:
            volume_estimate = 'Very High'
        elif avg_interest >= 60:
            volume_estimate = 'High'
        elif avg_interest >= 40:
            volume_estimate = 'Medium'
        elif avg_interest >= 20:
            volume_estimate = 'Low'
        else:
            volume_estimate = 'Very Low'
        
        return {
            'keyword': keyword,
            'estimate': volume_estimate,
            'trend': trend,
            'avg_interest': round(avg_interest, 2),
            'max_interest': max_interest,
            'min_interest': min_interest,
            'data_points': len(values)
        }
    
    @error_handler(pd.DataFrame)
    def get_trends_data(self, keywords, timeframe='today 12-m', geo=''):
        """è·å–å…³é”®è¯çš„è¶‹åŠ¿æ•°æ® (å…¼å®¹æ–¹æ³•)"""
        # æ„å»ºpayloadå¹¶è·å–æ•°æ®
        self.build_payload(keywords, timeframe=timeframe, geo=geo)
        return self.interest_over_time()
    
    @error_handler(dict)
    def get_keyword_trends(self, keyword, timeframe='today 12-m', geo=''):
        """è·å–å…³é”®è¯è¶‹åŠ¿æ•°æ® - ä¸ºroot_word_trends_analyzeræä¾›çš„æ¥å£

        Args:
            keyword: å…³é”®è¯ï¼ˆå­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            timeframe: æ—¶é—´èŒƒå›´
            geo: åœ°ç†ä½ç½®

        Returns:
            åŒ…å«è¶‹åŠ¿æ•°æ®å’Œç›¸å…³æŸ¥è¯¢çš„å­—å…¸
        """
        try:
            # ç¡®ä¿keywordæ˜¯åˆ—è¡¨æ ¼å¼
            if isinstance(keyword, str):
                keywords = [keyword]
            else:
                keywords = keyword

            # æ„å»ºpayload
            self.build_payload(keywords, timeframe=timeframe, geo=geo)

            # è·å–è¶‹åŠ¿æ•°æ®
            interest_data = self.interest_over_time()

            # è·å–ç›¸å…³æŸ¥è¯¢
            related_queries = self.related_queries()

            # æ„å»ºè¿”å›æ•°æ®
            result = {
                'interest_over_time': interest_data,
                'related_queries': related_queries,
                'keyword': keywords[0] if len(keywords) == 1 else keywords,
                'timeframe': timeframe,
                'geo': geo
            }

            return result

        except Exception as e:
            logger.error(f"è·å–å…³é”®è¯è¶‹åŠ¿å¤±è´¥: {e}")
            return {}
