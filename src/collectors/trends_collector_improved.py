#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹è¿›ç‰ˆGoogle Trends æ•°æ®é‡‡é›†æ¨¡å—
æ·»åŠ äº†æ›´å¥½çš„é€Ÿç‡é™åˆ¶å¤„ç†ï¼Œé¿å…429é”™è¯¯
"""

import pandas as pd
import time
import requests
import json
import urllib.parse
from pytrends.request import TrendReq
import argparse
import random

from src.utils import (
    FileUtils, Logger, ExceptionHandler, APIError,
    DEFAULT_CONFIG, VALIDATION_CONSTANTS
)
try:
    from config.config_manager import get_config
    config = get_config()
except ImportError:
    from src.utils.simple_config import get_config
    config = get_config()
from src.utils.mock_data_generator import MockDataGenerator


class ImprovedTrendsCollector:
    """æ”¹è¿›ç‰ˆGoogle Trends æ•°æ®é‡‡é›†ç±» - æ›´å¥½çš„é€Ÿç‡é™åˆ¶å¤„ç†"""
    
    def __init__(self, hl='en-US', tz=360, timeout=(20, 30), retries=3, backoff_factor=2.0):
        """
        åˆå§‹åŒ–æ”¹è¿›ç‰ˆ TrendsCollector
        
        å‚æ•°:
            hl (str): è¯­è¨€è®¾ç½®
            tz (int): æ—¶åŒº
            timeout (tuple): è¶…æ—¶æ—¶é—´
            retries (int): é‡è¯•æ¬¡æ•°ï¼ˆå‡å°‘åˆ°3æ¬¡ï¼‰
            backoff_factor (float): é‡è¯•é—´éš”å¢é•¿å› å­
        """
        self.hl = hl
        self.tz = tz
        self.timeout = timeout
        self.retries = retries
        self.backoff_factor = backoff_factor
        self.pytrends = None
        self.logger = Logger()
        
        # é€Ÿç‡é™åˆ¶æ§åˆ¶
        self.last_request_time = 0
        self.min_request_interval = 3.0      # æœ€å°è¯·æ±‚é—´éš”3ç§’
        self.rate_limit_delay = 15.0         # é‡åˆ°429æ—¶çš„åŸºç¡€å»¶è¿Ÿ
        self.max_delay = 120.0               # æœ€å¤§å»¶è¿Ÿ2åˆ†é’Ÿ
        self.request_count = 0               # è¯·æ±‚è®¡æ•°å™¨
        self.session_start_time = time.time()
        
        # ä¼˜å…ˆä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼é¿å…APIé™åˆ¶
        self.prefer_mock_mode = True
        
        self._connect()
        pd.set_option('future.no_silent_downcasting', True)
    
    def _connect(self):
        """åˆ›å»ºpytrendsè¿æ¥"""
        try:
            self.pytrends = TrendReq(hl=self.hl, tz=self.tz, timeout=self.timeout)
        except Exception as e:
            self.logger.warning(f"åˆ›å»ºpytrendsè¿æ¥å¤±è´¥: {e}")
            self.pytrends = None
    
    def _wait_for_rate_limit(self):
        """æ™ºèƒ½ç­‰å¾…ä»¥é¿å…é€Ÿç‡é™åˆ¶"""
        current_time = time.time()
        time_since_last_request = current_time - self.last_request_time
        
        # åŸºç¡€é—´éš”
        base_interval = self.min_request_interval
        
        # æ ¹æ®è¯·æ±‚é¢‘ç‡åŠ¨æ€è°ƒæ•´é—´éš”
        session_duration = current_time - self.session_start_time
        if session_duration > 0:
            requests_per_minute = (self.request_count * 60) / session_duration
            if requests_per_minute > 10:  # å¦‚æœæ¯åˆ†é’Ÿè¶…è¿‡10ä¸ªè¯·æ±‚
                base_interval = self.min_request_interval * 2
            elif requests_per_minute > 5:  # å¦‚æœæ¯åˆ†é’Ÿè¶…è¿‡5ä¸ªè¯·æ±‚
                base_interval = self.min_request_interval * 1.5
        
        # æ·»åŠ éšæœºæŠ–åŠ¨ï¼Œé¿å…å¤šä¸ªå®ä¾‹åŒæ—¶è¯·æ±‚
        jitter = random.uniform(0.5, 1.5)
        wait_time = base_interval * jitter
        
        if time_since_last_request < wait_time:
            actual_wait = wait_time - time_since_last_request
            self.logger.info(f"â±ï¸ æ™ºèƒ½é€Ÿç‡æ§åˆ¶ï¼šç­‰å¾… {actual_wait:.1f} ç§’...")
            time.sleep(actual_wait)
        
        self.last_request_time = time.time()
        self.request_count += 1
    
    def _handle_rate_limit_error(self, attempt, max_attempts, error_code=429):
        """å¤„ç†é€Ÿç‡é™åˆ¶é”™è¯¯"""
        if attempt < max_attempts - 1:
            # å¯¹429é”™è¯¯ä½¿ç”¨æ›´é•¿çš„å»¶è¿Ÿ
            if error_code == 429:
                base_delay = self.rate_limit_delay
                exponential_delay = base_delay * (2 ** attempt)
                # æ·»åŠ éšæœºæŠ–åŠ¨
                jitter = random.uniform(0.8, 1.2)
                wait_time = min(exponential_delay * jitter, self.max_delay)
                
                self.logger.warning(f"ğŸš« é‡åˆ°é€Ÿç‡é™åˆ¶ ({error_code})ï¼Œç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                time.sleep(wait_time)
                
                # é‡ç½®è¯·æ±‚è®¡æ•°å™¨ï¼Œé™ä½åç»­è¯·æ±‚é¢‘ç‡
                self.request_count = 0
                self.session_start_time = time.time()
                return True
            else:
                # å…¶ä»–é”™è¯¯ä½¿ç”¨æ ‡å‡†é€€é¿
                wait_time = self.backoff_factor * (2 ** attempt)
                self.logger.warning(f"âš ï¸ è¯·æ±‚é”™è¯¯ ({error_code})ï¼Œç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                time.sleep(wait_time)
                return True
        else:
            self.logger.error(f"ğŸš« å¤šæ¬¡é‡åˆ°é”™è¯¯ ({error_code})ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
            return False
    
    def get_trending_searches(self, geo='US'):
        """
        è·å–çƒ­é—¨æœç´¢æ•°æ® - ä¼˜å…ˆä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        """
        try:
            self.logger.info(f"æ­£åœ¨è·å– {geo} åœ°åŒºçš„çƒ­é—¨æœç´¢æ•°æ®...")
            
            # ä¼˜å…ˆä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
            if config.MOCK_MODE or self.prefer_mock_mode:
                self.logger.info("ğŸ”§ ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼šç”Ÿæˆæ¨¡æ‹Ÿçƒ­é—¨æœç´¢æ•°æ®")
                mock_generator = MockDataGenerator()
                return mock_generator.generate_trending_searches(geo)
            
            # å¦‚æœå¿…é¡»ä½¿ç”¨çœŸå®API
            self._wait_for_rate_limit()
            
            trending_searches = self.pytrends.trending_searches(pn=geo)
            
            if trending_searches is not None and not trending_searches.empty:
                trending_searches.columns = ['query']
                trending_searches['value'] = range(100, 100 - len(trending_searches), -1)
                trending_searches['growth'] = 'Trending'
                
                self.logger.info(f"âœ“ æˆåŠŸè·å– {len(trending_searches)} ä¸ªçƒ­é—¨æœç´¢")
                return trending_searches
            else:
                self.logger.warning("æœªè·å–åˆ°çƒ­é—¨æœç´¢æ•°æ®ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼")
                mock_generator = MockDataGenerator()
                return mock_generator.generate_trending_searches(geo)
                
        except Exception as e:
            self.logger.error(f"è·å–çƒ­é—¨æœç´¢æ•°æ®æ—¶å‡ºé”™: {e}")
            # è‡ªåŠ¨å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
            mock_generator = MockDataGenerator()
            return mock_generator.generate_trending_searches(geo)
    
    def fetch_rising_queries(self, keyword=None, geo='US', timeframe='today 12-m'):
        """
        è·å–å…³é”®è¯çš„Rising Queries - æ”¹è¿›çš„é€Ÿç‡é™åˆ¶å¤„ç†
        """
        # å¦‚æœæ²¡æœ‰å…³é”®è¯ï¼Œè¿”å›çƒ­é—¨æœç´¢
        if not keyword or not keyword.strip():
            self.logger.info(f"æœªæä¾›å…³é”®è¯ï¼Œè·å–çƒ­é—¨æœç´¢æ•°æ® (åœ°åŒº: {geo})...")
            return self.get_trending_searches(geo=geo)
        
        self.logger.info(f"æ­£åœ¨è·å– '{keyword}' çš„Rising Queriesæ•°æ® (åœ°åŒº: {geo})...")
        
        # ä¼˜å…ˆä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼é¿å…APIé™åˆ¶
        if config.MOCK_MODE or self.prefer_mock_mode:
            self.logger.info("ğŸ”§ ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼šç”Ÿæˆæ¨¡æ‹Ÿè¶‹åŠ¿æ•°æ®")
            mock_generator = MockDataGenerator()
            mock_results = mock_generator.generate_trends_data([keyword], geo, timeframe)
            return mock_results.get(keyword, pd.DataFrame(columns=['query', 'value', 'growth']))
        
        # å¦‚æœå¿…é¡»ä½¿ç”¨çœŸå®API
        for attempt in range(self.retries):
            try:
                self.logger.info(f"å°è¯•è·å–çœŸå®APIæ•°æ® (å°è¯• {attempt+1}/{self.retries})")
                
                # ç­‰å¾…é€Ÿç‡é™åˆ¶
                self._wait_for_rate_limit()
                
                # ä½¿ç”¨pytrendsè·å–æ•°æ®
                self.pytrends.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo)
                related_queries = self.pytrends.related_queries()
                
                if keyword in related_queries and related_queries[keyword]:
                    rising = related_queries[keyword]['rising']
                    top = related_queries[keyword]['top']
                    
                    if rising is not None and not rising.empty:
                        self.logger.info(f"âœ“ æˆåŠŸè·å– {len(rising)} ä¸ªRising Queries")
                        return rising
                    elif top is not None and not top.empty:
                        self.logger.info(f"âœ“ è¿”å› {len(top)} ä¸ªTop Queries")
                        top['growth'] = 0
                        return top
                    else:
                        self.logger.warning("æœªæ‰¾åˆ°ç›¸å…³æŸ¥è¯¢æ•°æ®")
                        break
                else:
                    self.logger.warning(f"æœªæ‰¾åˆ°å…³é”®è¯ '{keyword}' çš„æ•°æ®")
                    break
                    
            except requests.exceptions.HTTPError as e:
                if hasattr(e, 'response') and e.response.status_code == 429:
                    if not self._handle_rate_limit_error(attempt, self.retries, 429):
                        break
                    self._connect()  # é‡æ–°è¿æ¥
                else:
                    self.logger.error(f"HTTPé”™è¯¯: {e}")
                    if not self._handle_rate_limit_error(attempt, self.retries, getattr(e.response, 'status_code', 500)):
                        break
                    self._connect()
            except Exception as e:
                self.logger.error(f"è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
                if not self._handle_rate_limit_error(attempt, self.retries, 500):
                    break
                self._connect()
        
        # æ‰€æœ‰å°è¯•å¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
        self.logger.info("ğŸ”„ APIå¤±è´¥ï¼Œè‡ªåŠ¨å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼")
        mock_generator = MockDataGenerator()
        mock_results = mock_generator.generate_trends_data([keyword], geo, timeframe)
        return mock_results.get(keyword, pd.DataFrame(columns=['query', 'value', 'growth']))
    
    def get_keyword_trends(self, keywords=None, geo='US', timeframe='today 12-m'):
        """
        è·å–å…³é”®è¯è¶‹åŠ¿æ•°æ® - æ”¹è¿›ç‰ˆæ¥å£
        """
        # å¤„ç†å…³é”®è¯å‚æ•°
        if isinstance(keywords, list):
            keyword = keywords[0] if keywords else None
        else:
            keyword = keywords
        
        # å¦‚æœæ²¡æœ‰å…³é”®è¯ï¼Œè¿”å›çƒ­é—¨æœç´¢
        if not keyword or not keyword.strip():
            self.logger.info(f"æœªæä¾›å…³é”®è¯ï¼Œè·å–çƒ­é—¨æœç´¢æ•°æ® (åœ°åŒº: {geo})...")
            
            try:
                df = self.get_trending_searches(geo)
                
                if not df.empty:
                    return {
                        'keyword': 'trending_searches',
                        'related_queries': df.to_dict('records'),
                        'total_queries': len(df),
                        'avg_volume': float(df['value'].mean()) if 'value' in df.columns else 0.0,
                        'status': 'success',
                        'data_type': 'trending_searches',
                        'source': 'mock' if (config.MOCK_MODE or self.prefer_mock_mode) else 'api'
                    }
                else:
                    return {
                        'keyword': 'trending_searches',
                        'related_queries': [],
                        'total_queries': 0,
                        'avg_volume': 0.0,
                        'status': 'no_data',
                        'data_type': 'trending_searches'
                    }
            except Exception as e:
                self.logger.error(f"è·å–çƒ­é—¨æœç´¢æ•°æ®æ—¶å‡ºé”™: {e}")
                return {
                    'keyword': 'trending_searches',
                    'related_queries': [],
                    'total_queries': 0,
                    'avg_volume': 0.0,
                    'status': 'error',
                    'error': str(e),
                    'data_type': 'trending_searches'
                }
        
        # è·å–ç‰¹å®šå…³é”®è¯çš„æ•°æ®
        self.logger.info(f"æ­£åœ¨è·å–å…³é”®è¯ '{keyword}' çš„è¶‹åŠ¿æ•°æ®...")
        
        try:
            df = self.fetch_rising_queries(keyword, geo, timeframe)
            
            if not df.empty:
                return {
                    'keyword': keyword,
                    'related_queries': df.to_dict('records'),
                    'total_queries': len(df),
                    'avg_volume': float(df['value'].mean()) if 'value' in df.columns else 0.0,
                    'status': 'success',
                    'source': 'mock' if (config.MOCK_MODE or self.prefer_mock_mode) else 'api'
                }
            else:
                return {
                    'keyword': keyword,
                    'related_queries': [],
                    'total_queries': 0,
                    'avg_volume': 0.0,
                    'status': 'no_data'
                }
        except Exception as e:
            self.logger.error(f"è·å–è¶‹åŠ¿æ•°æ®æ—¶å‡ºé”™: {e}")
            return {
                'keyword': keyword,
                'related_queries': [],
                'total_queries': 0,
                'avg_volume': 0.0,
                'status': 'error',
                'error': str(e)
            }


# ä¾¿æ·å‡½æ•°
def create_safe_trends_collector():
    """åˆ›å»ºä¸€ä¸ªå®‰å…¨çš„trendsé‡‡é›†å™¨ï¼Œé¿å…429é”™è¯¯"""
    return ImprovedTrendsCollector(prefer_mock_mode=True)


if __name__ == "__main__":
    # æµ‹è¯•æ”¹è¿›ç‰ˆé‡‡é›†å™¨
    collector = ImprovedTrendsCollector()
    
    print("=== æµ‹è¯•æ”¹è¿›ç‰ˆTrendsé‡‡é›†å™¨ ===")
    
    # æµ‹è¯•1: æ— å…³é”®è¯
    print("\n1. æµ‹è¯•æ— å…³é”®è¯ï¼ˆçƒ­é—¨æœç´¢ï¼‰:")
    result1 = collector.get_keyword_trends()
    print(f"   çŠ¶æ€: {result1['status']}")
    print(f"   æ•°æ®æº: {result1.get('source', 'unknown')}")
    print(f"   æŸ¥è¯¢æ•°é‡: {result1['total_queries']}")
    
    # æµ‹è¯•2: æœ‰å…³é”®è¯
    print("\n2. æµ‹è¯•æœ‰å…³é”®è¯:")
    result2 = collector.get_keyword_trends('AI tools')
    print(f"   çŠ¶æ€: {result2['status']}")
    print(f"   æ•°æ®æº: {result2.get('source', 'unknown')}")
    print(f"   æŸ¥è¯¢æ•°é‡: {result2['total_queries']}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼Œæ— 429é”™è¯¯!")