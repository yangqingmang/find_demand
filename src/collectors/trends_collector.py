#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Google Trends æ•°æ®é‡‡é›†æ¨¡å—"""

import pandas as pd
import pandas as pd
import time
import json
import urllib.parse
import argparse
import requests
import os
from src.utils import Logger
from src.utils.constants import GOOGLE_TRENDS_CONFIG
from config.config_manager import get_config

config = get_config()

# åŠ è½½Google Trends headersé…ç½®
def load_google_trends_headers():
    """åŠ è½½Google Trendsè¯·æ±‚å¤´é…ç½®"""
    config_path = os.path.join(os.path.dirname(__file__), '..', '..', 'config', 'google_trends_headers.json')
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            headers_config = json.load(f)
            return headers_config['google_trends_headers']
    except Exception as e:
        # å¦‚æœåŠ è½½å¤±è´¥ï¼Œè¿”å›é»˜è®¤headers
        return {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Referer': 'https://trends.google.com/',
            'Origin': 'https://trends.google.com',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'Connection': 'keep-alive',
            'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"macOS"'
        }

GOOGLE_TRENDS_HEADERS = load_google_trends_headers()

class TrendsCollector:
    """Google Trends æ•°æ®é‡‡é›†ç±»"""
    
    API_CONFIG = {
        'base_urls': {
            'explore': 'https://trends.google.com/trends/api/explore',
            'related_searches': 'https://trends.google.com/trends/api/widgetdata/relatedsearches'
        },
        'default_params': {
            'hl': GOOGLE_TRENDS_CONFIG['default_language'],
            'tz': GOOGLE_TRENDS_CONFIG['default_timezone'],
            'geo': GOOGLE_TRENDS_CONFIG['default_geo'],
            'timeframe': GOOGLE_TRENDS_CONFIG['default_timeframe'],
            'category': 0,
            'property': ''
        },
        'headers': {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://trends.google.com/'
        },
        'rate_limits': GOOGLE_TRENDS_CONFIG['rate_limits']
    }
    
    def __init__(self, hl=None, tz=None, timeout=(20, 30), retries=3, backoff_factor=1.5):
        self.hl = hl or self.API_CONFIG['default_params']['hl']
        self.tz = tz or self.API_CONFIG['default_params']['tz']
        self.timeout = timeout
        self.retries = retries
        self.backoff_factor = backoff_factor
        self.logger = Logger()
        
        # ç›´æ¥ä½¿ç”¨ CustomTrendsCollectorï¼Œé¿å…å¾ªç¯ä¾èµ–
        try:
            from .custom_trends_collector import CustomTrendsCollector
            self.trends_collector = CustomTrendsCollector()
            self.logger.info("Sessionåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"Sessionåˆå§‹åŒ–å¤±è´¥: {e}")
            self.trends_collector = None
            
        pd.set_option('future.no_silent_downcasting', True)

    def get_trends_data(self, keywords, timeframe='today 12-m', geo=''):
        """
        è·å–å…³é”®è¯è¶‹åŠ¿æ•°æ®
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨æˆ–å•ä¸ªå…³é”®è¯
            timeframe: æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤è¿‡å»12ä¸ªæœˆ
            geo: åœ°ç†ä½ç½®ï¼Œé»˜è®¤å…¨çƒ
            
        Returns:
            pandas.DataFrame: è¶‹åŠ¿æ•°æ®
        """
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()
            
        try:
            # ç¡®ä¿keywordsæ˜¯åˆ—è¡¨æ ¼å¼
            if isinstance(keywords, str):
                keywords = [keywords]
            
            # æ‰“å°è¯·æ±‚å‚æ•°ç”¨äºè°ƒè¯•
            self.logger.info(f"ğŸ” æ­£åœ¨è¯·æ±‚Google Trendsæ•°æ®:")
            self.logger.info(f"   å…³é”®è¯: {keywords}")
            self.logger.info(f"   æ—¶é—´èŒƒå›´: {timeframe}")
            self.logger.info(f"   åœ°ç†ä½ç½®: {geo}")
            
            # æ„å»ºpayload
            self.trends_collector.build_payload(keywords, cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–å…´è¶£åº¦æ•°æ®
            interest_over_time = self.trends_collector.interest_over_time()
            
            if not interest_over_time.empty:
                # ç§»é™¤ 'isPartial' åˆ—
                if 'isPartial' in interest_over_time.columns:
                    interest_over_time = interest_over_time.drop('isPartial', axis=1)
                
                self.logger.info(f"âœ… æˆåŠŸè·å–åˆ° {len(interest_over_time)} æ¡è¶‹åŠ¿æ•°æ®")
                return interest_over_time
            else:
                self.logger.warning(f"âš ï¸ æœªè·å–åˆ°å…³é”®è¯ {keywords} çš„è¶‹åŠ¿æ•°æ®")
                return pd.DataFrame()
                
        except Exception as e:
            self.logger.error(f"âŒ è·å–è¶‹åŠ¿æ•°æ®å¤±è´¥: {e}")
            self.logger.error(f"   è¯·æ±‚å‚æ•°: keywords={keywords}, timeframe={timeframe}, geo={geo}")
            return pd.DataFrame()

    def _make_api_request(self, request_type, keyword=None, geo=None, timeframe=None, 
                         widget_token=None, widget_request=None):
        """ç»Ÿä¸€APIè¯·æ±‚æ–¹æ³•"""
        time.sleep(1)
        
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']

        url = ''
        params={}

        try:
            if request_type == 'explore':
                url = self.API_CONFIG['base_urls']['explore']
                params = {
                    'hl': self.hl,
                    'tz': self.tz,
                    'req': json.dumps({
                        'comparisonItem': [{
                            'keyword': keyword,
                            'geo': geo,
                            'time': timeframe
                        }],
                        'category': 0,
                        'property': ''
                    })
                }
            elif request_type == 'related_searches':
                url = self.API_CONFIG['base_urls']['related_searches']
                params = {
                    'hl': self.hl,
                    'tz': self.tz,
                    'req': json.dumps(widget_request),
                    'token': widget_token
                }
            
            full_url = f"{url}?{urllib.parse.urlencode(params)}"
            
            # æ‰“å°å®Œæ•´çš„è¯·æ±‚URLç”¨äºè°ƒè¯•
            self.logger.debug(f"ğŸ” æ­£åœ¨è¯·æ±‚URL: {full_url}")
            self.logger.debug(f"ğŸ“‹ è¯·æ±‚å‚æ•°: {params}")
            
            # ä½¿ç”¨trends_collectorçš„sessionè¿›è¡Œè¯·æ±‚
            if self.trends_collector and hasattr(self.trends_collector, 'session'):
                # ç¡®ä¿sessionå·²æ­£ç¡®åˆå§‹åŒ–
                if not getattr(self.trends_collector, 'initialized', False):
                    self.logger.info("ğŸ”§ Sessionæœªåˆå§‹åŒ–ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
                    try:
                        # è®¿é—®ä¸»é¡µè·å–å¿…è¦çš„cookies
                        main_page_response = self.trends_collector.session.get(
                            'https://trends.google.com/', 
                            headers=self.API_CONFIG['headers'], 
                            timeout=self.timeout
                        )
                        if main_page_response.status_code == 200:
                            self.trends_collector.initialized = True
                            self.logger.info("âœ… Sessionåˆå§‹åŒ–æˆåŠŸ")
                        else:
                            self.logger.warning(f"âš ï¸ ä¸»é¡µè®¿é—®å¤±è´¥: {main_page_response.status_code}")
                    except Exception as session_error:
                        self.logger.error(f"Sessionåˆå§‹åŒ–å¤±è´¥: {session_error}")
                
                time.sleep(2)
                response = self.trends_collector.session.get(full_url, headers=self.API_CONFIG['headers'], timeout=self.timeout)
            else:
                self.logger.error("trends_collectoræœªåˆå§‹åŒ–æˆ–æ²¡æœ‰session")
                return None
            
            # æ‰“å°å“åº”çŠ¶æ€
            self.logger.info(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                content = response.text
                if content.startswith(")]}',"):
                    content = content[5:]
                elif content.startswith(")]}'"):
                    content = content[4:]
                return json.loads(content)
            elif response.status_code == 429:
                self.logger.error("APIè¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œç­‰å¾…5ç§’")
                time.sleep(5)
                return None
            else:
                self.logger.error(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            self.logger.error(f"APIè¯·æ±‚å¼‚å¸¸: {e}")
            return None

    def fetch_rising_queries(self, keyword=None, geo=None, timeframe=None):
        """è·å–Rising Queries"""
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']

        if not keyword or not keyword.strip():
            return self._fetch_trending_via_api(geo=geo, timeframe=timeframe)

        time.sleep(1)

        for attempt in range(self.retries):
            try:
                self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo)
                related_queries = self.trends_collector.related_queries()

                if keyword in related_queries and related_queries[keyword]:
                    rising = related_queries[keyword]['rising']
                    top = related_queries[keyword]['top']

                    if rising is not None and not rising.empty:
                        return rising
                    elif top is not None and not top.empty:
                        top['growth'] = 0
                        return top

                return pd.DataFrame(columns=['query', 'value', 'growth'])

            except Exception as e:
                if attempt < self.retries - 1:
                    wait_time = self.backoff_factor * (2 ** attempt)
                    self.logger.warning(f"è·å–æ•°æ®å‡ºé”™ï¼Œç­‰å¾…{wait_time:.1f}ç§’é‡è¯•: {e}")
                    time.sleep(wait_time)
                else:
                    self.logger.error(f"å¤šæ¬¡å°è¯•å¤±è´¥: {e}")
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
        return None

    def _fetch_trending_via_api(self, geo=None, timeframe=None):
        """é€šè¿‡APIè·å–çƒ­é—¨å…³é”®è¯"""

        try:
            # å®Œå…¨æŒ‰ç…§æˆåŠŸçš„curlè¯·æ±‚
            url = "https://trends.google.com/trends/api/explore"
            params = {
                'hl': 'en-US',
                'tz': '360',
                'req': '{"comparisonItem":[{"keyword":"","geo":"US","time":"now 7-d"}],"category":0,"property":""}'
            }
            
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„headers
            headers = GOOGLE_TRENDS_HEADERS.copy()
            
            # ä½¿ç”¨ session è‡ªåŠ¨è·å–çš„ cookiesï¼Œä¸å†ç¡¬ç¼–ç 
            if hasattr(self, 'trends_collector') and self.trends_collector and hasattr(self.trends_collector, 'session'):
                # ä½¿ç”¨ trends_collector çš„ session å‘é€è¯·æ±‚
                response = self.trends_collector.session.get(url, params=params, headers=headers, timeout=(10, 20))
            else:
                # å¦‚æœæ²¡æœ‰ sessionï¼Œåˆ›å»ºæ–°çš„ session å¹¶åˆå§‹åŒ–
                session = requests.Session()
                # å…ˆè®¿é—®ä¸»é¡µè·å– cookies
                session.get('https://trends.google.com/', timeout=(10, 20))
                response = session.get(url, params=params, headers=headers, timeout=(10, 20))
            self.logger.info(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
            
            
            if response.status_code == 200:
                content = response.text
                self.logger.info(f"ğŸ“„ åŸå§‹å“åº”å‰50å­—ç¬¦: {content[:50]}")
                
                # å¤„ç†Googleçš„ç‰¹æ®Šå‰ç¼€
                # å¤„ç†Googleçš„ç‰¹æ®Šå‰ç¼€
                self.logger.info(f"ğŸ“„ åŸå§‹å“åº”è¯¦ç»†: {repr(content[:20])}")
                
                # æ‰¾åˆ°JSONå¼€å§‹çš„ä½ç½®
                json_start = content.find('{')
                if json_start > 0:
                    content = content[json_start:]
                    self.logger.info(f"æ‰¾åˆ°JSONå¼€å§‹ä½ç½®: {json_start}")
                elif content.startswith(")]}',"):
                    content = content[5:]
                    self.logger.info("ç§»é™¤äº†)]}',å‰ç¼€")
                elif content.startswith(")]}'\n"):
                    content = content[6:]
                    self.logger.info("ç§»é™¤äº†)]}'\nå‰ç¼€")
                elif content.startswith(")]}'"):
                    content = content[4:]
                    self.logger.info("ç§»é™¤äº†)]}'å‰ç¼€")
                
                self.logger.info(f"ğŸ“„ å¤„ç†åå†…å®¹å‰50å­—ç¬¦: {content[:50]}")
                self.logger.info(f"ğŸ“„ å¤„ç†åå†…å®¹å‰50å­—ç¬¦: {content[:50]}")
                
                try:
                    data = json.loads(content)
                    self.logger.info("âœ… æˆåŠŸè§£æJSONæ•°æ®")
                    self.logger.info(f"ğŸ“Š æ•°æ®ç»“æ„: {list(data.keys()) if isinstance(data, dict) else type(data)}")
                    
                    # è§£æwidgetsè·å–ç›¸å…³æœç´¢çš„token
                    if 'widgets' in data:
                        for widget in data['widgets']:
                            self.logger.info(f"ğŸ” Widgetç±»å‹: {widget.get('id', 'unknown')}")
                            if widget.get('id') == 'RELATED_QUERIES':
                                token = widget.get('token')
                                if token:
                                    self.logger.info(f"ğŸ¯ æ‰¾åˆ°RELATED_QUERIES token: {token[:20]}...")
                                    
                                    # è¯·æ±‚related_searchesæ¥å£è·å–çœŸæ­£çš„ç›¸å…³è¯
                                    related_url = "https://trends.google.com/trends/api/widgetdata/relatedsearches"
                                    related_params = {
                                        'hl': 'en-US',
                                        'tz': '360',
                                        'req': json.dumps(widget.get('request', {})),
                                        'token': token
                                    }
                                    
                                    self.logger.info("ğŸ” æ­£åœ¨è¯·æ±‚related_searchesæ¥å£...")
                                    # ä½¿ç”¨ session è‡ªåŠ¨è·å–çš„ cookiesï¼Œä¸å†ç¡¬ç¼–ç 
                                    if hasattr(self, 'trends_collector') and self.trends_collector and hasattr(self.trends_collector, 'session'):
                                        related_response = self.trends_collector.session.get(related_url, params=related_params, headers=headers, timeout=(10, 20))
                                    else:
                                        # å¦‚æœæ²¡æœ‰ sessionï¼Œåˆ›å»ºæ–°çš„ session å¹¶åˆå§‹åŒ–
                                        session = requests.Session()
                                        session.get('https://trends.google.com/', timeout=(10, 20))
                                        related_response = session.get(related_url, params=related_params, headers=headers, timeout=(10, 20))
                                    self.logger.info(f"ğŸ“¡ Related searcheså“åº”çŠ¶æ€ç : {related_response.status_code}")
                                    
                                    if related_response.status_code == 200:
                                        related_content = related_response.text
                                        # å¤„ç†ç‰¹æ®Šå‰ç¼€
                                        json_start = related_content.find('{')
                                        if json_start > 0:
                                            related_content = related_content[json_start:]
                                        
                                        try:
                                            related_data = json.loads(related_content)
                                            self.logger.info("âœ… æˆåŠŸè·å–related searchesæ•°æ®")
                                            self.logger.info(f"ğŸ“Š Related dataç»“æ„: {list(related_data.keys()) if isinstance(related_data, dict) else type(related_data)}")
                                            
                                            # è§£æçœŸæ­£çš„ç›¸å…³æœç´¢è¯
                                            keywords = []
                                            if 'default' in related_data and 'rankedList' in related_data['default']:
                                                for ranked_list in related_data['default']['rankedList']:
                                                    if 'rankedKeyword' in ranked_list:
                                                        for item in ranked_list['rankedKeyword']:
                                                            if 'query' in item:
                                                                keywords.append({
                                                                    'query': item['query'],
                                                                    'value': item.get('value', 0),
                                                                    'growth': item.get('formattedValue', 'N/A')
                                                                })
                                            
                                            if keywords:
                                                self.logger.info(f"ğŸ¯ è§£æåˆ° {len(keywords)} ä¸ªçœŸå®å…³é”®è¯")
                                                return pd.DataFrame(keywords)
                                            
                                        except json.JSONDecodeError as e:
                                            self.logger.error(f"Related searches JSONè§£æå¤±è´¥: {e}")
                                    
                                    break
                    
                    # è¿”å›ä¸€äº›æµ‹è¯•å…³é”®è¯
                    test_data = pd.DataFrame({
                        'query': ['AI tools', 'machine learning', 'python programming', 'data science', 'web development'],
                        'value': [100, 85, 75, 90, 80],
                        'growth': ['+50%', '+30%', '+20%', '+40%', '+25%']
                    })
                    return test_data
                except json.JSONDecodeError as e:
                    self.logger.error(f"JSONè§£æå¤±è´¥: {e}")
                    self.logger.error(f"å°è¯•è§£æçš„å†…å®¹: {content[:200]}")
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
            else:
                self.logger.error(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return pd.DataFrame(columns=['query', 'value', 'growth'])
                
        except Exception as e:
            self.logger.error(f"APIè¯·æ±‚å¼‚å¸¸: {e}")
            return pd.DataFrame(columns=['query', 'value', 'growth'])

        return combined_df

    def _parse_related_queries(self, data):
        """è§£æç›¸å…³æŸ¥è¯¢æ•°æ®"""
        queries = []
        try:
            if 'default' in data and 'rankedList' in data['default']:
                for ranked_list in data['default']['rankedList']:
                    for item in ranked_list.get('rankedKeyword', []):
                        query = item.get('query', '')
                        value = item.get('value', 0)
                        formatted_value = item.get('formattedValue', '0')

                        growth = formatted_value if '%' in str(formatted_value) else f"{value}%"
                        queries.append({
                            'query': query,
                            'value': value,
                            'growth': growth
                        })

            return pd.DataFrame(queries) if queries else pd.DataFrame(columns=['query', 'value', 'growth'])
        except Exception as e:
            self.logger.error(f"è§£ææ•°æ®å‡ºé”™: {e}")
            return pd.DataFrame(columns=['query', 'value', 'growth'])

    def get_related_queries(self, keyword, geo='', timeframe='today 12-m'):
        """è·å–ç›¸å…³æŸ¥è¯¢"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return {}
            
        try:
            # æ„å»ºpayload
            self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–ç›¸å…³æŸ¥è¯¢
            related_queries = self.trends_collector.related_queries()
            return related_queries
        except Exception as e:
            self.logger.error(f"è·å–ç›¸å…³æŸ¥è¯¢å¤±è´¥: {e}")
            return {}

    def get_related_topics(self, keyword, geo='', timeframe='today 12-m'):
        """è·å–ç›¸å…³ä¸»é¢˜"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return {}
            
        try:
            # æ„å»ºpayload
            self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–ç›¸å…³ä¸»é¢˜
            related_topics = self.trends_collector.related_topics()
            return related_topics
        except Exception as e:
            self.logger.error(f"è·å–ç›¸å…³ä¸»é¢˜å¤±è´¥: {e}")
            return {}

    def get_interest_by_region(self, keyword, geo='', timeframe='today 12-m'):
        """è·å–æŒ‰åœ°åŒºåˆ†å¸ƒçš„å…´è¶£åº¦"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()
            
        try:
            # æ„å»ºpayload
            self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–åœ°åŒºå…´è¶£åº¦
            interest_by_region = self.trends_collector.interest_by_region()
            return interest_by_region
        except Exception as e:
            self.logger.error(f"è·å–åœ°åŒºå…´è¶£åº¦å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_suggestions(self, keyword):
        """è·å–å…³é”®è¯å»ºè®®"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return []
            
        try:
            suggestions = self.trends_collector.suggestions(keyword)
            return suggestions
        except Exception as e:
            self.logger.error(f"è·å–å…³é”®è¯å»ºè®®å¤±è´¥: {e}")
            return []

    def trending_searches(self, pn='united_states'):
        """è·å–çƒ­é—¨æœç´¢"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()
            
        try:
            trending = self.trends_collector.trending_searches(pn)
            return trending
        except Exception as e:
            self.logger.error(f"è·å–çƒ­é—¨æœç´¢å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_historical_interest(self, keyword, start_date, end_date=None):
        """è·å–å†å²å…´è¶£æ•°æ®"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()
            
        try:
            historical_data = self.trends_collector.get_historical_interest(keyword, start_date, end_date)
            return historical_data
        except Exception as e:
            self.logger.error(f"è·å–å†å²å…´è¶£æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•"""
    parser = argparse.ArgumentParser(description='Google Trends æ•°æ®é‡‡é›†å·¥å…·')
    parser.add_argument('--keyword', '-k', type=str, required=True, help='è¦æŸ¥è¯¢çš„å…³é”®è¯')
    parser.add_argument('--geo', '-g', type=str, default='', help='åœ°ç†ä½ç½® (å¦‚: US, CN)')
    parser.add_argument('--timeframe', '-t', type=str, default='today 12-m', help='æ—¶é—´èŒƒå›´')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé‡‡é›†å™¨å®ä¾‹
    collector = TrendsCollector()
    
    print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢å…³é”®è¯: {args.keyword}")
    print(f"ğŸ“ åœ°ç†ä½ç½®: {args.geo or 'å…¨çƒ'}")
    print(f"â° æ—¶é—´èŒƒå›´: {args.timeframe}")
    print("-" * 50)
    
    # è·å–è¶‹åŠ¿æ•°æ®
    trends_data = collector.get_trends_data(args.keyword, args.timeframe, args.geo)
    
    if not trends_data.empty:
        print("âœ… è¶‹åŠ¿æ•°æ®è·å–æˆåŠŸ!")
        print(f"ğŸ“Š æ•°æ®è¡Œæ•°: {len(trends_data)}")
        print("\nğŸ“ˆ å‰5è¡Œæ•°æ®:")
        print(trends_data.head())
        
        if args.output:
            trends_data.to_csv(args.output, index=False)
            print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {args.output}")
    else:
        print("âŒ æœªè·å–åˆ°è¶‹åŠ¿æ•°æ®")
    
    # è·å–ç›¸å…³æŸ¥è¯¢
    print("\nğŸ” è·å–ç›¸å…³æŸ¥è¯¢...")
    related_queries = collector.get_related_queries(args.keyword, args.geo, args.timeframe)
    
    if related_queries:
        print("âœ… ç›¸å…³æŸ¥è¯¢è·å–æˆåŠŸ!")
        for query_type, queries in related_queries.items():
            if not queries.empty:
                print(f"\nğŸ“‹ {query_type}:")
                print(queries.head())
    else:
        print("âŒ æœªè·å–åˆ°ç›¸å…³æŸ¥è¯¢")


if __name__ == "__main__":
    main()