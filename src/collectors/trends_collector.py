#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google Trends æ•°æ®é‡‡é›†æ¨¡å—
ç”¨äºé‡‡é›†Google Trendsç›¸å…³æŸ¥è¯¢æ•°æ®
"""

import pandas as pd
import time
import requests
import json
import urllib.parse
from pytrends.request import TrendReq
import argparse
from src.utils import FileUtils, Logger

from src.utils.constants import GOOGLE_TRENDS_CONFIG
from config.config_manager import get_config
from src.utils.mock_data_generator import MockDataGenerator

config = get_config()

class TrendsCollector:
    """Google Trends æ•°æ®é‡‡é›†ç±» - ç»Ÿä¸€APIè¯·æ±‚ç®¡ç†"""
    
    # ç»Ÿä¸€çš„APIé…ç½®å¸¸é‡ - ä½¿ç”¨å…¨å±€é…ç½®
    API_CONFIG = {
        'base_urls': {
            'explore': 'https://trends.google.com/trends/api/explore',
            'related_searches': 'https://trends.google.com/trends/api/widgetdata/relatedsearches'
        },
        'default_params': {
            'hl': GOOGLE_TRENDS_CONFIG['default_language'],
            'tz': GOOGLE_TRENDS_CONFIG['default_timezone'],
            'geo': GOOGLE_TRENDS_CONFIG['default_geo'],
            'timeframe': GOOGLE_TRENDS_CONFIG['default_timeframe'],
            'category': 0,
            'property': ''
        },
        'headers': {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'https://trends.google.com/',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin'
        },
        'rate_limits': GOOGLE_TRENDS_CONFIG['rate_limits']
    }
    
    def __init__(self, hl=None, tz=None, timeout=(20, 30), retries=5, backoff_factor=2.0):
        """
        åˆå§‹åŒ– TrendsCollector
        
        å‚æ•°:
            hl (str): è¯­è¨€è®¾ç½®ï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            tz (int): æ—¶åŒºï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            timeout (tuple): è¿æ¥å’Œè¯»å–è¶…æ—¶æ—¶é—´(ç§’)
            retries (int): é‡è¯•æ¬¡æ•°
            backoff_factor (float): é‡è¯•é—´éš”å¢é•¿å› å­
        """
        # ä½¿ç”¨ä¼ å…¥å‚æ•°æˆ–é»˜è®¤é…ç½®
        self.hl = hl or self.API_CONFIG['default_params']['hl']
        self.tz = tz or self.API_CONFIG['default_params']['tz']
        self.timeout = timeout
        self.retries = retries
        self.backoff_factor = backoff_factor
        self.pytrends = None
        self.logger = Logger()
        self._connect()
        
        # é€Ÿç‡é™åˆ¶æ§åˆ¶
        self.last_request_time = 0
        self.min_request_interval = self.API_CONFIG['rate_limits']['min_request_interval']
        self.rate_limit_delay = self.API_CONFIG['rate_limits']['rate_limit_delay']
        
        # è®¾ç½®pandasé€‰é¡¹ï¼Œæ¶ˆé™¤è­¦å‘Š
        pd.set_option('future.no_silent_downcasting', True)
    
    def _connect(self):
        """åˆ›å»ºpytrendsè¿æ¥"""
        self.pytrends = TrendReq(hl=self.hl, tz=self.tz, timeout=self.timeout)

    def _make_unified_trends_request(self, request_type, keyword=None, geo=None, timeframe=None, 
                                   widget_token=None, widget_request=None):
        """
        ç»Ÿä¸€çš„Google Trends APIè¯·æ±‚æ–¹æ³•
        
        å‚æ•°:
            request_type (str): è¯·æ±‚ç±»å‹ ('explore' æˆ– 'related_searches')
            keyword (str): å…³é”®è¯
            geo (str): åœ°åŒºä»£ç 
            timeframe (str): æ—¶é—´èŒƒå›´
            widget_token (str): widget token (ä»…ç”¨äºrelated_searches)
            widget_request (dict): widgetè¯·æ±‚æ•°æ® (ä»…ç”¨äºrelated_searches)
            
        è¿”å›:
            dict: APIå“åº”æ•°æ®
        """
        # ç­‰å¾…é€Ÿç‡é™åˆ¶
        time.sleep(5)
        
        try:
            # ä½¿ç”¨é»˜è®¤å€¼å¡«å……å‚æ•°
            geo = geo or self.API_CONFIG['default_params']['geo']
            timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']
            
            # æ ¹æ®è¯·æ±‚ç±»å‹æ„å»ºURLå’Œå‚æ•°
            if request_type == 'explore':
                url = self.API_CONFIG['base_urls']['explore']
                req_data = {
                    "comparisonItem": [{
                        "keyword": keyword,
                        "geo": geo,
                        "time": timeframe,
                        "category": self.API_CONFIG['default_params']['category'],
                        "property": self.API_CONFIG['default_params']['property']
                    }]
                }
                params = {
                    "hl": self.hl,
                    "tz": self.tz,
                    "req": json.dumps(req_data)
                }
            elif request_type == 'related_searches':
                url = self.API_CONFIG['base_urls']['related_searches']
                params = {
                    'hl': self.hl,
                    'tz': self.tz,
                    'req': json.dumps(widget_request),
                    'token': widget_token
                }
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„è¯·æ±‚ç±»å‹: {request_type}")
            
            # æ„å»ºå®Œæ•´URL
            encoded_params = urllib.parse.urlencode(params)
            full_url = f"{url}?{encoded_params}"
            
            self.logger.info(f"ğŸŒ å‘é€{request_type}è¯·æ±‚: {url}")
            self.logger.debug(f"ğŸ“‹ è¯·æ±‚å‚æ•°: {params}")
            self.logger.info(f"ğŸ”— å®Œæ•´è¯·æ±‚è·¯å¾„: {full_url}")

            
            # å‘é€POSTè¯·æ±‚
            response = requests.post(full_url, headers=self.API_CONFIG['headers'], timeout=self.timeout)
            
            if response.status_code == 200:
                # å¤„ç†Google Trends APIç‰¹æ®Šçš„å“åº”å‰ç¼€
                content = response.text
                if content.startswith(")]}',"):
                    content = content[5:]  # å»é™¤ ")]}'"
                elif content.startswith(")]}',\n"):
                    content = content[6:]  # å»é™¤ ")]}',\n"
                
                self.logger.info(f"âœ… {request_type}è¯·æ±‚æˆåŠŸ")
                self.logger.debug(f"ğŸ“„ å“åº”å†…å®¹å‰100å­—ç¬¦: {content[:100]}")
                return json.loads(content)
            elif response.status_code == 429:
                # ä¸“é—¨å¤„ç†429é”™è¯¯
                self.logger.error(f"ğŸš« 429 Too Many Requests - APIè¯·æ±‚è¿‡äºé¢‘ç¹")
                self.logger.info(f"â° ç­‰å¾… 5 ç§’åé‡è¯•...")
                time.sleep(5)
                return None
            else:
                self.logger.error(f"âŒ {request_type}è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                self.logger.error(f"ğŸ“ å“åº”å†…å®¹: {response.text[:500]}")
                return None
                
        except Exception as e:
            self.logger.error(f"ğŸ’¥ {request_type}è¯·æ±‚å‡ºé”™: {e}")
            return None
    
    def _extract_related_queries_from_response(self, api_response):
        """
        ä»APIå“åº”ä¸­æå–ç›¸å…³æŸ¥è¯¢æ•°æ® - ä½¿ç”¨ç»Ÿä¸€çš„å¤„ç†é€»è¾‘
        
        å‚æ•°:
            api_response (dict): APIå“åº”æ•°æ®
            
        è¿”å›:
            pandas.DataFrame: ç›¸å…³æŸ¥è¯¢æ•°æ®
        """
        try:
            if not api_response:
                return pd.DataFrame(columns=['query', 'value', 'growth'])
            
            # å¤„ç†exploreå“åº” - æŸ¥æ‰¾ç›¸å…³æŸ¥è¯¢widget
            if 'widgets' in api_response:
                self.logger.info(f"æ‰¾åˆ° {len(api_response['widgets'])} ä¸ªwidgets")
                
                for widget in api_response['widgets']:
                    widget_id = widget.get('id', '')
                    widget_type = widget.get('type', '')
                    
                    if widget_id == 'RELATED_QUERIES' and widget_type == 'fe_related_searches':
                        self.logger.info("æ‰¾åˆ°ç›¸å…³æŸ¥è¯¢widget")
                        
                        token = widget.get('token')
                        if not token:
                            self.logger.warning("ç›¸å…³æŸ¥è¯¢widgetç¼ºå°‘token")
                            continue
                        
                        # ä½¿ç”¨ç»Ÿä¸€æ–¹æ³•è¯·æ±‚ç›¸å…³æŸ¥è¯¢æ•°æ®
                        related_response = self._make_unified_trends_request(
                            'related_searches',
                            widget_token=token,
                            widget_request=widget['request']
                        )
                        
                        if related_response:
                            return self._parse_related_queries_data(related_response)
                        
                        break
            
            # å¤„ç†related_searcheså“åº”
            elif 'default' in api_response:
                return self._parse_related_queries_data(api_response)
            
            return pd.DataFrame(columns=['query', 'value', 'growth'])
            
        except Exception as e:
            self.logger.error(f"æå–ç›¸å…³æŸ¥è¯¢æ•°æ®å‡ºé”™: {e}")
            return pd.DataFrame(columns=['query', 'value', 'growth'])
    
    def _parse_related_queries_data(self, data):
        """
        è§£æç›¸å…³æŸ¥è¯¢æ•°æ®çš„ç»Ÿä¸€æ–¹æ³•
        
        å‚æ•°:
            data (dict): ç›¸å…³æŸ¥è¯¢å“åº”æ•°æ®
            
        è¿”å›:
            pandas.DataFrame: è§£æåçš„æŸ¥è¯¢æ•°æ®
        """
        related_queries_data = []
        
        try:
            if 'default' in data and 'rankedList' in data['default']:
                for ranked_list in data['default']['rankedList']:
                    list_type = ranked_list.get('rankedKeyword', [])
                    
                    for item in list_type:
                        query = item.get('query', '')
                        value = item.get('value', 0)
                        formatted_value = item.get('formattedValue', '0')
                        
                        # ç»Ÿä¸€å¤„ç†å¢é•¿ç‡æ•°æ®
                        growth = formatted_value
                        if isinstance(formatted_value, str) and '%' in formatted_value:
                            growth = formatted_value
                        elif isinstance(value, (int, float)):
                            growth = f"{value}%"
                        
                        related_queries_data.append({
                            'query': query,
                            'value': value,
                            'growth': growth
                        })
                
                self.logger.info(f"è§£æäº† {len(related_queries_data)} ä¸ªç›¸å…³æŸ¥è¯¢")
            
            return pd.DataFrame(related_queries_data) if related_queries_data else pd.DataFrame(columns=['query', 'value', 'growth'])
            
        except Exception as e:
            self.logger.error(f"è§£æç›¸å…³æŸ¥è¯¢æ•°æ®å‡ºé”™: {e}")
            return pd.DataFrame(columns=['query', 'value', 'growth'])
    
    def get_trending_searches(self, geo=None):
        """
        è·å–çƒ­é—¨æœç´¢æ•°æ®
        
        å‚æ•°:
            geo (str): åœ°åŒºä»£ç ï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            
        è¿”å›:
            pandas.DataFrame: çƒ­é—¨æœç´¢æ•°æ®
        """
        geo = geo or self.API_CONFIG['default_params']['geo']
        
        try:
            self.logger.info(f"æ­£åœ¨è·å– {geo} åœ°åŒºçš„çƒ­é—¨æœç´¢æ•°æ®...")

            # ä½¿ç”¨pytrendsè·å–çƒ­é—¨æœç´¢
            trending_searches = self.pytrends.trending_searches(pn=geo)
            
            if trending_searches is not None and not trending_searches.empty:
                # é‡å‘½ååˆ—ä»¥åŒ¹é…é¢„æœŸæ ¼å¼
                trending_searches.columns = ['query']
                trending_searches['value'] = range(100, 100 - len(trending_searches), -1)
                trending_searches['growth'] = 'Trending'
                
                self.logger.info(f"âœ“ æˆåŠŸè·å– {len(trending_searches)} ä¸ªçƒ­é—¨æœç´¢")
                return trending_searches
            else:
                self.logger.warning("æœªè·å–åˆ°çƒ­é—¨æœç´¢æ•°æ®")
                return pd.DataFrame(columns=['query', 'value', 'growth'])
                
        except Exception as e:
            self.logger.error(f"è·å–çƒ­é—¨æœç´¢æ•°æ®æ—¶å‡ºé”™: {e}")
            return pd.DataFrame(columns=['query', 'value', 'growth'])
    
    def fetch_rising_queries(self, keyword=None, geo=None, timeframe=None):
        """
        è·å–å…³é”®è¯çš„Rising Queries - åªä½¿ç”¨pytrendsé¿å…åŒé‡è¯·æ±‚
        å¦‚æœæ²¡æœ‰æä¾›å…³é”®è¯ï¼Œè¿”å›çƒ­é—¨æœç´¢æ•°æ®
        
        å‚æ•°:
            keyword (str, optional): ç§å­å…³é”®è¯ï¼Œå¦‚æœä¸ºç©ºåˆ™è¿”å›çƒ­é—¨æœç´¢
            geo (str): åœ°åŒºä»£ç ï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            timeframe (str): æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            
        è¿”å›:
            pandas.DataFrame: Rising Queriesæ•°æ®æˆ–çƒ­é—¨æœç´¢æ•°æ®
        """
        # ä½¿ç”¨é»˜è®¤å€¼
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']
        
        # å¦‚æœæ²¡æœ‰æä¾›å…³é”®è¯ï¼Œè¿”å›çƒ­é—¨æœç´¢æ•°æ®
        if not keyword or not keyword.strip():
            self.logger.info(f"æœªæä¾›å…³é”®è¯ï¼Œè·å–çƒ­é—¨æœç´¢æ•°æ® (åœ°åŒº: {geo})...")
            return self.get_trending_searches(geo=geo)
        
        self.logger.info(f"æ­£åœ¨è·å– '{keyword}' çš„Rising Queriesæ•°æ® (åœ°åŒº: {geo})...")

        # ç­‰å¾…é€Ÿç‡é™åˆ¶ï¼ˆé¿å…429é”™è¯¯ï¼‰
        time.sleep(5)
        
        for attempt in range(self.retries):
            try:
                self.logger.info(f"ğŸ” ä½¿ç”¨pytrendsè·å–æ•°æ® (å°è¯• {attempt+1}/{self.retries})")
                
                # åªä½¿ç”¨pytrendsï¼Œé¿å…åŒé‡è¯·æ±‚
                self.pytrends.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo)
                
                # è·å–ç›¸å…³æŸ¥è¯¢
                related_queries = self.pytrends.related_queries()
                
                if keyword in related_queries and related_queries[keyword]:
                    rising = related_queries[keyword]['rising']
                    top = related_queries[keyword]['top']
                    
                    if rising is not None and not rising.empty:
                        self.logger.info(f"âœ… æˆåŠŸè·å– {len(rising)} ä¸ªRising Queries")
                        return rising
                    elif top is not None and not top.empty:
                        self.logger.info(f"âœ… æœªæ‰¾åˆ°Rising Queriesï¼Œè¿”å› {len(top)} ä¸ªTop Queries")
                        # ä¸ºTopæŸ¥è¯¢æ·»åŠ é»˜è®¤å¢é•¿ç‡0
                        top['growth'] = 0
                        return top
                    else:
                        self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æŸ¥è¯¢æ•°æ®")
                        return pd.DataFrame(columns=['query', 'value', 'growth'])
                else:
                    self.logger.warning(f"âš ï¸ æœªæ‰¾åˆ°å…³é”®è¯ '{keyword}' çš„ç›¸å…³æŸ¥è¯¢æ•°æ®")
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
                    
            except Exception as e:
                wait_time = self.backoff_factor * (2 ** attempt)
                if attempt < self.retries - 1:
                    self.logger.warning(f"âš ï¸ è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
                    self.logger.info(f"â° ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯• ({attempt+1}/{self.retries})...")
                    time.sleep(wait_time)
                    # é‡æ–°è¿æ¥
                    self._connect()
                else:
                    self.logger.error(f"âŒ å¤šæ¬¡å°è¯•åä»ç„¶å¤±è´¥: {e}")
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
    
    def fetch_multiple_keywords(self, keywords, geo=None, timeframe=None):
        """
        æ‰¹é‡è·å–å¤šä¸ªå…³é”®è¯çš„Rising Queries - ä½¿ç”¨ç»Ÿä¸€çš„å»¶è¿Ÿé…ç½®
        
        å‚æ•°:
            keywords (list): ç§å­å…³é”®è¯åˆ—è¡¨
            geo (str): åœ°åŒºä»£ç ï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            timeframe (str): æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            
        è¿”å›:
            dict: å…³é”®è¯åˆ°DataFrameçš„æ˜ å°„
        """
        # ä½¿ç”¨é»˜è®¤å€¼
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']

        results = {}
        
        for keyword in keywords:
            df = self.fetch_rising_queries(keyword, geo, timeframe)
            if not df.empty:
                df['seed_keyword'] = keyword  # æ·»åŠ ç§å­å…³é”®è¯åˆ—
                results[keyword] = df
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ‰¹æ¬¡å»¶è¿Ÿé…ç½®
            if keyword != keywords[-1]:  # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªå…³é”®è¯
                batch_delay = self.API_CONFIG['rate_limits']['batch_delay']
                self.logger.info(f"ç­‰å¾…{batch_delay}ç§’ä»¥é¿å…APIé™åˆ¶...")
                time.sleep(batch_delay)
        
        return results
    
    def collect_rising_queries(self, keywords, geo=None, timeframe=None):
        """
        ä¸ºä¸»åˆ†æå™¨æä¾›çš„ç»Ÿä¸€æ¥å£
        
        å‚æ•°:
            keywords (list): ç§å­å…³é”®è¯åˆ—è¡¨
            geo (str): åœ°åŒºä»£ç ï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            timeframe (str): æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            
        è¿”å›:
            pandas.DataFrame: åˆå¹¶åçš„æ‰€æœ‰å…³é”®è¯æ•°æ®
        """
        results = self.fetch_multiple_keywords(keywords, geo, timeframe)
        
        if results:
            # åˆå¹¶æ‰€æœ‰ç»“æœ
            all_df = pd.concat(results.values(), ignore_index=True)
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…é¢„æœŸæ ¼å¼
            if 'value' in all_df.columns:
                all_df = all_df.rename(columns={'value': 'volume'})
            
            # å¤„ç†å¢é•¿ç‡æ•°æ®
            if 'growth' in all_df.columns:
                # å°†å¢é•¿ç‡ä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å€¼
                def parse_growth(growth_val):
                    if pd.isna(growth_val) or growth_val == 0:
                        return 0
                    if isinstance(growth_val, str):
                        # ç§»é™¤%ç¬¦å·å¹¶è½¬æ¢ä¸ºæ•°å€¼
                        return float(growth_val.replace('%', '').replace('+', ''))
                    return float(growth_val)
                
                all_df['growth_rate'] = all_df['growth'].apply(parse_growth)
            else:
                all_df['growth_rate'] = 0
            
            self.logger.info(f"æˆåŠŸæ”¶é›†åˆ° {len(all_df)} ä¸ªå…³é”®è¯çš„è¶‹åŠ¿æ•°æ®")
            return all_df
        else:
            self.logger.warning("æœªæ”¶é›†åˆ°ä»»ä½•è¶‹åŠ¿æ•°æ®")
            return pd.DataFrame(columns=['query', 'volume', 'growth_rate', 'seed_keyword'])
    
    def get_keyword_trends(self, keywords, geo=None, timeframe=None):
        """
        è·å–å…³é”®è¯çš„è¶‹åŠ¿æ•°æ®ï¼ˆä¸ºRootWordTrendsAnalyzeræä¾›çš„æ¥å£ï¼‰
        
        å‚æ•°:
            keywords (str or list): å…³é”®è¯æˆ–å…³é”®è¯åˆ—è¡¨
            geo (str): åœ°åŒºä»£ç ï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            timeframe (str): æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä½¿ç”¨API_CONFIGä¸­çš„å€¼
            
        è¿”å›:
            dict: åŒ…å«è¶‹åŠ¿æ•°æ®çš„å­—å…¸
        """
        # ä½¿ç”¨é»˜è®¤å€¼
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']
        
        # å¤„ç†å…³é”®è¯å‚æ•°
        if isinstance(keywords, list):
            keyword = keywords[0] if keywords else None
        else:
            keyword = keywords
        
        # å¦‚æœæ²¡æœ‰æä¾›å…³é”®è¯ï¼Œè¿”å›çƒ­é—¨æœç´¢æ•°æ®
        if not keyword or not keyword.strip():
            self.logger.info(f"æœªæä¾›å…³é”®è¯ï¼Œè·å–çƒ­é—¨æœç´¢æ•°æ® (åœ°åŒº: {geo})...")
            
            try:
                df = self.get_trending_searches(geo)
                
                if not df.empty:
                    return {
                        'keyword': 'trending_searches',
                        'related_queries': df.to_dict('records'),
                        'total_queries': len(df),
                        'avg_volume': float(df['value'].mean()) if 'value' in df.columns else 0.0,
                        'status': 'success',
                        'data_type': 'trending_searches'
                    }
                else:
                    return {
                        'keyword': 'trending_searches',
                        'related_queries': [],
                        'total_queries': 0,
                        'avg_volume': 0.0,
                        'status': 'no_data',
                        'data_type': 'trending_searches'
                    }
            except Exception as e:
                self.logger.error(f"è·å–çƒ­é—¨æœç´¢æ•°æ®æ—¶å‡ºé”™: {e}")
                return {
                    'keyword': 'trending_searches',
                    'related_queries': [],
                    'total_queries': 0,
                    'avg_volume': 0.0,
                    'status': 'error',
                    'error': str(e),
                    'data_type': 'trending_searches'
                }
        
        self.logger.info(f"æ­£åœ¨è·å–å…³é”®è¯ '{keyword}' çš„è¶‹åŠ¿æ•°æ®...")

        # è·å–Rising Queriesæ•°æ®
        try:
            df = self.fetch_rising_queries(keyword, geo, timeframe)
            
            if not df.empty:
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                total_queries = len(df)
                avg_volume = float(df['value'].mean()) if 'value' in df.columns else 0.0
                
                return {
                    'keyword': keyword,
                    'related_queries': df.to_dict('records'),
                    'total_queries': total_queries,
                    'avg_volume': avg_volume,
                    'status': 'success'
                }
            else:
                return {
                    'keyword': keyword,
                    'related_queries': [],
                    'total_queries': 0,
                    'avg_volume': 0.0,
                    'status': 'no_data'
                }
        except Exception as e:
            self.logger.error(f"è·å–è¶‹åŠ¿æ•°æ®æ—¶å‡ºé”™: {e}")
            return {
                'keyword': keyword,
                'related_queries': [],
                'total_queries': 0,
                'avg_volume': 0.0,
                'status': 'error',
                'error': str(e)
            }
    
    def save_results(self, results, output_dir='data'):
        """
        ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
        
        å‚æ•°:
            results (dict): å…³é”®è¯åˆ°DataFrameçš„æ˜ å°„
            output_dir (str): è¾“å‡ºç›®å½•
        """
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_df = pd.concat(results.values(), ignore_index=True) if results else pd.DataFrame()
        
        if not all_df.empty:
            # ä¿å­˜åˆå¹¶çš„ç»“æœ
            all_filename = FileUtils.generate_filename('trends_all', extension='csv')
            all_file = FileUtils.save_dataframe(all_df, output_dir, all_filename)
            self.logger.info(f"å·²ä¿å­˜æ‰€æœ‰ç»“æœåˆ°: {all_file}")
            
            # ä¸ºæ¯ä¸ªå…³é”®è¯ä¿å­˜å•ç‹¬çš„æ–‡ä»¶
            for keyword, df in results.items():
                # æ¸…ç†å…³é”®è¯ä½œä¸ºæ–‡ä»¶å
                safe_keyword = FileUtils.clean_filename(keyword)
                individual_filename = FileUtils.generate_filename(f'trends_{safe_keyword}', extension='csv')
                file_path = FileUtils.save_dataframe(df, output_dir, individual_filename)
                self.logger.info(f"å·²ä¿å­˜ '{keyword}' çš„ç»“æœåˆ°: {file_path}")
        else:
            self.logger.warning("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Google Trends æ•°æ®é‡‡é›†å·¥å…·')
    parser.add_argument('--keywords', nargs='+', required=True, help='è¦æŸ¥è¯¢çš„å…³é”®è¯åˆ—è¡¨')
    parser.add_argument('--geo', help='åœ°åŒºä»£ç ï¼Œå¦‚USã€GBç­‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„å€¼')
    parser.add_argument('--timeframe', help='æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„å€¼')
    parser.add_argument('--output', default='data', help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºdata')

    args = parser.parse_args()

    # åˆ›å»ºé‡‡é›†å™¨
    collector = TrendsCollector()

    # è·å–æ•°æ®
    results = collector.fetch_multiple_keywords(
        keywords=args.keywords,
        geo=args.geo,
        timeframe=args.timeframe
    )

    # ä¿å­˜ç»“æœ
    collector.save_results(results, args.output)


if __name__ == "__main__":
    main()