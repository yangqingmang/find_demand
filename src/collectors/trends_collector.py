#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Google Trends æ•°æ®é‡‡é›†æ¨¡å—"""

import pandas as pd
import time
import requests
import json
import urllib.parse
from .trends_wrapper import TrendReq
import argparse
from src.utils import FileUtils, Logger
from src.utils.constants import GOOGLE_TRENDS_CONFIG
from config.config_manager import get_config

config = get_config()

class TrendsCollector:
    """Google Trends æ•°æ®é‡‡é›†ç±»"""
    
    API_CONFIG = {
        'base_urls': {
            'explore': 'https://trends.google.com/trends/api/explore',
            'related_searches': 'https://trends.google.com/trends/api/widgetdata/relatedsearches'
        },
        'default_params': {
            'hl': GOOGLE_TRENDS_CONFIG['default_language'],
            'tz': GOOGLE_TRENDS_CONFIG['default_timezone'],
            'geo': GOOGLE_TRENDS_CONFIG['default_geo'],
            'timeframe': GOOGLE_TRENDS_CONFIG['default_timeframe'],
            'category': 0,
            'property': ''
        },
        'headers': {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://trends.google.com/'
        },
        'rate_limits': GOOGLE_TRENDS_CONFIG['rate_limits']
    }
    
    def __init__(self, hl=None, tz=None, timeout=(20, 30), retries=3, backoff_factor=1.5):
        self.hl = hl or self.API_CONFIG['default_params']['hl']
        self.tz = tz or self.API_CONFIG['default_params']['tz']
        self.timeout = timeout
        self.retries = retries
        self.backoff_factor = backoff_factor
        self.logger = Logger()
        
        # åˆå§‹åŒ– pytrends
        try:
            self.pytrends = TrendReq(hl=self.hl, tz=self.tz, timeout=timeout, retries=retries, backoff_factor=backoff_factor)
            self.logger.info("Sessionåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"Sessionåˆå§‹åŒ–å¤±è´¥: {e}")
            self.pytrends = None
    
    def get_trends_data(self, keywords, timeframe='today 12-m', geo=''):
        """
        è·å–å…³é”®è¯è¶‹åŠ¿æ•°æ®
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨æˆ–å•ä¸ªå…³é”®è¯
            timeframe: æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤è¿‡å»12ä¸ªæœˆ
            geo: åœ°ç†ä½ç½®ï¼Œé»˜è®¤å…¨çƒ
            
        Returns:
            pandas.DataFrame: è¶‹åŠ¿æ•°æ®
        """
        if not self.pytrends:
            self.logger.error("pytrends æœªåˆå§‹åŒ–")
            return pd.DataFrame()
            
        try:
            if isinstance(keywords, str):
                keywords = [keywords]
            
            # æ‰“å°è¯·æ±‚å‚æ•°ç”¨äºè°ƒè¯•
            self.logger.info(f"ğŸ” æ­£åœ¨è¯·æ±‚Google Trendsæ•°æ®:")
            self.logger.info(f"   å…³é”®è¯: {keywords}")
            self.logger.info(f"   æ—¶é—´èŒƒå›´: {timeframe}")
            self.logger.info(f"   åœ°ç†ä½ç½®: {geo}")
            
            # æ„å»ºpayload
            self.pytrends.build_payload(keywords, cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–å…´è¶£åº¦æ•°æ®
            interest_over_time = self.pytrends.interest_over_time()
            
            if not interest_over_time.empty:
                # ç§»é™¤ 'isPartial' åˆ—
                if 'isPartial' in interest_over_time.columns:
                    interest_over_time = interest_over_time.drop('isPartial', axis=1)
                
                self.logger.info(f"âœ… æˆåŠŸè·å–åˆ° {len(interest_over_time)} æ¡è¶‹åŠ¿æ•°æ®")
                return interest_over_time
            else:
                self.logger.warning(f"âš ï¸ æœªè·å–åˆ°å…³é”®è¯ {keywords} çš„è¶‹åŠ¿æ•°æ®")
                return pd.DataFrame()
                
        except Exception as e:
            self.logger.error(f"âŒ è·å–è¶‹åŠ¿æ•°æ®å¤±è´¥: {e}")
            self.logger.error(f"   è¯·æ±‚å‚æ•°: keywords={keywords}, timeframe={timeframe}, geo={geo}")
            return pd.DataFrame()
        
        self.pytrends = TrendReq(hl=self.hl, tz=self.tz, timeout=self.timeout)
        self.session = requests.Session()
        self._init_session()
        
        pd.set_option('future.no_silent_downcasting', True)
    
    def _init_session(self):
        """åˆå§‹åŒ–Session"""
        try:
            response = self.session.get('https://trends.google.com/', 
                                      headers={'User-Agent': self.API_CONFIG['headers']['User-Agent']}, 
                                      timeout=30)
            if response.status_code == 200:
                self.logger.info(f"Sessionåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.warning(f"Sessionåˆå§‹åŒ–å¤±è´¥: {e}")

    def _make_api_request(self, request_type, keyword=None, geo=None, timeframe=None, 
                         widget_token=None, widget_request=None):
        """ç»Ÿä¸€APIè¯·æ±‚æ–¹æ³•"""
        time.sleep(1)
        
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']
        
        try:
            if request_type == 'explore':
                url = self.API_CONFIG['base_urls']['explore']
                req_data = {
                    "comparisonItem": [{
                        "keyword": keyword,
                        "geo": geo,
                        "time": timeframe,
                        "category": 0,
                        "property": ""
                    }]
                }
                params = {
                    "hl": self.hl,
                    "tz": self.tz,
                    "req": json.dumps(req_data)
                }
            else:  # related_searches
                url = self.API_CONFIG['base_urls']['related_searches']
                params = {
                    'hl': self.hl,
                    'tz': self.tz,
                    'req': json.dumps(widget_request),
                    'token': widget_token
                }
            
            full_url = f"{url}?{urllib.parse.urlencode(params)}"
            
            # æ‰“å°å®Œæ•´çš„è¯·æ±‚URLç”¨äºè°ƒè¯•
            self.logger.info(f"ğŸ” æ­£åœ¨è¯·æ±‚URL: {full_url}")
            self.logger.info(f"ğŸ“‹ è¯·æ±‚å‚æ•°: {params}")
            
            response = self.session.get(full_url, headers=self.API_CONFIG['headers'], timeout=self.timeout)
            
            # æ‰“å°å“åº”çŠ¶æ€
            self.logger.info(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                content = response.text
                if content.startswith(")]}',"):
                    content = content[5:]
                elif content.startswith(")]}"):
                    content = content[4:]
                return json.loads(content)
            elif response.status_code == 429:
                self.logger.error("APIè¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œç­‰å¾…5ç§’")
                time.sleep(5)
                return None
            else:
                self.logger.error(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            self.logger.error(f"è¯·æ±‚å¼‚å¸¸: {e}")
            return None
    
    def _parse_related_queries(self, data):
        """è§£æç›¸å…³æŸ¥è¯¢æ•°æ®"""
        queries = []
        try:
            if 'default' in data and 'rankedList' in data['default']:
                for ranked_list in data['default']['rankedList']:
                    for item in ranked_list.get('rankedKeyword', []):
                        query = item.get('query', '')
                        value = item.get('value', 0)
                        formatted_value = item.get('formattedValue', '0')
                        
                        growth = formatted_value if '%' in str(formatted_value) else f"{value}%"
                        queries.append({
                            'query': query,
                            'value': value,
                            'growth': growth
                        })
            
            return pd.DataFrame(queries) if queries else pd.DataFrame(columns=['query', 'value', 'growth'])
        except Exception as e:
            self.logger.error(f"è§£ææ•°æ®å‡ºé”™: {e}")
            return pd.DataFrame(columns=['query', 'value', 'growth'])
    
    def _fetch_trending_via_api(self, geo=None, timeframe=None):
        """é€šè¿‡APIè·å–çƒ­é—¨å…³é”®è¯"""
        all_data = []
        
        try:
            explore_response = self._make_api_request('explore', keyword="", geo=geo, timeframe=timeframe)
            
            if explore_response and 'widgets' in explore_response:
                for widget in explore_response['widgets']:
                    if widget.get('id') == 'RELATED_QUERIES' and widget.get('type') == 'fe_related_searches':
                        token = widget.get('token')
                        widget_request = widget.get('request')
                        
                        if token and widget_request:
                            related_response = self._make_api_request('related_searches', 
                                                                    widget_token=token, 
                                                                    widget_request=widget_request)
                            if related_response:
                                df = self._parse_related_queries(related_response)
                                if not df.empty:
                                    df['source'] = 'api'
                                    all_data.append(df)
        except Exception as e:
            self.logger.error(f"APIè·å–çƒ­é—¨å…³é”®è¯å‡ºé”™: {e}")
        
        if not all_data:
            return pd.DataFrame(columns=['query', 'value', 'growth'])
        
        combined_df = pd.concat(all_data, ignore_index=True)
        if 'query' in combined_df.columns:
            combined_df = combined_df.drop_duplicates(subset=['query'], keep='first')
            if 'value' in combined_df.columns:
                combined_df = combined_df.sort_values('value', ascending=False)
        
        return combined_df
    
    def get_trending_searches(self, geo=None):
        """è·å–çƒ­é—¨æœç´¢"""
        geo = geo or self.API_CONFIG['default_params']['geo']
        
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨pytrendsçš„trending_searchesæ–¹æ³•
            trending_searches = self.pytrends.trending_searches(pn=geo)
            
            if trending_searches is not None and not trending_searches.empty:
                trending_searches.columns = ['query']
                trending_searches['value'] = range(100, 100 - len(trending_searches), -1)
                trending_searches['growth'] = 'Trending'
                return trending_searches
            else:
                self.logger.warning("pytrends trending_searchesè¿”å›ç©ºæ•°æ®ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")
                return self._get_fallback_trending_data()
                
        except Exception as e:
            self.logger.error(f"è·å–çƒ­é—¨æœç´¢å‡ºé”™: {e}")
            self.logger.info("å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆè·å–çƒ­é—¨æ•°æ®")
            return self._get_fallback_trending_data()
    
    def _get_fallback_trending_data(self):
        """å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨é¢„å®šä¹‰çš„çƒ­é—¨å…³é”®è¯"""
        fallback_keywords = [
            "AI", "ChatGPT", "artificial intelligence", "machine learning", 
            "AI generator", "AI tool", "AI assistant", "automation",
            "digital marketing", "SEO", "content creation", "productivity",
            "remote work", "online business", "e-commerce", "social media",
            "cryptocurrency", "blockchain", "NFT", "web3"
        ]
        
        try:
            # å°è¯•è·å–è¿™äº›å…³é”®è¯çš„å®é™…è¶‹åŠ¿æ•°æ®
            trending_data = []
            for i, keyword in enumerate(fallback_keywords[:10]):  # é™åˆ¶ä¸ºå‰10ä¸ª
                try:
                    # ä½¿ç”¨ç®€å•çš„è¶‹åŠ¿æŸ¥è¯¢
                    self.pytrends.build_payload([keyword], timeframe='now 7-d')
                    interest_data = self.pytrends.interest_over_time()
                    
                    if not interest_data.empty and keyword in interest_data.columns:
                        avg_interest = interest_data[keyword].mean()
                        trending_data.append({
                            'query': keyword,
                            'value': int(avg_interest) if avg_interest > 0 else 50 - i,
                            'growth': 'Trending'
                        })
                    else:
                        # å¦‚æœæ— æ³•è·å–æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        trending_data.append({
                            'query': keyword,
                            'value': 50 - i,
                            'growth': 'Trending'
                        })
                    
                    time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
                    
                except Exception as e:
                    self.logger.warning(f"è·å–å…³é”®è¯ {keyword} æ•°æ®å¤±è´¥: {e}")
                    # ä½¿ç”¨é»˜è®¤å€¼
                    trending_data.append({
                        'query': keyword,
                        'value': 50 - i,
                        'growth': 'Trending'
                    })
            
            if trending_data:
                df = pd.DataFrame(trending_data)
                self.logger.info(f"âœ… ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆæˆåŠŸè·å– {len(df)} ä¸ªçƒ­é—¨å…³é”®è¯")
                return df
            else:
                return pd.DataFrame(columns=['query', 'value', 'growth'])
                
        except Exception as e:
            self.logger.error(f"å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e}")
            # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼šè¿”å›é™æ€æ•°æ®
            static_data = [
                {'query': 'AI generator', 'value': 95, 'growth': 'Trending'},
                {'query': 'ChatGPT', 'value': 90, 'growth': 'Trending'},
                {'query': 'AI tool', 'value': 85, 'growth': 'Trending'},
                {'query': 'machine learning', 'value': 80, 'growth': 'Trending'},
                {'query': 'artificial intelligence', 'value': 75, 'growth': 'Trending'}
            ]
            self.logger.info("ä½¿ç”¨é™æ€çƒ­é—¨å…³é”®è¯æ•°æ®")
            return pd.DataFrame(static_data)
    
    def fetch_rising_queries(self, keyword=None, geo=None, timeframe=None):
        """è·å–Rising Queries"""
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']
        
        if not keyword or not keyword.strip():
            return self._fetch_trending_via_api(geo=geo, timeframe=timeframe)
        
        time.sleep(1)
        
        for attempt in range(self.retries):
            try:
                self.pytrends.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo)
                related_queries = self.pytrends.related_queries()
                
                if keyword in related_queries and related_queries[keyword]:
                    rising = related_queries[keyword]['rising']
                    top = related_queries[keyword]['top']
                    
                    if rising is not None and not rising.empty:
                        return rising
                    elif top is not None and not top.empty:
                        top['growth'] = 0
                        return top
                
                return pd.DataFrame(columns=['query', 'value', 'growth'])
                    
            except Exception as e:
                if attempt < self.retries - 1:
                    wait_time = self.backoff_factor * (2 ** attempt)
                    self.logger.warning(f"è·å–æ•°æ®å‡ºé”™ï¼Œç­‰å¾…{wait_time:.1f}ç§’é‡è¯•: {e}")
                    time.sleep(wait_time)
                else:
                    self.logger.error(f"å¤šæ¬¡å°è¯•å¤±è´¥: {e}")
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
        return None

    def fetch_multiple_keywords(self, keywords, geo=None, timeframe=None):
        """æ‰¹é‡è·å–å…³é”®è¯æ•°æ®"""
        results = {}
        batch_delay = self.API_CONFIG['rate_limits']['batch_delay']
        
        for i, keyword in enumerate(keywords):
            df = self.fetch_rising_queries(keyword, geo, timeframe)
            if not df.empty:
                df['seed_keyword'] = keyword
                results[keyword] = df
            
            if i < len(keywords) - 1:
                time.sleep(batch_delay)
        
        return results
    
    def collect_rising_queries(self, keywords, geo=None, timeframe=None):
        """ç»Ÿä¸€æ¥å£"""
        results = self.fetch_multiple_keywords(keywords, geo, timeframe)
        
        if results:
            all_df = pd.concat(results.values(), ignore_index=True)
            
            if 'value' in all_df.columns:
                all_df = all_df.rename(columns={'value': 'volume'})
            
            if 'growth' in all_df.columns:
                def parse_growth(growth_val):
                    if pd.isna(growth_val) or growth_val == 0:
                        return 0
                    if isinstance(growth_val, str):
                        return float(growth_val.replace('%', '').replace('+', ''))
                    return float(growth_val)
                
                all_df['growth_rate'] = all_df['growth'].apply(parse_growth)
            else:
                all_df['growth_rate'] = 0
            
            return all_df
        else:
            return pd.DataFrame(columns=['query', 'volume', 'growth_rate', 'seed_keyword'])
    
    def get_keyword_trends(self, keywords, geo=None, timeframe=None):
        """è·å–å…³é”®è¯è¶‹åŠ¿æ•°æ®"""
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']
        
        if isinstance(keywords, list):
            keyword = keywords[0] if keywords else None
        else:
            keyword = keywords
        
        if not keyword or not keyword.strip():
            try:
                df = self.fetch_rising_queries(None, geo=geo, timeframe=timeframe)
                return {
                    'keyword': 'trending_keywords_via_api',
                    'related_queries': df.to_dict('records') if not df.empty else [],
                    'total_queries': len(df),
                    'avg_volume': float(df['value'].mean()) if not df.empty and 'value' in df.columns else 0.0,
                    'status': 'success' if not df.empty else 'no_data',
                    'data_type': 'trending_keywords_via_api'
                }
            except Exception as e:
                return {
                    'keyword': 'trending_keywords_via_api',
                    'related_queries': [],
                    'total_queries': 0,
                    'avg_volume': 0.0,
                    'status': 'error',
                    'error': str(e),
                    'data_type': 'trending_keywords_via_api'
                }
        
        try:
            df = self.fetch_rising_queries(keyword, geo, timeframe)
            
            if not df.empty:
                return {
                    'keyword': keyword,
                    'related_queries': df.to_dict('records'),
                    'total_queries': len(df),
                    'avg_volume': float(df['value'].mean()) if 'value' in df.columns else 0.0,
                    'status': 'success'
                }
            else:
                return {
                    'keyword': keyword,
                    'related_queries': [],
                    'total_queries': 0,
                    'avg_volume': 0.0,
                    'status': 'no_data'
                }
        except Exception as e:
            return {
                'keyword': keyword,
                'related_queries': [],
                'total_queries': 0,
                'avg_volume': 0.0,
                'status': 'error',
                'error': str(e)
            }
    
    def save_results(self, results, output_dir='data'):
        """ä¿å­˜ç»“æœ"""
        all_df = pd.concat(results.values(), ignore_index=True) if results else pd.DataFrame()
        
        if not all_df.empty:
            all_filename = FileUtils.generate_filename('trends_all', extension='csv')
            all_file = FileUtils.save_dataframe(all_df, output_dir, all_filename)
            self.logger.info(f"å·²ä¿å­˜æ‰€æœ‰ç»“æœåˆ°: {all_file}")
            
            for keyword, df in results.items():
                safe_keyword = FileUtils.clean_filename(keyword)
                individual_filename = FileUtils.generate_filename(f'trends_{safe_keyword}', extension='csv')
                file_path = FileUtils.save_dataframe(df, output_dir, individual_filename)
                self.logger.info(f"å·²ä¿å­˜ '{keyword}' çš„ç»“æœåˆ°: {file_path}")
        else:
            self.logger.warning("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")

