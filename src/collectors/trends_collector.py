#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Google Trends æ•°æ®é‡‡é›†æ¨¡å—"""

import pandas as pd
import time
import json
import urllib.parse
import argparse
from typing import Optional
from src.utils import Logger
from src.utils.constants import GOOGLE_TRENDS_CONFIG
from config.config_manager import get_config

config = get_config()

from .google_trends_session import get_global_session
from .request_rate_limiter import (
    wait_for_next_request,
    register_rate_limit_event,
)

class TrendsCollector:
    """Google Trends æ•°æ®é‡‡é›†ç±»"""
    
    API_CONFIG = {
        'base_urls': {
            'explore': 'https://trends.google.com/trends/api/explore',
            'related_searches': 'https://trends.google.com/trends/api/widgetdata/relatedsearches'
        },
        'default_params': {
            'hl': GOOGLE_TRENDS_CONFIG['default_language'],
            'tz': GOOGLE_TRENDS_CONFIG['default_timezone'],
            'geo': GOOGLE_TRENDS_CONFIG['default_geo'],
            'timeframe': GOOGLE_TRENDS_CONFIG['default_timeframe'],
            'category': 0,
            'property': ''
        },
        'headers': {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.6478.61 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Referer': 'https://trends.google.com/trends/explore?hl=en-US&tz=360',
            'Origin': 'https://trends.google.com',
            'Connection': 'keep-alive',
            'DNT': '0',
            'TE': 'trailers',
            'Priority': 'u=1, i',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'Sec-Ch-Ua': '"Not/A)Brand";v="99", "Google Chrome";v="126", "Chromium";v="126"',
            'Sec-Ch-Ua-Full-Version': '"126.0.6478.61"',
            'Sec-Ch-Ua-Full-Version-List': '"Not/A)Brand";v="99.0.0.0", "Google Chrome";v="126.0.6478.61", "Chromium";v="126.0.6478.61"',
            'Sec-Ch-Ua-Reduced': '"Google Chrome";v="126"',
            'Sec-Ch-Ua-Platform': '"Windows"',
            'Sec-Ch-Ua-Platform-Version': '"15.0.0"',
            'Sec-Ch-Ua-Arch': '"x86"',
            'Sec-Ch-Ua-Bitness': '"64"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Model': '""',
            'Sec-Ch-Ua-Wow64': '?0',
            'Sec-Ch-Ua-Form-Factor': '"Desktop"',
            'Sec-CH-Prefers-Color-Scheme': '"light"',
            'Sec-CH-Prefers-Reduced-Motion': '"no-preference"',
            'Viewport-Width': '1920',
            'Downlink': '10',
            'ECT': '4g',
            'RTT': '50',
            'X-Client-Data': 'CK6/ygEIlLbJAQjBtskBCKmdygEIptzKAQj8tc0BCJrdzgEIk7nOARis7c4B'
        },
        'rate_limits': GOOGLE_TRENDS_CONFIG['rate_limits']
    }
    
    def __init__(self, hl=None, tz=None, timeout=(20, 30), retries=3, backoff_factor=1.5):
        self.hl = hl or self.API_CONFIG['default_params']['hl']
        self.tz = tz or self.API_CONFIG['default_params']['tz']
        self.timeout = timeout
        self.retries = retries
        self.backoff_factor = backoff_factor
        self.logger = Logger()
        self._cooldown_until = 0.0
        self._last_cooldown_log = 0.0
        self._rate_limit_severity: Optional[str] = None

        # ç›´æ¥ä½¿ç”¨ CustomTrendsCollectorï¼Œé¿å…å¾ªç¯ä¾èµ–
        try:
            from .custom_trends_collector import CustomTrendsCollector
            self.trends_collector = CustomTrendsCollector()
            self.logger.info("Sessionåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"Sessionåˆå§‹åŒ–å¤±è´¥: {e}")
            self.trends_collector = None
            raise RuntimeError(f"Google Trendsä¼šè¯åˆå§‹åŒ–å¤±è´¥: {e}") from e
            
        if self.trends_collector and hasattr(self.trends_collector, 'set_rate_limit_callback'):
            try:
                self.trends_collector.set_rate_limit_callback(self._handle_rate_limit_event)
            except Exception as callback_error:
                self.logger.warning(f"âš ï¸ æ— æ³•æ³¨å†Œé™æµå›è°ƒ: {callback_error}")

        pd.set_option('future.no_silent_downcasting', True)

    def get_trends_data(self, keywords, timeframe='today 12-m', geo=''):
        """
        è·å–å…³é”®è¯è¶‹åŠ¿æ•°æ®
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨æˆ–å•ä¸ªå…³é”®è¯
            timeframe: æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤è¿‡å»12ä¸ªæœˆ
            geo: åœ°ç†ä½ç½®ï¼Œé»˜è®¤å…¨çƒ
            
        Returns:
            pandas.DataFrame: è¶‹åŠ¿æ•°æ®
        """
        if not self.trends_collector:
            error_msg = "Google Trends ä¼šè¯æœªåˆå§‹åŒ–ï¼Œå¯èƒ½ç¼ºå°‘å¿…è¦çš„ API/ä»£ç† é…ç½®"
            self.logger.error(error_msg)
            raise RuntimeError(error_msg)
            
        if not self._ensure_ready("å…´è¶£åº¦æ•°æ®è¯·æ±‚"):
            raise RuntimeError("Google Trends å¤„äºå†·å´æœŸï¼Œæš‚æœªæ‰§è¡Œè¶‹åŠ¿æ•°æ®è¯·æ±‚")

        try:
            # ç¡®ä¿keywordsæ˜¯åˆ—è¡¨æ ¼å¼
            if isinstance(keywords, str):
                keywords = [keywords]
            
            # æ‰“å°è¯·æ±‚å‚æ•°ç”¨äºè°ƒè¯•
            self.logger.info(f"ğŸ” æ­£åœ¨è¯·æ±‚Google Trendsæ•°æ®:")
            self.logger.info(f"   å…³é”®è¯: {keywords}")
            self.logger.info(f"   æ—¶é—´èŒƒå›´: {timeframe}")
            self.logger.info(f"   åœ°ç†ä½ç½®: {geo}")
            
            # æ„å»ºpayload
            self.trends_collector.build_payload(keywords, cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–å…´è¶£åº¦æ•°æ®
            interest_over_time = self.trends_collector.interest_over_time()

            if interest_over_time.empty:
                warning_msg = f"æœªè·å–åˆ°å…³é”®è¯ {keywords} çš„ Google Trends æ•°æ®"
                self.logger.warning(warning_msg)
                raise RuntimeError(warning_msg)

            # ç§»é™¤ 'isPartial' åˆ—
            if 'isPartial' in interest_over_time.columns:
                interest_over_time = interest_over_time.drop('isPartial', axis=1)

            self.logger.info(f"âœ… æˆåŠŸè·å–åˆ° {len(interest_over_time)} æ¡è¶‹åŠ¿æ•°æ®")
            return interest_over_time

        except Exception as e:
            self.logger.error(f"âŒ è·å–è¶‹åŠ¿æ•°æ®å¤±è´¥: {e}")
            self.logger.error(f"   è¯·æ±‚å‚æ•°: keywords={keywords}, timeframe={timeframe}, geo={geo}")
            raise

    def _make_api_request(self, request_type, keyword=None, geo=None, timeframe=None, 
                         widget_token=None, widget_request=None):
        """ç»Ÿä¸€APIè¯·æ±‚æ–¹æ³•"""
        time.sleep(1)
        
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']

        url = ''
        params={}

        if self._is_in_cooldown():
            self.logger.warning("âš ï¸ TrendsCollector ä»åœ¨å†·å´çª—å£å†…ï¼Œè·³è¿‡è¯·æ±‚: %s", request_type)
            return None

        try:
            if request_type == 'explore':
                url = self.API_CONFIG['base_urls']['explore']
                params = {
                    'hl': self.hl,
                    'tz': self.tz,
                    'req': json.dumps({
                        'comparisonItem': [{
                            'keyword': keyword,
                            'geo': geo,
                            'time': timeframe
                        }],
                        'category': 0,
                        'property': ''
                    })
                }
            elif request_type == 'related_searches':
                url = self.API_CONFIG['base_urls']['related_searches']
                params = {
                    'hl': self.hl,
                    'tz': self.tz,
                    'req': json.dumps(widget_request),
                    'token': widget_token
                }
            
            full_url = f"{url}?{urllib.parse.urlencode(params)}"

            # æ‰“å°å®Œæ•´çš„è¯·æ±‚URLç”¨äºè°ƒè¯•
            self.logger.debug(f"ğŸ” æ­£åœ¨è¯·æ±‚URL: {full_url}")
            self.logger.debug(f"ğŸ“‹ è¯·æ±‚å‚æ•°: {params}")
            
            # ä½¿ç”¨ç»Ÿä¸€çš„sessionç®¡ç†
            if self.trends_collector and hasattr(self.trends_collector, 'session'):
                if not self._wait_for_slot():
                    return None
                time.sleep(2)
                request_headers = dict(self.API_CONFIG['headers'])

                if keyword:
                    referer_params = {
                        'hl': self.hl,
                        'tz': self.tz,
                        'q': keyword
                    }
                    if geo:
                        referer_params['geo'] = geo
                    request_headers['Referer'] = f"https://trends.google.com/trends/explore?{urllib.parse.urlencode(referer_params)}"
                else:
                    referer_params = {
                        'hl': self.hl,
                        'tz': self.tz
                    }
                    if geo:
                        referer_params['geo'] = geo
                    request_headers['Referer'] = f"https://trends.google.com/trends/explore?{urllib.parse.urlencode(referer_params)}"

                response = self.trends_collector.trends_session.make_request(
                    'GET',
                    url,
                    headers=request_headers,
                    params=params,
                    timeout=self.timeout
                )
            else:
                self.logger.error("trends_collectoræœªåˆå§‹åŒ–æˆ–æ²¡æœ‰session")
                return None

            # æ‰“å°å“åº”çŠ¶æ€
            self.logger.info(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")

            if response.status_code == 200:
                content = response.text
                if content.startswith(")]}',"):
                    content = content[5:]
                elif content.startswith(")]}'"):
                    content = content[4:]
                return json.loads(content)
            elif response.status_code == 429:
                penalty = register_rate_limit_event('high')
                self._start_cooldown(penalty)
                self.logger.error("APIè¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè§¦å‘å†·å´ %.1f ç§’", penalty)
                return None
            else:
                self.logger.error(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None

        except Exception as e:
            self.logger.error(f"APIè¯·æ±‚å¼‚å¸¸: {e}")
            return None

    def fetch_rising_queries(self, keyword=None, geo=None, timeframe=None):
        """è·å–Rising Queries"""
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']

        if not self._ensure_ready("related queries æ•°æ®æŠ“å–"):
            return pd.DataFrame(columns=['query', 'value', 'growth'])

        if not keyword or not keyword.strip():
            return self._fetch_trending_via_api(geo=geo, timeframe=timeframe)

        time.sleep(1)

        for attempt in range(self.retries):
            try:
                self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo)
                related_queries = self.trends_collector.related_queries()

                if keyword in related_queries and related_queries[keyword]:
                    rising = related_queries[keyword]['rising']
                    top = related_queries[keyword]['top']

                    if rising is not None and not rising.empty:
                        return rising
                    if top is not None and not top.empty:
                        top['growth'] = 0
                        return top

                raise RuntimeError(f"æœªè·å–åˆ°å…³é”®è¯ {keyword} çš„ related queries æ•°æ®")

            except Exception as e:
                if attempt < self.retries - 1:
                    wait_time = self.backoff_factor * (2 ** attempt)
                    self.logger.warning(f"è·å–æ•°æ®å‡ºé”™ï¼Œç­‰å¾…{wait_time:.1f}ç§’é‡è¯•: {e}")
                    time.sleep(wait_time)
                else:
                    self.logger.error(f"å¤šæ¬¡å°è¯•å¤±è´¥: {e}")
                    raise

    def _fetch_trending_via_api(self, geo=None, timeframe=None):
        """é€šè¿‡APIè·å–çƒ­é—¨å…³é”®è¯"""

        if not self._ensure_ready("trending API è°ƒç”¨"):
            return pd.DataFrame(columns=['query', 'value', 'growth'])

        try:
            # å®Œå…¨æŒ‰ç…§æˆåŠŸçš„curlè¯·æ±‚
            url = "https://trends.google.com/trends/api/explore"
            params = {
                'hl': 'en-US',
                'tz': '360',
                'req': '{"comparisonItem":[{"keyword":"","geo":"US","time":"now 7-d"}],"category":0,"property":""}'
            }

            # ä½¿ç”¨å…¬å…±sessionç®¡ç†
            trends_session = get_global_session()

            try:
                if not self._wait_for_slot():
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
                response = trends_session.get(url, params=params)
            except Exception as session_error:
                self.logger.error(f"âŒ è¯·æ±‚å¤±è´¥: {session_error}")
                return pd.DataFrame(columns=['query', 'value', 'growth'])

            if response.status_code == 200:
                content = response.text
                
                # å¤„ç†Googleçš„ç‰¹æ®Šå‰ç¼€
                # å¤„ç†Googleçš„ç‰¹æ®Šå‰ç¼€
                self.logger.info(f"ğŸ“„ åŸå§‹å“åº”è¯¦ç»†: {repr(content[:20])}")
                
                # æ‰¾åˆ°JSONå¼€å§‹çš„ä½ç½®
                json_start = content.find('{')
                if json_start > 0:
                    content = content[json_start:]
                    self.logger.info(f"æ‰¾åˆ°JSONå¼€å§‹ä½ç½®: {json_start}")
                elif content.startswith(")]}',"):
                    content = content[5:]
                    self.logger.info("ç§»é™¤äº†)]}',å‰ç¼€")
                elif content.startswith(")]}'\n"):
                    content = content[6:]
                    self.logger.info("ç§»é™¤äº†)]}'\nå‰ç¼€")
                elif content.startswith(")]}'"):
                    content = content[4:]
                    self.logger.info("ç§»é™¤äº†)]}'å‰ç¼€")
                
                self.logger.info(f"ğŸ“„ å¤„ç†åå†…å®¹å‰50å­—ç¬¦: {content[:50]}")
                self.logger.info(f"ğŸ“„ å¤„ç†åå†…å®¹å‰50å­—ç¬¦: {content[:50]}")
                
                try:
                    data = json.loads(content)
                    self.logger.info("âœ… æˆåŠŸè§£æJSONæ•°æ®")
                    self.logger.info(f"ğŸ“Š æ•°æ®ç»“æ„: {list(data.keys()) if isinstance(data, dict) else type(data)}")
                    
                    # è§£æwidgetsè·å–ç›¸å…³æœç´¢çš„token
                    if 'widgets' in data:
                        for widget in data['widgets']:
                            self.logger.info(f"ğŸ” Widgetç±»å‹: {widget.get('id', 'unknown')}")
                            if widget.get('id') == 'RELATED_QUERIES':
                                token = widget.get('token')
                                if token:
                                    self.logger.info(f"ğŸ¯ æ‰¾åˆ°RELATED_QUERIES token: {token[:20]}...")
                                    
                                    # è¯·æ±‚related_searchesæ¥å£è·å–çœŸæ­£çš„ç›¸å…³è¯
                                    related_url = "https://trends.google.com/trends/api/widgetdata/relatedsearches"
                                    related_params = {
                                        'hl': 'en-US',
                                        'tz': '360',
                                        'req': json.dumps(widget.get('request', {})),
                                        'token': token
                                    }

                                    self.logger.info("ğŸ” æ­£åœ¨è¯·æ±‚related_searchesæ¥å£...")
                                    # ä½¿ç”¨å…¬å…±sessionç®¡ç†
                                    trends_session = get_global_session()
                                    if not self._wait_for_slot():
                                        return pd.DataFrame(columns=['query', 'value', 'growth'])
                                    related_response = trends_session.get(related_url, params=related_params)

                                    if related_response.status_code == 200:
                                        related_content = related_response.text
                                        # å¤„ç†ç‰¹æ®Šå‰ç¼€
                                        json_start = related_content.find('{')
                                        if json_start > 0:
                                            related_content = related_content[json_start:]
                                        
                                        try:
                                            related_data = json.loads(related_content)
                                            self.logger.info("âœ… æˆåŠŸè·å–related searchesæ•°æ®")
                                            self.logger.info(f"ğŸ“Š Related dataç»“æ„: {list(related_data.keys()) if isinstance(related_data, dict) else type(related_data)}")
                                            
                                            # è§£æçœŸæ­£çš„ç›¸å…³æœç´¢è¯
                                            keywords = []
                                            if 'default' in related_data and 'rankedList' in related_data['default']:
                                                for ranked_list in related_data['default']['rankedList']:
                                                    if 'rankedKeyword' in ranked_list:
                                                        for item in ranked_list['rankedKeyword']:
                                                            if 'query' in item:
                                                                keywords.append({
                                                                    'query': item['query'],
                                                                    'value': item.get('value', 0),
                                                                    'growth': item.get('formattedValue', 'N/A')
                                                                })
                                            
                                            if keywords:
                                                self.logger.info(f"ğŸ¯ è§£æåˆ° {len(keywords)} ä¸ªçœŸå®å…³é”®è¯")
                                                return pd.DataFrame(keywords)
                                            
                                        except json.JSONDecodeError as e:
                                            self.logger.error(f"Related searches JSONè§£æå¤±è´¥: {e}")
                                    else:
                                        if related_response.status_code == 429:
                                            penalty_inner = register_rate_limit_event('high')
                                            self._start_cooldown(penalty_inner)
                                            self.logger.error("âŒ related_searches å‘½ä¸­ 429ï¼Œå†·å´ %.1f ç§’", penalty_inner)
                                        else:
                                            self.logger.error(
                                                f"âš ï¸ related_searches è¯·æ±‚å¤±è´¥: {related_response.status_code}"
                                            )
                                        return pd.DataFrame(columns=['query', 'value', 'growth'])

                                    break
                    
                    raise RuntimeError("æ— æ³•ä» Google Trends è·å– related searches æ•°æ®ï¼Œä¸”æ²¡æœ‰å¯ç”¨çš„å¤‡é€‰æ•°æ®æº")
                except json.JSONDecodeError as e:
                    self.logger.error(f"JSONè§£æå¤±è´¥: {e}")
                    self.logger.error(f"å°è¯•è§£æçš„å†…å®¹: {content[:200]}")
                    raise
            else:
                if response.status_code == 429:
                    penalty = register_rate_limit_event('high')
                    self._start_cooldown(penalty)
                    self.logger.error("âŒ trending API å‘½ä¸­ 429ï¼Œå·²è¿›å…¥å†·å´ %.1f ç§’", penalty)
                else:
                    self.logger.error(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                raise RuntimeError(f"Google Trends related searches è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")

        except Exception as e:
            self.logger.error(f"APIè¯·æ±‚å¼‚å¸¸: {e}")
            raise


    def _parse_related_queries(self, data):
        """è§£æç›¸å…³æŸ¥è¯¢æ•°æ®"""
        queries = []
        try:
            if 'default' in data and 'rankedList' in data['default']:
                for ranked_list in data['default']['rankedList']:
                    for item in ranked_list.get('rankedKeyword', []):
                        query = item.get('query', '')
                        value = item.get('value', 0)
                        formatted_value = item.get('formattedValue', '0')

                        growth = formatted_value if '%' in str(formatted_value) else f"{value}%"
                        queries.append({
                            'query': query,
                            'value': value,
                            'growth': growth
                        })

            return pd.DataFrame(queries) if queries else pd.DataFrame(columns=['query', 'value', 'growth'])
        except Exception as e:
            self.logger.error(f"è§£ææ•°æ®å‡ºé”™: {e}")
            return pd.DataFrame(columns=['query', 'value', 'growth'])

    def get_related_queries(self, keyword, geo='', timeframe='today 12-m'):
        """è·å–ç›¸å…³æŸ¥è¯¢"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return {}

        if not self._ensure_ready("Google Trends ç›¸å…³æŸ¥è¯¢"):
            return {}
            
        try:
            # æ„å»ºpayload
            self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–ç›¸å…³æŸ¥è¯¢
            related_queries = self.trends_collector.related_queries()
            return related_queries
        except Exception as e:
            self.logger.error(f"è·å–ç›¸å…³æŸ¥è¯¢å¤±è´¥: {e}")
            return {}

    def _is_in_cooldown(self) -> bool:
        return time.time() < self._cooldown_until

    def _start_cooldown(self, seconds: float) -> None:
        seconds = max(float(seconds or 0.0), 0.0)
        if seconds <= 0:
            return
        new_until = time.time() + seconds
        if new_until > self._cooldown_until:
            self._cooldown_until = new_until
            self.logger.warning("â³ TrendsCollector è¿›å…¥å†·å´ï¼Œå‰©ä½™ %.1f ç§’", seconds)
            self._last_cooldown_log = 0.0

    def _handle_rate_limit_event(self, penalty: float, severity: str = 'medium') -> None:
        try:
            wait_seconds = float(penalty or 0.0)
        except (TypeError, ValueError):
            wait_seconds = 0.0

        if wait_seconds <= 0:
            return

        self._rate_limit_severity = severity
        self._start_cooldown(wait_seconds)

    def _ensure_ready(self, action_desc: str) -> bool:
        if not self._is_in_cooldown():
            return True

        remaining = max(self._cooldown_until - time.time(), 0.0)
        now = time.time()
        if now - self._last_cooldown_log >= 1.0:
            self.logger.warning(
                "â¸ Google Trends å†·å´ä¸­ (%.1f ç§’)ï¼Œè·³è¿‡ %s", remaining, action_desc
            )
            self._last_cooldown_log = now
        return False

    def is_in_cooldown(self) -> bool:
        """å¯¹å¤–æš´éœ²çš„å†·å´çŠ¶æ€æŸ¥è¯¢"""
        return self._is_in_cooldown()

    def _wait_for_slot(self) -> bool:
        try:
            wait_for_next_request()
            return True
        except RuntimeError as exc:
            self.logger.error(f"âŒ è¯·æ±‚è¢«é™æµå®ˆå«é˜»æ­¢: {exc}")
            return False
        except Exception as exc:
            self.logger.warning(f"âš ï¸ ç­‰å¾…é™æµæ§½ä½æ—¶å¼‚å¸¸: {exc}")
            return True

    def get_related_topics(self, keyword, geo='', timeframe='today 12-m'):
        """è·å–ç›¸å…³ä¸»é¢˜"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return {}

        if not self._ensure_ready("Google Trends ç›¸å…³ä¸»é¢˜"):
            return {}
            
        try:
            # æ„å»ºpayload
            self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–ç›¸å…³ä¸»é¢˜
            related_topics = self.trends_collector.related_topics()
            return related_topics
        except Exception as e:
            self.logger.error(f"è·å–ç›¸å…³ä¸»é¢˜å¤±è´¥: {e}")
            return {}

    def get_interest_by_region(self, keyword, geo='', timeframe='today 12-m'):
        """è·å–æŒ‰åœ°åŒºåˆ†å¸ƒçš„å…´è¶£åº¦"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()

        if not self._ensure_ready("Google Trends åŒºåŸŸå…´è¶£åº¦"):
            return pd.DataFrame()
            
        try:
            # æ„å»ºpayload
            self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–åœ°åŒºå…´è¶£åº¦
            interest_by_region = self.trends_collector.interest_by_region()
            return interest_by_region
        except Exception as e:
            self.logger.error(f"è·å–åœ°åŒºå…´è¶£åº¦å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_suggestions(self, keyword):
        """è·å–å…³é”®è¯å»ºè®®"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return []

        if not self._ensure_ready("Google Trends å…³é”®è¯å»ºè®®"):
            return []
            
        try:
            suggestions = self.trends_collector.suggestions(keyword)
            return suggestions
        except Exception as e:
            self.logger.error(f"è·å–å…³é”®è¯å»ºè®®å¤±è´¥: {e}")
            return []

    def trending_searches(self, pn='united_states'):
        """è·å–çƒ­é—¨æœç´¢"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()

        if not self._ensure_ready("Google Trends çƒ­é—¨æœç´¢"):
            return pd.DataFrame()
            
        try:
            trending = self.trends_collector.trending_searches(pn)
            return trending
        except Exception as e:
            self.logger.error(f"è·å–çƒ­é—¨æœç´¢å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_historical_interest(self, keyword, start_date, end_date=None):
        """è·å–å†å²å…´è¶£æ•°æ®"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()

        if not self._ensure_ready("Google Trends å†å²æ•°æ®"):
            return pd.DataFrame()
            
        try:
            historical_data = self.trends_collector.get_historical_interest(keyword, start_date, end_date)
            return historical_data
        except Exception as e:
            self.logger.error(f"è·å–å†å²å…´è¶£æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_keyword_trends(self, keyword, timeframe='today 12-m', geo=''):
        """è·å–å…³é”®è¯è¶‹åŠ¿æ•°æ® - ä¸ºroot_word_trends_analyzeræä¾›çš„æ¥å£"""
        if not self.trends_collector:
            error_msg = "Google Trends ä¼šè¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•è·å–å…³é”®è¯è¶‹åŠ¿æ•°æ®"
            self.logger.error(error_msg)
            raise RuntimeError(error_msg)

        if not self._ensure_ready("Google Trends å•è¯è¶‹åŠ¿æ•°æ®"):
            raise RuntimeError("Google Trends å¤„äºå†·å´æœŸï¼Œæš‚æœªæ‰§è¡Œå…³é”®è¯è¶‹åŠ¿è¯·æ±‚")

        try:
            return self.trends_collector.get_keyword_trends(keyword, timeframe, geo)
        except Exception as e:
            self.logger.error(f"è·å–å…³é”®è¯è¶‹åŠ¿å¤±è´¥: {e}")
            raise


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•"""
    parser = argparse.ArgumentParser(description='Google Trends æ•°æ®é‡‡é›†å·¥å…·')
    parser.add_argument('--keyword', '-k', type=str, required=True, help='è¦æŸ¥è¯¢çš„å…³é”®è¯')
    parser.add_argument('--geo', '-g', type=str, default='', help='åœ°ç†ä½ç½® (å¦‚: US, CN)')
    parser.add_argument('--timeframe', '-t', type=str, default='today 12-m', help='æ—¶é—´èŒƒå›´')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé‡‡é›†å™¨å®ä¾‹
    collector = TrendsCollector()
    
    print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢å…³é”®è¯: {args.keyword}")
    print(f"ğŸ“ åœ°ç†ä½ç½®: {args.geo or 'å…¨çƒ'}")
    print(f"â° æ—¶é—´èŒƒå›´: {args.timeframe}")
    print("-" * 50)
    
    # è·å–è¶‹åŠ¿æ•°æ®
    trends_data = collector.get_trends_data(args.keyword, args.timeframe, args.geo)
    
    if not trends_data.empty:
        print("âœ… è¶‹åŠ¿æ•°æ®è·å–æˆåŠŸ!")
        print(f"ğŸ“Š æ•°æ®è¡Œæ•°: {len(trends_data)}")
        print("\nğŸ“ˆ å‰5è¡Œæ•°æ®:")
        print(trends_data.head())
        
        if args.output:
            trends_data.to_csv(args.output, index=False)
            print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {args.output}")
    else:
        print("âŒ æœªè·å–åˆ°è¶‹åŠ¿æ•°æ®")
    
    # è·å–ç›¸å…³æŸ¥è¯¢
    print("\nğŸ” è·å–ç›¸å…³æŸ¥è¯¢...")
    related_queries = collector.get_related_queries(args.keyword, args.geo, args.timeframe)
    
    if related_queries:
        print("âœ… ç›¸å…³æŸ¥è¯¢è·å–æˆåŠŸ!")
        for query_type, queries in related_queries.items():
            if not queries.empty:
                print(f"\nğŸ“‹ {query_type}:")
                print(queries.head())
    else:
        print("âŒ æœªè·å–åˆ°ç›¸å…³æŸ¥è¯¢")


if __name__ == "__main__":
    main()
