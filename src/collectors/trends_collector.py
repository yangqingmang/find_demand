#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google Trends æ•°æ®é‡‡é›†æ¨¡å—
ç”¨äºé‡‡é›†Google Trendsç›¸å…³æŸ¥è¯¢æ•°æ®
"""

import pandas as pd
import time
import requests
import json
import urllib.parse
from pytrends.request import TrendReq
import argparse

from src.utils import (
    FileUtils, Logger, ExceptionHandler, APIError,
    DEFAULT_CONFIG, VALIDATION_CONSTANTS
)
try:
    from config.config_manager import get_config
    config = get_config()
except ImportError:
    # å¦‚æœé…ç½®ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆé…ç½®
    from src.utils.simple_config import get_config
    config = get_config()
from src.utils.mock_data_generator import MockDataGenerator

class TrendsCollector:
    """Google Trends æ•°æ®é‡‡é›†ç±»"""
    
    def __init__(self, hl='en-US', tz=360, timeout=(20, 30), retries=5, backoff_factor=2.0):
        """
        åˆå§‹åŒ– TrendsCollector
        
        å‚æ•°:
            hl (str): è¯­è¨€è®¾ç½®ï¼Œé»˜è®¤'en-US'ï¼ˆæ”¹ä¸ºè‹±æ–‡ä»¥æé«˜å…¼å®¹æ€§ï¼‰
            tz (int): æ—¶åŒºï¼Œé»˜è®¤360
            timeout (tuple): è¿æ¥å’Œè¯»å–è¶…æ—¶æ—¶é—´(ç§’)
            retries (int): é‡è¯•æ¬¡æ•°
            backoff_factor (float): é‡è¯•é—´éš”å¢é•¿å› å­
        """
        self.hl = hl
        self.tz = tz
        self.timeout = timeout
        self.retries = retries
        self.backoff_factor = backoff_factor
        self.pytrends = None
        self.logger = Logger()
        self._connect()
        
        # è®¾ç½®pandasé€‰é¡¹ï¼Œæ¶ˆé™¤è­¦å‘Š
        pd.set_option('future.no_silent_downcasting', True)
    
    def _connect(self):
        """åˆ›å»ºpytrendsè¿æ¥"""
        self.pytrends = TrendReq(hl=self.hl, tz=self.tz, timeout=self.timeout)
    
    def _make_direct_api_request(self, keyword, geo='US', timeframe='today 12-m'):
        """
        ä½¿ç”¨æ­£ç¡®çš„APIæ ¼å¼ç›´æ¥è¯·æ±‚Google Trendsæ•°æ®
        
        å‚æ•°:
            keyword (str): å…³é”®è¯
            geo (str): åœ°åŒºä»£ç ï¼Œé»˜è®¤'US'
            timeframe (str): æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤'today 12-m'
            
        è¿”å›:
            dict: APIå“åº”æ•°æ®
        """
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°ï¼ŒæŒ‰ç…§ä½ æä¾›çš„æ ¼å¼
            req_data = {
                "comparisonItem": [{
                    "keyword": keyword,
                    "geo": geo,
                    "time": timeframe
                }]
            }
            
            # æ„å»ºå®Œæ•´çš„URL
            base_url = "https://trends.google.com/trends/api/explore"
            params = {
                "hl": self.hl,
                "tz": self.tz,
                "req": json.dumps(req_data)
            }
            
            # å‘é€è¯·æ±‚
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            self.logger.info(f"å‘é€APIè¯·æ±‚: {base_url}")
            self.logger.info(f"è¯·æ±‚å‚æ•°: {params}")
            
            response = requests.get(base_url, params=params, headers=headers, timeout=self.timeout)
            
            if response.status_code == 200:
                # Google Trends APIè¿”å›çš„æ•°æ®ä»¥")]}'"å¼€å¤´ï¼Œéœ€è¦å»é™¤è¿™4ä¸ªå­—ç¬¦
                content = response.text
                if content.startswith(")]}',"):
                    # å»é™¤å‰4ä¸ªå­—ç¬¦ ")]}'"
                    content = content[4:]
                    # å¦‚æœåé¢è¿˜æœ‰æ¢è¡Œç¬¦ï¼Œä¹Ÿå»é™¤
                    if content.startswith('\n'):
                        content = content[1:]
                elif content.startswith(")]}',\n"):
                    # å…¼å®¹ä¹‹å‰çš„å¤„ç†æ–¹å¼
                    content = content[6:]
                
                self.logger.info("âœ“ APIè¯·æ±‚æˆåŠŸï¼Œæ­£åœ¨è§£æå“åº”æ•°æ®")
                self.logger.debug(f"å¤„ç†åçš„å“åº”å†…å®¹å‰100å­—ç¬¦: {content[:100]}")
                return json.loads(content)
            else:
                self.logger.error(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                self.logger.error(f"å“åº”å†…å®¹: {response.text[:500]}")
                return None
                
        except Exception as e:
            self.logger.error(f"ç›´æ¥APIè¯·æ±‚å‡ºé”™: {e}")
            return None
    
    def _extract_related_queries_from_api_response(self, api_response):
        """
        ä»APIå“åº”ä¸­æå–ç›¸å…³æŸ¥è¯¢æ•°æ®
        æ ¹æ®çœŸå®çš„Google Trends APIå“åº”æ ¼å¼è¿›è¡Œè§£æ
        
        å‚æ•°:
            api_response (dict): APIå“åº”æ•°æ®
            
        è¿”å›:
            pandas.DataFrame: ç›¸å…³æŸ¥è¯¢æ•°æ®
        """
        try:
            if not api_response or 'widgets' not in api_response:
                self.logger.warning("APIå“åº”ä¸­æ²¡æœ‰widgetsæ•°æ®")
                return pd.DataFrame(columns=['query', 'value', 'growth'])
            
            self.logger.info(f"æ‰¾åˆ° {len(api_response['widgets'])} ä¸ªwidgets")
            
            # æŸ¥æ‰¾ç›¸å…³æŸ¥è¯¢widget (RELATED_QUERIES)
            related_queries_data = []
            
            for widget in api_response['widgets']:
                widget_id = widget.get('id', '')
                widget_type = widget.get('type', '')
                self.logger.info(f"å¤„ç†widget: id={widget_id}, type={widget_type}")
                
                if widget_id == 'RELATED_QUERIES' and widget_type == 'fe_related_searches':
                    self.logger.info("æ‰¾åˆ°ç›¸å…³æŸ¥è¯¢widget (RELATED_QUERIES)")
                    
                    # è·å–widgetçš„token
                    token = widget.get('token')
                    if not token:
                        self.logger.warning("ç›¸å…³æŸ¥è¯¢widgetç¼ºå°‘token")
                        continue
                    
                    # æ„å»ºç›¸å…³æŸ¥è¯¢çš„è¯·æ±‚URL
                    related_url = "https://trends.google.com/trends/api/widgetdata/relatedsearches"
                    params = {
                        'hl': self.hl,
                        'tz': self.tz,
                        'req': json.dumps(widget['request']),
                        'token': token
                    }
                    
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                    }
                    
                    self.logger.info(f"è¯·æ±‚ç›¸å…³æŸ¥è¯¢æ•°æ®: {related_url}")
                    response = requests.get(related_url, params=params, headers=headers, timeout=self.timeout)
                    
                    if response.status_code == 200:
                        content = response.text
                        # å¤„ç†Google Trends APIç‰¹æ®Šçš„å“åº”å‰ç¼€ ")]}'"
                        if content.startswith(")]}',"):
                            content = content[4:]
                            if content.startswith('\n'):
                                content = content[1:]
                        elif content.startswith(")]}',\n"):
                            content = content[6:]
                        
                        self.logger.debug(f"ç›¸å…³æŸ¥è¯¢å“åº”å‰100å­—ç¬¦: {content[:100]}")
                        
                        try:
                            data = json.loads(content)
                            
                            # æ ¹æ®çœŸå®APIå“åº”ç»“æ„è§£ææ•°æ®
                            if 'default' in data and 'rankedList' in data['default']:
                                for ranked_list in data['default']['rankedList']:
                                    list_type = ranked_list.get('rankedKeyword', [])
                                    
                                    for item in list_type:
                                        # æå–æŸ¥è¯¢æ•°æ®
                                        query = item.get('query', '')
                                        value = item.get('value', 0)
                                        formatted_value = item.get('formattedValue', '0')
                                        
                                        # å¤„ç†å¢é•¿ç‡æ•°æ®
                                        growth = formatted_value
                                        if isinstance(formatted_value, str) and '%' in formatted_value:
                                            growth = formatted_value
                                        elif isinstance(value, (int, float)):
                                            growth = f"{value}%"
                                        
                                        query_data = {
                                            'query': query,
                                            'value': value,
                                            'growth': growth
                                        }
                                        related_queries_data.append(query_data)
                                        
                                self.logger.info(f"ä»rankedListä¸­æå–äº† {len(related_queries_data)} ä¸ªæŸ¥è¯¢")
                            else:
                                self.logger.warning("ç›¸å…³æŸ¥è¯¢å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°expectedçš„æ•°æ®ç»“æ„")
                                self.logger.debug(f"å“åº”æ•°æ®ç»“æ„: {list(data.keys()) if isinstance(data, dict) else type(data)}")
                                
                        except json.JSONDecodeError as e:
                            self.logger.error(f"è§£æç›¸å…³æŸ¥è¯¢JSONæ•°æ®å¤±è´¥: {e}")
                            self.logger.debug(f"åŸå§‹å“åº”å†…å®¹: {content[:200]}")
                            
                    else:
                        self.logger.error(f"ç›¸å…³æŸ¥è¯¢è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                        self.logger.debug(f"é”™è¯¯å“åº”: {response.text[:200]}")
                    
                    break  # æ‰¾åˆ°RELATED_QUERIESåå°±é€€å‡ºå¾ªç¯
            
            if related_queries_data:
                self.logger.info(f"âœ“ æˆåŠŸæå– {len(related_queries_data)} ä¸ªç›¸å…³æŸ¥è¯¢")
                return pd.DataFrame(related_queries_data)
            else:
                self.logger.warning("æœªæ‰¾åˆ°ç›¸å…³æŸ¥è¯¢æ•°æ®ï¼Œè¿”å›ç©ºDataFrame")
                return pd.DataFrame(columns=['query', 'value', 'growth'])
                
        except Exception as e:
            self.logger.error(f"æå–ç›¸å…³æŸ¥è¯¢æ•°æ®å‡ºé”™: {e}")
            import traceback
            self.logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return pd.DataFrame(columns=['query', 'value', 'growth'])
    
    def fetch_rising_queries(self, keyword, geo='US', timeframe='today 12-m'):
        """
        è·å–å…³é”®è¯çš„Rising Queries - ä½¿ç”¨æ”¹è¿›çš„APIè¯·æ±‚æ ¼å¼
        
        å‚æ•°:
            keyword (str): ç§å­å…³é”®è¯
            geo (str): åœ°åŒºä»£ç ï¼Œå¦‚'US','GB'ç­‰ï¼Œé»˜è®¤'US'
            timeframe (str): æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤'today 12-m'
            
        è¿”å›:
            pandas.DataFrame: Rising Queriesæ•°æ®
        """
        self.logger.info(f"æ­£åœ¨è·å– '{keyword}' çš„Rising Queriesæ•°æ® (åœ°åŒº: {geo})...")
        
        # å¦‚æœå¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        if config.MOCK_MODE:
            self.logger.info("ğŸ”§ æ¨¡æ‹Ÿæ¨¡å¼ï¼šç”Ÿæˆæ¨¡æ‹Ÿè¶‹åŠ¿æ•°æ®")
            mock_generator = MockDataGenerator()
            mock_results = mock_generator.generate_trends_data([keyword], geo, timeframe)
            if keyword in mock_results:
                return mock_results[keyword]
            else:
                return pd.DataFrame(columns=['query', 'value', 'growth'])
        
        for attempt in range(self.retries):
            try:
                # é¦–å…ˆå°è¯•ä½¿ç”¨æ”¹è¿›çš„ç›´æ¥APIè¯·æ±‚
                self.logger.info(f"å°è¯•ä½¿ç”¨ç›´æ¥APIè¯·æ±‚ (å°è¯• {attempt+1}/{self.retries})")
                
                api_response = self._make_direct_api_request(keyword, geo, timeframe)
                
                if api_response:
                    # ä»APIå“åº”ä¸­æå–ç›¸å…³æŸ¥è¯¢æ•°æ®
                    df = self._extract_related_queries_from_api_response(api_response)
                    
                    if not df.empty:
                        self.logger.info(f"âœ“ ç›´æ¥APIæˆåŠŸè·å– {len(df)} ä¸ªç›¸å…³æŸ¥è¯¢")
                        return df
                    else:
                        self.logger.warning("ç›´æ¥APIå“åº”ä¸­æœªæ‰¾åˆ°ç›¸å…³æŸ¥è¯¢æ•°æ®")
                
                # å¦‚æœç›´æ¥APIè¯·æ±‚å¤±è´¥ï¼Œå›é€€åˆ°pytrends
                self.logger.info("ç›´æ¥APIè¯·æ±‚å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨pytrendsåº“")
                
                # æ„å»ºpayload
                self.pytrends.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo)
                
                # è·å–ç›¸å…³æŸ¥è¯¢
                related_queries = self.pytrends.related_queries()
                
                if keyword in related_queries and related_queries[keyword]:
                    rising = related_queries[keyword]['rising']
                    top = related_queries[keyword]['top']
                    
                    if rising is not None and not rising.empty:
                        self.logger.info(f"âœ“ pytrendsæˆåŠŸè·å– {len(rising)} ä¸ªRising Queries")
                        return rising
                    elif top is not None and not top.empty:
                        self.logger.info(f"âœ“ pytrendsæœªæ‰¾åˆ°Rising Queriesï¼Œè¿”å› {len(top)} ä¸ªTop Queries")
                        # ä¸ºTopæŸ¥è¯¢æ·»åŠ é»˜è®¤å¢é•¿ç‡0
                        top['growth'] = 0
                        return top
                    else:
                        self.logger.warning(f"pytrendsæœªæ‰¾åˆ°ç›¸å…³æŸ¥è¯¢æ•°æ®")
                        return pd.DataFrame(columns=['query', 'value', 'growth'])
                else:
                    self.logger.warning(f"pytrendsæœªæ‰¾åˆ°å…³é”®è¯ '{keyword}' çš„ç›¸å…³æŸ¥è¯¢æ•°æ®")
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
                    
            except Exception as e:
                wait_time = self.backoff_factor * (2 ** attempt)
                if attempt < self.retries - 1:
                    self.logger.warning(f"è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
                    self.logger.info(f"ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯• ({attempt+1}/{self.retries})...")
                    time.sleep(wait_time)
                    # é‡æ–°è¿æ¥
                    self._connect()
                else:
                    self.logger.error(f"å¤šæ¬¡å°è¯•åä»ç„¶å¤±è´¥: {e}")
                    self.logger.info("ğŸ”„ APIå¤±è´¥ï¼Œè‡ªåŠ¨å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼")
                    # è‡ªåŠ¨å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
                    try:
                        mock_generator = MockDataGenerator()
                        mock_results = mock_generator.generate_trends_data([keyword], geo, timeframe)
                        if keyword in mock_results:
                            self.logger.info(f"âœ“ å·²ç”Ÿæˆ '{keyword}' çš„æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºå›é€€")
                            return mock_results[keyword]
                    except Exception as mock_error:
                        self.logger.error(f"æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆä¹Ÿå¤±è´¥: {mock_error}")
                    
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
    
    def fetch_multiple_keywords(self, keywords, geo='US', timeframe='today 12-m'):
        """
        æ‰¹é‡è·å–å¤šä¸ªå…³é”®è¯çš„Rising Queries
        
        å‚æ•°:
            keywords (list): ç§å­å…³é”®è¯åˆ—è¡¨
            geo (str): åœ°åŒºä»£ç 
            timeframe (str): æ—¶é—´èŒƒå›´
            
        è¿”å›:
            dict: å…³é”®è¯åˆ°DataFrameçš„æ˜ å°„
        """
        # å¦‚æœå¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼Œç›´æ¥ç”Ÿæˆæ‰€æœ‰å…³é”®è¯çš„æ¨¡æ‹Ÿæ•°æ®
        if config.MOCK_MODE:
            self.logger.info("ğŸ”§ æ¨¡æ‹Ÿæ¨¡å¼ï¼šæ‰¹é‡ç”Ÿæˆæ¨¡æ‹Ÿè¶‹åŠ¿æ•°æ®")
            mock_generator = MockDataGenerator()
            return mock_generator.generate_trends_data(keywords, geo, timeframe)
        
        results = {}
        
        for keyword in keywords:
            df = self.fetch_rising_queries(keyword, geo, timeframe)
            if not df.empty:
                df['seed_keyword'] = keyword  # æ·»åŠ ç§å­å…³é”®è¯åˆ—
                results[keyword] = df
            
            # é¿å…APIé™åˆ¶ï¼Œæ¯æ¬¡è¯·æ±‚ä¹‹é—´ç­‰å¾…
            if keyword != keywords[-1]:  # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªå…³é”®è¯
                self.logger.info("ç­‰å¾…30ç§’ä»¥é¿å…APIé™åˆ¶...")
                time.sleep(30)
        
        return results
    
    def collect_rising_queries(self, keywords, geo='US', timeframe='today 12-m'):
        """
        ä¸ºä¸»åˆ†æå™¨æä¾›çš„ç»Ÿä¸€æ¥å£
        
        å‚æ•°:
            keywords (list): ç§å­å…³é”®è¯åˆ—è¡¨
            geo (str): åœ°åŒºä»£ç 
            timeframe (str): æ—¶é—´èŒƒå›´
            
        è¿”å›:
            pandas.DataFrame: åˆå¹¶åçš„æ‰€æœ‰å…³é”®è¯æ•°æ®
        """
        results = self.fetch_multiple_keywords(keywords, geo, timeframe)
        
        if results:
            # åˆå¹¶æ‰€æœ‰ç»“æœ
            all_df = pd.concat(results.values(), ignore_index=True)
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…é¢„æœŸæ ¼å¼
            if 'value' in all_df.columns:
                all_df = all_df.rename(columns={'value': 'volume'})
            
            # å¤„ç†å¢é•¿ç‡æ•°æ®
            if 'growth' in all_df.columns:
                # å°†å¢é•¿ç‡ä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å€¼
                def parse_growth(growth_val):
                    if pd.isna(growth_val) or growth_val == 0:
                        return 0
                    if isinstance(growth_val, str):
                        # ç§»é™¤%ç¬¦å·å¹¶è½¬æ¢ä¸ºæ•°å€¼
                        return float(growth_val.replace('%', '').replace('+', ''))
                    return float(growth_val)
                
                all_df['growth_rate'] = all_df['growth'].apply(parse_growth)
            else:
                all_df['growth_rate'] = 0
            
            self.logger.info(f"æˆåŠŸæ”¶é›†åˆ° {len(all_df)} ä¸ªå…³é”®è¯çš„è¶‹åŠ¿æ•°æ®")
            return all_df
        else:
            self.logger.warning("æœªæ”¶é›†åˆ°ä»»ä½•è¶‹åŠ¿æ•°æ®")
            return pd.DataFrame(columns=['query', 'volume', 'growth_rate', 'seed_keyword'])
    
    def get_keyword_trends(self, keywords, geo='US', timeframe='today 12-m'):
        """
        è·å–å…³é”®è¯çš„è¶‹åŠ¿æ•°æ®ï¼ˆä¸ºRootWordTrendsAnalyzeræä¾›çš„æ¥å£ï¼‰
        
        å‚æ•°:
            keywords (str or list): å…³é”®è¯æˆ–å…³é”®è¯åˆ—è¡¨
            geo (str): åœ°åŒºä»£ç 
            timeframe (str): æ—¶é—´èŒƒå›´
            
        è¿”å›:
            dict: åŒ…å«è¶‹åŠ¿æ•°æ®çš„å­—å…¸
        """
        # ç¡®ä¿keywordsæ˜¯å­—ç¬¦ä¸²ï¼ˆå•ä¸ªå…³é”®è¯ï¼‰
        if isinstance(keywords, list):
            keyword = keywords[0] if keywords else ""
        else:
            keyword = keywords
            
        self.logger.info(f"æ­£åœ¨è·å–å…³é”®è¯ '{keyword}' çš„è¶‹åŠ¿æ•°æ®...")
        
        # å¦‚æœå¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        if config.MOCK_MODE:
            self.logger.info("ğŸ”§ æ¨¡æ‹Ÿæ¨¡å¼ï¼šç”Ÿæˆæ¨¡æ‹Ÿè¶‹åŠ¿æ•°æ®")
            mock_generator = MockDataGenerator()
            
            try:
                # ç”Ÿæˆå•ä¸ªå…³é”®è¯çš„æ¨¡æ‹Ÿæ•°æ®
                mock_results = mock_generator.generate_trends_data([keyword], geo, timeframe)
                if keyword in mock_results:
                    df = mock_results[keyword]
                    
                    # ç¡®ä¿DataFrameä¸ä¸ºç©ºä¸”æœ‰æ­£ç¡®çš„åˆ—
                    if not df.empty and 'value' in df.columns:
                        return {
                            'keyword': keyword,
                            'related_queries': df.to_dict('records'),
                            'total_queries': len(df),
                            'avg_volume': float(df['value'].mean()),
                            'status': 'success'
                        }
                    else:
                        return {
                            'keyword': keyword,
                            'related_queries': [],
                            'total_queries': 0,
                            'avg_volume': 0.0,
                            'status': 'no_data'
                        }
                else:
                    return {
                        'keyword': keyword,
                        'related_queries': [],
                        'total_queries': 0,
                        'avg_volume': 0.0,
                        'status': 'no_data'
                    }
            except Exception as e:
                self.logger.error(f"ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®æ—¶å‡ºé”™: {e}")
                return {
                    'keyword': keyword,
                    'related_queries': [],
                    'total_queries': 0,
                    'avg_volume': 0.0,
                    'status': 'error',
                    'error': str(e)
                }
        
        # è·å–Rising Queriesæ•°æ®
        try:
            df = self.fetch_rising_queries(keyword, geo, timeframe)
            
            if not df.empty:
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                total_queries = len(df)
                avg_volume = float(df['value'].mean()) if 'value' in df.columns else 0.0
                
                return {
                    'keyword': keyword,
                    'related_queries': df.to_dict('records'),
                    'total_queries': total_queries,
                    'avg_volume': avg_volume,
                    'status': 'success'
                }
            else:
                return {
                    'keyword': keyword,
                    'related_queries': [],
                    'total_queries': 0,
                    'avg_volume': 0.0,
                    'status': 'no_data'
                }
        except Exception as e:
            self.logger.error(f"è·å–è¶‹åŠ¿æ•°æ®æ—¶å‡ºé”™: {e}")
            return {
                'keyword': keyword,
                'related_queries': [],
                'total_queries': 0,
                'avg_volume': 0.0,
                'status': 'error',
                'error': str(e)
            }
    
    def save_results(self, results, output_dir='data'):
        """
        ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
        
        å‚æ•°:
            results (dict): å…³é”®è¯åˆ°DataFrameçš„æ˜ å°„
            output_dir (str): è¾“å‡ºç›®å½•
        """
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_df = pd.concat(results.values(), ignore_index=True) if results else pd.DataFrame()
        
        if not all_df.empty:
            # ä¿å­˜åˆå¹¶çš„ç»“æœ
            all_filename = FileUtils.generate_filename('trends_all', extension='csv')
            all_file = FileUtils.save_dataframe(all_df, output_dir, all_filename)
            self.logger.info(f"å·²ä¿å­˜æ‰€æœ‰ç»“æœåˆ°: {all_file}")
            
            # ä¸ºæ¯ä¸ªå…³é”®è¯ä¿å­˜å•ç‹¬çš„æ–‡ä»¶
            for keyword, df in results.items():
                # æ¸…ç†å…³é”®è¯ä½œä¸ºæ–‡ä»¶å
                safe_keyword = FileUtils.clean_filename(keyword)
                individual_filename = FileUtils.generate_filename(f'trends_{safe_keyword}', extension='csv')
                file_path = FileUtils.save_dataframe(df, output_dir, individual_filename)
                self.logger.info(f"å·²ä¿å­˜ '{keyword}' çš„ç»“æœåˆ°: {file_path}")
        else:
            self.logger.warning("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Google Trends æ•°æ®é‡‡é›†å·¥å…·')
    parser.add_argument('--keywords', nargs='+', required=True, help='è¦æŸ¥è¯¢çš„å…³é”®è¯åˆ—è¡¨')
    parser.add_argument('--geo', default='US', help='åœ°åŒºä»£ç ï¼Œå¦‚USã€GBç­‰ï¼Œé»˜è®¤ä¸ºUS')
    parser.add_argument('--timeframe', default='today 12-m', help='æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä¸ºè¿‡å»12ä¸ªæœˆ')
    parser.add_argument('--output', default='data', help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºdata')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé‡‡é›†å™¨
    collector = TrendsCollector()
    
    # è·å–æ•°æ®
    results = collector.fetch_multiple_keywords(args.keywords, args.geo, args.timeframe)
    
    # ä¿å­˜ç»“æœ
    collector.save_results(results, args.output)


if __name__ == "__main__":
    main()