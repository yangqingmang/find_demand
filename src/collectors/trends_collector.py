#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Google Trends æ•°æ®é‡‡é›†æ¨¡å—"""

import pandas as pd
import time
import json
import urllib.parse
import argparse
from src.utils import Logger
from src.utils.constants import GOOGLE_TRENDS_CONFIG
from config.config_manager import get_config

config = get_config()

class TrendsCollector:
    """Google Trends æ•°æ®é‡‡é›†ç±»"""
    
    API_CONFIG = {
        'base_urls': {
            'explore': 'https://trends.google.com/trends/api/explore',
            'related_searches': 'https://trends.google.com/trends/api/widgetdata/relatedsearches'
        },
        'default_params': {
            'hl': GOOGLE_TRENDS_CONFIG['default_language'],
            'tz': GOOGLE_TRENDS_CONFIG['default_timezone'],
            'geo': GOOGLE_TRENDS_CONFIG['default_geo'],
            'timeframe': GOOGLE_TRENDS_CONFIG['default_timeframe'],
            'category': 0,
            'property': ''
        },
        'headers': {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://trends.google.com/'
        },
        'rate_limits': GOOGLE_TRENDS_CONFIG['rate_limits']
    }
    
    def __init__(self, hl=None, tz=None, timeout=(20, 30), retries=3, backoff_factor=1.5):
        self.hl = hl or self.API_CONFIG['default_params']['hl']
        self.tz = tz or self.API_CONFIG['default_params']['tz']
        self.timeout = timeout
        self.retries = retries
        self.backoff_factor = backoff_factor
        self.logger = Logger()
        
        # ç›´æ¥ä½¿ç”¨ CustomTrendsCollectorï¼Œé¿å…å¾ªç¯ä¾èµ–
        try:
            from .custom_trends_collector import CustomTrendsCollector
            self.trends_collector = CustomTrendsCollector()
            self.logger.info("Sessionåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"Sessionåˆå§‹åŒ–å¤±è´¥: {e}")
            self.trends_collector = None
            
        pd.set_option('future.no_silent_downcasting', True)

    def get_trends_data(self, keywords, timeframe='today 12-m', geo=''):
        """
        è·å–å…³é”®è¯è¶‹åŠ¿æ•°æ®
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨æˆ–å•ä¸ªå…³é”®è¯
            timeframe: æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤è¿‡å»12ä¸ªæœˆ
            geo: åœ°ç†ä½ç½®ï¼Œé»˜è®¤å…¨çƒ
            
        Returns:
            pandas.DataFrame: è¶‹åŠ¿æ•°æ®
        """
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()
            
        try:
            # ç¡®ä¿keywordsæ˜¯åˆ—è¡¨æ ¼å¼
            if isinstance(keywords, str):
                keywords = [keywords]
            
            # æ‰“å°è¯·æ±‚å‚æ•°ç”¨äºè°ƒè¯•
            self.logger.info(f"ğŸ” æ­£åœ¨è¯·æ±‚Google Trendsæ•°æ®:")
            self.logger.info(f"   å…³é”®è¯: {keywords}")
            self.logger.info(f"   æ—¶é—´èŒƒå›´: {timeframe}")
            self.logger.info(f"   åœ°ç†ä½ç½®: {geo}")
            
            # æ„å»ºpayload
            self.trends_collector.build_payload(keywords, cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–å…´è¶£åº¦æ•°æ®
            interest_over_time = self.trends_collector.interest_over_time()
            
            if not interest_over_time.empty:
                # ç§»é™¤ 'isPartial' åˆ—
                if 'isPartial' in interest_over_time.columns:
                    interest_over_time = interest_over_time.drop('isPartial', axis=1)
                
                self.logger.info(f"âœ… æˆåŠŸè·å–åˆ° {len(interest_over_time)} æ¡è¶‹åŠ¿æ•°æ®")
                return interest_over_time
            else:
                self.logger.warning(f"âš ï¸ æœªè·å–åˆ°å…³é”®è¯ {keywords} çš„è¶‹åŠ¿æ•°æ®")
                return pd.DataFrame()
                
        except Exception as e:
            self.logger.error(f"âŒ è·å–è¶‹åŠ¿æ•°æ®å¤±è´¥: {e}")
            self.logger.error(f"   è¯·æ±‚å‚æ•°: keywords={keywords}, timeframe={timeframe}, geo={geo}")
            return pd.DataFrame()

    def _make_api_request(self, request_type, keyword=None, geo=None, timeframe=None, 
                         widget_token=None, widget_request=None):
        """ç»Ÿä¸€APIè¯·æ±‚æ–¹æ³•"""
        time.sleep(1)
        
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']

        url = ''
        params={}

        try:
            if request_type == 'explore':
                url = self.API_CONFIG['base_urls']['explore']
                params = {
                    'hl': self.hl,
                    'tz': self.tz,
                    'req': json.dumps({
                        'comparisonItem': [{
                            'keyword': keyword,
                            'geo': geo,
                            'time': timeframe
                        }],
                        'category': 0,
                        'property': ''
                    })
                }
            elif request_type == 'related_searches':
                url = self.API_CONFIG['base_urls']['related_searches']
                params = {
                    'hl': self.hl,
                    'tz': self.tz,
                    'req': json.dumps(widget_request),
                    'token': widget_token
                }
            
            full_url = f"{url}?{urllib.parse.urlencode(params)}"
            
            # æ‰“å°å®Œæ•´çš„è¯·æ±‚URLç”¨äºè°ƒè¯•
            self.logger.debug(f"ğŸ” æ­£åœ¨è¯·æ±‚URL: {full_url}")
            self.logger.debug(f"ğŸ“‹ è¯·æ±‚å‚æ•°: {params}")
            
            # ä½¿ç”¨trends_collectorçš„sessionè¿›è¡Œè¯·æ±‚
            if self.trends_collector and hasattr(self.trends_collector, 'session'):
                # ç¡®ä¿sessionå·²æ­£ç¡®åˆå§‹åŒ–
                if not getattr(self.trends_collector, 'initialized', False):
                    self.logger.info("ğŸ”§ Sessionæœªåˆå§‹åŒ–ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
                    try:
                        # è®¿é—®ä¸»é¡µè·å–å¿…è¦çš„cookies
                        main_page_response = self.trends_collector.session.get(
                            'https://trends.google.com/', 
                            headers=self.API_CONFIG['headers'], 
                            timeout=self.timeout
                        )
                        if main_page_response.status_code == 200:
                            self.trends_collector.initialized = True
                            self.logger.info("âœ… Sessionåˆå§‹åŒ–æˆåŠŸ")
                        else:
                            self.logger.warning(f"âš ï¸ ä¸»é¡µè®¿é—®å¤±è´¥: {main_page_response.status_code}")
                    except Exception as session_error:
                        self.logger.error(f"Sessionåˆå§‹åŒ–å¤±è´¥: {session_error}")
                
                time.sleep(2)
                response = self.trends_collector.session.get(full_url, headers=self.API_CONFIG['headers'], timeout=self.timeout)
            else:
                self.logger.error("trends_collectoræœªåˆå§‹åŒ–æˆ–æ²¡æœ‰session")
                return None
            
            # æ‰“å°å“åº”çŠ¶æ€
            self.logger.info(f"ğŸ“¡ å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                content = response.text
                if content.startswith(")]}',"):
                    content = content[5:]
                elif content.startswith(")]}'"):
                    content = content[4:]
                return json.loads(content)
            elif response.status_code == 429:
                self.logger.error("APIè¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œç­‰å¾…5ç§’")
                time.sleep(5)
                return None
            else:
                self.logger.error(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            self.logger.error(f"APIè¯·æ±‚å¼‚å¸¸: {e}")
            return None

    def fetch_rising_queries(self, keyword=None, geo=None, timeframe=None):
        """è·å–Rising Queries"""
        geo = geo or self.API_CONFIG['default_params']['geo']
        timeframe = timeframe or self.API_CONFIG['default_params']['timeframe']

        if not keyword or not keyword.strip():
            return self._fetch_trending_via_api(geo=geo, timeframe=timeframe)

        time.sleep(1)

        for attempt in range(self.retries):
            try:
                self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo)
                related_queries = self.trends_collector.related_queries()

                if keyword in related_queries and related_queries[keyword]:
                    rising = related_queries[keyword]['rising']
                    top = related_queries[keyword]['top']

                    if rising is not None and not rising.empty:
                        return rising
                    elif top is not None and not top.empty:
                        top['growth'] = 0
                        return top

                return pd.DataFrame(columns=['query', 'value', 'growth'])

            except Exception as e:
                if attempt < self.retries - 1:
                    wait_time = self.backoff_factor * (2 ** attempt)
                    self.logger.warning(f"è·å–æ•°æ®å‡ºé”™ï¼Œç­‰å¾…{wait_time:.1f}ç§’é‡è¯•: {e}")
                    time.sleep(wait_time)
                else:
                    self.logger.error(f"å¤šæ¬¡å°è¯•å¤±è´¥: {e}")
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
        return None

    def _fetch_trending_via_api(self, geo=None, timeframe=None):
        """é€šè¿‡APIè·å–çƒ­é—¨å…³é”®è¯"""
        all_data = []

        try:
            explore_response = self._make_api_request('explore', keyword="", geo=geo, timeframe=timeframe)

            if explore_response and 'widgets' in explore_response:
                for widget in explore_response['widgets']:
                    if widget.get('id') == 'RELATED_QUERIES' and widget.get('type') == 'fe_related_searches':
                        token = widget.get('token')
                        widget_request = widget.get('request')

                        if token and widget_request:
                            time.sleep(2)
                            related_response = self._make_api_request('related_searches',
                                                                      widget_token=token,
                                                                      widget_request=widget_request)
                            if related_response:
                                df = self._parse_related_queries(related_response)
                                if not df.empty:
                                    df['source'] = 'api'
                                    all_data.append(df)
        except Exception as e:
            self.logger.error(f"APIè·å–çƒ­é—¨å…³é”®è¯å‡ºé”™: {e}")

        if not all_data:
            return pd.DataFrame(columns=['query', 'value', 'growth'])

        combined_df = pd.concat(all_data, ignore_index=True)
        if 'query' in combined_df.columns:
            combined_df = combined_df.drop_duplicates(subset=['query'], keep='first')
            if 'value' in combined_df.columns:
                combined_df = combined_df.sort_values('value', ascending=False)

        return combined_df

    def _parse_related_queries(self, data):
        """è§£æç›¸å…³æŸ¥è¯¢æ•°æ®"""
        queries = []
        try:
            if 'default' in data and 'rankedList' in data['default']:
                for ranked_list in data['default']['rankedList']:
                    for item in ranked_list.get('rankedKeyword', []):
                        query = item.get('query', '')
                        value = item.get('value', 0)
                        formatted_value = item.get('formattedValue', '0')

                        growth = formatted_value if '%' in str(formatted_value) else f"{value}%"
                        queries.append({
                            'query': query,
                            'value': value,
                            'growth': growth
                        })

            return pd.DataFrame(queries) if queries else pd.DataFrame(columns=['query', 'value', 'growth'])
        except Exception as e:
            self.logger.error(f"è§£ææ•°æ®å‡ºé”™: {e}")
            return pd.DataFrame(columns=['query', 'value', 'growth'])

    def get_related_queries(self, keyword, geo='', timeframe='today 12-m'):
        """è·å–ç›¸å…³æŸ¥è¯¢"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return {}
            
        try:
            # æ„å»ºpayload
            self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–ç›¸å…³æŸ¥è¯¢
            related_queries = self.trends_collector.related_queries()
            return related_queries
        except Exception as e:
            self.logger.error(f"è·å–ç›¸å…³æŸ¥è¯¢å¤±è´¥: {e}")
            return {}

    def get_related_topics(self, keyword, geo='', timeframe='today 12-m'):
        """è·å–ç›¸å…³ä¸»é¢˜"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return {}
            
        try:
            # æ„å»ºpayload
            self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–ç›¸å…³ä¸»é¢˜
            related_topics = self.trends_collector.related_topics()
            return related_topics
        except Exception as e:
            self.logger.error(f"è·å–ç›¸å…³ä¸»é¢˜å¤±è´¥: {e}")
            return {}

    def get_interest_by_region(self, keyword, geo='', timeframe='today 12-m'):
        """è·å–æŒ‰åœ°åŒºåˆ†å¸ƒçš„å…´è¶£åº¦"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()
            
        try:
            # æ„å»ºpayload
            self.trends_collector.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo, gprop='')
            
            # è·å–åœ°åŒºå…´è¶£åº¦
            interest_by_region = self.trends_collector.interest_by_region()
            return interest_by_region
        except Exception as e:
            self.logger.error(f"è·å–åœ°åŒºå…´è¶£åº¦å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_suggestions(self, keyword):
        """è·å–å…³é”®è¯å»ºè®®"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return []
            
        try:
            suggestions = self.trends_collector.suggestions(keyword)
            return suggestions
        except Exception as e:
            self.logger.error(f"è·å–å…³é”®è¯å»ºè®®å¤±è´¥: {e}")
            return []

    def trending_searches(self, pn='united_states'):
        """è·å–çƒ­é—¨æœç´¢"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()
            
        try:
            trending = self.trends_collector.trending_searches(pn)
            return trending
        except Exception as e:
            self.logger.error(f"è·å–çƒ­é—¨æœç´¢å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_historical_interest(self, keyword, start_date, end_date=None):
        """è·å–å†å²å…´è¶£æ•°æ®"""
        if not self.trends_collector:
            self.logger.error("trends_collector æœªåˆå§‹åŒ–")
            return pd.DataFrame()
            
        try:
            historical_data = self.trends_collector.get_historical_interest(keyword, start_date, end_date)
            return historical_data
        except Exception as e:
            self.logger.error(f"è·å–å†å²å…´è¶£æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•"""
    parser = argparse.ArgumentParser(description='Google Trends æ•°æ®é‡‡é›†å·¥å…·')
    parser.add_argument('--keyword', '-k', type=str, required=True, help='è¦æŸ¥è¯¢çš„å…³é”®è¯')
    parser.add_argument('--geo', '-g', type=str, default='', help='åœ°ç†ä½ç½® (å¦‚: US, CN)')
    parser.add_argument('--timeframe', '-t', type=str, default='today 12-m', help='æ—¶é—´èŒƒå›´')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé‡‡é›†å™¨å®ä¾‹
    collector = TrendsCollector()
    
    print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢å…³é”®è¯: {args.keyword}")
    print(f"ğŸ“ åœ°ç†ä½ç½®: {args.geo or 'å…¨çƒ'}")
    print(f"â° æ—¶é—´èŒƒå›´: {args.timeframe}")
    print("-" * 50)
    
    # è·å–è¶‹åŠ¿æ•°æ®
    trends_data = collector.get_trends_data(args.keyword, args.timeframe, args.geo)
    
    if not trends_data.empty:
        print("âœ… è¶‹åŠ¿æ•°æ®è·å–æˆåŠŸ!")
        print(f"ğŸ“Š æ•°æ®è¡Œæ•°: {len(trends_data)}")
        print("\nğŸ“ˆ å‰5è¡Œæ•°æ®:")
        print(trends_data.head())
        
        if args.output:
            trends_data.to_csv(args.output, index=False)
            print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {args.output}")
    else:
        print("âŒ æœªè·å–åˆ°è¶‹åŠ¿æ•°æ®")
    
    # è·å–ç›¸å…³æŸ¥è¯¢
    print("\nğŸ” è·å–ç›¸å…³æŸ¥è¯¢...")
    related_queries = collector.get_related_queries(args.keyword, args.geo, args.timeframe)
    
    if related_queries:
        print("âœ… ç›¸å…³æŸ¥è¯¢è·å–æˆåŠŸ!")
        for query_type, queries in related_queries.items():
            if not queries.empty:
                print(f"\nğŸ“‹ {query_type}:")
                print(queries.head())
    else:
        print("âŒ æœªè·å–åˆ°ç›¸å…³æŸ¥è¯¢")


if __name__ == "__main__":
    main()