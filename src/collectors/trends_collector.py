#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google Trends æ•°æ®é‡‡é›†æ¨¡å—
ç”¨äºé‡‡é›†Google Trendsç›¸å…³æŸ¥è¯¢æ•°æ®
"""

import pandas as pd
import time
from pytrends.request import TrendReq
import argparse

from src.utils import (
    FileUtils, Logger, ExceptionHandler, APIError,
    DEFAULT_CONFIG, VALIDATION_CONSTANTS
)
from src.config.settings import config
from src.utils.mock_data_generator import MockDataGenerator

class TrendsCollector:
    """Google Trends æ•°æ®é‡‡é›†ç±»"""
    
    def __init__(self, hl='zh-CN', tz=360, timeout=(10, 25), retries=3, backoff_factor=1.5):
        """
        åˆå§‹åŒ– TrendsCollector
        
        å‚æ•°:
            hl (str): è¯­è¨€è®¾ç½®ï¼Œé»˜è®¤'zh-CN'
            tz (int): æ—¶åŒºï¼Œé»˜è®¤360
            timeout (tuple): è¿æ¥å’Œè¯»å–è¶…æ—¶æ—¶é—´(ç§’)
            retries (int): é‡è¯•æ¬¡æ•°
            backoff_factor (float): é‡è¯•é—´éš”å¢é•¿å› å­
        """
        self.hl = hl
        self.tz = tz
        self.timeout = timeout
        self.retries = retries
        self.backoff_factor = backoff_factor
        self.pytrends = None
        self.logger = Logger()
        self._connect()
        
        # è®¾ç½®pandasé€‰é¡¹ï¼Œæ¶ˆé™¤è­¦å‘Š
        pd.set_option('future.no_silent_downcasting', True)
    
    def _connect(self):
        """åˆ›å»ºpytrendsè¿æ¥"""
        self.pytrends = TrendReq(hl=self.hl, tz=self.tz, timeout=self.timeout)
    
    def fetch_rising_queries(self, keyword, geo='', timeframe='today 3-m'):
        """
        è·å–å…³é”®è¯çš„Rising Queries
        
        å‚æ•°:
            keyword (str): ç§å­å…³é”®è¯
            geo (str): åœ°åŒºä»£ç ï¼Œå¦‚'US','GB'ç­‰ï¼Œé»˜è®¤ä¸ºå…¨çƒ
            timeframe (str): æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤'today 3-m'
            
        è¿”å›:
            pandas.DataFrame: Rising Queriesæ•°æ®
        """
        self.logger.info(f"æ­£åœ¨è·å– '{keyword}' çš„Rising Queriesæ•°æ® (åœ°åŒº: {geo or 'å…¨çƒ'})...")
        
        # å¦‚æœå¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        if config.MOCK_MODE:
            self.logger.info("ğŸ”§ æ¨¡æ‹Ÿæ¨¡å¼ï¼šç”Ÿæˆæ¨¡æ‹Ÿè¶‹åŠ¿æ•°æ®")
            mock_generator = MockDataGenerator()
            mock_results = mock_generator.generate_trends_data([keyword], geo, timeframe)
            if keyword in mock_results:
                return mock_results[keyword]
            else:
                return pd.DataFrame(columns=['query', 'value', 'growth'])
        
        for attempt in range(self.retries):
            try:
                # æ„å»ºpayload
                self.pytrends.build_payload([keyword], cat=0, timeframe=timeframe, geo=geo)
                
                # è·å–ç›¸å…³æŸ¥è¯¢
                related_queries = self.pytrends.related_queries()
                
                if keyword in related_queries and related_queries[keyword]:
                    rising = related_queries[keyword]['rising']
                    top = related_queries[keyword]['top']
                    
                    if rising is not None and not rising.empty:
                        self.logger.info(f"æˆåŠŸè·å– {len(rising)} ä¸ªRising Queries")
                        return rising
                    elif top is not None and not top.empty:
                        self.logger.info(f"æœªæ‰¾åˆ°Rising Queriesï¼Œè¿”å› {len(top)} ä¸ªTop Queries")
                        # ä¸ºTopæŸ¥è¯¢æ·»åŠ é»˜è®¤å¢é•¿ç‡0
                        top['growth'] = 0
                        return top
                    else:
                        self.logger.warning(f"æœªæ‰¾åˆ°ç›¸å…³æŸ¥è¯¢æ•°æ®")
                        return pd.DataFrame(columns=['query', 'value', 'growth'])
                else:
                    self.logger.warning(f"æœªæ‰¾åˆ°å…³é”®è¯ '{keyword}' çš„ç›¸å…³æŸ¥è¯¢æ•°æ®")
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
                    
            except Exception as e:
                wait_time = self.backoff_factor * (2 ** attempt)
                if attempt < self.retries - 1:
                    self.logger.warning(f"è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
                    self.logger.info(f"ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯• ({attempt+1}/{self.retries})...")
                    time.sleep(wait_time)
                    # é‡æ–°è¿æ¥
                    self._connect()
                else:
                    self.logger.error(f"å¤šæ¬¡å°è¯•åä»ç„¶å¤±è´¥: {e}")
                    return pd.DataFrame(columns=['query', 'value', 'growth'])
    
    def fetch_multiple_keywords(self, keywords, geo='', timeframe='today 3-m'):
        """
        æ‰¹é‡è·å–å¤šä¸ªå…³é”®è¯çš„Rising Queries
        
        å‚æ•°:
            keywords (list): ç§å­å…³é”®è¯åˆ—è¡¨
            geo (str): åœ°åŒºä»£ç 
            timeframe (str): æ—¶é—´èŒƒå›´
            
        è¿”å›:
            dict: å…³é”®è¯åˆ°DataFrameçš„æ˜ å°„
        """
        # å¦‚æœå¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼Œç›´æ¥ç”Ÿæˆæ‰€æœ‰å…³é”®è¯çš„æ¨¡æ‹Ÿæ•°æ®
        if config.MOCK_MODE:
            self.logger.info("ğŸ”§ æ¨¡æ‹Ÿæ¨¡å¼ï¼šæ‰¹é‡ç”Ÿæˆæ¨¡æ‹Ÿè¶‹åŠ¿æ•°æ®")
            mock_generator = MockDataGenerator()
            return mock_generator.generate_trends_data(keywords, geo, timeframe)
        
        results = {}
        
        for keyword in keywords:
            df = self.fetch_rising_queries(keyword, geo, timeframe)
            if not df.empty:
                df['seed_keyword'] = keyword  # æ·»åŠ ç§å­å…³é”®è¯åˆ—
                results[keyword] = df
            
            # é¿å…APIé™åˆ¶ï¼Œæ¯æ¬¡è¯·æ±‚ä¹‹é—´ç­‰å¾…
            if keyword != keywords[-1]:  # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªå…³é”®è¯
                self.logger.info("ç­‰å¾…3ç§’ä»¥é¿å…APIé™åˆ¶...")
                time.sleep(3)
        
        return results
    
    def collect_rising_queries(self, keywords, geo='', timeframe='today 3-m'):
        """
        ä¸ºä¸»åˆ†æå™¨æä¾›çš„ç»Ÿä¸€æ¥å£
        
        å‚æ•°:
            keywords (list): ç§å­å…³é”®è¯åˆ—è¡¨
            geo (str): åœ°åŒºä»£ç 
            timeframe (str): æ—¶é—´èŒƒå›´
            
        è¿”å›:
            pandas.DataFrame: åˆå¹¶åçš„æ‰€æœ‰å…³é”®è¯æ•°æ®
        """
        results = self.fetch_multiple_keywords(keywords, geo, timeframe)
        
        if results:
            # åˆå¹¶æ‰€æœ‰ç»“æœ
            all_df = pd.concat(results.values(), ignore_index=True)
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…é¢„æœŸæ ¼å¼
            if 'value' in all_df.columns:
                all_df = all_df.rename(columns={'value': 'volume'})
            
            # å¤„ç†å¢é•¿ç‡æ•°æ®
            if 'growth' in all_df.columns:
                # å°†å¢é•¿ç‡ä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å€¼
                def parse_growth(growth_val):
                    if pd.isna(growth_val) or growth_val == 0:
                        return 0
                    if isinstance(growth_val, str):
                        # ç§»é™¤%ç¬¦å·å¹¶è½¬æ¢ä¸ºæ•°å€¼
                        return float(growth_val.replace('%', '').replace('+', ''))
                    return float(growth_val)
                
                all_df['growth_rate'] = all_df['growth'].apply(parse_growth)
            else:
                all_df['growth_rate'] = 0
            
            self.logger.info(f"æˆåŠŸæ”¶é›†åˆ° {len(all_df)} ä¸ªå…³é”®è¯çš„è¶‹åŠ¿æ•°æ®")
            return all_df
        else:
            self.logger.warning("æœªæ”¶é›†åˆ°ä»»ä½•è¶‹åŠ¿æ•°æ®")
            return pd.DataFrame(columns=['query', 'volume', 'growth_rate', 'seed_keyword'])
    
    def save_results(self, results, output_dir='data'):
        """
        ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
        
        å‚æ•°:
            results (dict): å…³é”®è¯åˆ°DataFrameçš„æ˜ å°„
            output_dir (str): è¾“å‡ºç›®å½•
        """
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_df = pd.concat(results.values(), ignore_index=True) if results else pd.DataFrame()
        
        if not all_df.empty:
            # ä¿å­˜åˆå¹¶çš„ç»“æœ
            all_filename = FileUtils.generate_filename('trends_all', extension='csv')
            all_file = FileUtils.save_dataframe(all_df, output_dir, all_filename)
            self.logger.info(f"å·²ä¿å­˜æ‰€æœ‰ç»“æœåˆ°: {all_file}")
            
            # ä¸ºæ¯ä¸ªå…³é”®è¯ä¿å­˜å•ç‹¬çš„æ–‡ä»¶
            for keyword, df in results.items():
                # æ¸…ç†å…³é”®è¯ä½œä¸ºæ–‡ä»¶å
                safe_keyword = FileUtils.clean_filename(keyword)
                individual_filename = FileUtils.generate_filename(f'trends_{safe_keyword}', extension='csv')
                file_path = FileUtils.save_dataframe(df, output_dir, individual_filename)
                self.logger.info(f"å·²ä¿å­˜ '{keyword}' çš„ç»“æœåˆ°: {file_path}")
        else:
            self.logger.warning("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Google Trends æ•°æ®é‡‡é›†å·¥å…·')
    parser.add_argument('--keywords', nargs='+', required=True, help='è¦æŸ¥è¯¢çš„å…³é”®è¯åˆ—è¡¨')
    parser.add_argument('--geo', default='', help='åœ°åŒºä»£ç ï¼Œå¦‚USã€GBç­‰ï¼Œé»˜è®¤ä¸ºå…¨çƒ')
    parser.add_argument('--timeframe', default='today 3-m', help='æ—¶é—´èŒƒå›´ï¼Œé»˜è®¤ä¸ºè¿‡å»3ä¸ªæœˆ')
    parser.add_argument('--output', default='data', help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºdata')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé‡‡é›†å™¨
    collector = TrendsCollector()
    
    # è·å–æ•°æ®
    results = collector.fetch_multiple_keywords(args.keywords, args.geo, args.timeframe)
    
    # ä¿å­˜ç»“æœ
    collector.save_results(results, args.output)


if __name__ == "__main__":
    main()