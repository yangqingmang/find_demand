#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Google Trends Session ç®¡ç†æ¨¡å—"""

import json
import logging
import os
import re
import threading
import time
from http.cookiejar import MozillaCookieJar
from typing import Any, Dict, Optional, TYPE_CHECKING, Union
from urllib.parse import urljoin

import requests
from requests.cookies import RequestsCookieJar, create_cookie

try:
    import httpx  # type: ignore
except ImportError:  # pragma: no cover
    httpx = None

try:
    from playwright.sync_api import (
        sync_playwright,  # type: ignore
        TimeoutError as PlaywrightTimeoutError,  # type: ignore
    )
except ImportError:  # pragma: no cover
    sync_playwright = None
    PlaywrightTimeoutError = None

if TYPE_CHECKING:  # pragma: no cover
    from httpx import Response as HTTPXResponse

# å¯¼å…¥ä»£ç†ç®¡ç†å™¨
try:
    from ..demand_mining.core.proxy_manager import get_proxy_manager
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨None
    get_proxy_manager = None
    logging.warning("ä»£ç†ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç›´æ¥è¯·æ±‚")

logger = logging.getLogger(__name__)

ResponseType = Union[requests.Response, "HTTPXResponse", "PlaywrightResponseAdapter"]


class PlaywrightResponseAdapter:
    """é€‚é… Playwright APIResponse ä»¥å…¼å®¹ requests æ¥å£"""

    def __init__(self, response, cookies: RequestsCookieJar):
        self._response = response
        self.url = response.url
        self.status_code = response.status
        self.headers = response.headers
        self._cookies = cookies
        try:
            self._text = response.text()
        except Exception:
            self._text = ""
        try:
            self._content = response.body()
        except Exception:
            self._content = b""
        self._json_cache: Optional[Any] = None

    @property
    def text(self) -> str:
        return self._text

    @property
    def content(self) -> bytes:
        return self._content

    @property
    def cookies(self) -> RequestsCookieJar:
        return self._cookies

    def json(self) -> Any:
        if self._json_cache is None:
            try:
                self._json_cache = self._response.json()
            except Exception as json_error:
                raise ValueError(f"æ— æ³•è§£æ Playwright å“åº” JSON: {json_error}")
        return self._json_cache

    def raise_for_status(self) -> None:
        if 400 <= self.status_code:
            raise requests.HTTPError(
                f"{self.status_code} Error for url: {self.url}", response=self
            )

from .request_rate_limiter import wait_for_next_request, register_rate_limit_event

class GoogleTrendsSession:
    """Google Trends Session ç®¡ç†ç±»"""
    
    def __init__(
        self,
        timeout: tuple = (20, 30),
        use_proxy: bool = True,
        backend: Optional[str] = None,
    ):
        self.timeout = timeout
        self.client_backend = self._resolve_backend(backend)
        self.session: Optional[Any] = None
        self.headers = self._load_headers()
        self.initialized = False
        self.use_proxy = use_proxy
        self.proxy_manager = None
        self._cookie_lock = threading.Lock()
        self._playwright = None
        self._playwright_browser = None
        self._playwright_context = None
        logger.debug(
            "GoogleTrendsSession åˆå§‹åŒ–ï¼Œåç«¯=%sï¼Œä»£ç†=%s",
            self.client_backend,
            "on" if use_proxy else "off",
        )

        if self.client_backend == 'playwright' and self.use_proxy:
            logger.info("Playwright åç«¯æš‚æœªæ•´åˆä»£ç†é€šé“ï¼Œè‡ªåŠ¨ç¦ç”¨ä»£ç†æ¨¡å¼")
            self.use_proxy = False

        project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        cookie_dir = os.path.join(project_root, 'output', 'tmp')
        os.makedirs(cookie_dir, exist_ok=True)
        self.cookie_path = os.path.join(cookie_dir, 'google_trends_cookie.txt')
        self.cookie_jar = MozillaCookieJar(self.cookie_path)
        self._load_cookie_jar()
        
        # åˆå§‹åŒ–ä»£ç†ç®¡ç†å™¨
        if self.use_proxy and get_proxy_manager:
            try:
                # æ£€æŸ¥ä»£ç†é…ç½®æ˜¯å¦å¯ç”¨
                import sys
                project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
                if project_root not in sys.path:
                    sys.path.insert(0, project_root)
                
                from config.proxy_config_loader import get_proxy_config
                proxy_config = get_proxy_config()
                
                if not proxy_config.enabled:
                    logger.info("â„¹ï¸ ä»£ç†åœ¨å½“å‰ç¯å¢ƒä¸­è¢«ç¦ç”¨ï¼Œä½¿ç”¨ç›´æ¥è¯·æ±‚")
                    self.use_proxy = False
                elif not proxy_config.proxies:
                    logger.warning("âš ï¸ ä»£ç†åˆ—è¡¨ä¸ºç©ºï¼Œä½¿ç”¨ç›´æ¥è¯·æ±‚")
                    self.use_proxy = False
                else:
                    self.proxy_manager = get_proxy_manager()
                    logger.info(f"âœ… ä»£ç†ç®¡ç†å™¨å·²å¯ç”¨ï¼ŒåŠ è½½äº† {len(proxy_config.proxies)} ä¸ªä»£ç†")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ ä»£ç†ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨ç›´æ¥è¯·æ±‚")
                self.use_proxy = False
        
    @staticmethod
    def _load_headers() -> Dict[str, str]:
        """åŠ è½½Google Trendsè¯·æ±‚å¤´é…ç½®"""
        config_path = os.path.join(os.path.dirname(__file__), '..', '..', 'config', 'google_trends_headers.json')
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                headers_config = json.load(f)
                return headers_config['google_trends_headers']
        except Exception as e:
            logger.warning(f"åŠ è½½headersé…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            # å¦‚æœåŠ è½½å¤±è´¥ï¼Œè¿”å›é»˜è®¤headers
            return {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.6478.61 Safari/537.36',
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br, zstd',
                'Referer': 'https://trends.google.com/trends/explore?hl=en-US&tz=360',
                'Origin': 'https://trends.google.com',
                'Connection': 'keep-alive',
                'DNT': '0',
                'TE': 'trailers',
                'Priority': 'u=1, i',
                'Sec-Fetch-Dest': 'empty',
                'Sec-Fetch-Mode': 'cors',
                'Sec-Fetch-Site': 'same-origin',
                'Sec-Ch-Ua': '"Not/A)Brand";v="99", "Google Chrome";v="126", "Chromium";v="126"',
                'Sec-Ch-Ua-Full-Version': '"126.0.6478.61"',
                'Sec-Ch-Ua-Full-Version-List': '"Not/A)Brand";v="99.0.0.0", "Google Chrome";v="126.0.6478.61", "Chromium";v="126.0.6478.61"',
                'Sec-Ch-Ua-Reduced': '"Google Chrome";v="126"',
                'Sec-Ch-Ua-Platform': '"Windows"',
                'Sec-Ch-Ua-Platform-Version': '"15.0.0"',
                'Sec-Ch-Ua-Arch': '"x86"',
                'Sec-Ch-Ua-Bitness': '"64"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Model': '""',
                'Sec-Ch-Ua-Wow64': '?0',
                'Sec-Ch-Ua-Form-Factor': '"Desktop"',
                'Sec-CH-Prefers-Color-Scheme': '"light"',
                'Sec-CH-Prefers-Reduced-Motion': '"no-preference"',
                'Viewport-Width': '1920',
                'Downlink': '10',
                'ECT': '4g',
                'RTT': '50',
                'X-Client-Data': 'CK6/ygEIlLbJAQjBtskBCKmdygEIptzKAQj8tc0BCJrdzgEIk7nOARis7c4B'
            }

    def _resolve_backend(self, backend: Optional[str]) -> str:
        """è§£æä¼šè¯ä½¿ç”¨çš„HTTPåç«¯"""
        candidates = [
            backend,
            os.getenv('FIND_DEMAND_TRENDS_BACKEND'),
            os.getenv('FIND_DEMAND_HTTP_BACKEND'),
            'playwright' if sync_playwright is not None else None,
            'httpx' if httpx is not None else None,
            'requests',
        ]
        for candidate in candidates:
            if not candidate:
                continue
            normalized = candidate.strip().lower()
            if normalized not in {'requests', 'httpx', 'playwright'}:
                logger.warning(f"æœªçŸ¥çš„HTTPåç«¯é…ç½®: {candidate}ï¼Œå¿½ç•¥")
                continue
            if normalized == 'httpx' and httpx is None:
                logger.warning("httpx æœªå®‰è£…ï¼ŒGoogleTrendsSession è‡ªåŠ¨å›é€€è‡³ requests")
                return 'requests'
            if normalized == 'playwright' and sync_playwright is None:
                logger.warning("Playwright æœªå®‰è£…ï¼ŒGoogleTrendsSession è‡ªåŠ¨å›é€€è‡³å…¶ä»–åç«¯")
                continue
            return normalized
        return 'requests'

    def _build_httpx_timeout(self, timeout: Union[int, float, tuple]) -> "httpx.Timeout":
        """æ„é€  httpx Timeout å¯¹è±¡"""
        assert httpx is not None
        if isinstance(timeout, (int, float)):
            return httpx.Timeout(timeout=timeout)
        if isinstance(timeout, tuple):
            if len(timeout) == 2:
                connect, read = timeout
                return httpx.Timeout(
                    connect=connect,
                    read=read,
                    write=read,
                    pool=connect,
                )
            if len(timeout) == 4:
                connect, read, write, pool = timeout
                return httpx.Timeout(
                    connect=connect,
                    read=read,
                    write=write,
                    pool=pool,
                )
        return httpx.Timeout(timeout=30)

    def _prepare_httpx_kwargs(self, kwargs: Dict[str, Any]) -> Dict[str, Any]:
        """requests å‚æ•°è½¬ä¸º httpx å…¼å®¹å½¢å¼"""
        assert httpx is not None
        converted = dict(kwargs)
        timeout = converted.get('timeout', self.timeout)
        converted['timeout'] = self._build_httpx_timeout(timeout)
        if 'allow_redirects' in converted:
            converted['follow_redirects'] = converted.pop('allow_redirects')
        return converted

    def _session_request(self, method: str, url: str, **kwargs) -> ResponseType:
        """ç»Ÿä¸€ä¼šè¯è¯·æ±‚å…¥å£ï¼Œå…¼å®¹ requests ä¸ httpx"""
        if not self.session:
            raise RuntimeError("ä¼šè¯å°šæœªåˆå§‹åŒ–")

        if self.client_backend == 'playwright':
            return self._playwright_request(method, url, **kwargs)

        if self.client_backend == 'httpx':
            if httpx is None:
                raise RuntimeError("httpx æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨ httpx åç«¯")
            httpx_kwargs = self._prepare_httpx_kwargs(kwargs)
            return self.session.request(method, url, **httpx_kwargs)

        return self.session.request(method, url, **kwargs)

    def _get_session_cookie_jar(self):
        """è·å–åº•å±‚cookie jar"""
        if self.client_backend == 'playwright':
            return self._playwright_cookies_to_jar()

        if not self.session:
            return None
        cookies = getattr(self.session, 'cookies', None)
        if cookies is None:
            return None
        jar = getattr(cookies, 'jar', None)
        return jar if jar is not None else cookies

    def _set_cookie_on_session(self, cookie) -> None:
        """å°†cookieå†™å…¥å½“å‰ä¼šè¯"""
        if self.client_backend == 'playwright':
            if not self._playwright_context:
                return
            cookie_dict = {
                'name': cookie.name,
                'value': cookie.value,
                'path': cookie.path or '/',
                'domain': cookie.domain or '.trends.google.com',
            }
            if cookie.expires:
                cookie_dict['expires'] = cookie.expires
            try:
                self._playwright_context.add_cookies([cookie_dict])
            except Exception as cookie_error:
                logger.debug(f"Playwright cookie å†™å…¥å¤±è´¥: {cookie_error}")
            return

        if not self.session:
            return
        cookies_obj = getattr(self.session, 'cookies', None)
        if cookies_obj is None:
            return
        if hasattr(cookies_obj, 'set_cookie'):
            try:
                cookies_obj.set_cookie(cookie)
                return
            except Exception:
                pass
        try:
            cookies_obj.set(
                cookie.name,
                cookie.value,
                domain=cookie.domain,
                path=cookie.path or '/',
                expires=cookie.expires,
            )
        except Exception as cookie_error:
            logger.debug(f"å†™å…¥cookieå¤±è´¥ï¼Œå·²å¿½ç•¥: {cookie_error}")

    def _iter_session_cookies(self):
        """è¿­ä»£å½“å‰sessionçš„cookieå¯¹è±¡"""
        jar = self._get_session_cookie_jar()
        if jar is None:
            return []
        try:
            return list(jar)
        except TypeError:
            return []

    def _load_cookie_jar(self) -> None:
        """å°è¯•ä»ç£ç›˜åŠ è½½å·²æœ‰cookie"""
        if not os.path.exists(self.cookie_path):
            return

        try:
            if os.path.getsize(self.cookie_path) == 0:
                return
        except OSError as os_error:
            logger.debug(f"è¯»å–cookieæ–‡ä»¶å¤±è´¥: {os_error}")
            return

        with self._cookie_lock:
            try:
                self.cookie_jar.load(ignore_discard=True, ignore_expires=True)
                logger.debug("å·²ä»ç£ç›˜è½½å…¥ Google Trends cookies")
            except Exception as load_error:
                logger.warning(f"åŠ è½½cookieå¤±è´¥ï¼Œå°†é‡æ–°ç”Ÿæˆ: {load_error}")
                try:
                    os.remove(self.cookie_path)
                except OSError:
                    pass
                self.cookie_jar = MozillaCookieJar(self.cookie_path)
    
    def get_session(self) -> Any:
        """è·å–å·²åˆå§‹åŒ–çš„session"""
        if self.session is None:
            self._create_session()
        
        if not self.initialized:
            self._init_session()
            if not self.initialized:
                raise RuntimeError("Google Trendsä¼šè¯åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·åœ¨æ‰§è¡Œä»»ä½• API è¯·æ±‚å‰æ£€æŸ¥ç½‘ç»œæˆ–ä»£ç†é…ç½®")

        return self.session
    
    def _create_session(self) -> None:
        """åˆ›å»ºæ–°çš„session"""
        if self.client_backend == 'playwright':
            self._create_playwright_session()
        elif self.client_backend == 'httpx' and httpx is not None:
            try:
                timeout = self._build_httpx_timeout(self.timeout)
                self.session = httpx.Client(
                    http2=True,
                    headers=self.headers.copy(),
                    timeout=timeout,
                    trust_env=False,
                    follow_redirects=True,
                )
                logger.debug("åˆ›å»ºæ–°çš„Google Trends httpx å®¢æˆ·ç«¯")
            except Exception as exc:
                logger.warning(f"httpx å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥ ({exc})ï¼Œå›é€€åˆ° requests")
                self.client_backend = 'requests'
                self.session = None

        if self.session is None and self.client_backend != 'playwright':
            self.session = requests.Session()
            logger.debug("åˆ›å»ºæ–°çš„Google Trends requests session")

        if self.client_backend != 'playwright':
            try:
                self.session.headers.update(self.headers)
            except AttributeError:
                pass

        self._apply_cookies_to_session()
        logger.debug("åˆ›å»ºæ–°çš„Google Trends session")

    def _create_playwright_session(self) -> None:
        """åˆ›å»º Playwright æµè§ˆå™¨ä¸Šä¸‹æ–‡å¹¶å¤ç”¨å…¶è¯·æ±‚èƒ½åŠ›"""
        if sync_playwright is None:  # pragma: no cover - è¿è¡Œç¯å¢ƒç¼ºå°‘playwright
            raise RuntimeError("Playwright æœªå®‰è£…ï¼Œæ— æ³•å¯ç”¨æµè§ˆå™¨æŒ‡çº¹ä¼šè¯")

        headless_flag = os.getenv('FIND_DEMAND_PLAYWRIGHT_HEADLESS', '1').strip().lower()
        headless = headless_flag not in {'0', 'false', 'no'}

        if self._playwright is None:
            self._playwright = sync_playwright().start()

        launch_args = [
            "--disable-blink-features=AutomationControlled",
            "--disable-dev-shm-usage",
        ]

        if self._playwright_browser is None:
            self._playwright_browser = self._playwright.chromium.launch(
                headless=headless,
                args=launch_args,
            )

        locale = (self.headers.get('Accept-Language') or 'en-US').split(',')[0]
        user_agent = self.headers.get('User-Agent')

        context_kwargs: Dict[str, Any] = {
            'ignore_https_errors': True,
            'locale': locale,
        }
        if user_agent:
            context_kwargs['user_agent'] = user_agent

        if self._playwright_context is not None:
            try:
                self._playwright_context.close()
            except Exception:
                pass

        self._playwright_context = self._playwright_browser.new_context(**context_kwargs)
        self._playwright_context.set_extra_http_headers(self.headers.copy())
        self.session = self._playwright_context.request
        logger.debug("Playwright è¯·æ±‚ä¸Šä¸‹æ–‡å·²åˆ›å»º (headless=%s)", headless)

    def _playwright_cookies_to_jar(self) -> RequestsCookieJar:
        jar = RequestsCookieJar()
        if not self._playwright_context:
            return jar
        try:
            cookies = self._playwright_context.cookies()
        except Exception as cookie_error:
            logger.debug(f"è¯»å– Playwright cookies å¤±è´¥: {cookie_error}")
            return jar

        for cookie in cookies:
            try:
                jar.set_cookie(
                    create_cookie(
                        name=cookie.get('name'),
                        value=cookie.get('value'),
                        domain=cookie.get('domain'),
                        path=cookie.get('path', '/'),
                        expires=cookie.get('expires'),
                        secure=cookie.get('secure', False),
                        rest={'HttpOnly': cookie.get('httpOnly', False)},
                    )
                )
            except Exception as cookie_error:
                logger.debug(f"å†™å…¥ Playwright cookie è‡³ Jar å¤±è´¥: {cookie_error}")
        return jar

    def _convert_timeout_to_ms(self, timeout: Union[int, float, tuple]) -> Optional[float]:
        if timeout is None:
            return None
        if isinstance(timeout, (int, float)):
            return max(float(timeout), 0.0) * 1000
        if isinstance(timeout, tuple) and timeout:
            try:
                effective = max(float(value) for value in timeout)
                return max(effective, 0.0) * 1000
            except Exception:
                return None
        return None

    def _playwright_request(self, method: str, url: str, **kwargs) -> PlaywrightResponseAdapter:
        if not self.session or not self._playwright_context:
            raise RuntimeError("Playwright ä¼šè¯å°šæœªåˆå§‹åŒ–")

        request = self.session
        request_kwargs: Dict[str, Any] = {}

        headers = kwargs.pop('headers', None)
        params = kwargs.pop('params', None)
        data = kwargs.pop('data', None)
        json_payload = kwargs.pop('json', None)
        allow_redirects = kwargs.pop('allow_redirects', True)
        timeout = kwargs.pop('timeout', self.timeout)

        timeout_ms = self._convert_timeout_to_ms(timeout)
        if headers:
            request_kwargs['headers'] = headers
        if params is not None:
            request_kwargs['params'] = params
        if data is not None:
            request_kwargs['data'] = data
        if json_payload is not None:
            request_kwargs['json'] = json_payload
        if timeout_ms is not None:
            request_kwargs['timeout'] = timeout_ms
        if allow_redirects is not None:
            request_kwargs['max_redirects'] = 20 if allow_redirects else 0

        method_lower = method.lower()
        method_callable = getattr(request, method_lower, None)

        try:
            if callable(method_callable):
                response = method_callable(url, **request_kwargs)
            else:
                request_kwargs['method'] = method.upper()
                response = request.fetch(url, **request_kwargs)
        except PlaywrightTimeoutError as timeout_error:
            raise requests.Timeout(f"Playwright è¯·æ±‚è¶…æ—¶: {timeout_error}")
        except Exception as playwright_error:
            raise requests.RequestException(f"Playwright è¯·æ±‚å¼‚å¸¸: {playwright_error}")

        cookies_jar = self._playwright_cookies_to_jar()
        return PlaywrightResponseAdapter(response, cookies_jar)

    def _apply_cookies_to_session(self) -> None:
        """å°†æŒä¹…åŒ–cookieå†™å…¥session"""
        if not self.session:
            return
        with self._cookie_lock:
            for cookie in list(self.cookie_jar):
                try:
                    self._set_cookie_on_session(cookie)
                except Exception as cookie_error:
                    logger.debug(f"å†™å…¥cookieå¤±è´¥ï¼Œå·²å¿½ç•¥: {cookie_error}")

    def _persist_session_cookies(self) -> None:
        """å°†å½“å‰session cookieæŒä¹…åŒ–åˆ°ç£ç›˜"""
        if not self.session:
            return

        with self._cookie_lock:
            jar = MozillaCookieJar(self.cookie_path)
            for cookie in self._iter_session_cookies():
                try:
                    jar.set_cookie(cookie)
                except Exception as cookie_error:
                    logger.debug(f"æŒä¹…åŒ–cookieå¤±è´¥ï¼Œå·²å¿½ç•¥: {cookie_error}")
            try:
                jar.save(ignore_discard=True, ignore_expires=True)
                self.cookie_jar = jar
                logger.debug("å·²åˆ·æ–° Google Trends cookies åˆ°ç£ç›˜")
            except Exception as save_error:
                logger.warning(f"ä¿å­˜cookieå¤±è´¥: {save_error}")

    def _merge_response_cookies(self, response: ResponseType) -> None:
        """å°†å“åº”ä¸­çš„cookieåˆå¹¶åˆ°å½“å‰session"""
        if not self.session or not response:
            return
        cookies_obj = getattr(response, 'cookies', None)
        if not cookies_obj:
            return
        source = getattr(cookies_obj, 'jar', None) or cookies_obj
        try:
            for cookie in source:
                self._set_cookie_on_session(cookie)
        except TypeError:
            items = getattr(source, 'items', None)
            if callable(items):
                for name, value in items():
                    try:
                        self.session.cookies.set(name, value)
                    except Exception:
                        pass
        except Exception as cookie_error:
            logger.debug(f"å“åº”cookieåˆå¹¶å¤±è´¥: {cookie_error}")

    def _prefetch_primary_assets(self, main_page_html: str) -> None:
        """æ¨¡æ‹Ÿæµè§ˆå™¨åŠ è½½é¦–æ‰¹é™æ€èµ„æºï¼Œè¡¥å…¨æŒ‡çº¹"""
        if not main_page_html:
            return

        try:
            script_match = re.search(r'src="(https://[^"]+/_/scs/tt-static/[^"]+\.js)"', main_page_html)
            if not script_match:
                script_match = re.search(r'src="(/_/scs/tt-static/[^"]+\.js)"', main_page_html)

            style_match = re.search(r'href="(https://[^"]+/_/scs/tt-static/[^"]+\.css)"', main_page_html)
            if not style_match:
                style_match = re.search(r'href="(/_/scs/tt-static/[^"]+\.css)"', main_page_html)

            assets = []
            if script_match:
                assets.append(('script', script_match.group(1)))
            if style_match:
                assets.append(('style', style_match.group(1)))

            for asset_type, raw_url in assets[:2]:
                asset_url = urljoin('https://trends.google.com/', raw_url)
                asset_headers = dict(self.headers)
                asset_headers['Referer'] = 'https://trends.google.com/'
                asset_headers['Origin'] = 'https://trends.google.com'
                asset_headers['Priority'] = 'u=2, i' if asset_type == 'script' else 'u=3, i'
                if asset_type == 'script':
                    asset_headers['Accept'] = 'text/javascript, application/javascript;q=0.9, */*;q=0.8'
                    asset_headers['Sec-Fetch-Dest'] = 'script'
                else:
                    asset_headers['Accept'] = 'text/css,*/*;q=0.1'
                    asset_headers['Sec-Fetch-Dest'] = 'style'
                asset_headers['Sec-Fetch-Mode'] = 'no-cors'
                asset_headers['Sec-Fetch-Site'] = 'same-origin' if asset_url.startswith('https://trends.google.com') else 'cross-site'

                try:
                    wait_for_next_request()
                except RuntimeError:
                    pass
                except Exception as limiter_error:
                    logger.debug(f"é¢„å–èµ„æºç­‰å¾…é™æµæ§½ä½æ—¶å¼‚å¸¸: {limiter_error}")

                try:
                    response = self._session_request('GET', asset_url, headers=asset_headers, timeout=self.timeout)
                    if response.status_code == 200:
                        logger.debug("å·²é¢„å– Google Trends %s èµ„æº: %s", asset_type, asset_url)
                        if response.cookies:
                            self._persist_session_cookies()
                except Exception as fetch_error:
                    logger.debug("é¢„å–èµ„æºå¤±è´¥ (%s): %s", asset_url, fetch_error)

        except Exception as parse_error:
            logger.debug(f"é¢„å–èµ„æºè§£æå¤±è´¥: {parse_error}")
    
    def _init_session(self) -> None:
        """åˆå§‹åŒ–ä¼šè¯ï¼Œè·å–å¿…è¦çš„cookies"""
        try:
            logger.info("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–Google Trendsä¼šè¯...")

            bootstrap_headers = dict(self.headers)
            bootstrap_headers.pop('Origin', None)
            bootstrap_headers['Referer'] = 'https://trends.google.com/'
            bootstrap_headers.update({
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                'Accept-Encoding': 'gzip, deflate, br, zstd',
                'Accept-Language': 'en-US,en;q=0.9',
                'Cache-Control': 'no-cache',
                'Pragma': 'no-cache',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'Priority': 'u=0, i'
            })

            time.sleep(3)

            # å…ˆè®¿é—®ä¸»é¡µè·å–cookies
            main_page_url = 'https://trends.google.com/'
            try:
                wait_for_next_request()
            except RuntimeError as limiter_error:
                penalty = register_rate_limit_event('medium')
                logger.error("âŒ ä¼šè¯åˆå§‹åŒ–å› é¢‘æ§é™åˆ¶è¢«é˜»æ­¢: %s", limiter_error)
                if penalty:
                    logger.info("å»ºè®®ç­‰å¾… %.1f ç§’åé‡è¯•ä¼šè¯åˆå§‹åŒ–", penalty)
                self.initialized = False
                return

            response = self._session_request('GET', main_page_url, headers=bootstrap_headers, timeout=self.timeout)
            self._persist_session_cookies()
            main_page_html = ''

            if response.status_code == 429:
                logger.warning("âš ï¸ é¦–æ¬¡è®¿é—®ä¸»é¡µé‡åˆ°429ï¼Œå°è¯•ä½¿ç”¨æ–°cookieé‡è¯•")
                time.sleep(2)
                try:
                    wait_for_next_request()
                except RuntimeError as limiter_error:
                    penalty = register_rate_limit_event('high')
                    logger.error("âŒ é‡è¯•å‰è¢«é™æµ: %s", limiter_error)
                    if penalty:
                        logger.info("å»ºè®®ç­‰å¾… %.1f ç§’åé‡è¯•åˆå§‹åŒ–æµç¨‹", penalty)
                    self.initialized = False
                    return

                response = self._session_request('GET', main_page_url, headers=bootstrap_headers, timeout=self.timeout)
                self._persist_session_cookies()

            if response.status_code != 200:
                penalty = register_rate_limit_event('high')
                if penalty:
                    logger.error("âŒ ä¸»é¡µè®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç : %sï¼Œå»ºè®®ç­‰å¾… %.1f ç§’", response.status_code, penalty)
                else:
                    logger.error(f"âŒ ä¸»é¡µè®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                self.initialized = False
                return
            else:
                main_page_html = response.text

            self._prefetch_primary_assets(main_page_html)

            # å†è®¿é—®ä¸€ä¸ªtrends exploreé¡µé¢ï¼Œç¡®ä¿sessionå®Œå…¨å»ºç«‹
            time.sleep(2)
            trends_page_url = 'https://trends.google.com/trends/explore?q=automation'

            try:
                wait_for_next_request()
            except RuntimeError as limiter_error:
                penalty = register_rate_limit_event('medium')
                logger.error("âŒ ä¼šè¯åˆå§‹åŒ–åç»­è¯·æ±‚è¢«é™æµ: %s", limiter_error)
                if penalty:
                    logger.info("å»ºè®®ç­‰å¾… %.1f ç§’åé‡è¯•åˆå§‹åŒ–æµç¨‹", penalty)
                self.initialized = False
                return

            trends_response = self._session_request('GET', trends_page_url, headers=bootstrap_headers, timeout=self.timeout)
            self._persist_session_cookies()

            if trends_response.status_code == 429:
                logger.warning("âš ï¸ explore é¡µé¢è¿”å›429ï¼Œå°è¯•æºå¸¦cookieå†æ¬¡è®¿é—®")
                time.sleep(2)
                try:
                    wait_for_next_request()
                except RuntimeError as limiter_error:
                    penalty = register_rate_limit_event('high')
                    logger.error("âŒ explore é‡è¯•å‰è¢«é™æµ: %s", limiter_error)
                    if penalty:
                        logger.info("å»ºè®®ç­‰å¾… %.1f ç§’åé‡è¯•åˆå§‹åŒ–æµç¨‹", penalty)
                    self.initialized = False
                    return

                trends_response = self._session_request('GET', trends_page_url, headers=bootstrap_headers, timeout=self.timeout)
                self._persist_session_cookies()

            if trends_response.status_code == 200:
                self.initialized = True
                logger.info("âœ… Google Trendsä¼šè¯åˆå§‹åŒ–æˆåŠŸ")
            else:
                penalty = register_rate_limit_event('high')
                if penalty:
                    logger.error("âŒ explore é¡µé¢è®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç : %sï¼Œå»ºè®®ç­‰å¾… %.1f ç§’", trends_response.status_code, penalty)
                else:
                    logger.error(f"âŒ explore é¡µé¢è®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç : {trends_response.status_code}")
                self.initialized = False

        except Exception as e:
            logger.error(f"âŒ ä¼šè¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.initialized = False
    
    def reset_session(self) -> None:
        """é‡ç½®ä¼šè¯"""
        try:
            self._close_session()
            self._create_session()
            self._init_session()
            if not self.initialized:
                raise RuntimeError("Google Trendsä¼šè¯é‡ç½®å¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆä¼šè¯")
            logger.info("ä¼šè¯å·²é‡ç½®")
        except Exception as e:
            logger.error(f"é‡ç½®ä¼šè¯å¤±è´¥: {e}")
    
    def get_headers(self) -> Dict[str, str]:
        """è·å–headers"""
        return self.headers.copy()
    
    def update_headers(self, new_headers: Dict[str, str]) -> None:
        """æ›´æ–°headers"""
        self.headers.update(new_headers)
        if self.client_backend == 'playwright' and self._playwright_context:
            try:
                self._playwright_context.set_extra_http_headers(self.headers.copy())
            except Exception as header_error:
                logger.debug(f"Playwright header æ›´æ–°å¤±è´¥: {header_error}")
        elif self.session:
            try:
                self.session.headers.update(new_headers)
            except Exception as header_error:
                logger.debug(f"ä¼šè¯headeræ›´æ–°å¤±è´¥: {header_error}")

    def _close_playwright(self) -> None:
        if self.session:
            try:
                dispose = getattr(self.session, "dispose", None)
                if callable(dispose):
                    dispose()
            except Exception:
                pass
        if self._playwright_context:
            try:
                self._playwright_context.close()
            except Exception:
                pass
            finally:
                self._playwright_context = None
        if self._playwright_browser:
            try:
                self._playwright_browser.close()
            except Exception:
                pass
            finally:
                self._playwright_browser = None
        if self._playwright:
            try:
                self._playwright.stop()
            except Exception:
                pass
            finally:
                self._playwright = None
        self.session = None

    def _close_session(self) -> None:
        if self.client_backend == 'playwright':
            self._close_playwright()
            return
        if self.session:
            try:
                self.session.close()
            except Exception:
                pass
        self.session = None

    def _log_request_debug_snapshot(
        self,
        method: str,
        url: str,
        kwargs: Dict[str, Any],
        via_proxy: bool = False,
    ) -> None:
        """è¾“å‡ºè°ƒè¯•è¯·æ±‚å¿«ç…§ï¼ŒååŠ©æŒ‡çº¹å¯¹æ¯”"""
        if not logger.isEnabledFor(logging.DEBUG):
            return

        effective_headers: Dict[str, str] = {}
        if self.session:
            try:
                effective_headers.update(self.session.headers or {})
            except Exception as header_error:
                logger.debug(f"ä¼šè¯é»˜è®¤è¯·æ±‚å¤´è¯»å–å¤±è´¥: {header_error}")
        else:
            effective_headers.update(self.headers)
        extra_headers = kwargs.get('headers') or {}
        effective_headers.update(extra_headers)

        cookie_dump: Dict[str, str] = {}
        if self.session:
            try:
                cookie_dump = self.session.cookies.get_dict()
            except Exception as cookie_error:
                logger.debug(f"ä¼šè¯ cookie è¯»å–å¤±è´¥: {cookie_error}")

        logger.debug(
            "ğŸ“¡ å‡†å¤‡%sè¯·æ±‚ %s %s",
            "é€šè¿‡ä»£ç†å‘èµ·" if via_proxy else "ç›´æ¥å‘èµ·",
            method,
            url,
        )
        logger.debug("â†³ è¯·æ±‚å¤´: %s", json.dumps(effective_headers, ensure_ascii=False))

        if cookie_dump:
            logger.debug("â†³ ä¼šè¯Cookies: %s", json.dumps(cookie_dump, ensure_ascii=False))

        if kwargs.get('params'):
            logger.debug("â†³ Queryå‚æ•°: %s", json.dumps(kwargs['params'], ensure_ascii=False))

        if kwargs.get('data') is not None:
            payload = kwargs['data']
            if isinstance(payload, (bytes, bytearray)):
                logger.debug("â†³ è¡¨å•/æ­£æ–‡: <äºŒè¿›åˆ¶æ•°æ®ï¼Œé•¿åº¦=%s>", len(payload))
            else:
                try:
                    logger.debug("â†³ è¡¨å•/æ­£æ–‡: %s", json.dumps(payload, ensure_ascii=False))
                except (TypeError, ValueError):
                    length_hint = getattr(payload, "__len__", None)
                    logged_length = False
                    if callable(length_hint):
                        try:
                            logger.debug(
                                "â†³ è¡¨å•/æ­£æ–‡: <éJSONå¯åºåˆ—åŒ–æ•°æ®ï¼Œé•¿åº¦=%s>",
                                length_hint(),
                            )
                            logged_length = True
                        except Exception:
                            pass
                    if not logged_length:
                        logger.debug(
                            "â†³ è¡¨å•/æ­£æ–‡: <éJSONå¯åºåˆ—åŒ–æ•°æ®ï¼Œç±»å‹=%s>",
                            type(payload).__name__,
                        )
    
    def _clone_request_kwargs(self, kwargs: Dict[str, Any]) -> Dict[str, Any]:
        """å¤åˆ¶è¯·æ±‚å‚æ•°ï¼Œé¿å…åœ¨é‡è¯•æ—¶ä¿®æ”¹åŸå§‹å¼•ç”¨"""
        cloned = dict(kwargs)
        if 'headers' in cloned and cloned['headers'] is not None:
            cloned['headers'] = dict(cloned['headers'])
        if 'data' in cloned and isinstance(cloned['data'], dict):
            cloned['data'] = dict(cloned['data'])
        if 'params' in cloned and isinstance(cloned['params'], dict):
            cloned['params'] = dict(cloned['params'])
        return cloned

    def _attempt_429_recovery(
        self,
        method: str,
        url: str,
        original_kwargs: Dict[str, Any],
    ) -> Optional[requests.Response]:
        """é‡åˆ°429æ—¶å°è¯•é€šè¿‡é‡ç½®ä¼šè¯å¹¶é‡è¯•"""
        penalty = register_rate_limit_event('high')
        if penalty:
            logger.warning("âš ï¸ Google Trends è¿”å›429ï¼Œé‡ç½®ä¼šè¯å¹¶ç­‰å¾…å»ºè®® %.1f ç§’", penalty)

        try:
            self.reset_session()
        except Exception as reset_error:
            logger.error(f"âŒ é‡ç½®Google Trendsä¼šè¯å¤±è´¥: {reset_error}")
            return None

        try:
            wait_for_next_request()
        except RuntimeError as limiter_error:
            logger.error("âŒ 429æ¢å¤è¿‡ç¨‹ä»è¢«é™æµé˜»æ­¢: %s", limiter_error)
            return None
        except Exception as limiter_error:
            logger.warning(f"âš ï¸ 429æ¢å¤ç­‰å¾…æ—¶å‘ç”Ÿå¼‚å¸¸: {limiter_error}")

        retry_kwargs = self._clone_request_kwargs(original_kwargs)
        retry_kwargs.setdefault('timeout', self.timeout)

        return self.make_request(method, url, retry_on_429=False, **retry_kwargs)

    def make_request(
        self,
        method: str,
        url: str,
        retry_on_429: bool = True,
        **kwargs,
    ) -> ResponseType:
        """å‘é€è¯·æ±‚çš„ç»Ÿä¸€æ¥å£"""
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å·²æˆåŠŸåˆå§‹åŒ–
        if not self.initialized:
            raise Exception("Google Trendsä¼šè¯åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•å‘é€è¯·æ±‚ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚")
        
        # å¦‚æœå¯ç”¨ä»£ç†ç®¡ç†å™¨ï¼Œä½¿ç”¨ä»£ç†å‘é€è¯·æ±‚
        if self.use_proxy and self.proxy_manager:
            try:
                request_kwargs = self._clone_request_kwargs(kwargs)
                if 'headers' not in request_kwargs or request_kwargs['headers'] is None:
                    request_kwargs['headers'] = {}
                request_kwargs['headers'].update(self.headers)

                self._log_request_debug_snapshot(method, url, request_kwargs, via_proxy=True)

                if 'timeout' not in request_kwargs:
                    request_kwargs['timeout'] = self.timeout
                
                # ä½¿ç”¨ä»£ç†ç®¡ç†å™¨å‘é€è¯·æ±‚
                response = self.proxy_manager.make_request(
                    url,
                    method,
                    backend=self.client_backend,
                    **request_kwargs,
                )
                if response:
                    self._merge_response_cookies(response)
                    self._persist_session_cookies()
                    if response.status_code == 429 and retry_on_429:
                        retry_response = self._attempt_429_recovery(method, url, request_kwargs)
                        if retry_response is not None:
                            return retry_response
                    return response
                else:
                    logger.warning("âš ï¸ ä»£ç†è¯·æ±‚å¤±è´¥ï¼Œå°è¯•ç›´æ¥è¯·æ±‚")
                    # å¦‚æœä»£ç†è¯·æ±‚å¤±è´¥ï¼Œå›é€€åˆ°ç›´æ¥è¯·æ±‚
                    
            except Exception as e:
                logger.warning(f"âš ï¸ ä»£ç†è¯·æ±‚å¼‚å¸¸: {e}ï¼Œå°è¯•ç›´æ¥è¯·æ±‚")
        
        # ç›´æ¥è¯·æ±‚ï¼ˆæ— ä»£ç†æˆ–ä»£ç†å¤±è´¥æ—¶çš„å›é€€æ–¹æ¡ˆï¼‰
        self.get_session()

        # è®¾ç½®é»˜è®¤è¶…æ—¶
        if 'timeout' not in kwargs:
            kwargs['timeout'] = self.timeout

        self._log_request_debug_snapshot(method, url, kwargs, via_proxy=False)
            
        # å‘é€è¯·æ±‚
        response = self._session_request(method, url, **kwargs)
        self._persist_session_cookies()

        if response.status_code == 429 and retry_on_429:
            retry_response = self._attempt_429_recovery(method, url, kwargs)
            if retry_response is not None:
                return retry_response

        return response
    
    def get(self, url: str, **kwargs) -> ResponseType:
        """GETè¯·æ±‚"""
        return self.make_request('GET', url, **kwargs)
    
    def post(self, url: str, **kwargs) -> ResponseType:
        """POSTè¯·æ±‚"""
        return self.make_request('POST', url, **kwargs)
    
    def close(self) -> None:
        """å…³é—­session"""
        try:
            self._close_session()
            self.initialized = False
            logger.debug("Google Trends sessionå·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­sessionå¤±è´¥: {e}")


# å…¨å±€sessionå®ä¾‹
_global_session = None
_session_lock = threading.Lock()

def get_global_session() -> GoogleTrendsSession:
    """è·å–å…¨å±€sessionå®ä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    global _global_session
    
    # åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼
    if _global_session is None:
        with _session_lock:
            if _global_session is None:
                _global_session = GoogleTrendsSession()
                logger.debug("åˆ›å»ºGoogle Trendsä¼šè¯ç®¡ç†å™¨å®ä¾‹")
    return _global_session

def reset_global_session() -> None:
    """é‡ç½®å…¨å±€sessionï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    global _global_session
    
    with _session_lock:
        if _global_session:
            _global_session.close()
            _global_session = GoogleTrendsSession()
            logger.info("å…¨å±€Sessionå·²é‡ç½®")
