#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SEOå·¥å…·é›†æˆé‡‡é›†å™¨
æ”¯æŒ Semrushã€Ahrefsã€Similarweb ç­‰ä¸»æµSEOå·¥å…·çš„APIé›†æˆ
"""

import pandas as pd
import requests
import time
import json
from typing import Dict, List, Optional, Any
from abc import ABC, abstractmethod

from src.utils import Logger, FileUtils
try:
    from config.config_manager import get_config
    config = get_config()
except ImportError:
    from src.utils.simple_config import get_config
    config = get_config()
from src.utils.mock_data_generator import MockDataGenerator


class BaseSEOToolCollector(ABC):
    """SEOå·¥å…·é‡‡é›†å™¨åŸºç±»"""
    
    def __init__(self, api_key: str, tool_name: str):
        self.api_key = api_key
        self.tool_name = tool_name
        self.logger = Logger()
        self.session = requests.Session()
        self.rate_limit_delay = 1.0  # åŸºç¡€å»¶è¿Ÿ1ç§’
        self.last_request_time = 0
    
    def _wait_for_rate_limit(self):
        """ç­‰å¾…é€Ÿç‡é™åˆ¶"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.rate_limit_delay:
            wait_time = self.rate_limit_delay - time_since_last
            time.sleep(wait_time)
        
        self.last_request_time = time.time()
    
    @abstractmethod
    def get_keyword_data(self, keyword: str, **kwargs) -> Dict[str, Any]:
        """è·å–å…³é”®è¯æ•°æ®"""
        pass
    
    @abstractmethod
    def get_competitor_keywords(self, domain: str, **kwargs) -> pd.DataFrame:
        """è·å–ç«äº‰å¯¹æ‰‹å…³é”®è¯"""
        pass


class SemrushCollector(BaseSEOToolCollector):
    """Semrush API é‡‡é›†å™¨"""
    
    def __init__(self, api_key: str):
        super().__init__(api_key, "Semrush")
        self.base_url = "https://api.semrush.com/"
        self.rate_limit_delay = 0.1  # Semrushå…è®¸æ¯ç§’10ä¸ªè¯·æ±‚
    
    def get_keyword_data(self, keyword: str, database: str = "us", **kwargs) -> Dict[str, Any]:
        """
        è·å–å…³é”®è¯æ•°æ®
        
        å‚æ•°:
            keyword (str): å…³é”®è¯
            database (str): æ•°æ®åº“ä»£ç ï¼Œå¦‚'us', 'uk', 'de'ç­‰
        """
        try:
            self.logger.info(f"ğŸ” Semrush: è·å–å…³é”®è¯ '{keyword}' æ•°æ®...")
            
            # å¦‚æœå¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼
            if config.MOCK_MODE:
                return self._generate_mock_keyword_data(keyword)
            
            self._wait_for_rate_limit()
            
            # Semrush Keyword Overview API
            params = {
                'type': 'phrase_this',
                'key': self.api_key,
                'phrase': keyword,
                'database': database,
                'export_columns': 'Ph,Nq,Cp,Co,Nr,Td'
            }
            
            response = self.session.get(f"{self.base_url}reports/v1/projects/", params=params)
            
            if response.status_code == 200:
                data = self._parse_semrush_response(response.text)
                self.logger.info(f"âœ“ Semrush: æˆåŠŸè·å– '{keyword}' æ•°æ®")
                return {
                    'keyword': keyword,
                    'source': 'semrush',
                    'data': data,
                    'status': 'success'
                }
            else:
                self.logger.error(f"âŒ Semrush APIé”™è¯¯: {response.status_code}")
                return self._generate_mock_keyword_data(keyword)
                
        except Exception as e:
            self.logger.error(f"âŒ Semrushé‡‡é›†é”™è¯¯: {e}")
            return self._generate_mock_keyword_data(keyword)
    
    def get_competitor_keywords(self, domain: str, database: str = "us", limit: int = 100) -> pd.DataFrame:
        """è·å–ç«äº‰å¯¹æ‰‹å…³é”®è¯"""
        try:
            self.logger.info(f"ğŸ” Semrush: è·å–åŸŸå '{domain}' çš„å…³é”®è¯...")
            
            if config.MOCK_MODE:
                return self._generate_mock_competitor_data(domain, limit)
            
            self._wait_for_rate_limit()
            
            params = {
                'type': 'domain_organic',
                'key': self.api_key,
                'domain': domain,
                'database': database,
                'limit': limit,
                'export_columns': 'Ph,Po,Pp,Pd,Nq,Cp,Ur,Tr,Tc,Co,Nr,Td'
            }
            
            response = self.session.get(f"{self.base_url}reports/v1/projects/", params=params)
            
            if response.status_code == 200:
                df = self._parse_semrush_organic_response(response.text)
                self.logger.info(f"âœ“ Semrush: æˆåŠŸè·å– {len(df)} ä¸ªå…³é”®è¯")
                return df
            else:
                self.logger.error(f"âŒ Semrush APIé”™è¯¯: {response.status_code}")
                return self._generate_mock_competitor_data(domain, limit)
                
        except Exception as e:
            self.logger.error(f"âŒ Semrushé‡‡é›†é”™è¯¯: {e}")
            return self._generate_mock_competitor_data(domain, limit)
    
    def _parse_semrush_response(self, response_text: str) -> Dict:
        """è§£æSemrushå“åº”"""
        lines = response_text.strip().split('\n')
        if len(lines) < 2:
            return {}
        
        headers = lines[0].split(';')
        data = lines[1].split(';') if len(lines) > 1 else []
        
        result = {}
        for i, header in enumerate(headers):
            if i < len(data):
                result[header] = data[i]
        
        return result
    
    def _parse_semrush_organic_response(self, response_text: str) -> pd.DataFrame:
        """è§£æSemrushæœ‰æœºå…³é”®è¯å“åº”"""
        lines = response_text.strip().split('\n')
        if len(lines) < 2:
            return pd.DataFrame()
        
        headers = lines[0].split(';')
        data_rows = []
        
        for line in lines[1:]:
            if line.strip():
                data_rows.append(line.split(';'))
        
        return pd.DataFrame(data_rows, columns=headers)
    
    def _generate_mock_keyword_data(self, keyword: str) -> Dict:
        """ç”Ÿæˆæ¨¡æ‹Ÿå…³é”®è¯æ•°æ®"""
        mock_generator = MockDataGenerator()
        mock_df = mock_generator.generate_trends_data([keyword])
        
        return {
            'keyword': keyword,
            'source': 'semrush_mock',
            'data': {
                'Ph': keyword,
                'Nq': '12100',  # æœç´¢é‡
                'Cp': '2.45',   # CPC
                'Co': '0.67',   # ç«äº‰åº¦
                'Nr': '1250000', # æœç´¢ç»“æœæ•°
                'Td': '45'      # è¶‹åŠ¿
            },
            'status': 'mock'
        }
    
    def _generate_mock_competitor_data(self, domain: str, limit: int) -> pd.DataFrame:
        """ç”Ÿæˆæ¨¡æ‹Ÿç«äº‰å¯¹æ‰‹æ•°æ®"""
        mock_generator = MockDataGenerator()
        keywords = [f"{domain} keyword {i}" for i in range(1, min(limit + 1, 51))]
        mock_results = mock_generator.generate_trends_data(keywords)
        
        all_data = []
        for keyword, df in mock_results.items():
            if not df.empty:
                for _, row in df.iterrows():
                    all_data.append({
                        'Ph': row['query'],
                        'Po': f"{len(all_data) + 1}",  # æ’å
                        'Nq': str(row['value'] * 100),  # æœç´¢é‡
                        'Cp': f"{2.0 + (len(all_data) * 0.1):.2f}",  # CPC
                        'Ur': f"https://{domain}/page{len(all_data) + 1}",
                        'domain': domain
                    })
        
        return pd.DataFrame(all_data[:limit])


class AhrefsCollector(BaseSEOToolCollector):
    """Ahrefs API é‡‡é›†å™¨"""
    
    def __init__(self, api_key: str):
        super().__init__(api_key, "Ahrefs")
        self.base_url = "https://apiv2.ahrefs.com/"
        self.rate_limit_delay = 2.0  # Ahrefsé™åˆ¶è¾ƒä¸¥æ ¼
    
    def get_keyword_data(self, keyword: str, country: str = "us", **kwargs) -> Dict[str, Any]:
        """è·å–å…³é”®è¯æ•°æ®"""
        try:
            self.logger.info(f"ğŸ” Ahrefs: è·å–å…³é”®è¯ '{keyword}' æ•°æ®...")
            
            if config.MOCK_MODE:
                return self._generate_mock_keyword_data(keyword)
            
            self._wait_for_rate_limit()
            
            params = {
                'token': self.api_key,
                'from': 'keywords_explorer',
                'target': keyword,
                'country': country,
                'mode': 'exact'
            }
            
            response = self.session.get(f"{self.base_url}keywords-explorer", params=params)
            
            if response.status_code == 200:
                data = response.json()
                self.logger.info(f"âœ“ Ahrefs: æˆåŠŸè·å– '{keyword}' æ•°æ®")
                return {
                    'keyword': keyword,
                    'source': 'ahrefs',
                    'data': data,
                    'status': 'success'
                }
            else:
                self.logger.error(f"âŒ Ahrefs APIé”™è¯¯: {response.status_code}")
                return self._generate_mock_keyword_data(keyword)
                
        except Exception as e:
            self.logger.error(f"âŒ Ahrefsé‡‡é›†é”™è¯¯: {e}")
            return self._generate_mock_keyword_data(keyword)
    
    def get_competitor_keywords(self, domain: str, country: str = "us", limit: int = 100) -> pd.DataFrame:
        """è·å–ç«äº‰å¯¹æ‰‹å…³é”®è¯"""
        try:
            self.logger.info(f"ğŸ” Ahrefs: è·å–åŸŸå '{domain}' çš„å…³é”®è¯...")
            
            if config.MOCK_MODE:
                return self._generate_mock_competitor_data(domain, limit)
            
            self._wait_for_rate_limit()
            
            params = {
                'token': self.api_key,
                'from': 'ahrefs_rank',
                'target': domain,
                'country': country,
                'limit': limit
            }
            
            response = self.session.get(f"{self.base_url}site-explorer", params=params)
            
            if response.status_code == 200:
                data = response.json()
                df = self._parse_ahrefs_response(data)
                self.logger.info(f"âœ“ Ahrefs: æˆåŠŸè·å– {len(df)} ä¸ªå…³é”®è¯")
                return df
            else:
                self.logger.error(f"âŒ Ahrefs APIé”™è¯¯: {response.status_code}")
                return self._generate_mock_competitor_data(domain, limit)
                
        except Exception as e:
            self.logger.error(f"âŒ Ahrefsé‡‡é›†é”™è¯¯: {e}")
            return self._generate_mock_competitor_data(domain, limit)
    
    def _parse_ahrefs_response(self, data: Dict) -> pd.DataFrame:
        """è§£æAhrefså“åº”"""
        if 'keywords' in data:
            return pd.DataFrame(data['keywords'])
        return pd.DataFrame()
    
    def _generate_mock_keyword_data(self, keyword: str) -> Dict:
        """ç”Ÿæˆæ¨¡æ‹Ÿå…³é”®è¯æ•°æ®"""
        return {
            'keyword': keyword,
            'source': 'ahrefs_mock',
            'data': {
                'keyword': keyword,
                'volume': 8900,
                'difficulty': 45,
                'cpc': 3.20,
                'clicks': 5600,
                'return_rate': 0.23
            },
            'status': 'mock'
        }
    
    def _generate_mock_competitor_data(self, domain: str, limit: int) -> pd.DataFrame:
        """ç”Ÿæˆæ¨¡æ‹Ÿç«äº‰å¯¹æ‰‹æ•°æ®"""
        mock_generator = MockDataGenerator()
        keywords = [f"{domain} ahrefs keyword {i}" for i in range(1, min(limit + 1, 51))]
        mock_results = mock_generator.generate_trends_data(keywords)
        
        all_data = []
        for keyword, df in mock_results.items():
            if not df.empty:
                for _, row in df.iterrows():
                    all_data.append({
                        'keyword': row['query'],
                        'position': len(all_data) + 1,
                        'volume': row['value'] * 150,
                        'difficulty': min(100, 20 + (len(all_data) * 2)),
                        'url': f"https://{domain}/page{len(all_data) + 1}",
                        'domain': domain
                    })
        
        return pd.DataFrame(all_data[:limit])


class SimilarwebCollector(BaseSEOToolCollector):
    """Similarweb API é‡‡é›†å™¨"""
    
    def __init__(self, api_key: str):
        super().__init__(api_key, "Similarweb")
        self.base_url = "https://api.similarweb.com/v1/"
        self.rate_limit_delay = 1.5
    
    def get_keyword_data(self, keyword: str, country: str = "us", **kwargs) -> Dict[str, Any]:
        """è·å–å…³é”®è¯æ•°æ®"""
        try:
            self.logger.info(f"ğŸ” Similarweb: è·å–å…³é”®è¯ '{keyword}' æ•°æ®...")
            
            if config.MOCK_MODE:
                return self._generate_mock_keyword_data(keyword)
            
            self._wait_for_rate_limit()
            
            headers = {'api-key': self.api_key}
            params = {
                'keyword': keyword,
                'country': country,
                'start_date': '2024-01',
                'end_date': '2024-12'
            }
            
            response = self.session.get(
                f"{self.base_url}keywords/{keyword}/analysis",
                headers=headers,
                params=params
            )
            
            if response.status_code == 200:
                data = response.json()
                self.logger.info(f"âœ“ Similarweb: æˆåŠŸè·å– '{keyword}' æ•°æ®")
                return {
                    'keyword': keyword,
                    'source': 'similarweb',
                    'data': data,
                    'status': 'success'
                }
            else:
                self.logger.error(f"âŒ Similarweb APIé”™è¯¯: {response.status_code}")
                return self._generate_mock_keyword_data(keyword)
                
        except Exception as e:
            self.logger.error(f"âŒ Similarwebé‡‡é›†é”™è¯¯: {e}")
            return self._generate_mock_keyword_data(keyword)
    
    def get_competitor_keywords(self, domain: str, country: str = "us", limit: int = 100) -> pd.DataFrame:
        """è·å–ç«äº‰å¯¹æ‰‹å…³é”®è¯"""
        try:
            self.logger.info(f"ğŸ” Similarweb: è·å–åŸŸå '{domain}' çš„å…³é”®è¯...")
            
            if config.MOCK_MODE:
                return self._generate_mock_competitor_data(domain, limit)
            
            self._wait_for_rate_limit()
            
            headers = {'api-key': self.api_key}
            params = {
                'domain': domain,
                'country': country,
                'limit': limit
            }
            
            response = self.session.get(
                f"{self.base_url}website/{domain}/search-keywords",
                headers=headers,
                params=params
            )
            
            if response.status_code == 200:
                data = response.json()
                df = self._parse_similarweb_response(data)
                self.logger.info(f"âœ“ Similarweb: æˆåŠŸè·å– {len(df)} ä¸ªå…³é”®è¯")
                return df
            else:
                self.logger.error(f"âŒ Similarweb APIé”™è¯¯: {response.status_code}")
                return self._generate_mock_competitor_data(domain, limit)
                
        except Exception as e:
            self.logger.error(f"âŒ Similarwebé‡‡é›†é”™è¯¯: {e}")
            return self._generate_mock_competitor_data(domain, limit)
    
    def _parse_similarweb_response(self, data: Dict) -> pd.DataFrame:
        """è§£æSimilarwebå“åº”"""
        if 'data' in data:
            return pd.DataFrame(data['data'])
        return pd.DataFrame()
    
    def _generate_mock_keyword_data(self, keyword: str) -> Dict:
        """ç”Ÿæˆæ¨¡æ‹Ÿå…³é”®è¯æ•°æ®"""
        return {
            'keyword': keyword,
            'source': 'similarweb_mock',
            'data': {
                'keyword': keyword,
                'volume': 15600,
                'trend': 'rising',
                'competition': 'medium',
                'traffic_share': 0.15
            },
            'status': 'mock'
        }
    
    def _generate_mock_competitor_data(self, domain: str, limit: int) -> pd.DataFrame:
        """ç”Ÿæˆæ¨¡æ‹Ÿç«äº‰å¯¹æ‰‹æ•°æ®"""
        mock_generator = MockDataGenerator()
        keywords = [f"{domain} similarweb keyword {i}" for i in range(1, min(limit + 1, 51))]
        mock_results = mock_generator.generate_trends_data(keywords)
        
        all_data = []
        for keyword, df in mock_results.items():
            if not df.empty:
                for _, row in df.iterrows():
                    all_data.append({
                        'keyword': row['query'],
                        'volume': row['value'] * 200,
                        'traffic_share': round(0.01 + (len(all_data) * 0.005), 3),
                        'trend': 'stable' if len(all_data) % 3 == 0 else 'rising',
                        'domain': domain
                    })
        
        return pd.DataFrame(all_data[:limit])


class IntegratedSEOCollector:
    """é›†æˆSEOå·¥å…·é‡‡é›†å™¨"""
    
    def __init__(self):
        self.logger = Logger()
        self.collectors = {}
        self._initialize_collectors()
    
    def _initialize_collectors(self):
        """åˆå§‹åŒ–å„ä¸ªé‡‡é›†å™¨"""
        try:
            # ä»é…ç½®ä¸­è·å–APIå¯†é’¥
            semrush_key = getattr(config, 'SEMRUSH_API_KEY', None)
            ahrefs_key = getattr(config, 'AHREFS_API_KEY', None)
            similarweb_key = getattr(config, 'SIMILARWEB_API_KEY', None)
            
            if semrush_key:
                self.collectors['semrush'] = SemrushCollector(semrush_key)
                self.logger.info("âœ“ Semrushé‡‡é›†å™¨å·²åˆå§‹åŒ–")
            
            if ahrefs_key:
                self.collectors['ahrefs'] = AhrefsCollector(ahrefs_key)
                self.logger.info("âœ“ Ahrefsé‡‡é›†å™¨å·²åˆå§‹åŒ–")
            
            if similarweb_key:
                self.collectors['similarweb'] = SimilarwebCollector(similarweb_key)
                self.logger.info("âœ“ Similarwebé‡‡é›†å™¨å·²åˆå§‹åŒ–")
            
            if not self.collectors:
                self.logger.warning("âš ï¸ æœªé…ç½®ä»»ä½•SEOå·¥å…·APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                
        except Exception as e:
            self.logger.error(f"âŒ åˆå§‹åŒ–SEOé‡‡é›†å™¨å¤±è´¥: {e}")
    
    def get_comprehensive_keyword_data(self, keyword: str, **kwargs) -> Dict[str, Any]:
        """è·å–ç»¼åˆå…³é”®è¯æ•°æ®"""
        results = {
            'keyword': keyword,
            'sources': {},
            'summary': {},
            'timestamp': time.time()
        }
        
        # ä»æ‰€æœ‰å¯ç”¨çš„é‡‡é›†å™¨è·å–æ•°æ®
        for tool_name, collector in self.collectors.items():
            try:
                data = collector.get_keyword_data(keyword, **kwargs)
                results['sources'][tool_name] = data
                self.logger.info(f"âœ“ {tool_name}: å·²è·å– '{keyword}' æ•°æ®")
            except Exception as e:
                self.logger.error(f"âŒ {tool_name}: è·å– '{keyword}' æ•°æ®å¤±è´¥: {e}")
        
        # ç”Ÿæˆç»¼åˆæ‘˜è¦
        results['summary'] = self._generate_summary(results['sources'])
        
        return results
    
    def get_competitor_analysis(self, domain: str, **kwargs) -> Dict[str, pd.DataFrame]:
        """è·å–ç«äº‰å¯¹æ‰‹åˆ†æ"""
        results = {}
        
        for tool_name, collector in self.collectors.items():
            try:
                df = collector.get_competitor_keywords(domain, **kwargs)
                results[tool_name] = df
                self.logger.info(f"âœ“ {tool_name}: å·²è·å– '{domain}' ç«äº‰å¯¹æ‰‹æ•°æ®")
            except Exception as e:
                self.logger.error(f"âŒ {tool_name}: è·å– '{domain}' ç«äº‰å¯¹æ‰‹æ•°æ®å¤±è´¥: {e}")
        
        return results
    
    def _generate_summary(self, sources: Dict) -> Dict:
        """ç”Ÿæˆæ•°æ®æ‘˜è¦"""
        summary = {
            'available_sources': list(sources.keys()),
            'data_quality': 'high' if len(sources) >= 2 else 'medium',
            'recommendations': []
        }
        
        # æ·»åŠ åŸºäºæ•°æ®æºçš„å»ºè®®
        if 'semrush' in sources:
            summary['recommendations'].append('ä½¿ç”¨Semrushæ•°æ®è¿›è¡Œå…³é”®è¯éš¾åº¦åˆ†æ')
        if 'ahrefs' in sources:
            summary['recommendations'].append('ä½¿ç”¨Ahrefsæ•°æ®è¿›è¡Œåå‘é“¾æ¥åˆ†æ')
        if 'similarweb' in sources:
            summary['recommendations'].append('ä½¿ç”¨Similarwebæ•°æ®è¿›è¡Œæµé‡åˆ†æ')
        
        return summary
    
    def save_results(self, results: Dict, output_dir: str = 'data/seo_tools'):
        """ä¿å­˜ç»“æœ"""
        try:
            import os
            os.makedirs(output_dir, exist_ok=True)
            
            keyword = results.get('keyword', 'unknown')
            filename = f"seo_analysis_{keyword}_{int(time.time())}.json"
            filepath = os.path.join(output_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"âœ“ ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return None


# ä¾¿æ·å‡½æ•°
def create_seo_collector() -> IntegratedSEOCollector:
    """åˆ›å»ºé›†æˆSEOé‡‡é›†å™¨"""
    return IntegratedSEOCollector()


def analyze_keyword_with_seo_tools(keyword: str, **kwargs) -> Dict[str, Any]:
    """ä½¿ç”¨SEOå·¥å…·åˆ†æå…³é”®è¯"""
    collector = create_seo_collector()
    return collector.get_comprehensive_keyword_data(keyword, **kwargs)


def analyze_competitor_with_seo_tools(domain: str, **kwargs) -> Dict[str, pd.DataFrame]:
    """ä½¿ç”¨SEOå·¥å…·åˆ†æç«äº‰å¯¹æ‰‹"""
    collector = create_seo_collector()
    return collector.get_competitor_analysis(domain, **kwargs)


if __name__ == "__main__":
    # æµ‹è¯•é›†æˆSEOé‡‡é›†å™¨
    print("=== æµ‹è¯•é›†æˆSEOå·¥å…·é‡‡é›†å™¨ ===")
    
    collector = IntegratedSEOCollector()
    
    # æµ‹è¯•å…³é”®è¯åˆ†æ
    print("\n1. æµ‹è¯•å…³é”®è¯åˆ†æ:")
    keyword_results = collector.get_comprehensive_keyword_data("AI tools")
    print(f"   å…³é”®è¯: {keyword_results['keyword']}")
    print(f"   æ•°æ®æº: {list(keyword_results['sources'].keys())}")
    print(f"   æ•°æ®è´¨é‡: {keyword_results['summary']['data_quality']}")
    
    # æµ‹è¯•ç«äº‰å¯¹æ‰‹åˆ†æ
    print("\n2. æµ‹è¯•ç«äº‰å¯¹æ‰‹åˆ†æ:")
    competitor_results = collector.get_competitor_analysis("openai.com")
    print(f"   åŸŸå: openai.com")
    print(f"   æ•°æ®æº: {list(competitor_results.keys())}")
    for tool, df in competitor_results.items():
        print(f"   {tool}: {len(df)} ä¸ªå…³é”®è¯")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")