#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å…³é”®è¯æå–å·¥å…· - å¢å¼ºç‰ˆ
ä»å„ç§æ•°æ®æºæå–å’Œæ‰©å±•å…³é”®è¯ï¼Œé›†æˆGoogleè‡ªåŠ¨å®ŒæˆAPIã€ç›¸å…³æœç´¢è¯æŒ–æ˜å’Œè¯­ä¹‰ç›¸ä¼¼è¯å‘ç°
"""

import re
import requests
import json
import time
import random
from typing import List, Dict, Set, Any, Optional
from collections import Counter
import pandas as pd
from urllib.parse import quote_plus
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class KeywordExtractor:
    """å¢å¼ºç‰ˆå…³é”®è¯æå–å™¨"""
    
    def __init__(self):
        self.stop_words = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 
            'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 
            'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should'
        }
        
        # åˆå§‹åŒ–Google Trendsæ”¶é›†å™¨ç”¨äºç›¸å…³æœç´¢
        self.trends_collector = None
        try:
            from src.collectors.custom_trends_collector import CustomTrendsCollector
            self.trends_collector = CustomTrendsCollector()
            logger.info("âœ… Google Trendsæ”¶é›†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except ImportError as e:
            logger.warning(f"âš ï¸ Google Trendsæ”¶é›†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # AIå·¥å…·ç±»åˆ«è¯æ±‡åº“
        self.ai_tool_categories = {
            'image': ['generator', 'creator', 'maker', 'editor', 'enhancer', 'upscaler'],
            'text': ['writer', 'generator', 'editor', 'translator', 'summarizer', 'paraphraser'],
            'video': ['generator', 'editor', 'creator', 'enhancer', 'converter'],
            'audio': ['generator', 'editor', 'transcriber', 'converter', 'enhancer'],
            'code': ['generator', 'assistant', 'reviewer', 'optimizer', 'debugger'],
            'design': ['generator', 'creator', 'assistant', 'optimizer', 'enhancer']
        }
        
        # é•¿å°¾è¯æ‰©å±•ä¿®é¥°è¯åº“ï¼ˆä¼˜åŒ–ä¸ºä½ç«äº‰ã€é«˜æ„å›¾çš„è¯æ±‡ï¼‰
        self.long_tail_modifiers = [
            'how to use', 'step by step guide', 'tutorial for beginners',
            'free alternative to', 'open source version of', 'simple way to create',
            'easy method for', 'complete guide to', 'beginner friendly',
            'without coding', 'for small business', 'budget friendly',
            'quick tutorial on', 'detailed review of', 'comparison between',
            'pros and cons of', 'getting started with', 'tips for using',
            'common mistakes with', 'troubleshooting guide for'
        ]
        
        # ä¿ç•™åŸæœ‰ä¿®é¥°è¯ä½œä¸ºå¤‡ç”¨ï¼ˆæ ‡è®°ä¸ºé«˜ç«äº‰ï¼‰
        self.high_competition_modifiers = [
            'best', 'top', 'review', 'vs', 'comparison'
        ]
        
        # ä¸­ç­‰ç«äº‰ä¿®é¥°è¯
        self.medium_competition_modifiers = [
            'free', 'online', 'guide', 'tutorial', 'alternative', 'tool',
            'software', 'app', 'platform', 'service', 'solution', 'api',
            'open source', 'simple', 'easy'
        ]
    
    def get_google_autocomplete_suggestions(self, keyword: str, language: str = 'en', 
                                          country: str = 'us', max_suggestions: int = 10) -> List[str]:
        """
        è·å–Googleè‡ªåŠ¨å®Œæˆå»ºè®®
        
        Args:
            keyword: ç§å­å…³é”®è¯
            language: è¯­è¨€ä»£ç 
            country: å›½å®¶ä»£ç 
            max_suggestions: æœ€å¤§å»ºè®®æ•°é‡
            
        Returns:
            è‡ªåŠ¨å®Œæˆå»ºè®®åˆ—è¡¨
        """
        suggestions = []
        
        try:
            # Googleè‡ªåŠ¨å®ŒæˆAPI URL
            url = "http://suggestqueries.google.com/complete/search"
            
            params = {
                'client': 'firefox',
                'q': keyword,
                'hl': language,
                'gl': country
            }
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, params=params, headers=headers, timeout=10)
            
            if response.status_code == 200:
                # è§£æJSONå“åº”
                data = response.json()
                if len(data) > 1 and isinstance(data[1], list):
                    suggestions = data[1][:max_suggestions]
                    
            # è¿‡æ»¤å’Œæ¸…ç†å»ºè®®
            filtered_suggestions = []
            for suggestion in suggestions:
                if isinstance(suggestion, str) and len(suggestion) > len(keyword):
                    # ç§»é™¤åŸå…³é”®è¯ï¼Œåªä¿ç•™æ‰©å±•éƒ¨åˆ†
                    if suggestion.lower().startswith(keyword.lower()):
                        filtered_suggestions.append(suggestion)
            
            logger.info(f"âœ… è·å–åˆ° {len(filtered_suggestions)} ä¸ªGoogleè‡ªåŠ¨å®Œæˆå»ºè®®: {keyword}")
            return filtered_suggestions[:max_suggestions]
            
        except Exception as e:
            logger.warning(f"âš ï¸ Googleè‡ªåŠ¨å®Œæˆè·å–å¤±è´¥ {keyword}: {e}")
            return []
    
    def get_related_search_terms(self, keyword: str, max_terms: int = 10) -> List[str]:
        """
        è·å–ç›¸å…³æœç´¢è¯ï¼ˆé€šè¿‡Google Trendsï¼‰
        
        Args:
            keyword: ç§å­å…³é”®è¯
            max_terms: æœ€å¤§ç›¸å…³è¯æ•°é‡
            
        Returns:
            ç›¸å…³æœç´¢è¯åˆ—è¡¨
        """
        related_terms = []
        
        try:
            if self.trends_collector:
                # ä½¿ç”¨Google Trendsæ”¶é›†å™¨è·å–ç›¸å…³æœç´¢
                trends_data = self.trends_collector.collect_trends([keyword])
                
                if trends_data and 'related_queries' in trends_data:
                    for query_data in trends_data['related_queries']:
                        if 'query' in query_data:
                            related_terms.append(query_data['query'])
                
                logger.info(f"âœ… é€šè¿‡Trendsè·å–åˆ° {len(related_terms)} ä¸ªç›¸å…³æœç´¢è¯: {keyword}")
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºäºå…³é”®è¯ç”Ÿæˆç›¸å…³è¯
                related_terms = self._generate_related_terms_fallback(keyword, max_terms)
                logger.info(f"âœ… ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆç”Ÿæˆ {len(related_terms)} ä¸ªç›¸å…³è¯: {keyword}")
            
            return related_terms[:max_terms]
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç›¸å…³æœç´¢è¯è·å–å¤±è´¥ {keyword}: {e}")
            return self._generate_related_terms_fallback(keyword, max_terms)
    
    def _generate_related_terms_fallback(self, keyword: str, max_terms: int = 10) -> List[str]:
        """å¤‡ç”¨ç›¸å…³è¯ç”Ÿæˆæ–¹æ¡ˆ"""
        related_terms = []
        keyword_lower = keyword.lower()
        
        # åŸºäºAIå·¥å…·ç±»åˆ«ç”Ÿæˆç›¸å…³è¯
        for category, tools in self.ai_tool_categories.items():
            if category in keyword_lower or any(tool in keyword_lower for tool in tools):
                for tool in tools:
                    if tool not in keyword_lower:
                        related_terms.append(f"{keyword} {tool}")
                        related_terms.append(f"{tool} {keyword}")
        
        # ä¼˜å…ˆä½¿ç”¨é•¿å°¾ä¿®é¥°è¯ç”Ÿæˆç›¸å…³è¯
        for modifier in self.long_tail_modifiers[:max_terms//2]:
            if modifier not in keyword_lower:
                related_terms.append(f"{modifier} {keyword}")
        
        # è¡¥å……ä¸­ç­‰ç«äº‰ä¿®é¥°è¯
        for modifier in self.medium_competition_modifiers[:max_terms//3]:
            if modifier not in keyword_lower:
                related_terms.append(f"{modifier} {keyword}")
        
        return list(set(related_terms))[:max_terms]
    
    def expand_seed_keywords(self, seed_keywords: List[str], max_per_seed: int = 20) -> Dict[str, List[str]]:
        """
        æ‰©å±•ç§å­å…³é”®è¯ï¼ˆè¯­ä¹‰ç›¸ä¼¼è¯å‘ç°ï¼‰
        
        Args:
            seed_keywords: ç§å­å…³é”®è¯åˆ—è¡¨
            max_per_seed: æ¯ä¸ªç§å­è¯æœ€å¤§æ‰©å±•æ•°é‡
            
        Returns:
            æŒ‰ç§å­è¯åˆ†ç»„çš„æ‰©å±•å…³é”®è¯å­—å…¸
        """
        expanded_keywords = {}
        
        for seed in seed_keywords:
            expanded = set()
            seed_lower = seed.lower()
            
            # 1. åŸºäºAIå·¥å…·ç±»åˆ«æ‰©å±•
            for category, tools in self.ai_tool_categories.items():
                if category in seed_lower or any(tool in seed_lower for tool in tools):
                    for tool in tools:
                        if tool not in seed_lower:
                            expanded.add(f"{seed} {tool}")
                            expanded.add(f"{tool} for {seed}")
            
            # 2. ä¼˜å…ˆåŸºäºé•¿å°¾ä¿®é¥°è¯æ‰©å±•
            for modifier in self.long_tail_modifiers:
                if modifier not in seed_lower:
                    expanded.add(f"{modifier} {seed}")
                    # ç‰¹æ®Šå¤„ç†æ•™ç¨‹ç±»ä¿®é¥°è¯
                    if 'tutorial' in modifier or 'guide' in modifier:
                        expanded.add(f"{modifier} {seed} for beginners")
            
            # 3. è¡¥å……ä¸­ç­‰ç«äº‰ä¿®é¥°è¯
            for modifier in self.medium_competition_modifiers[:5]:  # é™åˆ¶æ•°é‡
                if modifier not in seed_lower:
                    expanded.add(f"{modifier} {seed}")
            
            # 4. åŸºäºè¯æ±‡å˜å½¢æ‰©å±•
            if 'generator' in seed_lower:
                expanded.add(seed.replace('generator', 'creator'))
                expanded.add(seed.replace('generator', 'maker'))
            elif 'creator' in seed_lower:
                expanded.add(seed.replace('creator', 'generator'))
                expanded.add(seed.replace('creator', 'maker'))
            
            # è¿‡æ»¤å’Œé™åˆ¶æ•°é‡ï¼ˆä¼˜å…ˆé•¿å°¾è¯ï¼‰
            filtered_expanded = []
            for kw in expanded:
                if self._is_long_tail_keyword(kw):
                    filtered_expanded.append(kw)
            
            # å¦‚æœé•¿å°¾è¯ä¸å¤Ÿï¼Œè¡¥å……ä¸­ç­‰é•¿åº¦çš„å…³é”®è¯
            if len(filtered_expanded) < max_per_seed:
                for kw in expanded:
                    if not self._is_long_tail_keyword(kw) and len(kw) > 10 and len(kw) < 100:
                        filtered_expanded.append(kw)
                        if len(filtered_expanded) >= max_per_seed:
                            break
            
            expanded_keywords[seed] = filtered_expanded[:max_per_seed]
            logger.info(f"âœ… è¯­ä¹‰æ‰©å±• {seed}: {len(expanded_keywords[seed])} ä¸ªå…³é”®è¯")
        
        return expanded_keywords
    
    def _is_long_tail_keyword(self, keyword: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºé•¿å°¾å…³é”®è¯
        
        Args:
            keyword: å…³é”®è¯
            
        Returns:
            æ˜¯å¦ä¸ºé•¿å°¾å…³é”®è¯
        """
        words = keyword.split()
        # é•¿å°¾è¯æ ‡å‡†ï¼š3ä¸ªä»¥ä¸Šè¯æ±‡ä¸”æ€»é•¿åº¦15ä¸ªå­—ç¬¦ä»¥ä¸Š
        return len(words) >= 3 and len(keyword) >= 15
    
    def calculate_long_tail_score(self, keyword: str) -> float:
        """
        è®¡ç®—é•¿å°¾è¯è¯„åˆ†ï¼ˆé•¿å°¾è¯è·å¾—æ›´é«˜åˆ†æ•°ï¼‰
        
        Args:
            keyword: å…³é”®è¯
            
        Returns:
            è¯„åˆ†å€æ•°
        """
        word_count = len(keyword.split())
        keyword_lower = keyword.lower()
        
        base_score = 1.0
        
        # åŸºäºè¯æ•°çš„è¯„åˆ†åŠ æƒ
        if word_count >= 5:
            base_score *= 2.5  # 5+è¯æ±‡è·å¾—æœ€é«˜åŠ æƒ
        elif word_count >= 4:
            base_score *= 2.0  # 4è¯æ±‡è·å¾—é«˜åŠ æƒ
        elif word_count >= 3:
            base_score *= 1.5  # 3è¯æ±‡è·å¾—ä¸­ç­‰åŠ æƒ
        
        # åŸºäºæ„å›¾æ˜ç¡®æ€§çš„åŠ æƒ
        high_intent_phrases = ['how to', 'step by step', 'tutorial', 'guide', 'without']
        if any(phrase in keyword_lower for phrase in high_intent_phrases):
            base_score *= 1.3
        
        # åŸºäºç«äº‰åº¦çš„è°ƒæ•´
        if any(comp in keyword_lower for comp in self.high_competition_modifiers):
            base_score *= 0.7  # é«˜ç«äº‰è¯é™ä½è¯„åˆ†
        elif any(comp in keyword_lower for comp in self.medium_competition_modifiers):
            base_score *= 0.9  # ä¸­ç­‰ç«äº‰è¯ç•¥å¾®é™ä½è¯„åˆ†
        
        return base_score
    
    def analyze_keyword_difficulty(self, keyword: str) -> str:
        """
        åˆ†æå…³é”®è¯éš¾åº¦
        
        Args:
            keyword: å…³é”®è¯
            
        Returns:
            éš¾åº¦ç­‰çº§ (Low/Medium/High)
        """
        keyword_lower = keyword.lower()
        word_count = len(keyword.split())
        
        # åŸºäºè¯æ•°åˆ¤æ–­åŸºç¡€éš¾åº¦
        if word_count >= 4:
            base_difficulty = 'Low'
        elif word_count >= 2:
            base_difficulty = 'Medium'
        else:
            base_difficulty = 'High'
        
        # åŸºäºç«äº‰è¯è°ƒæ•´éš¾åº¦
        high_competition_words = ['best', 'top', 'review', 'vs', 'comparison']
        medium_competition_words = ['free', 'online', 'tool', 'software']
        
        if any(word in keyword_lower for word in high_competition_words):
            if base_difficulty == 'Low':
                return 'Medium'
            elif base_difficulty == 'Medium':
                return 'High'
        elif any(word in keyword_lower for word in medium_competition_words):
            if base_difficulty == 'Low':
                return 'Low'
            elif base_difficulty == 'Medium':
                return 'Medium'
        
        return base_difficulty
    
    def extract_from_text(self, text: str, min_length: int = 3, max_length: int = 50) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            min_length: æœ€å°å…³é”®è¯é•¿åº¦
            max_length: æœ€å¤§å…³é”®è¯é•¿åº¦
            
        Returns:
            æå–çš„å…³é”®è¯åˆ—è¡¨
        """
        # æ¸…ç†æ–‡æœ¬
        text = re.sub(r'[^\w\s]', ' ', text.lower())
        words = text.split()
        
        # è¿‡æ»¤åœç”¨è¯
        filtered_words = [word for word in words if word not in self.stop_words and len(word) >= min_length]
        
        # ç”Ÿæˆn-gramå…³é”®è¯
        keywords = set()
        
        # å•è¯
        for word in filtered_words:
            if min_length <= len(word) <= max_length:
                keywords.add(word)
        
        # äºŒå…ƒç»„
        for i in range(len(filtered_words) - 1):
            bigram = f"{filtered_words[i]} {filtered_words[i+1]}"
            if min_length <= len(bigram) <= max_length:
                keywords.add(bigram)
        
        # ä¸‰å…ƒç»„
        for i in range(len(filtered_words) - 2):
            trigram = f"{filtered_words[i]} {filtered_words[i+1]} {filtered_words[i+2]}"
            if min_length <= len(trigram) <= max_length:
                keywords.add(trigram)
        
        return list(keywords)


def main():
    """æµ‹è¯•å…³é”®è¯æå–å™¨"""
    extractor = KeywordExtractor()
    
    print("ğŸš€ å…³é”®è¯æå–å™¨æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•å…³é”®è¯
    test_keywords = ['ai image generator', 'chatgpt alternative']
    
    for keyword in test_keywords:
        print(f"\nğŸ” æµ‹è¯•å…³é”®è¯: {keyword}")
        
        # Googleè‡ªåŠ¨å®Œæˆæµ‹è¯•
        autocomplete = extractor.get_google_autocomplete_suggestions(keyword, max_suggestions=5)
        print(f"  è‡ªåŠ¨å®Œæˆå»ºè®® ({len(autocomplete)}): {autocomplete[:3]}")
        
        # ç›¸å…³æœç´¢è¯æµ‹è¯•
        related = extractor.get_related_search_terms(keyword, max_terms=5)
        print(f"  ç›¸å…³æœç´¢è¯ ({len(related)}): {related[:3]}")
        
        # è¯­ä¹‰æ‰©å±•æµ‹è¯•
        expanded = extractor.expand_seed_keywords([keyword], max_per_seed=5)
        if keyword in expanded:
            print(f"  è¯­ä¹‰æ‰©å±• ({len(expanded[keyword])}): {expanded[keyword][:3]}")
        
        # éš¾åº¦åˆ†æ
        difficulty = extractor.analyze_keyword_difficulty(keyword)
        print(f"  å…³é”®è¯éš¾åº¦: {difficulty}")
    
    print(f"\nâœ… å…³é”®è¯æå–å™¨æµ‹è¯•å®Œæˆ!")


if __name__ == '__main__':
    main()