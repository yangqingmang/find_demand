#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å…³é”®è¯æå–å·¥å…· - å¢å¼ºç‰ˆ
ä»å„ç§æ•°æ®æºæå–å’Œæ‰©å±•å…³é”®è¯ï¼Œé›†æˆGoogleè‡ªåŠ¨å®ŒæˆAPIã€ç›¸å…³æœç´¢è¯æŒ–æ˜å’Œè¯­ä¹‰ç›¸ä¼¼è¯å‘ç°
"""

import re
import requests
import json
import time
import random
from typing import List, Dict, Set, Any, Optional
from collections import Counter
import pandas as pd
from urllib.parse import quote_plus
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class KeywordExtractor:
    """å¢å¼ºç‰ˆå…³é”®è¯æå–å™¨"""
    
    def __init__(self):
        self.stop_words = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 
            'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 
            'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should'
        }
        
        # åˆå§‹åŒ–Google Trendsæ”¶é›†å™¨ç”¨äºç›¸å…³æœç´¢
        self.trends_collector = None
        try:
            from src.collectors.custom_trends_collector import CustomTrendsCollector
            self.trends_collector = CustomTrendsCollector()
            logger.info("âœ… Google Trendsæ”¶é›†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except ImportError as e:
            logger.warning(f"âš ï¸ Google Trendsæ”¶é›†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # AIå·¥å…·ç±»åˆ«è¯æ±‡åº“
        self.ai_tool_categories = {
            'image': ['generator', 'creator', 'maker', 'editor', 'enhancer', 'upscaler'],
            'text': ['writer', 'generator', 'editor', 'translator', 'summarizer', 'paraphraser'],
            'video': ['generator', 'editor', 'creator', 'enhancer', 'converter'],
            'audio': ['generator', 'editor', 'transcriber', 'converter', 'enhancer'],
            'code': ['generator', 'assistant', 'reviewer', 'optimizer', 'debugger'],
            'design': ['generator', 'creator', 'assistant', 'optimizer', 'enhancer']
        }
        
        # æ‰©å±•ä¿®é¥°è¯åº“
        self.expansion_modifiers = [
            'best', 'top', 'free', 'online', 'how to', 'what is', 'guide', 
            'tutorial', 'review', 'comparison', 'vs', 'alternative', 'tool',
            'software', 'app', 'platform', 'service', 'solution', 'api',
            'open source', 'premium', 'professional', 'advanced', 'simple',
            'easy', 'fast', 'powerful', 'smart', 'intelligent', 'automated'
        ]
    
    def get_google_autocomplete_suggestions(self, keyword: str, language: str = 'en', 
                                          country: str = 'us', max_suggestions: int = 10) -> List[str]:
        """
        è·å–Googleè‡ªåŠ¨å®Œæˆå»ºè®®
        
        Args:
            keyword: ç§å­å…³é”®è¯
            language: è¯­è¨€ä»£ç 
            country: å›½å®¶ä»£ç 
            max_suggestions: æœ€å¤§å»ºè®®æ•°é‡
            
        Returns:
            è‡ªåŠ¨å®Œæˆå»ºè®®åˆ—è¡¨
        """
        suggestions = []
        
        try:
            # Googleè‡ªåŠ¨å®ŒæˆAPI URL
            url = "http://suggestqueries.google.com/complete/search"
            
            params = {
                'client': 'firefox',
                'q': keyword,
                'hl': language,
                'gl': country
            }
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, params=params, headers=headers, timeout=10)
            
            if response.status_code == 200:
                # è§£æJSONå“åº”
                data = response.json()
                if len(data) > 1 and isinstance(data[1], list):
                    suggestions = data[1][:max_suggestions]
                    
            # è¿‡æ»¤å’Œæ¸…ç†å»ºè®®
            filtered_suggestions = []
            for suggestion in suggestions:
                if isinstance(suggestion, str) and len(suggestion) > len(keyword):
                    # ç§»é™¤åŸå…³é”®è¯ï¼Œåªä¿ç•™æ‰©å±•éƒ¨åˆ†
                    if suggestion.lower().startswith(keyword.lower()):
                        filtered_suggestions.append(suggestion)
            
            logger.info(f"âœ… è·å–åˆ° {len(filtered_suggestions)} ä¸ªGoogleè‡ªåŠ¨å®Œæˆå»ºè®®: {keyword}")
            return filtered_suggestions[:max_suggestions]
            
        except Exception as e:
            logger.warning(f"âš ï¸ Googleè‡ªåŠ¨å®Œæˆè·å–å¤±è´¥ {keyword}: {e}")
            return []
    
    def get_related_search_terms(self, keyword: str, max_terms: int = 10) -> List[str]:
        """
        è·å–ç›¸å…³æœç´¢è¯ï¼ˆé€šè¿‡Google Trendsï¼‰
        
        Args:
            keyword: ç§å­å…³é”®è¯
            max_terms: æœ€å¤§ç›¸å…³è¯æ•°é‡
            
        Returns:
            ç›¸å…³æœç´¢è¯åˆ—è¡¨
        """
        related_terms = []
        
        try:
            if self.trends_collector:
                # ä½¿ç”¨Google Trendsæ”¶é›†å™¨è·å–ç›¸å…³æœç´¢
                trends_data = self.trends_collector.collect_trends([keyword])
                
                if trends_data and 'related_queries' in trends_data:
                    for query_data in trends_data['related_queries']:
                        if 'query' in query_data:
                            related_terms.append(query_data['query'])
                
                logger.info(f"âœ… é€šè¿‡Trendsè·å–åˆ° {len(related_terms)} ä¸ªç›¸å…³æœç´¢è¯: {keyword}")
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºäºå…³é”®è¯ç”Ÿæˆç›¸å…³è¯
                related_terms = self._generate_related_terms_fallback(keyword, max_terms)
                logger.info(f"âœ… ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆç”Ÿæˆ {len(related_terms)} ä¸ªç›¸å…³è¯: {keyword}")
            
            return related_terms[:max_terms]
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç›¸å…³æœç´¢è¯è·å–å¤±è´¥ {keyword}: {e}")
            return self._generate_related_terms_fallback(keyword, max_terms)
    
    def _generate_related_terms_fallback(self, keyword: str, max_terms: int = 10) -> List[str]:
        """å¤‡ç”¨ç›¸å…³è¯ç”Ÿæˆæ–¹æ¡ˆ"""
        related_terms = []
        keyword_lower = keyword.lower()
        
        # åŸºäºAIå·¥å…·ç±»åˆ«ç”Ÿæˆç›¸å…³è¯
        for category, tools in self.ai_tool_categories.items():
            if category in keyword_lower or any(tool in keyword_lower for tool in tools):
                for tool in tools:
                    if tool not in keyword_lower:
                        related_terms.append(f"{keyword} {tool}")
                        related_terms.append(f"{tool} {keyword}")
        
        # åŸºäºä¿®é¥°è¯ç”Ÿæˆç›¸å…³è¯
        for modifier in self.expansion_modifiers[:max_terms]:
            if modifier not in keyword_lower:
                related_terms.append(f"{modifier} {keyword}")
        
        return list(set(related_terms))[:max_terms]
    
    def expand_seed_keywords(self, seed_keywords: List[str], max_per_seed: int = 20) -> Dict[str, List[str]]:
        """
        æ‰©å±•ç§å­å…³é”®è¯ï¼ˆè¯­ä¹‰ç›¸ä¼¼è¯å‘ç°ï¼‰
        
        Args:
            seed_keywords: ç§å­å…³é”®è¯åˆ—è¡¨
            max_per_seed: æ¯ä¸ªç§å­è¯æœ€å¤§æ‰©å±•æ•°é‡
            
        Returns:
            æŒ‰ç§å­è¯åˆ†ç»„çš„æ‰©å±•å…³é”®è¯å­—å…¸
        """
        expanded_keywords = {}
        
        for seed in seed_keywords:
            expanded = set()
            seed_lower = seed.lower()
            
            # 1. åŸºäºAIå·¥å…·ç±»åˆ«æ‰©å±•
            for category, tools in self.ai_tool_categories.items():
                if category in seed_lower or any(tool in seed_lower for tool in tools):
                    for tool in tools:
                        if tool not in seed_lower:
                            expanded.add(f"{seed} {tool}")
                            expanded.add(f"{tool} for {seed}")
            
            # 2. åŸºäºä¿®é¥°è¯æ‰©å±•
            for modifier in self.expansion_modifiers:
                if modifier not in seed_lower:
                    expanded.add(f"{modifier} {seed}")
                    if modifier in ['how to', 'what is']:
                        expanded.add(f"{modifier} use {seed}")
            
            # 3. åŸºäºè¯æ±‡å˜å½¢æ‰©å±•
            if 'generator' in seed_lower:
                expanded.add(seed.replace('generator', 'creator'))
                expanded.add(seed.replace('generator', 'maker'))
            elif 'creator' in seed_lower:
                expanded.add(seed.replace('creator', 'generator'))
                expanded.add(seed.replace('creator', 'maker'))
            
            # è¿‡æ»¤å’Œé™åˆ¶æ•°é‡
            filtered_expanded = []
            for kw in expanded:
                if len(kw) > 5 and len(kw) < 100:
                    filtered_expanded.append(kw)
            
            expanded_keywords[seed] = filtered_expanded[:max_per_seed]
            logger.info(f"âœ… è¯­ä¹‰æ‰©å±• {seed}: {len(expanded_keywords[seed])} ä¸ªå…³é”®è¯")
        
        return expanded_keywords
    
    def analyze_keyword_difficulty(self, keyword: str) -> str:
        """
        åˆ†æå…³é”®è¯éš¾åº¦
        
        Args:
            keyword: å…³é”®è¯
            
        Returns:
            éš¾åº¦ç­‰çº§ (Low/Medium/High)
        """
        keyword_lower = keyword.lower()
        word_count = len(keyword.split())
        
        # åŸºäºè¯æ•°åˆ¤æ–­åŸºç¡€éš¾åº¦
        if word_count >= 4:
            base_difficulty = 'Low'
        elif word_count >= 2:
            base_difficulty = 'Medium'
        else:
            base_difficulty = 'High'
        
        # åŸºäºç«äº‰è¯è°ƒæ•´éš¾åº¦
        high_competition_words = ['best', 'top', 'review', 'vs', 'comparison']
        medium_competition_words = ['free', 'online', 'tool', 'software']
        
        if any(word in keyword_lower for word in high_competition_words):
            if base_difficulty == 'Low':
                return 'Medium'
            elif base_difficulty == 'Medium':
                return 'High'
        elif any(word in keyword_lower for word in medium_competition_words):
            if base_difficulty == 'Low':
                return 'Low'
            elif base_difficulty == 'Medium':
                return 'Medium'
        
        return base_difficulty
    
    def extract_from_text(self, text: str, min_length: int = 3, max_length: int = 50) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            min_length: æœ€å°å…³é”®è¯é•¿åº¦
            max_length: æœ€å¤§å…³é”®è¯é•¿åº¦
            
        Returns:
            æå–çš„å…³é”®è¯åˆ—è¡¨
        """
        # æ¸…ç†æ–‡æœ¬
        text = re.sub(r'[^\w\s]', ' ', text.lower())
        words = text.split()
        
        # è¿‡æ»¤åœç”¨è¯
        filtered_words = [word for word in words if word not in self.stop_words and len(word) >= min_length]
        
        # ç”Ÿæˆn-gramå…³é”®è¯
        keywords = set()
        
        # å•è¯
        for word in filtered_words:
            if min_length <= len(word) <= max_length:
                keywords.add(word)
        
        # äºŒå…ƒç»„
        for i in range(len(filtered_words) - 1):
            bigram = f"{filtered_words[i]} {filtered_words[i+1]}"
            if min_length <= len(bigram) <= max_length:
                keywords.add(bigram)
        
        # ä¸‰å…ƒç»„
        for i in range(len(filtered_words) - 2):
            trigram = f"{filtered_words[i]} {filtered_words[i+1]} {filtered_words[i+2]}"
            if min_length <= len(trigram) <= max_length:
                keywords.add(trigram)
        
        return list(keywords)


def main():
    """æµ‹è¯•å…³é”®è¯æå–å™¨"""
    extractor = KeywordExtractor()
    
    print("ğŸš€ å…³é”®è¯æå–å™¨æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•å…³é”®è¯
    test_keywords = ['ai image generator', 'chatgpt alternative']
    
    for keyword in test_keywords:
        print(f"\nğŸ” æµ‹è¯•å…³é”®è¯: {keyword}")
        
        # Googleè‡ªåŠ¨å®Œæˆæµ‹è¯•
        autocomplete = extractor.get_google_autocomplete_suggestions(keyword, max_suggestions=5)
        print(f"  è‡ªåŠ¨å®Œæˆå»ºè®® ({len(autocomplete)}): {autocomplete[:3]}")
        
        # ç›¸å…³æœç´¢è¯æµ‹è¯•
        related = extractor.get_related_search_terms(keyword, max_terms=5)
        print(f"  ç›¸å…³æœç´¢è¯ ({len(related)}): {related[:3]}")
        
        # è¯­ä¹‰æ‰©å±•æµ‹è¯•
        expanded = extractor.expand_seed_keywords([keyword], max_per_seed=5)
        if keyword in expanded:
            print(f"  è¯­ä¹‰æ‰©å±• ({len(expanded[keyword])}): {expanded[keyword][:3]}")
        
        # éš¾åº¦åˆ†æ
        difficulty = extractor.analyze_keyword_difficulty(keyword)
        print(f"  å…³é”®è¯éš¾åº¦: {difficulty}")
    
    print(f"\nâœ… å…³é”®è¯æå–å™¨æµ‹è¯•å®Œæˆ!")


if __name__ == '__main__':
    main()