#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…³é”®è¯ç®¡ç†å™¨ - è´Ÿè´£å…³é”®è¯åˆ†æåŠŸèƒ½
"""

import os
import sys
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any
from src.demand_mining.analyzers.intent_analyzer_v2 import IntentAnalyzerV2 as IntentAnalyzer
from src.demand_mining.analyzers.market_analyzer import MarketAnalyzer
from src.demand_mining.analyzers.keyword_analyzer import KeywordAnalyzer
from src.demand_mining.analyzers.comprehensive_analyzer import ComprehensiveAnalyzer

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, project_root)

from .base_manager import BaseManager


class KeywordManager(BaseManager):
    """å…³é”®è¯åˆ†æç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = None):
        super().__init__(config_path)
        
        # å»¶è¿Ÿå¯¼å…¥åˆ†æå™¨ï¼Œé¿å…å¾ªç¯å¯¼å…¥
        self._intent_analyzer = None
        self._market_analyzer = None
        self._keyword_analyzer = None
        self._comprehensive_analyzer = None
        
        print("ğŸ” å…³é”®è¯ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    @property
    def intent_analyzer(self):
        """å»¶è¿ŸåŠ è½½æ„å›¾åˆ†æå™¨"""
        if self._intent_analyzer is None:
            self._intent_analyzer = IntentAnalyzer()
        return self._intent_analyzer
    
    @property
    def market_analyzer(self):
        """å»¶è¿ŸåŠ è½½å¸‚åœºåˆ†æå™¨"""
        if self._market_analyzer is None:
            self._market_analyzer = MarketAnalyzer()
        return self._market_analyzer
    
    @property
    def keyword_analyzer(self):
        """å»¶è¿ŸåŠ è½½å…³é”®è¯åˆ†æå™¨"""
        if self._keyword_analyzer is None:
            self._keyword_analyzer = KeywordAnalyzer()
        return self._keyword_analyzer
    
    @property
    def comprehensive_analyzer(self):
        """å»¶è¿ŸåŠ è½½ç»¼åˆåˆ†æå™¨"""
        if self._comprehensive_analyzer is None:
            self._comprehensive_analyzer = ComprehensiveAnalyzer()
        return self._comprehensive_analyzer
    
    def analyze(self, input_source: str, analysis_type: str = 'file', 
                output_dir: str = None, use_comprehensive: bool = False) -> Dict[str, Any]:
        """
        åˆ†æå…³é”®è¯
        
        Args:
            input_source: è¾“å…¥æºï¼ˆæ–‡ä»¶è·¯å¾„æˆ–å…³é”®è¯åˆ—è¡¨ï¼‰
            analysis_type: åˆ†æç±»å‹ ('file' æˆ– 'keywords')
            output_dir: è¾“å‡ºç›®å½•
            use_comprehensive: æ˜¯å¦ä½¿ç”¨ç»¼åˆåˆ†æå™¨
            
        Returns:
            åˆ†æç»“æœ
        """
        print(f"ğŸš€ å¼€å§‹å…³é”®è¯åˆ†æ - ç±»å‹: {analysis_type}, ç»¼åˆåˆ†æ: {use_comprehensive}")
        
        if use_comprehensive:
            return self._comprehensive_analyze(input_source, analysis_type, output_dir)
        
        if analysis_type == 'file':
            return self._analyze_from_file(input_source, output_dir)
        elif analysis_type == 'keywords':
            return self._analyze_from_keywords([input_source], output_dir)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åˆ†æç±»å‹: {analysis_type}")
    
    def _analyze_from_file(self, file_path: str, output_dir: str = None) -> Dict[str, Any]:
        """ä»æ–‡ä»¶åˆ†æå…³é”®è¯"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # è¯»å–æ•°æ®
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path)
        elif file_path.endswith('.json'):
            df = pd.read_json(file_path)
        else:
            raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨CSVæˆ–JSONæ–‡ä»¶")
        
        print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡å…³é”®è¯æ•°æ®")
        
        # æå–å…³é”®è¯åˆ—è¡¨
        keywords = []
        for col in ['query', 'keyword', 'term']:
            if col in df.columns:
                keywords = df[col].dropna().tolist()
                break
        
        if not keywords:
            raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„å…³é”®è¯åˆ—")
        
        return self._perform_analysis(keywords, output_dir)
    
    def _analyze_from_keywords(self, keywords: List[str], output_dir: str = None) -> Dict[str, Any]:
        """ä»å…³é”®è¯åˆ—è¡¨åˆ†æ"""
        if not keywords:
            raise ValueError("å…³é”®è¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        print(f"âœ… æ¥æ”¶åˆ° {len(keywords)} ä¸ªå…³é”®è¯")
        return self._perform_analysis(keywords, output_dir)
    
    def _perform_analysis(self, keywords: List[str], output_dir: str = None) -> Dict[str, Any]:
        """æ‰§è¡Œå…³é”®è¯åˆ†æ"""
        results = {
            'total_keywords': len(keywords),
            'analysis_time': datetime.now().isoformat(),
            'keywords': [],
            'intent_summary': {},
            'market_insights': {},
            'recommendations': []
        }
        
        # é€ä¸ªåˆ†æå…³é”®è¯
        for idx, keyword in enumerate(keywords):
            print(f"ğŸ” åˆ†æå…³é”®è¯ ({idx+1}/{len(keywords)}): {keyword}")
            
            # æ„å›¾åˆ†æ
            intent_result = self._analyze_keyword_intent(keyword)
            
            # å¸‚åœºåˆ†æ
            market_result = self._analyze_keyword_market(keyword)
            
            # æ•´åˆç»“æœ
            keyword_result = {
                'keyword': keyword,
                'intent': intent_result,
                'market': market_result,
                'opportunity_score': self._calculate_opportunity_score(intent_result, market_result)
            }
            
            results['keywords'].append(keyword_result)
        
        # ç”Ÿæˆæ‘˜è¦
        results['intent_summary'] = self._generate_intent_summary(results['keywords'])
        results['market_insights'] = self._generate_market_insights(results['keywords'])
        results['recommendations'] = self._generate_recommendations(results['keywords'])
        
        # ä¿å­˜ç»“æœ
        if output_dir:
            output_path = self._save_analysis_results(results, output_dir)
            results['output_path'] = output_path
        
        return results
    
    def _analyze_keyword_intent(self, keyword: str) -> Dict[str, Any]:
        """åˆ†æå…³é”®è¯æ„å›¾"""
        try:
            if self.intent_analyzer is None:
                return self._get_default_intent_result()
            
            # åˆ›å»ºåŒ…å«å…³é”®è¯çš„DataFrameè¿›è¡Œåˆ†æ
            df = pd.DataFrame({'query': [keyword]})
            
            # ä½¿ç”¨æ„å›¾åˆ†æå™¨è¿›è¡Œå®Œæ•´åˆ†æ
            result = self.intent_analyzer.analyze_keywords(df)
            
            # å¤„ç†æ„å›¾åˆ†æç»“æœ
            if result and 'results' in result and len(result['results']) > 0:
                intent_data = result['results'][0]  # è·å–ç¬¬ä¸€ä¸ªç»“æœ
                return {
                    'primary_intent': intent_data.get('intent_primary', 'Unknown'),
                    'confidence': intent_data.get('probability', 0.0),
                    'secondary_intent': intent_data.get('intent_secondary', ''),
                    'intent_description': intent_data.get('intent_primary', 'Unknown'),
                    'website_recommendations': {
                        'website_type': intent_data.get('website_type', 'Unknown'),
                        'ai_tool_category': intent_data.get('ai_tool_category', 'General'),
                        'domain_suggestions': intent_data.get('domain_suggestions', []),
                        'monetization_strategy': intent_data.get('monetization_strategy', []),
                        'technical_requirements': intent_data.get('technical_requirements', []),
                        'competition_analysis': intent_data.get('competition_analysis', {}),
                        'development_priority': intent_data.get('development_priority', {}),
                        'content_strategy': intent_data.get('content_strategy', [])
                    }
                }
            else:
                return self._get_default_intent_result()
                
        except Exception as e:
            print(f"âš ï¸ æ„å›¾åˆ†æå¤±è´¥ ({keyword}): {e}")
            return self._get_default_intent_result()
    
    def _analyze_keyword_market(self, keyword: str) -> Dict[str, Any]:
        """åˆ†æå…³é”®è¯å¸‚åœºæ•°æ®"""
        try:
            # åŸºç¡€å¸‚åœºæ•°æ®ï¼ˆå®é™…å¯æ¥å…¥çœŸå®APIï¼‰
            base_data = {
                'search_volume': 1000,
                'competition': 0.5,
                'cpc': 2.0,
                'trend': 'stable',
                'seasonality': 'low'
            }
            
            # AIç›¸å…³å…³é”®è¯åŠ åˆ†
            ai_bonus = self._calculate_ai_bonus(keyword)
            
            # å•†ä¸šä»·å€¼è¯„ä¼°
            commercial_value = self._assess_commercial_value(keyword)
            
            # æ•´åˆè¯„åˆ†
            base_data.update({
                'ai_bonus': ai_bonus,
                'commercial_value': commercial_value,
                'opportunity_indicators': self._get_opportunity_indicators(keyword)
            })
            
            return base_data
            
        except Exception as e:
            print(f"âš ï¸ å¸‚åœºåˆ†æå¤±è´¥ ({keyword}): {e}")
            return {
                'search_volume': 0,
                'competition': 0.0,
                'cpc': 0.0,
                'trend': 'unknown',
                'seasonality': 'unknown',
                'ai_bonus': 0,
                'commercial_value': 0,
                'opportunity_indicators': []
            }
    
    @staticmethod
    def _calculate_opportunity_score(intent_result: Dict, market_result: Dict) -> float:
        """è®¡ç®—ç»¼åˆæœºä¼šåˆ†æ•°"""
        try:
            # åŸºç¡€è¯„åˆ†æƒé‡
            weights = {
                'intent_confidence': 0.2,
                'search_volume': 0.25,
                'competition': 0.15,
                'ai_bonus': 0.2,
                'commercial_value': 0.2
            }
            
            # å„é¡¹åˆ†æ•°è®¡ç®—
            intent_score = intent_result.get('confidence', 0) * 100
            volume_score = min(market_result.get('search_volume', 0) / 1000, 1) * 100
            competition_score = (1 - market_result.get('competition', 1)) * 100
            ai_bonus = market_result.get('ai_bonus', 0)
            commercial_value = market_result.get('commercial_value', 0)
            
            # åŠ æƒè®¡ç®—æ€»åˆ†
            total_score = (
                intent_score * weights['intent_confidence'] +
                volume_score * weights['search_volume'] +
                competition_score * weights['competition'] +
                ai_bonus * weights['ai_bonus'] +
                commercial_value * weights['commercial_value']
            )
            
            return round(min(total_score, 100), 2)
            
        except Exception as e:
            print(f"âš ï¸ æœºä¼šåˆ†æ•°è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    @staticmethod
    def _get_default_intent_result() -> Dict[str, Any]:
        """è·å–é»˜è®¤æ„å›¾åˆ†æç»“æœ"""
        return {
            'primary_intent': 'Unknown',
            'confidence': 0.0,
            'secondary_intent': None,
            'intent_description': 'åˆ†æå¤±è´¥',
            'website_recommendations': {}
        }
    
    @staticmethod
    def _calculate_ai_bonus(keyword: str) -> float:
        """è®¡ç®—AIç›¸å…³å…³é”®è¯åŠ åˆ†"""
        keyword_lower = keyword.lower()
        ai_score = 0
        
        # AIå‰ç¼€åŒ¹é…
        ai_prefixes = ['ai', 'artificial intelligence', 'machine learning', 'deep learning']
        for prefix in ai_prefixes:
            if prefix in keyword_lower:
                ai_score += 20
                break
        
        # AIå·¥å…·ç±»å‹åŒ¹é…
        ai_tool_types = ['generator', 'detector', 'writer', 'assistant', 'chatbot']
        for tool_type in ai_tool_types:
            if tool_type in keyword_lower:
                ai_score += 15
                break
        
        return min(ai_score, 50)
    
    @staticmethod
    def _assess_commercial_value(keyword: str) -> float:
        """è¯„ä¼°å•†ä¸šä»·å€¼"""
        keyword_lower = keyword.lower()
        commercial_score = 0
        
        # é«˜ä»·å€¼å…³é”®è¯ç±»å‹
        high_value_types = [
            'generator', 'converter', 'editor', 'maker', 'creator',
            'optimizer', 'enhancer', 'analyzer', 'detector'
        ]
        
        for value_type in high_value_types:
            if value_type in keyword_lower:
                commercial_score += 25
                break
        
        # ä»˜è´¹æ„æ„¿å¼ºçš„é¢†åŸŸ
        high_payment_domains = [
            'business', 'marketing', 'seo', 'content', 'design',
            'video', 'image', 'writing', 'coding', 'academic'
        ]
        
        for domain in high_payment_domains:
            if domain in keyword_lower:
                commercial_score += 20
                break
        
        return min(commercial_score, 50)
    
    @staticmethod
    def _get_opportunity_indicators(keyword: str) -> List[str]:
        """è·å–æœºä¼šæŒ‡æ ‡"""
        indicators = []
        keyword_lower = keyword.lower()
        
        # AIç›¸å…³
        if any(prefix in keyword_lower for prefix in ['ai', 'artificial intelligence']):
            indicators.append("AIç›¸å…³éœ€æ±‚")
        
        # å·¥å…·ç±»
        if any(tool in keyword_lower for tool in ['generator', 'converter', 'editor']):
            indicators.append("å·¥å…·ç±»éœ€æ±‚")
        
        # æ–°å…´æ¦‚å¿µ
        if any(concept in keyword_lower for concept in ['gpt', 'chatbot', 'neural']):
            indicators.append("æ–°å…´æŠ€æœ¯")
        
        # å‡ºæµ·å‹å¥½
        if not any(ord(char) > 127 for char in keyword):
            indicators.append("å‡ºæµ·å‹å¥½")
        
        return indicators
    
    @staticmethod
    def _generate_intent_summary(keywords: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆæ„å›¾æ‘˜è¦"""
        intent_counts = {}
        total_keywords = len(keywords)
        
        for kw in keywords:
            intent = kw['intent']['primary_intent']
            intent_counts[intent] = intent_counts.get(intent, 0) + 1
        
        intent_percentages = {
            intent: round(count / total_keywords * 100, 1)
            for intent, count in intent_counts.items()
        }
        
        return {
            'total_keywords': total_keywords,
            'intent_distribution': intent_counts,
            'intent_percentages': intent_percentages,
            'dominant_intent': max(intent_counts.items(), key=lambda x: x[1])[0] if intent_counts else 'Unknown'
        }

    @staticmethod
    def _generate_market_insights(keywords: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆå¸‚åœºæ´å¯Ÿ"""
        high_opportunity = [kw for kw in keywords if kw['opportunity_score'] >= 70]
        medium_opportunity = [kw for kw in keywords if 40 <= kw['opportunity_score'] < 70]
        low_opportunity = [kw for kw in keywords if kw['opportunity_score'] < 40]

        return {
            'high_opportunity_count': len(high_opportunity),
            'medium_opportunity_count': len(medium_opportunity),
            'low_opportunity_count': len(low_opportunity),
            'top_opportunities': sorted(keywords, key=lambda x: x['opportunity_score'], reverse=True)[:10],
            'avg_opportunity_score': round(sum(kw['opportunity_score'] for kw in keywords) / len(keywords), 2) if keywords else 0
        }

    @staticmethod
    def _generate_recommendations(keywords: List[Dict]) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        # åˆ†æå…³é”®è¯åˆ†å¸ƒ
        high_opportunity = [kw for kw in keywords if kw['opportunity_score'] >= 70]
        ai_keywords = [kw for kw in keywords if kw['market'].get('ai_bonus', 0) > 0]
        
        # é«˜æœºä¼šå…³é”®è¯å»ºè®®
        if high_opportunity:
            recommendations.append(f"ğŸ¯ å‘ç° {len(high_opportunity)} ä¸ªé«˜æœºä¼šå…³é”®è¯ï¼Œå»ºè®®ç«‹å³å¼€å‘MVPäº§å“")
            top_3 = sorted(high_opportunity, key=lambda x: x['opportunity_score'], reverse=True)[:3]
            for i, kw in enumerate(top_3, 1):
                recommendations.append(f"   {i}. {kw['keyword']} (æœºä¼šåˆ†æ•°: {kw['opportunity_score']})")
        
        # AIç›¸å…³å»ºè®®
        if ai_keywords:
            recommendations.append(f"ğŸ¤– å‘ç° {len(ai_keywords)} ä¸ªAIç›¸å…³å…³é”®è¯ï¼Œç¬¦åˆå‡ºæµ·AIå·¥å…·æ–¹å‘")
        
        return recommendations
    
    @staticmethod
    def _save_analysis_results(results: Dict[str, Any], output_dir: str) -> str:
        """ä¿å­˜åˆ†æç»“æœ"""
        from src.utils.file_utils import save_results_with_timestamp
        
        # ä¿å­˜JSONæ ¼å¼
        json_path = save_results_with_timestamp(results, output_dir, 'keyword_analysis')
        
        # ä¿å­˜CSVæ ¼å¼ï¼ˆå…³é”®è¯è¯¦æƒ…ï¼‰
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        csv_path = os.path.join(output_dir, f'keywords_detail_{timestamp}.csv')
        keywords_df = pd.DataFrame([
            {
                'keyword': kw['keyword'],
                'primary_intent': kw['intent']['primary_intent'],
                'confidence': kw['intent']['confidence'],
                'search_volume': kw['market']['search_volume'],
                'competition': kw['market']['competition'],
                'opportunity_score': kw['opportunity_score']
            }
            for kw in results['keywords']
        ])
        keywords_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        
        return json_path
    
    def _comprehensive_analyze(self, input_source: str, analysis_type: str, output_dir: str = None) -> Dict[str, Any]:
        """ä½¿ç”¨ç»¼åˆåˆ†æå™¨è¿›è¡Œå…¨é¢åˆ†æ"""
        print("ğŸ”§ å¯åŠ¨ç»¼åˆåˆ†ææ¨¡å¼...")
        
        # å‡†å¤‡æ•°æ®
        if analysis_type == 'file':
            if not os.path.exists(input_source):
                raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_source}")
            
            # è¯»å–æ•°æ®
            if input_source.endswith('.csv'):
                df = pd.read_csv(input_source)
            elif input_source.endswith('.json'):
                df = pd.read_json(input_source)
            else:
                raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨CSVæˆ–JSONæ–‡ä»¶")
            
            print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡å…³é”®è¯æ•°æ®")
            
        elif analysis_type == 'keywords':
            keywords = [input_source] if isinstance(input_source, str) else input_source
            df = pd.DataFrame({'query': keywords})
            print(f"âœ… æ¥æ”¶åˆ° {len(keywords)} ä¸ªå…³é”®è¯")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åˆ†æç±»å‹: {analysis_type}")
        
        # æ‰§è¡Œç»¼åˆåˆ†æ
        try:
            analysis_result = self.comprehensive_analyzer.analyze(df)
            
            # ä¿å­˜ç»“æœ
            if output_dir:
                output_path = self.comprehensive_analyzer.export_comprehensive_report(
                    analysis_result, output_dir
                )
                analysis_result['output_path'] = output_path
                print(f"ğŸ“Š ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_dir}")
            
            # ç”Ÿæˆç®€åŒ–çš„è¿”å›ç»“æœï¼ˆå…¼å®¹åŸæœ‰æ¥å£ï¼‰
            simplified_result = self._convert_to_legacy_format(analysis_result)
            
            return simplified_result
            
        except Exception as e:
            print(f"âŒ ç»¼åˆåˆ†æå¤±è´¥: {e}")
            # é™çº§åˆ°åŸæœ‰åˆ†ææ–¹æ³•
            print("ğŸ”„ é™çº§åˆ°åŸºç¡€åˆ†ææ¨¡å¼...")
            if analysis_type == 'file':
                return self._analyze_from_file(input_source, output_dir)
            else:
                return self._analyze_from_keywords([input_source], output_dir)
    
    def _convert_to_legacy_format(self, comprehensive_result: Dict[str, Any]) -> Dict[str, Any]:
        """å°†ç»¼åˆåˆ†æç»“æœè½¬æ¢ä¸ºå…¼å®¹åŸæœ‰æ¥å£çš„æ ¼å¼"""
        df = comprehensive_result['results']
        summary = comprehensive_result['summary']
        
        # è½¬æ¢ä¸ºåŸæœ‰æ ¼å¼
        legacy_result = {
            'total_keywords': summary['total_keywords'],
            'analysis_time': comprehensive_result['analysis_time'],
            'keywords': [],
            'intent_summary': {},
            'market_insights': {},
            'recommendations': [],
            'comprehensive_summary': summary  # æ–°å¢ç»¼åˆæ‘˜è¦
        }
        
        # è½¬æ¢å…³é”®è¯è¯¦æƒ…
        for _, row in df.iterrows():
            keyword_result = {
                'keyword': row['query'],
                'comprehensive_score': row.get('comprehensive_score', 0),
                'comprehensive_grade': row.get('comprehensive_grade', 'C'),
                'intent': {
                    'primary_intent': row.get('intent_intent', 'Unknown'),
                    'confidence': row.get('intent_confidence', 0.0),
                    'intent_description': row.get('intent_intent_description', '')
                },
                'market': {
                    'search_volume': row.get('market_search_volume', 0),
                    'competition': row.get('market_competition', 0.5),
                    'cpc': row.get('market_cpc', 0.0)
                },
                'timeliness': {
                    'score': row.get('timeliness_score', 50.0),
                    'grade': row.get('timeliness_grade', 'C'),
                    'trend_direction': row.get('timeliness_trend_direction', 'stable')
                },
                'scorer': {
                    'total_score': row.get('scorer_total_score', 50.0),
                    'pray_score': row.get('scorer_pray_score', 50.0),
                    'commercial_score': row.get('scorer_commercial_score', 30.0)
                },
                'opportunity_score': row.get('comprehensive_score', 50.0)  # ä½¿ç”¨ç»¼åˆè¯„åˆ†ä½œä¸ºæœºä¼šåˆ†æ•°
            }
            legacy_result['keywords'].append(keyword_result)
        
        # ç”Ÿæˆæ„å›¾æ‘˜è¦
        if 'intent_intent' in df.columns:
            intent_counts = df['intent_intent'].value_counts().to_dict()
            total = len(df)
            legacy_result['intent_summary'] = {
                'total_keywords': total,
                'intent_distribution': intent_counts,
                'intent_percentages': {k: round(v/total*100, 1) for k, v in intent_counts.items()},
                'dominant_intent': max(intent_counts.items(), key=lambda x: x[1])[0] if intent_counts else 'Unknown'
            }
        
        # ç”Ÿæˆå¸‚åœºæ´å¯Ÿ
        high_opportunity = df[df['comprehensive_score'] >= 80] if 'comprehensive_score' in df.columns else pd.DataFrame()
        medium_opportunity = df[(df['comprehensive_score'] >= 60) & (df['comprehensive_score'] < 80)] if 'comprehensive_score' in df.columns else pd.DataFrame()
        low_opportunity = df[df['comprehensive_score'] < 60] if 'comprehensive_score' in df.columns else pd.DataFrame()
        
        legacy_result['market_insights'] = {
            'high_opportunity_count': len(high_opportunity),
            'medium_opportunity_count': len(medium_opportunity),
            'low_opportunity_count': len(low_opportunity),
            'top_opportunities': df.nlargest(10, 'comprehensive_score')[['query', 'comprehensive_score']].to_dict('records') if 'comprehensive_score' in df.columns else [],
            'avg_opportunity_score': round(df['comprehensive_score'].mean(), 2) if 'comprehensive_score' in df.columns else 50.0
        }
        
        # ç”Ÿæˆå»ºè®®
        recommendations = []
        if len(high_opportunity) > 0:
            recommendations.append(f"ğŸ¯ å‘ç° {len(high_opportunity)} ä¸ªé«˜ä»·å€¼å…³é”®è¯ (ç»¼åˆè¯„åˆ†â‰¥80)ï¼Œå»ºè®®ä¼˜å…ˆå¼€å‘")
            top_3 = high_opportunity.nlargest(3, 'comprehensive_score')
            for i, (_, row) in enumerate(top_3.iterrows(), 1):
                recommendations.append(f"   {i}. {row['query']} (ç»¼åˆè¯„åˆ†: {row['comprehensive_score']})")
        
        if 'timeliness_grade' in df.columns:
            high_timeliness = df[df['timeliness_grade'].isin(['A', 'B'])]
            if len(high_timeliness) > 0:
                recommendations.append(f"â° å‘ç° {len(high_timeliness)} ä¸ªé«˜æ—¶æ•ˆæ€§å…³é”®è¯ï¼Œå»ºè®®å¿«é€Ÿè¡ŒåŠ¨")
        
        if 'scorer_commercial_score' in df.columns:
            high_commercial = df[df['scorer_commercial_score'] >= 70]
            if len(high_commercial) > 0:
                recommendations.append(f"ğŸ’° å‘ç° {len(high_commercial)} ä¸ªé«˜å•†ä¸šä»·å€¼å…³é”®è¯ï¼Œå˜ç°æ½œåŠ›å¤§")
        
        legacy_result['recommendations'] = recommendations
        
        return legacy_result