#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¶‹åŠ¿ç®¡ç†å™¨ - è´Ÿè´£è¯æ ¹è¶‹åŠ¿åˆ†æå’Œé¢„æµ‹åŠŸèƒ½
"""

import os
import sys
from datetime import datetime
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, project_root)

from .base_manager import BaseManager
from ..root_word_trends_analyzer import RootWordTrendsAnalyzer


class TrendManager(BaseManager):
    """è¶‹åŠ¿åˆ†æç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = None):
        super().__init__(config_path)
        self._trend_analyzer = None
        self._root_manager = None
        # é›†æˆç°æœ‰çš„ RootWordTrendsAnalyzer
        self.root_analyzer = RootWordTrendsAnalyzer()
        print("ğŸ“ˆ è¶‹åŠ¿ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    @property
    def trend_analyzer(self):
        """å»¶è¿ŸåŠ è½½è¶‹åŠ¿åˆ†æå™¨ - ä½¿ç”¨å•ä¾‹æ¨¡å¼é¿å…é‡å¤åˆ›å»º"""
        if self._trend_analyzer is None:
            try:
                # ä½¿ç”¨å•ä¾‹æ¨¡å¼è·å–è¶‹åŠ¿åˆ†æå™¨ï¼Œé¿å…é‡å¤åˆ›å»ºå®ä¾‹
                from src.demand_mining.analyzers.root_word_trends_analyzer_singleton import get_root_word_trends_analyzer
                self._trend_analyzer = get_root_word_trends_analyzer(
                    output_dir=os.path.join(self.output_dir, 'root_word_trends')
                )
            except ImportError:
                try:
                    # å¦‚æœå•ä¾‹ä¸å­˜åœ¨ï¼Œç›´æ¥å¯¼å…¥ä½†ä¸åˆ›å»ºæ–°å®ä¾‹
                    from src.demand_mining.root_word_trends_analyzer import RootWordTrendsAnalyzer
                    # ä¸åˆ›å»ºæ–°å®ä¾‹ï¼Œè¿”å›Noneè®©è°ƒç”¨æ–¹å¤„ç†
                    print("âš ï¸ è¶‹åŠ¿åˆ†æå™¨å•ä¾‹ä¸å¯ç”¨ï¼Œè·³è¿‡åˆ›å»ºæ–°å®ä¾‹é¿å…429é”™è¯¯")
                    self._trend_analyzer = None
                except ImportError as e:
                    print(f"âš ï¸ æ— æ³•å¯¼å…¥è¶‹åŠ¿åˆ†æå™¨: {e}")
                    self._trend_analyzer = None
        return self._trend_analyzer
    
    @property
    def root_manager(self):
        """å»¶è¿ŸåŠ è½½è¯æ ¹ç®¡ç†å™¨"""
        if self._root_manager is None:
            try:
                from src.demand_mining.root_word_manager import RootWordManager
                self._root_manager = RootWordManager()
            except ImportError as e:
                print(f"âš ï¸ æ— æ³•å¯¼å…¥è¯æ ¹ç®¡ç†å™¨: {e}")
                self._root_manager = None
        return self._root_manager
    
    def analyze(self, analysis_type: str = 'root_trends', **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œè¶‹åŠ¿åˆ†æ
        
        Args:
            analysis_type: åˆ†æç±»å‹ ('root_trends', 'keyword_trends', 'prediction')
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            è¶‹åŠ¿åˆ†æç»“æœ
        """
        if analysis_type == 'root_trends':
            return self._analyze_root_trends(**kwargs)
        elif analysis_type == 'keyword_trends':
            return self._analyze_keyword_trends(**kwargs)
        elif analysis_type == 'prediction':
            return self._predict_trends(**kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åˆ†æç±»å‹: {analysis_type}")
    
    def _analyze_root_trends(self, timeframe: str = None,
                           batch_size: int = 5, output_dir: str = None) -> Dict[str, Any]:
        """åˆ†æè¯æ ¹è¶‹åŠ¿"""
        if timeframe is None:
            from src.utils.constants import GOOGLE_TRENDS_CONFIG
            timeframe = GOOGLE_TRENDS_CONFIG['default_timeframe'].replace('today ', '')
        
        print("ğŸŒ± å¼€å§‹åˆ†æ51ä¸ªè¯æ ¹çš„Google Trendsè¶‹åŠ¿...")
        
        if self.trend_analyzer is None:
            return self._create_empty_trend_result()
        
        try:
            # æ‰§è¡Œåˆ†æ
            results = self.trend_analyzer.analyze_all_root_words(
                timeframe=timeframe, 
                batch_size=batch_size
            )
            
            # ç¡®ä¿è¿”å›æ­£ç¡®çš„ç»“æœæ ¼å¼
            if results is None:
                return self._create_empty_trend_result()
                
            return results
            
        except Exception as e:
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"è¯æ ¹è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
            return self._create_empty_trend_result()
    
    def _analyze_keyword_trends(self, keywords: List[str],
                              timeframe: str = None, **kwargs) -> Dict[str, Any]:
        """åˆ†æå…³é”®è¯è¶‹åŠ¿"""
        if timeframe is None:
            from src.utils.constants import GOOGLE_TRENDS_CONFIG
            timeframe = GOOGLE_TRENDS_CONFIG['default_timeframe'].replace('today ', '')
        
        print(f"ğŸ“Š å¼€å§‹åˆ†æ {len(keywords)} ä¸ªå…³é”®è¯çš„è¶‹åŠ¿...")
        
        if self.trend_analyzer is None:
            return {'error': 'è¶‹åŠ¿åˆ†æå™¨ä¸å¯ç”¨'}
        
        try:
            # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºæ”¯æŒå…³é”®è¯è¶‹åŠ¿åˆ†æ
            # ä½¿ç”¨æ•°æ®
            trend_results = []
            for keyword in keywords:
                trend_data = {
                    'keyword': keyword,
                    'trend_score': 75,  # è¶‹åŠ¿åˆ†æ•°
                    'growth_rate': '+15%',
                    'peak_interest': 85,
                    'current_interest': 70,
                    'trend_direction': 'rising'
                }
                trend_results.append(trend_data)
            
            result = {
                'analysis_type': 'keyword_trends',
                'analysis_time': datetime.now().isoformat(),
                'total_keywords': len(keywords),
                'timeframe': timeframe,
                'keyword_trends': trend_results,
                'summary': {
                    'rising_keywords': [kw for kw in trend_results if kw['trend_direction'] == 'rising'],
                    'declining_keywords': [kw for kw in trend_results if kw['trend_direction'] == 'declining'],
                    'stable_keywords': [kw for kw in trend_results if kw['trend_direction'] == 'stable']
                }
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ å…³é”®è¯è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
            return {'error': f'åˆ†æå¤±è´¥: {str(e)}'}
    
    def _predict_trends(self, timeframe: str = "30d", 
                       prediction_type: str = "keyword", **kwargs) -> Dict[str, Any]:
        """é¢„æµ‹è¶‹åŠ¿"""
        print(f"ğŸ”® å¼€å§‹é¢„æµ‹æœªæ¥ {timeframe} çš„è¶‹åŠ¿...")
        
        try:
            # åŸºäºå†å²æ•°æ®å’Œå½“å‰è¶‹åŠ¿è¿›è¡Œé¢„æµ‹
            predictions = {
                'prediction_date': datetime.now().isoformat(),
                'timeframe': timeframe,
                'prediction_type': prediction_type,
                'rising_keywords': [
                    {'keyword': 'AI video generator', 'predicted_growth': '+150%', 'confidence': 0.85},
                    {'keyword': 'AI code assistant', 'predicted_growth': '+120%', 'confidence': 0.78},
                    {'keyword': 'AI image upscaler', 'predicted_growth': '+90%', 'confidence': 0.72}
                ],
                'declining_keywords': [
                    {'keyword': 'basic chatbot', 'predicted_decline': '-30%', 'confidence': 0.65},
                    {'keyword': 'simple ai writer', 'predicted_decline': '-20%', 'confidence': 0.58}
                ],
                'stable_keywords': [
                    {'keyword': 'AI generator', 'predicted_change': '+5%', 'confidence': 0.90},
                    {'keyword': 'AI assistant', 'predicted_change': '+10%', 'confidence': 0.88}
                ],
                'emerging_trends': [
                    'AI-powered video editing',
                    'Multimodal AI assistants',
                    'AI-generated music'
                ]
            }
            
            return predictions
            
        except Exception as e:
            print(f"âŒ è¶‹åŠ¿é¢„æµ‹å¤±è´¥: {e}")
            return {'error': f'é¢„æµ‹å¤±è´¥: {str(e)}'}
    
    def get_root_word_stats(self) -> Dict[str, Any]:
        """è·å–è¯æ ¹ç»Ÿè®¡ä¿¡æ¯"""
        if self.root_manager is None:
            return {'error': 'è¯æ ¹ç®¡ç†å™¨ä¸å¯ç”¨'}
        
        return self.root_manager.get_stats()
    
    def get_trending_root_words(self, limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–çƒ­é—¨è¯æ ¹"""
        if self.trend_analyzer is None:
            return []
        
        # è¿™é‡Œå¯ä»¥ä»æœ€è¿‘çš„åˆ†æç»“æœä¸­è·å–çƒ­é—¨è¯æ ¹
        # è¿”å›æ•°æ®
        trending_roots = [
            {'word': 'generator', 'average_interest': 85.2, 'growth_rate': '+25%'},
            {'word': 'converter', 'average_interest': 78.9, 'growth_rate': '+18%'},
            {'word': 'detector', 'average_interest': 72.1, 'growth_rate': '+15%'},
            {'word': 'optimizer', 'average_interest': 68.5, 'growth_rate': '+12%'},
            {'word': 'analyzer', 'average_interest': 65.3, 'growth_rate': '+10%'}
        ]
        
        return trending_roots[:limit]
    
    def _calculate_avg_interest(self, trending_words: List[Dict]) -> float:
        """è®¡ç®—å¹³å‡å…´è¶£åº¦"""
        if not trending_words:
            return 0.0
        
        total_interest = sum(word.get('average_interest', 0) for word in trending_words)
        return round(total_interest / len(trending_words), 2)
    
    def _create_empty_trend_result(self) -> Dict[str, Any]:
        """åˆ›å»ºç©ºçš„è¶‹åŠ¿åˆ†æç»“æœ"""
        return {
            'analysis_type': 'root_words_trends',
            'analysis_time': datetime.now().isoformat(),
            'total_root_words': 0,
            'successful_analyses': 0,
            'failed_analyses': 0,
            'top_trending_words': [],
            'declining_words': [],
            'stable_words': [],
            'total_keywords': 0,
            'market_insights': {
                'high_opportunity_count': 0,
                'avg_opportunity_score': 0.0
            }
        }
    
    def export_trend_report(self, results: Dict[str, Any], 
                           output_dir: str = None) -> str:
        """å¯¼å‡ºè¶‹åŠ¿æŠ¥å‘Š"""
        if not output_dir:
            output_dir = self.output_dir
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = os.path.join(output_dir, f'trend_report_{timestamp}.md')
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        report_content = f"""# è¶‹åŠ¿åˆ†ææŠ¥å‘Š

        ## ğŸ“Š åˆ†ææ¦‚è§ˆ
        - **åˆ†ææ—¶é—´**: {results.get('analysis_time', '')}
        - **åˆ†æç±»å‹**: {results.get('analysis_type', '')}
        - **æ€»è¯æ ¹æ•°**: {results.get('total_root_words', 0)}
        - **æˆåŠŸåˆ†æ**: {results.get('successful_analyses', 0)}
        
        ## ğŸ“ˆ ä¸Šå‡è¶‹åŠ¿è¯æ ¹
        """
        
        # æ·»åŠ ä¸Šå‡è¶‹åŠ¿è¯æ ¹
        top_trending = results.get('top_trending_words', [])
        if top_trending:
            for i, word in enumerate(top_trending[:10], 1):
                report_content += f"{i}. **{word.get('word', '')}**: å¹³å‡å…´è¶£åº¦ {word.get('average_interest', 0):.1f}\n"
        else:
            report_content += "æš‚æ— ä¸Šå‡è¶‹åŠ¿è¯æ ¹\n"
        
        # æ·»åŠ ä¸‹é™è¶‹åŠ¿è¯æ ¹
        declining_words = results.get('declining_words', [])
        if declining_words:
            report_content += f"\n## ğŸ“‰ ä¸‹é™è¶‹åŠ¿è¯æ ¹\n"
            for i, word in enumerate(declining_words[:5], 1):
                report_content += f"{i}. **{word.get('word', '')}**: å¹³å‡å…´è¶£åº¦ {word.get('average_interest', 0):.1f}\n"
        
        # æ·»åŠ å»ºè®®
        report_content += f"""
        ## ğŸ’¡ è¶‹åŠ¿å»ºè®®
        
        ### é‡ç‚¹å…³æ³¨
        - ä¼˜å…ˆå¼€å‘ä¸Šå‡è¶‹åŠ¿è¯æ ¹ç›¸å…³çš„AIå·¥å…·
        - å…³æ³¨æ–°å…´æŠ€æœ¯è¯æ ¹çš„å‘å±•æœºä¼š
        - å»ºç«‹è¶‹åŠ¿ç›‘æ§å’Œé¢„è­¦æœºåˆ¶
        
        ### å¸‚åœºæœºä¼š
        - åŸºäºçƒ­é—¨è¯æ ¹åˆ›å»ºäº§å“åŸå‹
        - ç»“åˆAIå‰ç¼€æ‰©å±•å…³é”®è¯ç»„åˆ
        - å…³æ³¨ç«äº‰åº¦è¾ƒä½çš„æ–°å…´è¯æ ¹
        
        ---
        *æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
        """
        
        # ä¿å­˜æŠ¥å‘Š
        os.makedirs(output_dir, exist_ok=True)
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“‹ è¶‹åŠ¿æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path
    
    def batch_trends_analysis(self, keywords: List[str], batch_size: int = 5) -> Dict[str, Any]:
        """
        æ‰¹é‡å…³é”®è¯è¶‹åŠ¿åˆ†æå’Œç¨³å®šæ€§è¯„ä¼°
        
        Args:
            keywords: è¦åˆ†æçš„å…³é”®è¯åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤5ä¸ªå…³é”®è¯ä¸€æ‰¹
            
        Returns:
            åŒ…å«è¶‹åŠ¿åˆ†æç»“æœå’Œç¨³å®šæ€§è¯„åˆ†çš„å­—å…¸
        """
        print(f"ğŸ” å¼€å§‹æ‰¹é‡è¶‹åŠ¿åˆ†æï¼Œå…³é”®è¯æ•°é‡: {len(keywords)}, æ‰¹å¤„ç†å¤§å°: {batch_size}")
        
        results = {
            'total_keywords': len(keywords),
            'batch_size': batch_size,
            'keyword_results': {},
            'summary': {
                'successful': 0,
                'failed': 0,
                'stability_scores': {}
            }
        }
        
        # åˆ†æ‰¹å¤„ç†å…³é”®è¯
        for i in range(0, len(keywords), batch_size):
            batch_keywords = keywords[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            print(f"ğŸ“Š å¤„ç†ç¬¬ {batch_num} æ‰¹å…³é”®è¯: {batch_keywords}")
            
            try:
                # ä½¿ç”¨ç°æœ‰çš„ RootWordTrendsAnalyzer è¿›è¡Œåˆ†æ
                batch_results = self._analyze_keyword_batch(batch_keywords)
                
                # åˆå¹¶æ‰¹æ¬¡ç»“æœ
                for keyword, result in batch_results.items():
                    results['keyword_results'][keyword] = result
                    
                    if result.get('success', False):
                        results['summary']['successful'] += 1
                        # è®¡ç®—ç¨³å®šæ€§è¯„åˆ†
                        stability_score = self._calculate_stability_score(result)
                        results['summary']['stability_scores'][keyword] = stability_score
                    else:
                        results['summary']['failed'] += 1
                        
            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡ {batch_num} å¤„ç†å¤±è´¥: {e}")
                for keyword in batch_keywords:
                    results['keyword_results'][keyword] = {
                        'success': False,
                        'error': str(e),
                        'keyword': keyword
                    }
                    results['summary']['failed'] += 1
        
        # ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
        results['summary']['success_rate'] = (
            results['summary']['successful'] / len(keywords) * 100 
            if len(keywords) > 0 else 0
        )
        
        print(f"âœ… æ‰¹é‡è¶‹åŠ¿åˆ†æå®Œæˆï¼ŒæˆåŠŸç‡: {results['summary']['success_rate']:.1f}%")
        return results
    
    def analyze_keyword_trends(self, keywords: List[str]) -> Dict[str, Any]:
        """
        åˆ†æä»»æ„å…³é”®è¯çš„è¶‹åŠ¿ï¼ˆæ‰©å±•æ”¯æŒéroot wordï¼‰
        
        Args:
            keywords: è¦åˆ†æçš„å…³é”®è¯åˆ—è¡¨
            
        Returns:
            è¶‹åŠ¿åˆ†æç»“æœ
        """
        print(f"ğŸ” åˆ†æå…³é”®è¯è¶‹åŠ¿: {keywords}")
        
        results = {}
        for keyword in keywords:
            try:
                # å¤ç”¨ç°æœ‰çš„è¶‹åŠ¿åˆ†æé€»è¾‘ï¼Œæ‰©å±•æ”¯æŒä»»æ„å…³é”®è¯
                trend_result = self.root_analyzer.analyze_single_root_word(keyword)
                
                if trend_result and trend_result.get('status') == 'success':
                    # å¤„ç†è¶‹åŠ¿æ•°æ®
                    results[keyword] = {
                        'success': True,
                        'keyword': keyword,
                        'trend_data': trend_result.get('data', {}),
                        'analysis_timestamp': trend_result.get('timestamp', datetime.now().isoformat())
                    }
                else:
                    results[keyword] = {
                        'success': False,
                        'keyword': keyword,
                        'error': trend_result.get('error', 'No trend data available')
                    }
                    
            except Exception as e:
                print(f"âŒ åˆ†æå…³é”®è¯ '{keyword}' è¶‹åŠ¿å¤±è´¥: {e}")
                results[keyword] = {
                    'success': False,
                    'keyword': keyword,
                    'error': str(e)
                }
        
        return results
    
    def _analyze_keyword_batch(self, keywords: List[str]) -> Dict[str, Any]:
        """åˆ†æä¸€æ‰¹å…³é”®è¯"""
        batch_results = {}
        
        for keyword in keywords:
            try:
                # ä½¿ç”¨ç°æœ‰åˆ†æå™¨è·å–è¶‹åŠ¿æ•°æ®
                trend_result = self.root_analyzer.analyze_single_root_word(keyword)
                
                if trend_result and trend_result.get('status') == 'success':
                    batch_results[keyword] = {
                        'success': True,
                        'keyword': keyword,
                        'trend_data': trend_result.get('data', {}),
                        'analysis_timestamp': trend_result.get('timestamp', datetime.now().isoformat())
                    }
                else:
                    batch_results[keyword] = {
                        'success': False,
                        'keyword': keyword,
                        'error': trend_result.get('error', 'No trend data available')
                    }
                    
            except Exception as e:
                print(f"âŒ åˆ†æå…³é”®è¯ '{keyword}' å¤±è´¥: {e}")
                batch_results[keyword] = {
                    'success': False,
                    'keyword': keyword,
                    'error': str(e)
                }
        
        return batch_results
    
    def _calculate_stability_score(self, result: Dict[str, Any]) -> float:
        """
        è®¡ç®—è¶‹åŠ¿ç¨³å®šæ€§è¯„åˆ†
        
        Args:
            result: è¶‹åŠ¿åˆ†æç»“æœ
            
        Returns:
            ç¨³å®šæ€§è¯„åˆ† (0-100)
        """
        try:
            trend_data = result.get('trend_data', {})
            
            if not trend_data:
                return 0.0
            
            # åŸºäºè¶‹åŠ¿æ–¹å‘å’Œå…´è¶£åº¦è®¡ç®—ç¨³å®šæ€§è¯„åˆ†
            trend_direction = trend_data.get('trend_direction', 'stable')
            average_interest = trend_data.get('average_interest', 0)
            peak_interest = trend_data.get('peak_interest', 0)
            related_queries_count = len(trend_data.get('related_queries', []))
            
            # åŸºç¡€åˆ†æ•°ï¼šåŸºäºå¹³å‡å…´è¶£åº¦
            base_score = min(average_interest * 2, 50)  # æœ€é«˜50åˆ†
            
            # è¶‹åŠ¿æ–¹å‘åŠ åˆ†
            direction_bonus = {
                'rising': 30,
                'stable': 20,
                'declining': 10
            }.get(trend_direction, 15)
            
            # æ•°æ®ä¸°å¯Œåº¦åŠ åˆ†
            data_richness_bonus = min(related_queries_count * 2, 20)  # æœ€é«˜20åˆ†
            
            total_score = base_score + direction_bonus + data_richness_bonus
            return min(total_score, 100.0)
            
        except Exception as e:
            print(f"âŒ è®¡ç®—ç¨³å®šæ€§è¯„åˆ†å¤±è´¥: {e}")
            return 0.0