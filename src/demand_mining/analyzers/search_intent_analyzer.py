#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æœç´¢æ„å›¾åˆ†æå™¨
åˆ†æå…³é”®è¯çš„æœç´¢æ„å›¾ï¼Œä¼˜å…ˆè¯†åˆ«é«˜è½¬åŒ–æ„å›¾çš„é•¿å°¾è¯
"""

from .base_analyzer import BaseAnalyzer
from typing import Dict, Any, List
import re

class SearchIntentAnalyzer(BaseAnalyzer):
    """æœç´¢æ„å›¾åˆ†æå™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æœç´¢æ„å›¾åˆ†æå™¨"""
        super().__init__()
        
        # å®šä¹‰ä¸åŒæ„å›¾çš„å…³é”®è¯æ¨¡å¼
        self.intent_patterns = {
            'informational': {
                'patterns': [
                    r'\b(what is|how to|tutorial|guide|learn|understand|explain)\b',
                    r'\b(definition|meaning|introduction|basics|fundamentals)\b'
                ],
                'score': 2.0,  # ä¿¡æ¯ç±»æ„å›¾ï¼Œé€‚åˆå†…å®¹è¥é”€
                'description': 'ä¿¡æ¯æœç´¢æ„å›¾'
            },
            'navigational': {
                'patterns': [
                    r'\b(login|sign in|download|official|website|homepage)\b',
                    r'\b(app store|google play|github|documentation)\b'
                ],
                'score': 1.5,  # å¯¼èˆªç±»æ„å›¾
                'description': 'å¯¼èˆªæœç´¢æ„å›¾'
            },
            'transactional': {
                'patterns': [
                    r'\b(buy|purchase|price|cost|free|trial|subscription)\b',
                    r'\b(discount|coupon|deal|offer|sale)\b'
                ],
                'score': 3.0,  # äº¤æ˜“ç±»æ„å›¾ï¼Œè½¬åŒ–ç‡æœ€é«˜
                'description': 'äº¤æ˜“æœç´¢æ„å›¾'
            },
            'commercial': {
                'patterns': [
                    r'\b(best|top|review|comparison|vs|alternative)\b',
                    r'\b(pros and cons|features|benefits|advantages)\b'
                ],
                'score': 2.5,  # å•†ä¸šè°ƒç ”æ„å›¾ï¼Œè½¬åŒ–ç‡è¾ƒé«˜
                'description': 'å•†ä¸šè°ƒç ”æ„å›¾'
            },
            'problem_solving': {
                'patterns': [
                    r'\b(fix|solve|troubleshoot|error|problem|issue)\b',
                    r'\b(not working|broken|help|support)\b'
                ],
                'score': 2.2,  # é—®é¢˜è§£å†³æ„å›¾ï¼Œæœ‰ä¸€å®šè½¬åŒ–ä»·å€¼
                'description': 'é—®é¢˜è§£å†³æ„å›¾'
            },
            'local': {
                'patterns': [
                    r'\b(near me|local|nearby|in [A-Z][a-z]+)\b',
                    r'\b(address|location|directions|map)\b'
                ],
                'score': 1.8,  # æœ¬åœ°æœç´¢æ„å›¾
                'description': 'æœ¬åœ°æœç´¢æ„å›¾'
            }
        }
        
        # é•¿å°¾è¯ç‰¹å¾æ¨¡å¼
        self.long_tail_indicators = [
            'step by step', 'for beginners', 'complete guide', 'detailed tutorial',
            'without coding', 'easy way', 'simple method', 'quick guide',
            'beginner friendly', 'getting started', 'from scratch'
        ]
    
    def analyze(self, data, **kwargs):
        """
        å®ç°åŸºç¡€åˆ†æå™¨çš„æŠ½è±¡æ–¹æ³•
        
        Args:
            data: å…³é”®è¯æ•°æ®
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            åˆ†æç»“æœ
        """
        if isinstance(data, list):
            return self.analyze_keywords_intent(data)
        elif hasattr(data, 'iterrows'):  # DataFrame
            keywords = data['query'].tolist() if 'query' in data.columns else data.iloc[:, 0].tolist()
            return self.analyze_keywords_intent(keywords)
        elif isinstance(data, dict):
            if 'query' in data:
                keywords = [data['query']] if isinstance(data['query'], str) else data['query']
            elif 'keyword' in data:
                keywords = [data['keyword']] if isinstance(data['keyword'], str) else data['keyword']
            else:
                keywords = list(data.values())[:1] if data else []
            return self.analyze_keywords_intent(keywords)
        else:
            return {}
    
    def analyze_keywords_intent(self, keywords: List[str]) -> Dict[str, Any]:
        """
        åˆ†æå…³é”®è¯åˆ—è¡¨çš„æœç´¢æ„å›¾
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            
        Returns:
            æ„å›¾åˆ†æç»“æœå­—å…¸
        """
        results = {}
        
        for keyword in keywords:
            intent_analysis = self.analyze_single_keyword_intent(keyword)
            results[keyword] = intent_analysis
        
        # ç”Ÿæˆæ•´ä½“ç»Ÿè®¡
        intent_distribution = {}
        total_score = 0
        long_tail_count = 0
        
        for keyword, analysis in results.items():
            primary_intent = analysis['primary_intent']
            if primary_intent not in intent_distribution:
                intent_distribution[primary_intent] = 0
            intent_distribution[primary_intent] += 1
            
            total_score += analysis['intent_score']
            if analysis['is_long_tail']:
                long_tail_count += 1
        
        # æ·»åŠ æ•´ä½“ç»Ÿè®¡ä¿¡æ¯
        results['_summary'] = {
            'total_keywords': len(keywords),
            'intent_distribution': intent_distribution,
            'average_intent_score': total_score / len(keywords) if keywords else 0,
            'long_tail_percentage': (long_tail_count / len(keywords) * 100) if keywords else 0,
            'high_value_keywords': [
                kw for kw, analysis in results.items() 
                if isinstance(analysis, dict) and analysis.get('intent_score', 0) >= 2.5
            ]
        }
        
        return results
    
    def analyze_single_keyword_intent(self, keyword: str) -> Dict[str, Any]:
        """
        åˆ†æå•ä¸ªå…³é”®è¯çš„æœç´¢æ„å›¾
        
        Args:
            keyword: å…³é”®è¯
            
        Returns:
            æ„å›¾åˆ†æç»“æœ
        """
        keyword_lower = keyword.lower()
        word_count = len(keyword.split())
        
        # æ£€æµ‹å„ç§æ„å›¾
        detected_intents = []
        max_score = 0
        primary_intent = 'general'
        
        for intent_type, intent_config in self.intent_patterns.items():
            for pattern in intent_config['patterns']:
                if re.search(pattern, keyword_lower, re.IGNORECASE):
                    detected_intents.append(intent_type)
                    if intent_config['score'] > max_score:
                        max_score = intent_config['score']
                        primary_intent = intent_type
                    break
        
        # æ£€æµ‹é•¿å°¾è¯ç‰¹å¾
        is_long_tail = word_count >= 3 and len(keyword) >= 15
        has_long_tail_indicators = any(
            indicator in keyword_lower for indicator in self.long_tail_indicators
        )
        
        # è®¡ç®—ç»¼åˆæ„å›¾è¯„åˆ†
        intent_score = max_score
        
        # é•¿å°¾è¯åŠ æƒ
        if is_long_tail:
            intent_score *= 1.3
        if has_long_tail_indicators:
            intent_score *= 1.2
        
        # åŸºäºè¯æ•°çš„é¢å¤–åŠ æƒ
        if word_count >= 5:
            intent_score *= 1.4
        elif word_count >= 4:
            intent_score *= 1.2
        
        return {
            'primary_intent': primary_intent,
            'detected_intents': list(set(detected_intents)),
            'intent_score': round(intent_score, 2),
            'is_long_tail': is_long_tail,
            'has_long_tail_indicators': has_long_tail_indicators,
            'word_count': word_count,
            'intent_description': self.intent_patterns.get(primary_intent, {}).get('description', 'é€šç”¨æ„å›¾'),
            'conversion_potential': self._assess_conversion_potential(intent_score, is_long_tail, primary_intent)
        }
    
    def _assess_conversion_potential(self, intent_score: float, is_long_tail: bool, primary_intent: str) -> str:
        """
        è¯„ä¼°è½¬åŒ–æ½œåŠ›
        
        Args:
            intent_score: æ„å›¾è¯„åˆ†
            is_long_tail: æ˜¯å¦ä¸ºé•¿å°¾è¯
            primary_intent: ä¸»è¦æ„å›¾
            
        Returns:
            è½¬åŒ–æ½œåŠ›ç­‰çº§
        """
        # åŸºç¡€è½¬åŒ–æ½œåŠ›è¯„ä¼°
        if primary_intent == 'transactional':
            base_potential = 'high'
        elif primary_intent in ['commercial', 'problem_solving']:
            base_potential = 'medium_high'
        elif primary_intent == 'informational':
            base_potential = 'medium'
        else:
            base_potential = 'low'
        
        # é•¿å°¾è¯æå‡è½¬åŒ–æ½œåŠ›
        if is_long_tail and base_potential in ['medium', 'medium_high']:
            if base_potential == 'medium':
                return 'medium_high'
            else:
                return 'high'
        
        # é«˜æ„å›¾è¯„åˆ†æå‡è½¬åŒ–æ½œåŠ›
        if intent_score >= 3.0:
            return 'very_high'
        elif intent_score >= 2.5:
            return 'high' if base_potential != 'low' else 'medium_high'
        
        return base_potential
    
    def get_high_value_keywords(self, analysis_results: Dict[str, Any], min_score: float = 2.5) -> List[Dict[str, Any]]:
        """
        è·å–é«˜ä»·å€¼å…³é”®è¯
        
        Args:
            analysis_results: åˆ†æç»“æœ
            min_score: æœ€å°æ„å›¾è¯„åˆ†
            
        Returns:
            é«˜ä»·å€¼å…³é”®è¯åˆ—è¡¨
        """
        high_value_keywords = []
        
        for keyword, analysis in analysis_results.items():
            if isinstance(analysis, dict) and analysis.get('intent_score', 0) >= min_score:
                high_value_keywords.append({
                    'keyword': keyword,
                    'intent_score': analysis['intent_score'],
                    'primary_intent': analysis['primary_intent'],
                    'conversion_potential': analysis['conversion_potential'],
                    'is_long_tail': analysis['is_long_tail']
                })
        
        # æŒ‰æ„å›¾è¯„åˆ†æ’åº
        high_value_keywords.sort(key=lambda x: x['intent_score'], reverse=True)
        
        return high_value_keywords


def main():
    """æµ‹è¯•æœç´¢æ„å›¾åˆ†æå™¨"""
    analyzer = SearchIntentAnalyzer()
    
    print("ğŸš€ æœç´¢æ„å›¾åˆ†æå™¨æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•å…³é”®è¯
    test_keywords = [
        'ai image generator',
        'how to use chatgpt for writing',
        'best free ai tools for small business',
        'step by step guide to machine learning',
        'buy premium ai software',
        'chatgpt vs google bard comparison',
        'troubleshooting ai model errors'
    ]
    
    # åˆ†ææ„å›¾
    results = analyzer.analyze_keywords_intent(test_keywords)
    
    print("ğŸ“Š æ„å›¾åˆ†æç»“æœ:")
    for keyword, analysis in results.items():
        if keyword != '_summary':
            print(f"\nğŸ” å…³é”®è¯: {keyword}")
            print(f"  ä¸»è¦æ„å›¾: {analysis['primary_intent']} ({analysis['intent_description']})")
            print(f"  æ„å›¾è¯„åˆ†: {analysis['intent_score']}")
            print(f"  è½¬åŒ–æ½œåŠ›: {analysis['conversion_potential']}")
            print(f"  é•¿å°¾è¯: {'æ˜¯' if analysis['is_long_tail'] else 'å¦'}")
    
    # æ˜¾ç¤ºæ‘˜è¦
    summary = results['_summary']
    print(f"\nğŸ“ˆ æ•´ä½“ç»Ÿè®¡:")
    print(f"  æ€»å…³é”®è¯æ•°: {summary['total_keywords']}")
    print(f"  å¹³å‡æ„å›¾è¯„åˆ†: {summary['average_intent_score']:.2f}")
    print(f"  é•¿å°¾è¯æ¯”ä¾‹: {summary['long_tail_percentage']:.1f}%")
    print(f"  é«˜ä»·å€¼å…³é”®è¯æ•°: {len(summary['high_value_keywords'])}")
    
    # è·å–é«˜ä»·å€¼å…³é”®è¯
    high_value = analyzer.get_high_value_keywords(results, min_score=2.0)
    print(f"\nğŸ† é«˜ä»·å€¼å…³é”®è¯ (è¯„åˆ†â‰¥2.0):")
    for i, kw_data in enumerate(high_value[:5], 1):
        print(f"  {i}. {kw_data['keyword']} (è¯„åˆ†: {kw_data['intent_score']}, æ½œåŠ›: {kw_data['conversion_potential']})")
    
    print(f"\nâœ… æœç´¢æ„å›¾åˆ†æå™¨æµ‹è¯•å®Œæˆ!")


if __name__ == '__main__':
    main()