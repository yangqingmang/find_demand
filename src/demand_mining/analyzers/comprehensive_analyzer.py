#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»¼åˆå…³é”®è¯åˆ†æå™¨ - æ•´åˆæ‰€æœ‰åˆ†æå™¨çš„ç»“æœ
"""

import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Any
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, project_root)

from .base_analyzer import BaseAnalyzer
from .intent_analyzer_v2 import IntentAnalyzerV2
from .market_analyzer import MarketAnalyzer
from .keyword_analyzer import KeywordAnalyzer
from .keyword_scorer import KeywordScorer
from .competitor_analyzer import CompetitorAnalyzer
from .timeliness_analyzer import TimelinessAnalyzer
from .website_recommendation import WebsiteRecommendationEngine
from .new_word_detector import NewWordDetector

try:
    from src.utils import Logger, FileUtils
except ImportError:
    class Logger:
        def info(self, msg): print(f"INFO: {msg}")
        def warning(self, msg): print(f"WARNING: {msg}")
        def error(self, msg): print(f"ERROR: {msg}")


class ComprehensiveAnalyzer(BaseAnalyzer):
    """ç»¼åˆå…³é”®è¯åˆ†æå™¨ï¼Œæ•´åˆæ‰€æœ‰åˆ†æå™¨çš„ç»“æœ"""
    
    def __init__(self):
        super().__init__()
        self.logger = Logger()
        
        # åˆå§‹åŒ–æ‰€æœ‰åˆ†æå™¨
        self._init_analyzers()
        
        # åˆ†æå™¨æƒé‡é…ç½®
        self.analyzer_weights = {
            'intent': 0.20,
            'market': 0.20,
            'keyword': 0.15,
            'scorer': 0.15,
            'timeliness': 0.15,
            'competitor': 0.10,
            'website': 0.05
        }
        
        print("ğŸ”§ ç»¼åˆåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_analyzers(self):
        """åˆå§‹åŒ–æ‰€æœ‰åˆ†æå™¨"""
        try:
            self.intent_analyzer = IntentAnalyzerV2()
            self.market_analyzer = MarketAnalyzer()
            self.keyword_analyzer = KeywordAnalyzer()
            self.keyword_scorer = KeywordScorer()
            self.competitor_analyzer = CompetitorAnalyzer()
            self.timeliness_analyzer = TimelinessAnalyzer()
            self.website_analyzer = WebsiteRecommendationEngine()
            self.new_word_detector = NewWordDetector()
            
            self.logger.info("æ‰€æœ‰åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            # è®¾ç½®ä¸ºNoneï¼Œåç»­ä¼šè·³è¿‡å¤±è´¥çš„åˆ†æå™¨
            self.intent_analyzer = None
            self.market_analyzer = None
            self.keyword_analyzer = None
            self.keyword_scorer = None
            self.competitor_analyzer = None
            self.timeliness_analyzer = None
            self.website_analyzer = None
            self.new_word_detector = None
    
    def analyze(self, data, **kwargs):
        """
        ç»¼åˆåˆ†æå…³é”®è¯æ•°æ®
        
        Args:
            data: å…³é”®è¯æ•°æ® (DataFrame æˆ– List)
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç»¼åˆåˆ†æç»“æœ
        """
        # æ•°æ®é¢„å¤„ç†
        if isinstance(data, list):
            df = pd.DataFrame({'query': data})
        elif isinstance(data, pd.DataFrame):
            df = data.copy()
        else:
            raise ValueError("æ•°æ®æ ¼å¼ä¸æ”¯æŒï¼Œè¯·ä½¿ç”¨DataFrameæˆ–List")
        
        # ç¡®ä¿æœ‰queryåˆ—
        if 'query' not in df.columns:
            if 'keyword' in df.columns:
                df['query'] = df['keyword']
            elif 'term' in df.columns:
                df['query'] = df['term']
            else:
                raise ValueError("æœªæ‰¾åˆ°å…³é”®è¯åˆ—")
        
        self.logger.info(f"å¼€å§‹ç»¼åˆåˆ†æ {len(df)} ä¸ªå…³é”®è¯")
        
        # æ‰§è¡Œå„ä¸ªåˆ†æå™¨
        result_df = self._run_all_analyzers(df)
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        result_df = self._calculate_comprehensive_score(result_df)
        
        # ç”Ÿæˆåˆ†ææ‘˜è¦
        summary = self._generate_comprehensive_summary(result_df)
        
        return {
            'results': result_df,
            'summary': summary,
            'analysis_time': datetime.now().isoformat(),
            'total_keywords': len(result_df)
        }
    
    def _run_all_analyzers(self, df: pd.DataFrame) -> pd.DataFrame:
        """è¿è¡Œæ‰€æœ‰åˆ†æå™¨"""
        result_df = df.copy()
        
        # 1. æ„å›¾åˆ†æ
        if self.intent_analyzer:
            try:
                self.logger.info("ğŸ¯ æ‰§è¡Œæ„å›¾åˆ†æ...")
                intent_result = self.intent_analyzer.analyze_keywords(result_df)
                result_df = self._merge_results(result_df, intent_result, 'intent_')
            except Exception as e:
                self.logger.error(f"æ„å›¾åˆ†æå¤±è´¥: {e}")
        
        # 2. å¸‚åœºåˆ†æ
        if self.market_analyzer:
            try:
                self.logger.info("ğŸ“Š æ‰§è¡Œå¸‚åœºåˆ†æ...")
                market_result = self.market_analyzer.analyze(result_df)
                result_df = self._merge_results(result_df, market_result, 'market_')
            except Exception as e:
                self.logger.error(f"å¸‚åœºåˆ†æå¤±è´¥: {e}")
        
        # 3. å…³é”®è¯åˆ†æ
        if self.keyword_analyzer:
            try:
                self.logger.info("ğŸ” æ‰§è¡Œå…³é”®è¯åˆ†æ...")
                keyword_result = self.keyword_analyzer.analyze(result_df)
                result_df = self._merge_results(result_df, keyword_result, 'keyword_')
            except Exception as e:
                self.logger.error(f"å…³é”®è¯åˆ†æå¤±è´¥: {e}")
        
        # 4. å…³é”®è¯è¯„åˆ†
        if self.keyword_scorer:
            try:
                self.logger.info("â­ æ‰§è¡Œå…³é”®è¯è¯„åˆ†...")
                keywords = result_df['query'].tolist()
                scores = self.keyword_scorer.score_keywords(keywords)
                score_df = pd.DataFrame([
                    {
                        'query': score.keyword,
                        'scorer_pray_score': score.pray_score,
                        'scorer_commercial_score': score.commercial_score,
                        'scorer_trend_score': score.trend_score,
                        'scorer_competition_score': score.competition_score,
                        'scorer_total_score': score.total_score
                    }
                    for score in scores
                ])
                result_df = result_df.merge(score_df, on='query', how='left')
            except Exception as e:
                self.logger.error(f"å…³é”®è¯è¯„åˆ†å¤±è´¥: {e}")
        
        # 5. æ—¶æ•ˆæ€§åˆ†æ
        if self.timeliness_analyzer:
            try:
                self.logger.info("â° æ‰§è¡Œæ—¶æ•ˆæ€§åˆ†æ...")
                timeliness_result = self.timeliness_analyzer.analyze_timeliness(result_df)
                result_df = self._merge_results(result_df, timeliness_result, 'timeliness_')
            except Exception as e:
                self.logger.error(f"æ—¶æ•ˆæ€§åˆ†æå¤±è´¥: {e}")
        
        # 6. ç«äº‰å¯¹æ‰‹åˆ†æ
        if self.competitor_analyzer:
            try:
                self.logger.info("ğŸ† æ‰§è¡Œç«äº‰å¯¹æ‰‹åˆ†æ...")
                competitor_result = self.competitor_analyzer.analyze(result_df)
                result_df = self._merge_results(result_df, competitor_result, 'competitor_')
            except Exception as e:
                self.logger.error(f"ç«äº‰å¯¹æ‰‹åˆ†æå¤±è´¥: {e}")
        
        # 7. ç½‘ç«™å»ºè®®åˆ†æ
        if self.website_analyzer:
            try:
                self.logger.info("ğŸŒ æ‰§è¡Œç½‘ç«™å»ºè®®åˆ†æ...")
                website_result = self.website_analyzer.analyze(result_df)
                result_df = self._merge_results(result_df, website_result, 'website_')
            except Exception as e:
                self.logger.error(f"ç½‘ç«™å»ºè®®åˆ†æå¤±è´¥: {e}")
        
        # 8. æ–°è¯æ£€æµ‹
        if self.new_word_detector:
            try:
                self.logger.info("ğŸ†• æ‰§è¡Œæ–°è¯æ£€æµ‹...")
                new_word_result = self.new_word_detector.detect_new_words(result_df)
                result_df = self._merge_results(result_df, new_word_result, 'newword_')
            except Exception as e:
                self.logger.error(f"æ–°è¯æ£€æµ‹å¤±è´¥: {e}")
        
        return result_df
    
    def _merge_results(self, main_df: pd.DataFrame, result_df: pd.DataFrame, prefix: str) -> pd.DataFrame:
        """åˆå¹¶åˆ†æç»“æœ"""
        if result_df is None or result_df.empty:
            return main_df
        
        # é‡å‘½ååˆ—ä»¥é¿å…å†²çª
        rename_dict = {}
        for col in result_df.columns:
            if col != 'query' and not col.startswith(prefix):
                rename_dict[col] = f"{prefix}{col}"
        
        if rename_dict:
            result_df = result_df.rename(columns=rename_dict)
        
        # åˆå¹¶æ•°æ®
        return main_df.merge(result_df, on='query', how='left')
    
    def _calculate_comprehensive_score(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        self.logger.info("ğŸ§® è®¡ç®—ç»¼åˆè¯„åˆ†...")
        
        # æ”¶é›†å„åˆ†æå™¨çš„ä¸»è¦è¯„åˆ†
        scores = {}
        
        # æ„å›¾åˆ†æè¯„åˆ†
        if 'intent_confidence' in df.columns:
            scores['intent'] = df['intent_confidence'].fillna(0) * 100
        
        # å¸‚åœºåˆ†æè¯„åˆ† (åŸºäºæœç´¢é‡å’Œç«äº‰åº¦)
        if 'market_search_volume' in df.columns and 'market_competition' in df.columns:
            volume_score = np.log1p(df['market_search_volume'].fillna(0)) * 10
            competition_score = (1 - df['market_competition'].fillna(0.5)) * 100
            scores['market'] = (volume_score + competition_score) / 2
        
        # å…³é”®è¯åˆ†æè¯„åˆ†
        if 'keyword_difficulty' in df.columns:
            scores['keyword'] = (1 - df['keyword_difficulty'].fillna(0.5)) * 100
        
        # è¯„åˆ†å™¨æ€»åˆ†
        if 'scorer_total_score' in df.columns:
            scores['scorer'] = df['scorer_total_score'].fillna(50)
        
        # æ—¶æ•ˆæ€§è¯„åˆ†
        if 'timeliness_score' in df.columns:
            scores['timeliness'] = df['timeliness_score'].fillna(50)
        
        # ç«äº‰å¯¹æ‰‹åˆ†æè¯„åˆ†
        if 'competitor_opportunity_score' in df.columns:
            scores['competitor'] = df['competitor_opportunity_score'].fillna(50)
        
        # ç½‘ç«™å»ºè®®è¯„åˆ†
        if 'website_feasibility_score' in df.columns:
            scores['website'] = df['website_feasibility_score'].fillna(50)
        
        # è®¡ç®—åŠ æƒç»¼åˆè¯„åˆ†
        comprehensive_score = np.zeros(len(df))
        total_weight = 0
        
        for analyzer, score_series in scores.items():
            weight = self.analyzer_weights.get(analyzer, 0)
            if weight > 0:
                comprehensive_score += score_series * weight
                total_weight += weight
        
        # å½’ä¸€åŒ–è¯„åˆ†
        if total_weight > 0:
            comprehensive_score = comprehensive_score / total_weight
        else:
            comprehensive_score = np.full(len(df), 50.0)
        
        df['comprehensive_score'] = np.round(comprehensive_score, 2)
        
        # è®¡ç®—ç»¼åˆç­‰çº§
        df['comprehensive_grade'] = df['comprehensive_score'].apply(self._get_grade)
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        df = df.sort_values('comprehensive_score', ascending=False).reset_index(drop=True)
        
        return df
    
    def _get_grade(self, score: float) -> str:
        """æ ¹æ®è¯„åˆ†è·å–ç­‰çº§"""
        if score >= 90:
            return 'A+'
        elif score >= 80:
            return 'A'
        elif score >= 70:
            return 'B+'
        elif score >= 60:
            return 'B'
        elif score >= 50:
            return 'C'
        elif score >= 40:
            return 'D'
        else:
            return 'F'
    
    def _generate_comprehensive_summary(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆåˆ†ææ‘˜è¦"""
        summary = {
            'total_keywords': len(df),
            'average_comprehensive_score': round(df['comprehensive_score'].mean(), 2),
            'grade_distribution': df['comprehensive_grade'].value_counts().to_dict(),
            'top_10_keywords': df.head(10)[['query', 'comprehensive_score', 'comprehensive_grade']].to_dict('records'),
            'analyzer_coverage': {},
            'key_insights': []
        }
        
        # åˆ†æå™¨è¦†ç›–æƒ…å†µ
        analyzer_columns = {
            'intent': 'intent_confidence',
            'market': 'market_search_volume',
            'keyword': 'keyword_difficulty',
            'scorer': 'scorer_total_score',
            'timeliness': 'timeliness_score',
            'competitor': 'competitor_opportunity_score',
            'website': 'website_feasibility_score'
        }
        
        for analyzer, col in analyzer_columns.items():
            if col in df.columns:
                coverage = df[col].notna().sum()
                summary['analyzer_coverage'][analyzer] = {
                    'covered': coverage,
                    'percentage': round(coverage / len(df) * 100, 1)
                }
        
        # å…³é”®æ´å¯Ÿ
        high_score_count = len(df[df['comprehensive_score'] >= 80])
        if high_score_count > 0:
            summary['key_insights'].append(f"å‘ç° {high_score_count} ä¸ªé«˜ä»·å€¼å…³é”®è¯ (è¯„åˆ†â‰¥80)")
        
        if 'intent_intent' in df.columns:
            top_intent = df['intent_intent'].value_counts().index[0] if not df['intent_intent'].isna().all() else 'Unknown'
            summary['key_insights'].append(f"ä¸»è¦æ„å›¾ç±»å‹: {top_intent}")
        
        if 'timeliness_grade' in df.columns:
            high_timeliness = len(df[df['timeliness_grade'].isin(['A', 'B'])])
            if high_timeliness > 0:
                summary['key_insights'].append(f"{high_timeliness} ä¸ªå…³é”®è¯å…·æœ‰é«˜æ—¶æ•ˆæ€§")
        
        return summary
    
    def export_comprehensive_report(self, analysis_result: Dict, output_dir: str = 'output') -> str:
        """å¯¼å‡ºç»¼åˆåˆ†ææŠ¥å‘Š"""
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = os.path.join(output_dir, f'comprehensive_analysis_{timestamp}.csv')
        analysis_result['results'].to_csv(results_file, index=False, encoding='utf-8-sig')
        
        # ä¿å­˜æ‘˜è¦
        summary_file = os.path.join(output_dir, f'comprehensive_summary_{timestamp}.json')
        import json
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_result['summary'], f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆå¯è¯»æ€§æŠ¥å‘Š
        report_file = os.path.join(output_dir, f'comprehensive_report_{timestamp}.md')
        self._generate_markdown_report(analysis_result, report_file)
        
        self.logger.info(f"ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_dir}")
        return results_file
    
    def _generate_markdown_report(self, analysis_result: Dict, file_path: str):
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        df = analysis_result['results']
        summary = analysis_result['summary']
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("# å…³é”®è¯ç»¼åˆåˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**åˆ†ææ—¶é—´**: {analysis_result['analysis_time']}\n")
            f.write(f"**å…³é”®è¯æ€»æ•°**: {summary['total_keywords']}\n")
            f.write(f"**å¹³å‡ç»¼åˆè¯„åˆ†**: {summary['average_comprehensive_score']}\n\n")
            
            # ç­‰çº§åˆ†å¸ƒ
            f.write("## è¯„åˆ†ç­‰çº§åˆ†å¸ƒ\n\n")
            for grade, count in summary['grade_distribution'].items():
                percentage = round(count / summary['total_keywords'] * 100, 1)
                f.write(f"- **{grade}çº§**: {count} ä¸ª ({percentage}%)\n")
            
            # Top 10å…³é”®è¯
            f.write("\n## Top 10 å…³é”®è¯\n\n")
            f.write("| æ’å | å…³é”®è¯ | ç»¼åˆè¯„åˆ† | ç­‰çº§ |\n")
            f.write("|------|--------|----------|------|\n")
            for i, kw in enumerate(summary['top_10_keywords'], 1):
                f.write(f"| {i} | {kw['query']} | {kw['comprehensive_score']} | {kw['comprehensive_grade']} |\n")
            
            # åˆ†æå™¨è¦†ç›–æƒ…å†µ
            f.write("\n## åˆ†æå™¨è¦†ç›–æƒ…å†µ\n\n")
            for analyzer, coverage in summary['analyzer_coverage'].items():
                f.write(f"- **{analyzer}**: {coverage['covered']}/{summary['total_keywords']} ({coverage['percentage']}%)\n")
            
            # å…³é”®æ´å¯Ÿ
            f.write("\n## å…³é”®æ´å¯Ÿ\n\n")
            for insight in summary['key_insights']:
                f.write(f"- {insight}\n")