#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è¯æ ¹æ¯è¯ç®¡ç†å™¨
æ•´åˆç½‘ç»œæ”¶é›†çš„51ä¸ªé«˜ä»·å€¼è¯æ ¹ä¸Žå…³é”®è¯æŒ–æŽ˜ç³»ç»Ÿ
æ”¯æŒé»˜è®¤é…ç½®å’Œæ‰‹åŠ¨æŒ‡å®šæ¯è¯
"""

import os
import json
import yaml
from typing import Dict, List, Set, Optional, Any
from datetime import datetime


class RootWordManager:
    """
    è¯æ ¹æ¯è¯ç®¡ç†å™¨
    ç®¡ç†AIå·¥å…·ç›¸å…³çš„æ ¸å¿ƒè¯æ ¹ï¼Œæ”¯æŒåŠ¨æ€é…ç½®å’Œæ‰‹åŠ¨æŒ‡å®š
    """
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–è¯æ ¹ç®¡ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.config = self._load_config()
        
        # åŠ è½½51ä¸ªæ ¸å¿ƒè¯æ ¹ï¼ˆæ¥è‡ªç½‘ç»œæ”¶é›†ï¼‰
        self.core_roots = self._get_core_roots()
        
        # AIå·¥å…·ç›¸å…³å‰ç¼€
        self.ai_prefixes = self._get_ai_prefixes()
        
        # å·¥å…·ç±»åž‹åˆ†ç±»
        self.tool_categories = self._get_tool_categories()
        
        # ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®šçš„æ¯è¯
        self.manual_roots = set()
        
        print(f"ðŸŽ¯ è¯æ ¹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ðŸ“Š å·²åŠ è½½ {len(self.core_roots)} ä¸ªæ ¸å¿ƒè¯æ ¹")
        print(f"ðŸ¤– å·²é…ç½® {len(self.ai_prefixes)} ä¸ªAIå‰ç¼€")
        print(f"ðŸ·ï¸ å·²åˆ†ç±» {len(self.tool_categories)} ä¸ªå·¥å…·ç±»åž‹")
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            'use_all_roots': True,
            'priority_roots': [],
            'excluded_roots': [],
            'ai_focus': True,
            'include_variations': True,
            'max_combinations': 1000
        }
        
        if self.config_path and os.path.exists(self.config_path):
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    if self.config_path.endswith('.json'):
                        user_config = json.load(f)
                    else:
                        user_config = yaml.safe_load(f)
                    default_config.update(user_config)
            except Exception as e:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        
        return default_config
    
    def _get_core_roots(self) -> List[str]:
        """
        èŽ·å–æ ¸å¿ƒè¯æ ¹
        æ•´åˆåŽŸæœ‰è¯æ ¹ + 51è¯æ ¹æ–‡ä»¶ä¸­çš„é«˜ä»·å€¼è¯æ ¹
        """
        return [
            # ç”Ÿæˆç±» (Generator)
            'generator', 'maker', 'creator', 'builder', 'producer',
            
            # è½¬æ¢ç±» (Converter) 
            'converter', 'transformer', 'translator', 'transcriber',
            
            # ç¼–è¾‘ç±» (Editor)
            'editor', 'modifier', 'enhancer', 'optimizer', 'improver',
            
            # åˆ†æžç±» (Analyzer)
            'analyzer', 'detector', 'scanner', 'checker', 'validator',
            'tester', 'inspector', 'examiner', 'evaluator', 'verifier',
            'comparator',
            
            # å¤„ç†ç±» (Processor)
            'processor', 'compressor', 'resizer', 'cropper', 'splitter',
            'merger', 'combiner', 'joiner', 'interpreter',
            
            # æå–ç±» (Extractor)
            'extractor', 'parser', 'scraper', 'harvester', 'collector',
            'cataloger',
            
            # ç®¡ç†ç±» (Manager)
            'manager', 'organizer', 'sorter', 'scheduler', 'planner',
            'tracker', 'monitor', 'dashboard',
            
            # è®¡ç®—ç±» (Calculator)
            'calculator', 'counter', 'estimator', 'predictor', 'simulator',
            
            # æœç´¢ç±» (Finder)
            'finder', 'searcher', 'explorer', 'browser', 'locator',
            'navigator',
            
            # ä¼ è¾“ç±» (Transfer)
            'downloader', 'uploader', 'exporter', 'importer', 'syncer',
            
            # æ¸…ç†ç±» (Cleaner)
            'cleaner', 'remover', 'eraser', 'deleter', 'purifier',
            
            # å±•ç¤ºç±» (Viewer) - æ–°å¢žç±»åˆ«
            'viewer', 'recorder', 'template', 'sample',
            
            # äº¤äº’ç±» (Interactive) - æ–°å¢žç±»åˆ«  
            'assistant', 'notifier', 'responder'
        ]
    
    def _get_ai_prefixes(self) -> List[str]:
        """èŽ·å–AIç›¸å…³å‰ç¼€"""
        return [
            'ai', 'artificial intelligence', 'machine learning', 'ml',
            'deep learning', 'neural', 'smart', 'intelligent', 'automated',
            'auto', 'gpt', 'chatgpt', 'openai', 'claude'
        ]
    
    def _get_tool_categories(self) -> Dict[str, List[str]]:
        """
        èŽ·å–å·¥å…·ç±»åž‹åˆ†ç±»
        æŒ‰ç…§åº”ç”¨åœºæ™¯å’ŒåŠŸèƒ½åˆ†ç±» (å·²æ•´åˆ51è¯æ ¹)
        """
        return {
            'content_creation': [
                'generator', 'maker', 'creator', 'builder', 'writer',
                'designer', 'composer', 'producer', 'template', 'sample'
            ],
            'data_processing': [
                'converter', 'transformer', 'processor', 'analyzer',
                'parser', 'extractor', 'compressor', 'interpreter', 'cataloger'
            ],
            'media_editing': [
                'editor', 'enhancer', 'optimizer', 'resizer', 'cropper',
                'filter', 'modifier', 'improver', 'recorder'
            ],
            'quality_assurance': [
                'checker', 'validator', 'tester', 'detector', 'scanner',
                'inspector', 'examiner', 'verifier', 'evaluator', 'comparator'
            ],
            'productivity': [
                'manager', 'organizer', 'scheduler', 'planner', 'tracker',
                'monitor', 'calculator', 'counter', 'dashboard', 'assistant'
            ],
            'search_discovery': [
                'finder', 'searcher', 'explorer', 'browser', 'locator',
                'discoverer', 'hunter', 'navigator'
            ],
            'file_management': [
                'downloader', 'uploader', 'exporter', 'importer', 'syncer',
                'backup', 'archiver', 'migrator', 'viewer'
            ],
            'maintenance': [
                'cleaner', 'remover', 'eraser', 'deleter', 'purifier',
                'optimizer', 'fixer', 'repairer'
            ],
            'communication': [  # æ–°å¢žç±»åˆ«
                'notifier', 'responder', 'assistant'
            ]
        }
    
    def set_manual_roots(self, roots: List[str]) -> None:
        """
        æ‰‹åŠ¨æŒ‡å®šæ¯è¯
        
        Args:
            roots: æ‰‹åŠ¨æŒ‡å®šçš„è¯æ ¹åˆ—è¡¨
        """
        self.manual_roots = set(roots)
        print(f"âœ… å·²æ‰‹åŠ¨æŒ‡å®š {len(roots)} ä¸ªæ¯è¯: {', '.join(roots[:5])}{'...' if len(roots) > 5 else ''}")
    
    def get_active_roots(self) -> List[str]:
        """
        èŽ·å–å½“å‰æ¿€æ´»çš„è¯æ ¹
        ä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨æŒ‡å®šçš„æ¯è¯ï¼Œå¦åˆ™ä½¿ç”¨é…ç½®çš„é»˜è®¤æ¯è¯
        
        Returns:
            å½“å‰æ¿€æ´»çš„è¯æ ¹åˆ—è¡¨
        """
        # å¦‚æžœæœ‰æ‰‹åŠ¨æŒ‡å®šçš„æ¯è¯ï¼Œä¼˜å…ˆä½¿ç”¨
        if self.manual_roots:
            return list(self.manual_roots)
        
        # å¦åˆ™ä½¿ç”¨é…ç½®çš„é»˜è®¤æ¯è¯
        active_roots = self.core_roots.copy()
        
        # åº”ç”¨é…ç½®è¿‡æ»¤
        if self.config.get('priority_roots'):
            # å¦‚æžœæœ‰ä¼˜å…ˆè¯æ ¹ï¼Œåªä½¿ç”¨ä¼˜å…ˆè¯æ ¹
            priority_set = set(self.config['priority_roots'])
            active_roots = [root for root in active_roots if root in priority_set]
        
        if self.config.get('excluded_roots'):
            # æŽ’é™¤æŒ‡å®šçš„è¯æ ¹
            excluded_set = set(self.config['excluded_roots'])
            active_roots = [root for root in active_roots if root not in excluded_set]
        
        return active_roots
    
    def generate_keyword_combinations(self, 
                                    seed_words: List[str], 
                                    include_ai: bool = True,
                                    max_combinations: int = None) -> List[str]:
        """
        ç”Ÿæˆå…³é”®è¯ç»„åˆ
        
        Args:
            seed_words: ç§å­è¯åˆ—è¡¨
            include_ai: æ˜¯å¦åŒ…å«AIå‰ç¼€
            max_combinations: æœ€å¤§ç»„åˆæ•°é‡
            
        Returns:
            ç”Ÿæˆçš„å…³é”®è¯ç»„åˆåˆ—è¡¨
        """
        if max_combinations is None:
            max_combinations = self.config.get('max_combinations', 1000)
        
        combinations = []
        active_roots = self.get_active_roots()
        
        print(f"ðŸ”„ å¼€å§‹ç”Ÿæˆå…³é”®è¯ç»„åˆ...")
        print(f"ðŸ“Š ç§å­è¯: {len(seed_words)} ä¸ª")
        print(f"ðŸŽ¯ æ¿€æ´»è¯æ ¹: {len(active_roots)} ä¸ª")
        
        # åŸºç¡€ç»„åˆ: seed + root
        for seed in seed_words:
            for root in active_roots:
                combinations.extend([
                    f"{seed} {root}",
                    f"{root} {seed}",
                    f"{seed}-{root}",
                    f"{root}-{seed}"
                ])
        
        # AIå‰ç¼€ç»„åˆ
        if include_ai and self.config.get('ai_focus', True):
            for seed in seed_words:
                for root in active_roots[:20]:  # é™åˆ¶è¯æ ¹æ•°é‡
                    for ai_prefix in self.ai_prefixes[:5]:  # é™åˆ¶AIå‰ç¼€æ•°é‡
                        combinations.extend([
                            f"{ai_prefix} {seed} {root}",
                            f"{ai_prefix} {root} {seed}",
                            f"{ai_prefix}-{seed}-{root}"
                        ])
        
        # åŽ»é‡å¹¶é™åˆ¶æ•°é‡
        unique_combinations = list(set(combinations))[:max_combinations]
        
        print(f"âœ… ç”Ÿæˆå®Œæˆ: {len(unique_combinations)} ä¸ªç‹¬ç‰¹ç»„åˆ")
        return unique_combinations
    
    def get_category_roots(self, category: str) -> List[str]:
        """
        èŽ·å–æŒ‡å®šç±»åˆ«çš„è¯æ ¹
        
        Args:
            category: å·¥å…·ç±»åˆ«åç§°
            
        Returns:
            è¯¥ç±»åˆ«çš„è¯æ ¹åˆ—è¡¨
        """
        return self.tool_categories.get(category, [])
    
    def analyze_root_coverage(self, keywords: List[str]) -> Dict[str, Any]:
        """
        åˆ†æžå…³é”®è¯çš„è¯æ ¹è¦†ç›–æƒ…å†µ
        
        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            
        Returns:
            è¯æ ¹è¦†ç›–åˆ†æžç»“æžœ
        """
        active_roots = self.get_active_roots()
        root_usage = {root: 0 for root in active_roots}
        covered_roots = set()
        
        for keyword in keywords:
            keyword_lower = keyword.lower()
            for root in active_roots:
                if root in keyword_lower:
                    root_usage[root] += 1
                    covered_roots.add(root)
        
        coverage_rate = len(covered_roots) / len(active_roots) if active_roots else 0
        
        return {
            'total_roots': len(active_roots),
            'covered_roots': len(covered_roots),
            'coverage_rate': round(coverage_rate * 100, 1),
            'root_usage': dict(sorted(root_usage.items(), key=lambda x: x[1], reverse=True)),
            'top_used_roots': [root for root, count in sorted(root_usage.items(), key=lambda x: x[1], reverse=True)[:10]],
            'unused_roots': [root for root in active_roots if root not in covered_roots]
        }
    
    def suggest_missing_opportunities(self, current_keywords: List[str]) -> List[str]:
        """
        åŸºäºŽè¯æ ¹è¦†ç›–åˆ†æžï¼Œå»ºè®®ç¼ºå¤±çš„æœºä¼šå…³é”®è¯
        
        Args:
            current_keywords: å½“å‰å…³é”®è¯åˆ—è¡¨
            
        Returns:
            å»ºè®®çš„æ–°å…³é”®è¯åˆ—è¡¨
        """
        coverage_analysis = self.analyze_root_coverage(current_keywords)
        unused_roots = coverage_analysis['unused_roots']
        
        # ä»Žå½“å‰å…³é”®è¯ä¸­æå–ç§å­è¯
        seed_words = self._extract_seed_words(current_keywords)
        
        # ä¸ºæœªä½¿ç”¨çš„è¯æ ¹ç”Ÿæˆæ–°å…³é”®è¯
        suggestions = []
        for root in unused_roots[:10]:  # é™åˆ¶æ•°é‡
            for seed in seed_words[:5]:  # é™åˆ¶ç§å­è¯æ•°é‡
                suggestions.extend([
                    f"{seed} {root}",
                    f"ai {seed} {root}",
                    f"free {seed} {root}",
                    f"online {seed} {root}"
                ])
        
        return list(set(suggestions))[:20]  # è¿”å›žå‰20ä¸ªå»ºè®®
    
    def _extract_seed_words(self, keywords: List[str]) -> List[str]:
        """ä»Žå…³é”®è¯ä¸­æå–ç§å­è¯"""
        seed_words = set()
        active_roots = set(self.get_active_roots())
        ai_prefixes = set(self.ai_prefixes)
        
        for keyword in keywords:
            words = keyword.lower().replace('-', ' ').split()
            for word in words:
                # æŽ’é™¤è¯æ ¹å’ŒAIå‰ç¼€ï¼Œå‰©ä¸‹çš„ä½œä¸ºç§å­è¯
                if word not in active_roots and word not in ai_prefixes:
                    if len(word) > 2:  # è¿‡æ»¤å¤ªçŸ­çš„è¯
                        seed_words.add(word)
        
        return list(seed_words)
    
    def export_config(self, output_path: str) -> None:
        """
        å¯¼å‡ºå½“å‰é…ç½®
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        export_data = {
            'config': self.config,
            'core_roots': self.core_roots,
            'ai_prefixes': self.ai_prefixes,
            'tool_categories': self.tool_categories,
            'manual_roots': list(self.manual_roots),
            'export_time': datetime.now().isoformat()
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            if output_path.endswith('.json'):
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            else:
                yaml.dump(export_data, f, allow_unicode=True, default_flow_style=False)
        
        print(f"âœ… é…ç½®å·²å¯¼å‡ºåˆ°: {output_path}")
    
    def get_stats(self) -> Dict[str, Any]:
        """èŽ·å–ç»Ÿè®¡ä¿¡æ¯"""
        active_roots = self.get_active_roots()
        
        return {
            'total_core_roots': len(self.core_roots),
            'active_roots': len(active_roots),
            'manual_roots': len(self.manual_roots),
            'ai_prefixes': len(self.ai_prefixes),
            'tool_categories': len(self.tool_categories),
            'using_manual_roots': len(self.manual_roots) > 0,
            'config_loaded': self.config_path is not None
        }