#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨ç½‘ç«™å»ºè®¾æ–¹æ¡ˆç”Ÿæˆå™¨ (åŸAIå·¥å…·ç½‘ç«™å»ºè®¾æ–¹æ¡ˆç”Ÿæˆå™¨å‡çº§ç‰ˆ)
åŸºäºä»»ä½•å…³é”®è¯åˆ†æç»“æœï¼Œè‡ªåŠ¨ç”Ÿæˆå¯¹åº”ä¸»é¢˜çš„ç½‘ç«™å»ºè®¾è®¡åˆ’
"""

import json
import pandas as pd
from datetime import datetime, timedelta
import os
import glob

class AIWebsiteBuilder:
    def __init__(self):
        self.comprehensive_data = None
        self.keyword_theme = None
        self.website_type = None
        
    def find_latest_analysis_report(self):
        """æŸ¥æ‰¾æœ€æ–°çš„å…³é”®è¯åˆ†ææŠ¥å‘Š"""
        # ä»å½“å‰ç›®å½•å‘ä¸ŠæŸ¥æ‰¾
        possible_paths = [
            "src/demand_mining/reports",
            "../demand_mining/reports",
            "../../src/demand_mining/reports"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                pattern = os.path.join(path, "keyword_analysis_*.json")
                report_files = glob.glob(pattern)
                if report_files:
                    # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œè·å–æœ€æ–°çš„
                    report_files.sort(reverse=True)
                    return report_files[0]
        return None
        
    def load_comprehensive_data(self):
        """åŠ è½½ç»¼åˆåˆ†ææ•°æ® - æ”¯æŒå¤šç§æ•°æ®æº"""
        # 1. é¦–å…ˆå°è¯•åŠ è½½åŸå§‹AIå·¥å…·æ•°æ®
        try:
            with open('data/ai_tools_analysis/comprehensive_report_2025-08-05.json', 'r', encoding='utf-8') as f:
                self.comprehensive_data = json.load(f)
                self.keyword_theme = "ai tools"
                self.website_type = "ai"
                print("âœ… åŠ è½½AIå·¥å…·åˆ†ææ•°æ®")
                return True
        except Exception as e:
            print(f"åŸå§‹AIæ•°æ®ä¸å­˜åœ¨: {e}")
            
        # 2. å°è¯•åŠ è½½æœ€æ–°çš„å…³é”®è¯åˆ†ææŠ¥å‘Š
        latest_report = self.find_latest_analysis_report()
        if latest_report:
            try:
                with open(latest_report, 'r', encoding='utf-8') as f:
                    keyword_data = json.load(f)
                
                # è½¬æ¢ä¸ºé€‚åˆçš„æ ¼å¼
                self.comprehensive_data = self.convert_keyword_data_to_ai_format(keyword_data)
                
                # æå–ä¸»é¢˜å…³é”®è¯
                if 'keywords' in keyword_data and keyword_data['keywords']:
                    self.keyword_theme = keyword_data['keywords'][0]['keyword']
                    self.website_type = self.analyze_keyword_theme()
                    print(f"âœ… åŸºäºå…³é”®è¯åˆ†ææŠ¥å‘Š: {os.path.basename(latest_report)}")
                    print(f"ğŸ¯ æ£€æµ‹åˆ°ä¸»é¢˜: {self.keyword_theme} (ç±»å‹: {self.website_type})")
                    return True
            except Exception as e2:
                print(f"åŠ è½½å…³é”®è¯åˆ†ææŠ¥å‘Šå¤±è´¥: {e2}")
        
        # 3. ä½¿ç”¨é»˜è®¤é…ç½®
        print("ä½¿ç”¨é»˜è®¤AIå·¥å…·é…ç½®...")
        self.comprehensive_data = self.get_default_ai_data()
        self.keyword_theme = "ai tools"
        self.website_type = "ai"
        return True
    
    def analyze_keyword_theme(self):
        """åˆ†æå…³é”®è¯ä¸»é¢˜ï¼Œç¡®å®šç½‘ç«™ç±»å‹"""
        if not self.keyword_theme:
            return "ai"
            
        keyword_lower = self.keyword_theme.lower()
        
        # å®šä¹‰ä¸»é¢˜æ˜ å°„
        theme_mapping = {
            'ai': ['ai', 'artificial intelligence', 'machine learning', 'chatgpt', 'openai'],
            'weather': ['hurricane', 'tornado', 'weather', 'storm', 'climate'],
            'health': ['health', 'medical', 'fitness', 'wellness', 'nutrition'],
            'finance': ['finance', 'investment', 'crypto', 'bitcoin', 'trading'],
            'tech': ['technology', 'software', 'programming', 'coding', 'development'],
            'travel': ['travel', 'vacation', 'hotel', 'flight', 'tourism'],
            'food': ['food', 'recipe', 'cooking', 'restaurant', 'cuisine'],
            'education': ['education', 'learning', 'course', 'tutorial', 'study'],
            'business': ['business', 'marketing', 'startup', 'entrepreneur', 'sales'],
            'entertainment': ['movie', 'music', 'game', 'entertainment', 'celebrity']
        }
        
        # åŒ¹é…ä¸»é¢˜
        for theme, keywords in theme_mapping.items():
            if any(kw in keyword_lower for kw in keywords):
                return theme
                
        return "ai"  # é»˜è®¤ä¸ºAIä¸»é¢˜
    
    def convert_keyword_data_to_ai_format(self, keyword_data):
        """å°†å…³é”®è¯æ•°æ®è½¬æ¢ä¸ºAIå·¥å…·åˆ†ææ ¼å¼"""
        keywords = keyword_data.get('keywords', [])
        
        converted_data = {
            'å…³é”®æŒ‡æ ‡': {
                'æ€»å…³é”®è¯æ•°': len(keywords),
                'é«˜åˆ†å…³é”®è¯æ•°': len([k for k in keywords if k.get('ç»¼åˆè¯„åˆ†', 0) > 70]),
                'å¹³å‡æœç´¢é‡': sum(k.get('æœç´¢é‡ä¼°ç®—', 0) for k in keywords) // max(len(keywords), 1)
            },
            'Top20é«˜ä»·å€¼å…³é”®è¯': []
        }
        
        # æå–é«˜ä»·å€¼å…³é”®è¯
        sorted_keywords = sorted(keywords, key=lambda x: x.get('ç»¼åˆè¯„åˆ†', 0), reverse=True)
        for kw in sorted_keywords[:20]:
            converted_data['Top20é«˜ä»·å€¼å…³é”®è¯'].append({
                'query': kw.get('keyword', ''),
                'score': kw.get('ç»¼åˆè¯„åˆ†', 0),
                'search_volume': kw.get('æœç´¢é‡ä¼°ç®—', 0),
                'intent': kw.get('intent', {}).get('primary_intent', 'I')
            })
        
        return converted_data
    
    def get_default_ai_data(self):
        """è·å–é»˜è®¤AIå·¥å…·æ•°æ®"""
        return {
            'å…³é”®æŒ‡æ ‡': {
                'æ€»å…³é”®è¯æ•°': 100,
                'é«˜åˆ†å…³é”®è¯æ•°': 25,
                'å¹³å‡æœç´¢é‡': 5000
            },
            'Top20é«˜ä»·å€¼å…³é”®è¯': [
                {'query': 'chatgpt', 'score': 95},
                {'query': 'midjourney', 'score': 92},
                {'query': 'claude ai', 'score': 88},
                {'query': 'stable diffusion', 'score': 85},
                {'query': 'github copilot', 'score': 82}
            ]
        }
    
    def generate_website_concept_by_theme(self, theme):
        """æ ¹æ®ä¸»é¢˜ç”Ÿæˆç½‘ç«™æ¦‚å¿µ"""
        concepts = {
            'ai': {
                'name': 'AIå·¥å…·å¯¼èˆªä¸­å¿ƒ',
                'description': 'æœ€å…¨é¢çš„äººå·¥æ™ºèƒ½å·¥å…·è¯„æµ‹å’Œæ¨èå¹³å°',
                'target_audience': 'å¼€å‘è€…ã€ä¼ä¸šç”¨æˆ·ã€AIçˆ±å¥½è€…',
                'value_proposition': 'å‘ç°æœ€æ–°æœ€å¥½ç”¨çš„AIå·¥å…·ï¼Œæä¾›ä¸“ä¸šè¯„æµ‹å’Œä½¿ç”¨æŒ‡å—'
            },
            'weather': {
                'name': 'å¤©æ°”é¢„è­¦ä¿¡æ¯ä¸­å¿ƒ',
                'description': 'å®æ—¶å¤©æ°”è¿½è¸ªã€é¢„æŠ¥å’Œå®‰å…¨æŒ‡å—å¹³å°',
                'target_audience': 'æ²¿æµ·å±…æ°‘ã€åº”æ€¥ç®¡ç†äººå‘˜ã€å¤©æ°”çˆ±å¥½è€…',
                'value_proposition': 'æä¾›æœ€åŠæ—¶ã€æœ€ä¸“ä¸šçš„å¤©æ°”ä¿¡æ¯å’Œå®‰å…¨æŒ‡å¯¼'
            },
            'health': {
                'name': 'å¥åº·ç”Ÿæ´»æŒ‡å—',
                'description': 'ä¸“ä¸šå¥åº·èµ„è®¯å’Œç”Ÿæ´»æ–¹å¼å»ºè®®å¹³å°',
                'target_audience': 'å¥åº·å…³æ³¨è€…ã€æ‚£è€…ã€åŒ»ç–—ä¸“ä¸šäººå£«',
                'value_proposition': 'æä¾›ç§‘å­¦å¯é çš„å¥åº·ä¿¡æ¯å’Œä¸ªæ€§åŒ–å»ºè®®'
            },
            'finance': {
                'name': 'æŠ•èµ„ç†è´¢åŠ©æ‰‹',
                'description': 'ä¸“ä¸šæŠ•èµ„åˆ†æå’Œç†è´¢å»ºè®®å¹³å°',
                'target_audience': 'æŠ•èµ„è€…ã€ç†è´¢è§„åˆ’å¸ˆã€é‡‘èä»ä¸šè€…',
                'value_proposition': 'æä¾›ä¸“ä¸šçš„æŠ•èµ„åˆ†æå’Œä¸ªæ€§åŒ–ç†è´¢æ–¹æ¡ˆ'
            },
            'tech': {
                'name': 'ç§‘æŠ€èµ„è®¯ä¸­å¿ƒ',
                'description': 'æœ€æ–°ç§‘æŠ€åŠ¨æ€å’Œäº§å“è¯„æµ‹å¹³å°',
                'target_audience': 'ç§‘æŠ€çˆ±å¥½è€…ã€å¼€å‘è€…ã€äº§å“ç»ç†',
                'value_proposition': 'ç¬¬ä¸€æ—¶é—´è·å–ç§‘æŠ€èµ„è®¯å’Œæ·±åº¦äº§å“åˆ†æ'
            }
        }
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ä¸»é¢˜ï¼Œä½¿ç”¨é€šç”¨æ¨¡æ¿
        if theme not in concepts:
            concepts[theme] = {
                'name': f'{self.keyword_theme.title()} ä¿¡æ¯ä¸­å¿ƒ',
                'description': f'ä¸“ä¸šçš„{self.keyword_theme}ç›¸å…³ä¿¡æ¯å’Œèµ„æºå¹³å°',
                'target_audience': f'{self.keyword_theme}ç›¸å…³ç”¨æˆ·ç¾¤ä½“',
                'value_proposition': f'æä¾›æœ€å…¨é¢çš„{self.keyword_theme}ä¿¡æ¯å’Œä¸“ä¸šæŒ‡å¯¼'
            }
        
        return concepts[theme]
    
    def analyze_keyword_categories(self):
        """åˆ†æå…³é”®è¯ç±»åˆ« - æ ¹æ®ä¸»é¢˜è‡ªé€‚åº”"""
        if not self.comprehensive_data:
            return {}
        
        # æ ¹æ®ç½‘ç«™ç±»å‹ç”Ÿæˆä¸åŒçš„åˆ†ç±»
        if self.website_type == 'ai':
            return self.get_ai_categories()
        elif self.website_type == 'weather':
            return self.get_weather_categories()
        elif self.website_type == 'health':
            return self.get_health_categories()
        elif self.website_type == 'finance':
            return self.get_finance_categories()
        else:
            return self.get_general_categories()
    
    def get_ai_categories(self):
        """AIä¸»é¢˜åˆ†ç±»"""
        return {
            'conversational_ai': {
                'name': 'å¯¹è¯AIå·¥å…·',
                'keywords': ['chatgpt', 'claude', 'bard', 'gemini', 'chatbot', 'ai assistant'],
                'priority': 'high',
                'estimated_traffic': 15000
            },
            'image_generation': {
                'name': 'å›¾åƒç”Ÿæˆå·¥å…·',
                'keywords': ['midjourney', 'dall-e', 'stable diffusion', 'ai image generator'],
                'priority': 'high',
                'estimated_traffic': 12000
            },
            'writing_tools': {
                'name': 'å†™ä½œAIå·¥å…·',
                'keywords': ['jasper ai', 'copy ai', 'writesonic', 'grammarly'],
                'priority': 'high',
                'estimated_traffic': 10000
            },
            'coding_tools': {
                'name': 'ç¼–ç¨‹AIå·¥å…·',
                'keywords': ['github copilot', 'codeium', 'tabnine', 'ai coding assistant'],
                'priority': 'high',
                'estimated_traffic': 9000
            }
        }
    
    def get_weather_categories(self):
        """å¤©æ°”ä¸»é¢˜åˆ†ç±»"""
        return {
            'tracking': {
                'name': 'å®æ—¶è¿½è¸ª',
                'keywords': ['hurricane tracker', 'storm tracker', 'weather radar'],
                'priority': 'high',
                'estimated_traffic': 8000
            },
            'safety': {
                'name': 'å®‰å…¨æŒ‡å—',
                'keywords': ['hurricane safety', 'storm preparedness', 'evacuation guide'],
                'priority': 'high',
                'estimated_traffic': 6000
            },
            'forecasting': {
                'name': 'å¤©æ°”é¢„æŠ¥',
                'keywords': ['hurricane forecast', 'weather prediction', 'storm warning'],
                'priority': 'medium',
                'estimated_traffic': 7000
            },
            'history': {
                'name': 'å†å²æ•°æ®',
                'keywords': ['hurricane history', 'storm archive', 'weather records'],
                'priority': 'medium',
                'estimated_traffic': 4000
            }
        }
    
    def get_health_categories(self):
        """å¥åº·ä¸»é¢˜åˆ†ç±»"""
        return {
            'nutrition': {
                'name': 'è¥å…»å¥åº·',
                'keywords': ['healthy diet', 'nutrition guide', 'meal planning'],
                'priority': 'high',
                'estimated_traffic': 10000
            },
            'fitness': {
                'name': 'è¿åŠ¨å¥èº«',
                'keywords': ['workout routine', 'fitness tips', 'exercise guide'],
                'priority': 'high',
                'estimated_traffic': 8000
            },
            'mental_health': {
                'name': 'å¿ƒç†å¥åº·',
                'keywords': ['mental wellness', 'stress management', 'mindfulness'],
                'priority': 'medium',
                'estimated_traffic': 6000
            }
        }
    
    def get_finance_categories(self):
        """é‡‘èä¸»é¢˜åˆ†ç±»"""
        return {
            'investment': {
                'name': 'æŠ•èµ„ç†è´¢',
                'keywords': ['investment guide', 'stock analysis', 'portfolio management'],
                'priority': 'high',
                'estimated_traffic': 12000
            },
            'crypto': {
                'name': 'åŠ å¯†è´§å¸',
                'keywords': ['bitcoin', 'cryptocurrency', 'crypto trading'],
                'priority': 'high',
                'estimated_traffic': 10000
            },
            'personal_finance': {
                'name': 'ä¸ªäººç†è´¢',
                'keywords': ['budgeting', 'saving money', 'financial planning'],
                'priority': 'medium',
                'estimated_traffic': 8000
            }
        }
    
    def get_general_categories(self):
        """é€šç”¨åˆ†ç±»"""
        return {
            'information': {
                'name': 'ä¿¡æ¯èµ„è®¯',
                'keywords': [f'{self.keyword_theme} news', f'{self.keyword_theme} guide'],
                'priority': 'high',
                'estimated_traffic': 8000
            },
            'guides': {
                'name': 'æŒ‡å—æ•™ç¨‹',
                'keywords': [f'how to {self.keyword_theme}', f'{self.keyword_theme} tutorial'],
                'priority': 'medium',
                'estimated_traffic': 6000
            },
            'reviews': {
                'name': 'è¯„æµ‹å¯¹æ¯”',
                'keywords': [f'{self.keyword_theme} review', f'best {self.keyword_theme}'],
                'priority': 'medium',
                'estimated_traffic': 5000
            }
        }
    
    def generate_website_structure(self, categories):
        """ç”Ÿæˆç½‘ç«™ç»“æ„"""
        website_concept = self.generate_website_concept_by_theme(self.website_type)
        
        structure = {
            'homepage': {
                'title': f'{website_concept["name"]} - {website_concept["description"]}',
                'description': website_concept['description'],
                'target_keywords': [self.keyword_theme, f'{self.keyword_theme} guide', f'best {self.keyword_theme}'],
                'sections': [
                    f'çƒ­é—¨{website_concept["name"]}æ¨è',
                    'åˆ†ç±»å¯¼èˆª',
                    'æœ€æ–°åŠ¨æ€',
                    'ç”¨æˆ·è¯„ä»·æ’è¡Œ',
                    'ç²¾é€‰æ¨è'
                ]
            },
            'categories': {},
            'content_pages': {}
        }
        
        # ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºé¡µé¢
        for cat_id, cat_info in categories.items():
            structure['categories'][cat_id] = {
                'title': f'{cat_info["name"]}å®Œæ•´æŒ‡å— - 2025å¹´æœ€æ–°',
                'url': f'/{cat_id.replace("_", "-")}',
                'description': f'ä¸“ä¸šçš„{cat_info["name"]}ä¿¡æ¯ï¼ŒåŒ…æ‹¬è¯¦ç»†åˆ†æå’Œä½¿ç”¨å»ºè®®',
                'target_keywords': cat_info['keywords'][:5],
                'priority': cat_info['priority'],
                'estimated_traffic': cat_info['estimated_traffic']
            }
        
        return structure
    
    def create_content_strategy(self, structure):
        """åˆ›å»ºå†…å®¹ç­–ç•¥"""
        content_calendar = []
        start_date = datetime.now()
        
        # æ ¹æ®ä¸»é¢˜ç”Ÿæˆä¸åŒçš„å†…å®¹ç­–ç•¥
        if self.website_type == 'ai':
            priority_topics = ['ChatGPT', 'Claude', 'Midjourney', 'DALL-E', 'GitHub Copilot']
        elif self.website_type == 'weather':
            priority_topics = ['é£“é£è¿½è¸ªæŒ‡å—', 'é£æš´å®‰å…¨å‡†å¤‡', 'å¤©æ°”é¢„æŠ¥è§£è¯»', 'å†å²é£“é£åˆ†æ', 'åº”æ€¥å“åº”è®¡åˆ’']
        elif self.website_type == 'health':
            priority_topics = ['å¥åº·é¥®é£ŸæŒ‡å—', 'è¿åŠ¨å¥èº«è®¡åˆ’', 'å¿ƒç†å¥åº·ç®¡ç†', 'ç–¾ç—…é¢„é˜²çŸ¥è¯†', 'å¥åº·ç”Ÿæ´»æ–¹å¼']
        elif self.website_type == 'finance':
            priority_topics = ['æŠ•èµ„åŸºç¡€çŸ¥è¯†', 'è‚¡ç¥¨åˆ†ææ–¹æ³•', 'åŠ å¯†è´§å¸æŒ‡å—', 'ç†è´¢è§„åˆ’ç­–ç•¥', 'é£é™©ç®¡ç†æŠ€å·§']
        else:
            priority_topics = [f'{self.keyword_theme}åŸºç¡€æŒ‡å—', f'{self.keyword_theme}è¿›é˜¶æŠ€å·§', f'{self.keyword_theme}æœ€ä½³å®è·µ', f'{self.keyword_theme}æ¡ˆä¾‹åˆ†æ', f'{self.keyword_theme}è¶‹åŠ¿é¢„æµ‹']
        
        for i, topic in enumerate(priority_topics):
            content_calendar.append({
                'week': i + 1,
                'publish_date': (start_date + timedelta(weeks=i)).strftime('%Y-%m-%d'),
                'content_type': 'guide_article',
                'title': topic,
                'target_keywords': [topic.lower(), f'{self.keyword_theme} {topic.lower()}'],
                'estimated_words': 2000 + (i * 200),
                'priority': 'high',
                'monetization': 'affiliate_links + display_ads'
            })
        
        return content_calendar
    
    def generate_technical_plan(self):
        """ç”ŸæˆæŠ€æœ¯å®æ–½è®¡åˆ’"""
        base_plan = {
            'architecture': {
                'frontend': {
                    'framework': 'Next.js 14 (App Router)',
                    'styling': 'Tailwind CSS + Shadcn/ui',
                    'state_management': 'Zustand'
                },
                'backend': {
                    'framework': 'Next.js API Routes',
                    'database': 'PostgreSQL (Supabase)',
                    'auth': 'NextAuth.js'
                },
                'hosting': {
                    'platform': 'Vercel',
                    'cdn': 'Vercel Edge Network',
                    'database': 'Supabase'
                }
            }
        }
        
        # æ ¹æ®ä¸»é¢˜æ·»åŠ ç‰¹æ®Šéœ€æ±‚
        if self.website_type == 'weather':
            base_plan['integrations'] = {
                'weather_apis': ['OpenWeatherMap', 'WeatherAPI'],
                'mapping': 'Leaflet.js',
                'real_time': 'WebSocket connections'
            }
        elif self.website_type == 'ai':
            base_plan['integrations'] = {
                'ai_apis': ['OpenAI API', 'Anthropic API'],
                'analytics': 'Google Analytics 4',
                'affiliate_tracking': 'Custom tracking system'
            }
        elif self.website_type == 'finance':
            base_plan['integrations'] = {
                'financial_apis': ['Alpha Vantage', 'Yahoo Finance'],
                'charts': 'Chart.js',
                'real_time_data': 'WebSocket for live prices'
            }
        
        return base_plan
    
    def create_monetization_plan(self):
        """åˆ›å»ºå˜ç°è®¡åˆ’"""
        # æ ¹æ®ä¸»é¢˜å®šåˆ¶å˜ç°ç­–ç•¥
        if self.website_type == 'ai':
            return {
                'primary': 'affiliate_marketing',
                'revenue_streams': {
                    'affiliate_commissions': '$2000-5000/æœˆ',
                    'display_advertising': '$800-2000/æœˆ',
                    'sponsored_reviews': '$500-1500/æœˆ'
                }
            }
        elif self.website_type == 'weather':
            return {
                'primary': 'display_advertising',
                'revenue_streams': {
                    'display_advertising': '$1500-3000/æœˆ',
                    'emergency_supplies_affiliate': '$500-1200/æœˆ',
                    'premium_alerts': '$300-800/æœˆ'
                }
            }
        elif self.website_type == 'health':
            return {
                'primary': 'affiliate_marketing',
                'revenue_streams': {
                    'health_products_affiliate': '$1800-4000/æœˆ',
                    'display_advertising': '$1000-2500/æœˆ',
                    'consultation_referrals': '$600-1500/æœˆ'
                }
            }
        else:
            return {
                'primary': 'display_advertising',
                'revenue_streams': {
                    'display_advertising': '$800-2000/æœˆ',
                    'affiliate_commissions': '$400-1000/æœˆ'
                }
            }
    
    def create_theme_directory(self):
        """åˆ›å»ºä¸»é¢˜ä¸“ç”¨ç›®å½•"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # æ¸…ç†ä¸»é¢˜åç§°ï¼Œç”¨äºæ–‡ä»¶å¤¹å‘½å
        clean_theme = self.keyword_theme.lower().replace(' ', '_').replace('-', '_')
        clean_theme = ''.join(c for c in clean_theme if c.isalnum() or c == '_')
        
        # åˆ›å»ºä¸»é¢˜ç›®å½•å
        theme_dir = f"generated_websites/{self.website_type}_{clean_theme}_{timestamp}"
        
        # åˆ›å»ºç›®å½•
        os.makedirs(theme_dir, exist_ok=True)
        
        return theme_dir
    
    def backup_existing_website(self):
        """å¤‡ä»½ç°æœ‰çš„ generated_website ç›®å½•"""
        if os.path.exists('generated_website'):
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_dir = f"generated_websites/backup_{timestamp}"
            
            os.makedirs('generated_websites', exist_ok=True)
            
            import shutil
            shutil.move('generated_website', backup_dir)
            print(f"ğŸ“¦ å·²å¤‡ä»½ç°æœ‰ç½‘ç«™åˆ°: {backup_dir}")
            return backup_dir
        return None

    def generate_complete_plan(self):
        """ç”Ÿæˆå®Œæ•´çš„ç½‘ç«™å»ºè®¾è®¡åˆ’"""
        print("ğŸš€ å¯åŠ¨é€šç”¨ç½‘ç«™å»ºè®¾æ–¹æ¡ˆç”Ÿæˆå™¨...")
        
        if not self.load_comprehensive_data():
            print("æ— æ³•åŠ è½½åŸºç¡€æ•°æ®")
            return
        
        # å¤‡ä»½ç°æœ‰ç½‘ç«™ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        backup_path = self.backup_existing_website()
        
        # åˆ›å»ºä¸»é¢˜ä¸“ç”¨ç›®å½•
        theme_dir = self.create_theme_directory()
        
        # ç”Ÿæˆç½‘ç«™æ¦‚å¿µ
        website_concept = self.generate_website_concept_by_theme(self.website_type)
        
        # åˆ†æå…³é”®è¯ç±»åˆ«
        categories = self.analyze_keyword_categories()
        
        # ç”Ÿæˆç½‘ç«™ç»“æ„
        website_structure = self.generate_website_structure(categories)
        
        # åˆ›å»ºå†…å®¹ç­–ç•¥
        content_strategy = self.create_content_strategy(website_structure)
        
        # ç”ŸæˆæŠ€æœ¯è®¡åˆ’
        technical_plan = self.generate_technical_plan()
        
        # åˆ›å»ºå˜ç°è®¡åˆ’
        monetization_plan = self.create_monetization_plan()
        
        # æ±‡æ€»å®Œæ•´è®¡åˆ’
        complete_plan = {
            'project_info': {
                'theme': self.website_type,
                'main_keyword': self.keyword_theme,
                'website_name': website_concept['name'],
                'description': website_concept['description'],
                'target_audience': website_concept['target_audience'],
                'value_proposition': website_concept['value_proposition'],
                'estimated_launch_date': (datetime.now() + timedelta(weeks=4)).strftime('%Y-%m-%d'),
                'theme_directory': theme_dir
            },
            'market_analysis': {
                'total_keywords_analyzed': self.comprehensive_data['å…³é”®æŒ‡æ ‡']['æ€»å…³é”®è¯æ•°'],
                'high_value_keywords': self.comprehensive_data['å…³é”®æŒ‡æ ‡']['é«˜åˆ†å…³é”®è¯æ•°'],
                'average_search_volume': self.comprehensive_data['å…³é”®æŒ‡æ ‡']['å¹³å‡æœç´¢é‡'],
                'market_opportunity': f'åŸºäº{self.keyword_theme}çš„åˆ©åŸºå¸‚åœºï¼Œå…·æœ‰è‰¯å¥½çš„SEOæœºä¼š'
            },
            'website_structure': website_structure,
            'content_strategy': {
                'content_calendar': content_strategy
            },
            'technical_implementation': technical_plan,
            'monetization_strategy': monetization_plan,
            'success_metrics': {
                'month_1': {'visitors': 1500, 'revenue': 200, 'articles': 8},
                'month_3': {'visitors': 8000, 'revenue': 800, 'articles': 20},
                'month_6': {'visitors': 25000, 'revenue': 2500, 'articles': 35},
                'month_12': {'visitors': 80000, 'revenue': 8000, 'articles': 60}
            }
        }
        
        # ä¿å­˜è®¡åˆ’åˆ°ä¸»é¢˜ç›®å½•
        plan_file = os.path.join(theme_dir, 'website_plan.json')
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(complete_plan, f, ensure_ascii=False, indent=2)
        
        # åˆ›å»ºé¡¹ç›®ä¿¡æ¯æ–‡ä»¶
        project_info = {
            'project_name': website_concept['name'],
            'theme': self.website_type,
            'main_keyword': self.keyword_theme,
            'created_at': datetime.now().isoformat(),
            'directory': theme_dir,
            'status': 'plan_generated'
        }
        
        info_file = os.path.join(theme_dir, 'project_info.json')
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(project_info, f, ensure_ascii=False, indent=2)
        
        # åˆ›å»º README æ–‡ä»¶
        readme_content = f"""# {website_concept['name']}

## é¡¹ç›®ä¿¡æ¯
- **ä¸»é¢˜**: {self.website_type}
- **å…³é”®è¯**: {self.keyword_theme}
- **åˆ›å»ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ç›®æ ‡å—ä¼—**: {website_concept['target_audience']}

## é¡¹ç›®æè¿°
{website_concept['description']}

## ä»·å€¼ä¸»å¼ 
{website_concept['value_proposition']}

## æ–‡ä»¶è¯´æ˜
- `website_plan.json` - å®Œæ•´çš„ç½‘ç«™å»ºè®¾è®¡åˆ’
- `project_info.json` - é¡¹ç›®åŸºæœ¬ä¿¡æ¯
- `website_source/` - ç½‘ç«™æºä»£ç ï¼ˆç”Ÿæˆåï¼‰

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨
1. è¿è¡Œç½‘ç«™ç”Ÿæˆå™¨åˆ›å»ºå®é™…ç½‘ç«™æ–‡ä»¶
2. é€‰æ‹©å¹¶æ³¨å†ŒåŸŸå
3. è®¾ç½®å¼€å‘ç¯å¢ƒ
4. å¼€å§‹ç½‘ç«™å¼€å‘
5. å‡†å¤‡é¦–æ‰¹å†…å®¹

## æŠ€æœ¯æ ˆ
- å‰ç«¯: {technical_plan['architecture']['frontend']['framework']}
- åç«¯: {technical_plan['architecture']['backend']['framework']}
- æ•°æ®åº“: {technical_plan['architecture']['backend']['database']}
- æ‰˜ç®¡: {technical_plan['architecture']['hosting']['platform']}
"""
        
        readme_file = os.path.join(theme_dir, 'README.md')
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        # æ›´æ–°é¡¹ç›®ç´¢å¼•
        self.update_project_index(theme_dir, project_info)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ‰ {website_concept['name']} å»ºè®¾æ–¹æ¡ˆå·²ç”Ÿæˆï¼")
        print(f"ğŸ“ é¡¹ç›®ç›®å½•: {theme_dir}")
        print(f"ğŸ“„ è¯¦ç»†è®¡åˆ’: {plan_file}")
        print(f"ğŸ¯ ä¸»é¢˜å…³é”®è¯: {self.keyword_theme}")
        print(f"ğŸ·ï¸ ç½‘ç«™ç±»å‹: {self.website_type}")
        print(f"ğŸš€ é¢„è®¡å‘å¸ƒæ—¶é—´: {complete_plan['project_info']['estimated_launch_date']}")
        
        if backup_path:
            print(f"ğŸ“¦ åŸç½‘ç«™å·²å¤‡ä»½åˆ°: {backup_path}")
        
        print(f"\nğŸ“Š å¸‚åœºåˆ†ææ‘˜è¦:")
        print(f"   â€¢ åˆ†æå…³é”®è¯æ€»æ•°: {complete_plan['market_analysis']['total_keywords_analyzed']}")
        print(f"   â€¢ é«˜ä»·å€¼å…³é”®è¯: {complete_plan['market_analysis']['high_value_keywords']}")
        print(f"   â€¢ å¹³å‡æœç´¢é‡: {complete_plan['market_analysis']['average_search_volume']}")
        
        print(f"\nğŸ’° æ”¶å…¥é¢„æœŸ:")
        for period, metrics in complete_plan['success_metrics'].items():
            print(f"   â€¢ {period}: {metrics['visitors']:,} è®¿å®¢, ${metrics['revenue']:,} æ”¶å…¥")
        
        print(f"\nğŸ—ï¸ æŠ€æœ¯æ ˆ:")
        tech = complete_plan['technical_implementation']
        print(f"   â€¢ å‰ç«¯: {tech['architecture']['frontend']['framework']}")
        print(f"   â€¢ åç«¯: {tech['architecture']['backend']['framework']}")
        print(f"   â€¢ æ•°æ®åº“: {tech['architecture']['backend']['database']}")
        print(f"   â€¢ æ‰˜ç®¡: {tech['architecture']['hosting']['platform']}")
        
        print(f"\nğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
        print("   1. è¿è¡Œç½‘ç«™ç”Ÿæˆå™¨åˆ›å»ºå®é™…ç½‘ç«™æ–‡ä»¶")
        print("   2. é€‰æ‹©å¹¶æ³¨å†ŒåŸŸå")
        print("   3. è®¾ç½®å¼€å‘ç¯å¢ƒ")
        print("   4. å¼€å§‹ç½‘ç«™å¼€å‘")
        print("   5. å‡†å¤‡é¦–æ‰¹å†…å®¹")
        
        return complete_plan, theme_dir
    
    def update_project_index(self, theme_dir, project_info):
        """æ›´æ–°é¡¹ç›®ç´¢å¼•"""
        index_file = 'generated_websites/projects_index.json'
        
        # è¯»å–ç°æœ‰ç´¢å¼•
        projects_index = []
        if os.path.exists(index_file):
            try:
                with open(index_file, 'r', encoding='utf-8') as f:
                    projects_index = json.load(f)
            except:
                projects_index = []
        
        # æ·»åŠ æ–°é¡¹ç›®
        projects_index.append(project_info)
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        projects_index.sort(key=lambda x: x.get('created_at', ''), reverse=True)
        
        # ä¿å­˜ç´¢å¼•
        os.makedirs('generated_websites', exist_ok=True)
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(projects_index, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ å·²æ›´æ–°é¡¹ç›®ç´¢å¼•: {index_file}")
    
    def list_projects(self):
        """åˆ—å‡ºæ‰€æœ‰é¡¹ç›®"""
        index_file = 'generated_websites/projects_index.json'
        
        if not os.path.exists(index_file):
            print("ğŸ“­ æš‚æ— é¡¹ç›®")
            return []
        
        try:
            with open(index_file, 'r', encoding='utf-8') as f:
                projects = json.load(f)
            
            print(f"\nğŸ“‹ é¡¹ç›®åˆ—è¡¨ (å…± {len(projects)} ä¸ªé¡¹ç›®):")
            print("=" * 80)
            
            for i, project in enumerate(projects, 1):
                print(f"{i}. {project['project_name']}")
                print(f"   ä¸»é¢˜: {project['theme']} | å…³é”®è¯: {project['main_keyword']}")
                print(f"   åˆ›å»ºæ—¶é—´: {project['created_at'][:19].replace('T', ' ')}")
                print(f"   ç›®å½•: {project['directory']}")
                print(f"   çŠ¶æ€: {project.get('status', 'unknown')}")
                print("-" * 80)
            
            return projects
            
        except Exception as e:
            print(f"âŒ è¯»å–é¡¹ç›®ç´¢å¼•å¤±è´¥: {e}")
            return []

if __name__ == "__main__":
    builder = AIWebsiteBuilder()
    builder.generate_complete_plan()