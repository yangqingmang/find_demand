#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
éœ€æ±‚æŒ–æ˜ â†’ æ„å›¾åˆ†æ â†’ å»ºç«™éƒ¨ç½² å®Œæ•´é›†æˆå·¥ä½œæµ
æ•´åˆä¸‰å¤§æ ¸å¿ƒæ¨¡å—ï¼Œå®ç°ä»éœ€æ±‚å‘ç°åˆ°ç½‘ç«™ä¸Šçº¿çš„å…¨è‡ªåŠ¨åŒ–æµç¨‹
"""

import os
import sys
import json
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.demand_mining.demand_mining_main import DemandMiningManager
from src.website_builder.intent_based_website_builder import IntentBasedWebsiteBuilder


class IntegratedWorkflow:
    """
    é›†æˆå·¥ä½œæµç®¡ç†å™¨
    å®ç°éœ€æ±‚æŒ–æ˜ â†’ æ„å›¾åˆ†æ â†’ ç½‘ç«™å»ºè®¾ â†’ è‡ªåŠ¨éƒ¨ç½²çš„å®Œæ•´æµç¨‹
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–é›†æˆå·¥ä½œæµ"""
        self.config = config or self._get_default_config()
        self.output_base_dir = "output/integrated_projects"
        self._ensure_output_dirs()
        
        # åˆå§‹åŒ–å„æ¨¡å—
        self.demand_miner = DemandMiningManager()
        
        print("ğŸš€ é›†æˆå·¥ä½œæµåˆå§‹åŒ–å®Œæˆ")
        print("ğŸ“Š æ”¯æŒåŠŸèƒ½ï¼šéœ€æ±‚æŒ–æ˜ â†’ æ„å›¾åˆ†æ â†’ ç½‘ç«™ç”Ÿæˆ â†’ è‡ªåŠ¨éƒ¨ç½²")
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'min_opportunity_score': 60,  # æœ€ä½æœºä¼šåˆ†æ•°é˜ˆå€¼
            'max_projects_per_batch': 5,  # æ¯æ‰¹æ¬¡æœ€å¤§é¡¹ç›®æ•°
            'auto_deploy': True,          # æ˜¯å¦è‡ªåŠ¨éƒ¨ç½²
            'deployment_platform': 'cloudflare',  # éƒ¨ç½²å¹³å°
            'use_tailwind': True,         # ä½¿ç”¨TailwindCSS
            'generate_reports': True      # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        }
    
    def _ensure_output_dirs(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        dirs = [
            self.output_base_dir,
            os.path.join(self.output_base_dir, 'demand_analysis'),
            os.path.join(self.output_base_dir, 'intent_analysis'),
            os.path.join(self.output_base_dir, 'websites'),
            os.path.join(self.output_base_dir, 'reports')
        ]
        
        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)
    
    def run_complete_workflow(self, keywords_file: str) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´å·¥ä½œæµ
        
        Args:
            keywords_file: å…³é”®è¯è¾“å…¥æ–‡ä»¶è·¯å¾„
            
        Returns:
            å·¥ä½œæµæ‰§è¡Œç»“æœ
        """
        print(f"ğŸ¯ å¼€å§‹æ‰§è¡Œå®Œæ•´å·¥ä½œæµ: {keywords_file}")
        
        workflow_results = {
            'start_time': datetime.now().isoformat(),
            'input_file': keywords_file,
            'steps_completed': [],
            'generated_projects': [],
            'deployment_results': [],
            'summary': {}
        }
        
        try:
            # æ­¥éª¤1: éœ€æ±‚æŒ–æ˜ä¸æ„å›¾åˆ†æ
            print("\nğŸ“Š æ­¥éª¤1: æ‰§è¡Œéœ€æ±‚æŒ–æ˜ä¸æ„å›¾åˆ†æ...")
            demand_results = self._run_demand_mining(keywords_file)
            workflow_results['steps_completed'].append('demand_mining')
            workflow_results['demand_analysis'] = demand_results
            
            # æ­¥éª¤2: ç­›é€‰é«˜ä»·å€¼å…³é”®è¯
            print("\nğŸ¯ æ­¥éª¤2: ç­›é€‰é«˜ä»·å€¼å…³é”®è¯...")
            high_value_keywords = self._filter_high_value_keywords(demand_results)
            workflow_results['steps_completed'].append('keyword_filtering')
            workflow_results['high_value_keywords'] = high_value_keywords
            
            # æ­¥éª¤3: æ‰¹é‡ç”Ÿæˆç½‘ç«™
            print("\nğŸ—ï¸ æ­¥éª¤3: æ‰¹é‡ç”Ÿæˆç½‘ç«™...")
            website_results = self._batch_generate_websites(high_value_keywords)
            workflow_results['steps_completed'].append('website_generation')
            workflow_results['generated_projects'] = website_results
            
            # æ­¥éª¤4: è‡ªåŠ¨éƒ¨ç½²ï¼ˆå¯é€‰ï¼‰
            if self.config.get('auto_deploy', False):
                print("\nğŸš€ æ­¥éª¤4: è‡ªåŠ¨éƒ¨ç½²ç½‘ç«™...")
                deployment_results = self._batch_deploy_websites(website_results)
                workflow_results['steps_completed'].append('deployment')
                workflow_results['deployment_results'] = deployment_results
            
            # æ­¥éª¤5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            print("\nğŸ“‹ æ­¥éª¤5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
            report_path = self._generate_workflow_report(workflow_results)
            workflow_results['steps_completed'].append('report_generation')
            workflow_results['report_path'] = report_path
            
            workflow_results['end_time'] = datetime.now().isoformat()
            workflow_results['status'] = 'success'
            
            print(f"\nğŸ‰ å®Œæ•´å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
            print(f"ğŸ“Š åˆ†æäº† {len(demand_results.get('keywords', []))} ä¸ªå…³é”®è¯")
            print(f"ğŸ¯ ç­›é€‰å‡º {len(high_value_keywords)} ä¸ªé«˜ä»·å€¼å…³é”®è¯")
            print(f"ğŸ—ï¸ ç”Ÿæˆäº† {len(website_results)} ä¸ªç½‘ç«™é¡¹ç›®")
            print(f"ğŸ“‹ æŠ¥å‘Šè·¯å¾„: {report_path}")
            
            return workflow_results
            
        except Exception as e:
            workflow_results['end_time'] = datetime.now().isoformat()
            workflow_results['status'] = 'failed'
            workflow_results['error'] = str(e)
            print(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            return workflow_results
    
    def _run_demand_mining(self, keywords_file: str) -> Dict[str, Any]:
        """æ‰§è¡Œéœ€æ±‚æŒ–æ˜åˆ†æ"""
        output_dir = os.path.join(self.output_base_dir, 'demand_analysis')
        return self.demand_miner.analyze_keywords(keywords_file, output_dir)
    
    def _filter_high_value_keywords(self, demand_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç­›é€‰é«˜ä»·å€¼å…³é”®è¯"""
        min_score = self.config.get('min_opportunity_score', 60)
        max_projects = self.config.get('max_projects_per_batch', 5)
        
        # è·å–æ‰€æœ‰å…³é”®è¯
        all_keywords = demand_results.get('keywords', [])
        
        # æŒ‰æœºä¼šåˆ†æ•°ç­›é€‰å’Œæ’åº
        high_value = [
            kw for kw in all_keywords 
            if kw.get('opportunity_score', 0) >= min_score
        ]
        
        # æŒ‰åˆ†æ•°é™åºæ’åºï¼Œå–å‰Nä¸ª
        high_value.sort(key=lambda x: x.get('opportunity_score', 0), reverse=True)
        
        return high_value[:max_projects]
    
    def _batch_generate_websites(self, keywords: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ‰¹é‡ç”Ÿæˆç½‘ç«™"""
        website_results = []
        
        for i, keyword_data in enumerate(keywords, 1):
            keyword = keyword_data['keyword']
            intent_info = keyword_data.get('intent', {})
            
            print(f"ğŸ—ï¸ ç”Ÿæˆç½‘ç«™ ({i}/{len(keywords)}): {keyword}")
            
            try:
                # å‡†å¤‡æ„å›¾æ•°æ®æ–‡ä»¶
                intent_data = self._prepare_intent_data(keyword_data)
                intent_file_path = self._save_intent_data(intent_data, keyword)
                
                # ç”Ÿæˆé¡¹ç›®åç§°
                project_name = self._generate_project_name(keyword)
                
                # åˆ›å»ºç½‘ç«™å»ºè®¾å™¨
                builder = IntentBasedWebsiteBuilder(
                    intent_data_path=intent_file_path,
                    output_dir=os.path.join(self.output_base_dir, 'websites'),
                    config={'project_name': project_name}
                )
                
                # æ‰§è¡Œå»ºç«™æµç¨‹
                if builder.load_intent_data():
                    structure = builder.generate_website_structure()
                    content_plan = builder.create_content_plan()
                    source_dir = builder.generate_website_source()
                    
                    if source_dir:
                        website_results.append({
                            'keyword': keyword,
                            'project_name': project_name,
                            'source_dir': source_dir,
                            'intent_info': intent_info,
                            'opportunity_score': keyword_data.get('opportunity_score', 0),
                            'status': 'success'
                        })
                        print(f"âœ… ç½‘ç«™ç”ŸæˆæˆåŠŸ: {source_dir}")
                    else:
                        website_results.append({
                            'keyword': keyword,
                            'project_name': project_name,
                            'status': 'failed',
                            'error': 'æºä»£ç ç”Ÿæˆå¤±è´¥'
                        })
                        print(f"âŒ ç½‘ç«™ç”Ÿæˆå¤±è´¥: {keyword}")
                else:
                    website_results.append({
                        'keyword': keyword,
                        'project_name': project_name,
                        'status': 'failed',
                        'error': 'æ„å›¾æ•°æ®åŠ è½½å¤±è´¥'
                    })
                    print(f"âŒ æ„å›¾æ•°æ®åŠ è½½å¤±è´¥: {keyword}")
                    
            except Exception as e:
                website_results.append({
                    'keyword': keyword,
                    'project_name': project_name if 'project_name' in locals() else 'unknown',
                    'status': 'failed',
                    'error': str(e)
                })
                print(f"âŒ ç½‘ç«™ç”Ÿæˆå¼‚å¸¸: {keyword} - {e}")
        
        return website_results
    
    def _prepare_intent_data(self, keyword_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å‡†å¤‡æ„å›¾æ•°æ®æ ¼å¼"""
        intent_info = keyword_data.get('intent', {})
        market_info = keyword_data.get('market', {})
        
        return [{
            'query': keyword_data['keyword'],
            'intent_primary': intent_info.get('primary_intent', 'I'),
            'intent_secondary': intent_info.get('secondary_intent', ''),
            'sub_intent': intent_info.get('primary_intent', 'I') + '1',
            'probability': intent_info.get('confidence', 0.8),
            'probability_secondary': 0.2,
            'search_volume': market_info.get('search_volume', 1000),
            'competition': market_info.get('competition', 0.5),
            'opportunity_score': keyword_data.get('opportunity_score', 70),
            'ai_bonus': market_info.get('ai_bonus', 0),
            'commercial_value': market_info.get('commercial_value', 0)
        }]
    
    def _save_intent_data(self, intent_data: List[Dict[str, Any]], keyword: str) -> str:
        """ä¿å­˜æ„å›¾æ•°æ®åˆ°æ–‡ä»¶"""
        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        safe_keyword = "".join(c for c in keyword if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_keyword = safe_keyword.replace(' ', '_')[:50]  # é™åˆ¶é•¿åº¦
        
        file_path = os.path.join(
            self.output_base_dir, 
            'intent_analysis', 
            f'intent_{safe_keyword}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        )
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(intent_data, f, ensure_ascii=False, indent=2)
        
        return file_path
    
    def _generate_project_name(self, keyword: str) -> str:
        """ç”Ÿæˆé¡¹ç›®åç§°"""
        # æ¸…ç†å…³é”®è¯ï¼Œç”Ÿæˆåˆé€‚çš„é¡¹ç›®å
        clean_name = "".join(c for c in keyword if c.isalnum() or c in (' ', '-')).strip()
        clean_name = clean_name.replace(' ', '-').lower()
        
        # é™åˆ¶é•¿åº¦å¹¶æ·»åŠ æ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%m%d_%H%M")
        return f"{clean_name[:30]}-{timestamp}"
    
    def _batch_deploy_websites(self, website_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ‰¹é‡éƒ¨ç½²ç½‘ç«™"""
        deployment_results = []
        
        successful_websites = [w for w in website_results if w.get('status') == 'success']
        
        for website in successful_websites:
            keyword = website['keyword']
            source_dir = website['source_dir']
            
            print(f"ğŸš€ éƒ¨ç½²ç½‘ç«™: {keyword}")
            
            try:
                # è¿™é‡Œå¯ä»¥é›†æˆå®é™…çš„éƒ¨ç½²é€»è¾‘
                # ç›®å‰è¿”å›æ¨¡æ‹Ÿç»“æœ
                deployment_url = f"https://{website['project_name']}.pages.dev"
                
                deployment_results.append({
                    'keyword': keyword,
                    'project_name': website['project_name'],
                    'deployment_url': deployment_url,
                    'platform': self.config.get('deployment_platform', 'cloudflare'),
                    'status': 'success'
                })
                
                print(f"âœ… éƒ¨ç½²æˆåŠŸ: {deployment_url}")
                
            except Exception as e:
                deployment_results.append({
                    'keyword': keyword,
                    'project_name': website['project_name'],
                    'status': 'failed',
                    'error': str(e)
                })
                print(f"âŒ éƒ¨ç½²å¤±è´¥: {keyword} - {e}")
        
        return deployment_results
    
    def _generate_workflow_report(self, workflow_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆå·¥ä½œæµç»¼åˆæŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = os.path.join(
            self.output_base_dir, 
            'reports', 
            f'integrated_workflow_report_{timestamp}.md'
        )
        
        # ç»Ÿè®¡æ•°æ®
        total_keywords = len(workflow_results.get('demand_analysis', {}).get('keywords', []))
        high_value_count = len(workflow_results.get('high_value_keywords', []))
        successful_websites = len([w for w in workflow_results.get('generated_projects', []) if w.get('status') == 'success'])
        successful_deployments = len([d for d in workflow_results.get('deployment_results', []) if d.get('status') == 'success'])
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = f"""# é›†æˆå·¥ä½œæµæ‰§è¡ŒæŠ¥å‘Š

## ğŸ“Š æ‰§è¡Œæ¦‚è§ˆ
- **æ‰§è¡Œæ—¶é—´**: {workflow_results.get('start_time', '')} - {workflow_results.get('end_time', '')}
- **è¾“å…¥æ–‡ä»¶**: {workflow_results.get('input_file', '')}
- **æ‰§è¡ŒçŠ¶æ€**: {workflow_results.get('status', '')}

## ğŸ“ˆ æ•°æ®ç»Ÿè®¡
- **æ€»å…³é”®è¯æ•°**: {total_keywords}
- **é«˜ä»·å€¼å…³é”®è¯**: {high_value_count}
- **æˆåŠŸç”Ÿæˆç½‘ç«™**: {successful_websites}
- **æˆåŠŸéƒ¨ç½²ç½‘ç«™**: {successful_deployments}

## ğŸ¯ é«˜ä»·å€¼å…³é”®è¯åˆ—è¡¨
"""
        
        # æ·»åŠ é«˜ä»·å€¼å…³é”®è¯è¯¦æƒ…
        for kw in workflow_results.get('high_value_keywords', [])[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            report_content += f"- **{kw['keyword']}** (æœºä¼šåˆ†æ•°: {kw.get('opportunity_score', 0)})\n"
            report_content += f"  - ä¸»è¦æ„å›¾: {kw.get('intent', {}).get('primary_intent', 'Unknown')}\n"
            report_content += f"  - AIåŠ åˆ†: {kw.get('market', {}).get('ai_bonus', 0)}\n"
            report_content += f"  - å•†ä¸šä»·å€¼: {kw.get('market', {}).get('commercial_value', 0)}\n\n"
        
        # æ·»åŠ ç”Ÿæˆçš„ç½‘ç«™é¡¹ç›®
        report_content += "\n## ğŸ—ï¸ ç”Ÿæˆçš„ç½‘ç«™é¡¹ç›®\n"
        for website in workflow_results.get('generated_projects', []):
            status_icon = "âœ…" if website.get('status') == 'success' else "âŒ"
            report_content += f"{status_icon} **{website['keyword']}**\n"
            if website.get('status') == 'success':
                report_content += f"  - é¡¹ç›®ç›®å½•: {website.get('source_dir', '')}\n"
            else:
                report_content += f"  - é”™è¯¯: {website.get('error', '')}\n"
        
        # æ·»åŠ éƒ¨ç½²ç»“æœ
        if workflow_results.get('deployment_results'):
            report_content += "\n## ğŸš€ éƒ¨ç½²ç»“æœ\n"
            for deployment in workflow_results.get('deployment_results', []):
                status_icon = "âœ…" if deployment.get('status') == 'success' else "âŒ"
                report_content += f"{status_icon} **{deployment['keyword']}**\n"
                if deployment.get('status') == 'success':
                    report_content += f"  - éƒ¨ç½²åœ°å€: {deployment.get('deployment_url', '')}\n"
                else:
                    report_content += f"  - é”™è¯¯: {deployment.get('error', '')}\n"
        
        # æ·»åŠ å»ºè®®
        report_content += f"""
## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### å…³é”®è¯ä¼˜åŒ–
- ç»§ç»­æŒ–æ˜ç›¸å…³é•¿å°¾å…³é”®è¯
- å…³æ³¨AIç›¸å…³é«˜ä»·å€¼å…³é”®è¯
- å®šæœŸæ›´æ–°å…³é”®è¯æœºä¼šåˆ†æ•°

### ç½‘ç«™ä¼˜åŒ–
- ä¼˜åŒ–SEOå…ƒæ•°æ®å’Œç»“æ„
- æ·»åŠ æ›´å¤šäº¤äº’åŠŸèƒ½
- å®Œå–„ç§»åŠ¨ç«¯é€‚é…

### è¿è¥å»ºè®®
- æäº¤åˆ°AIå·¥å…·å¯¼èˆªç«™
- å»ºç«‹ç¤¾äº¤åª’ä½“æ¨å¹¿è®¡åˆ’
- ç›‘æ§ç½‘ç«™æµé‡å’Œè½¬åŒ–

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # ä¿å­˜æŠ¥å‘Š
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return report_path


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='é›†æˆå·¥ä½œæµï¼šéœ€æ±‚æŒ–æ˜ â†’ æ„å›¾åˆ†æ â†’ ç½‘ç«™ç”Ÿæˆ â†’ è‡ªåŠ¨éƒ¨ç½²')
    parser.add_argument('--input', '-i', required=True, help='å…³é”®è¯è¾“å…¥æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--config', '-c', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--min-score', type=int, default=60, help='æœ€ä½æœºä¼šåˆ†æ•°é˜ˆå€¼')
    parser.add_argument('--max-projects', type=int, default=5, help='æœ€å¤§é¡¹ç›®æ•°é‡')
    parser.add_argument('--no-deploy', action='store_true', help='è·³è¿‡è‡ªåŠ¨éƒ¨ç½²')
    
    args = parser.parse_args()
    
    # å‡†å¤‡é…ç½®
    config = {
        'min_opportunity_score': args.min_score,
        'max_projects_per_batch': args.max_projects,
        'auto_deploy': not args.no_deploy,
        'deployment_platform': 'cloudflare',
        'use_tailwind': True,
        'generate_reports': True
    }
    
    # å¦‚æœæœ‰é…ç½®æ–‡ä»¶ï¼ŒåŠ è½½é…ç½®
    if args.config and os.path.exists(args.config):
        import json
        with open(args.config, 'r', encoding='utf-8') as f:
            user_config = json.load(f)
            config.update(user_config)
    
    try:
        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow = IntegratedWorkflow(config)
        
        # æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
        results = workflow.run_complete_workflow(args.input)
        
        if results['status'] == 'success':
            print(f"\nğŸ‰ é›†æˆå·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
            print(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {results.get('report_path', '')}")
            return 0
        else:
            print(f"\nâŒ é›†æˆå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {results.get('error', '')}")
            return 1
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¼‚å¸¸: {e}")
        return 1


if __name__ == '__main__':
    sys.exit(main())