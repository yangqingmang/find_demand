#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘½ä»¤è¡Œå‚æ•°è§£æå™¨æ¨¡å—
æä¾›ç»Ÿä¸€çš„å‘½ä»¤è¡Œå‚æ•°è§£æåŠŸèƒ½
"""

import argparse
import os
import json


def get_reports_dir() -> str:
    """ä»é…ç½®æ–‡ä»¶è·å–æŠ¥å‘Šè¾“å‡ºç›®å½•"""
    try:
        config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config/integrated_workflow_config.json')
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return config.get('output_settings', {}).get('reports_dir', 'output/reports')
    except:
        pass
    return 'output/reports'


def setup_argument_parser():
    """è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description='éœ€æ±‚æŒ–æ˜åˆ†æå·¥å…· - æ•´åˆå…­å¤§æŒ–æ˜æ–¹æ³•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
            ğŸ¯ å…­å¤§éœ€æ±‚æŒ–æ˜æ–¹æ³•:
              1. åŸºäºè¯æ ¹å…³é”®è¯æ‹“å±• (52ä¸ªæ ¸å¿ƒè¯æ ¹)
              2. åŸºäºSEOå¤§ç«™æµé‡åˆ†æ (8ä¸ªç«å“ç½‘ç«™)
              3. æœç´¢å¼•æ“ä¸‹æ‹‰æ¨è
              4. å¾ªç¯æŒ–æ˜æ³•
              5. ä»˜è´¹å¹¿å‘Šå…³é”®è¯åˆ†æ
              6. æ”¶å…¥æ’è¡Œæ¦œåˆ†æ
            
            ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹:
              # åˆ†æå…³é”®è¯æ–‡ä»¶
              python main.py --input data/keywords.csv
              
              # åˆ†æå…³é”®è¯æ–‡ä»¶å¹¶å¯ç”¨SERPåˆ†æ
              python main.py --input data/keywords.csv --serp
              
              # åˆ†æå•ä¸ªå…³é”®è¯
              python main.py --keywords "ai generator" "ai converter"
              
              # åˆ†æå•ä¸ªå…³é”®è¯å¹¶å¯ç”¨SERPåˆ†æ
              python main.py --keywords "AI" --serp
              
              # å¤šå¹³å°å…³é”®è¯å‘ç°
              python main.py --discover "AI image generator" "AI writing tool"
              
              # ä½¿ç”¨é»˜è®¤æœç´¢è¯è¿›è¡Œå¤šå¹³å°å‘ç°
              python main.py --discover default
              
              # ç”Ÿæˆåˆ†ææŠ¥å‘Š
              python main.py --report
            
              # ä½¿ç”¨51ä¸ªè¯æ ¹è¿›è¡Œè¶‹åŠ¿åˆ†æ
              python main.py --use-root-words
            
              # é™é»˜æ¨¡å¼åˆ†æ
              python main.py --input data/keywords.csv --quiet
            
            ğŸš€ å¢å¼ºåŠŸèƒ½ç¤ºä¾‹:
              # ç›‘æ§ç«å“å…³é”®è¯å˜åŒ–
              python main.py --monitor-competitors --sites canva.com midjourney.com
            
              # é¢„æµ‹å…³é”®è¯è¶‹åŠ¿
              python main.py --predict-trends --timeframe 30d
            
              # SEOå®¡è®¡
              python main.py --seo-audit --domain your-site.com --keywords "ai tool" "ai generator"
            
              # æ‰¹é‡ç”Ÿæˆç½‘ç«™
              python main.py --build-websites --top-keywords 5
        """
    )
    
    # è¾“å…¥æ–¹å¼é€‰æ‹© - ä¿®æ”¹ä¸ºéå¿…éœ€ï¼Œæ”¯æŒé»˜è®¤è¯æ ¹åˆ†æ
    input_group = parser.add_mutually_exclusive_group(required=False)
    input_group.add_argument('--input', help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„')
    input_group.add_argument('--keywords', nargs='+', help='ç›´æ¥è¾“å…¥å…³é”®è¯ï¼ˆå¯ä»¥æ˜¯å¤šä¸ªï¼‰')
    input_group.add_argument('--discover', nargs='+', help='å¤šå¹³å°å…³é”®è¯å‘ç°ï¼ˆå¯æŒ‡å®šæœç´¢è¯æ±‡ï¼‰')
    input_group.add_argument('--report', action='store_true', help='ç”Ÿæˆä»Šæ—¥åˆ†ææŠ¥å‘Š')
    input_group.add_argument('--hotkeywords', action='store_true', help='æœç´¢çƒ­é—¨å…³é”®è¯ (Google Trends)')
    input_group.add_argument('--trending-keywords', action='store_true', help='è·å–TrendingKeywords.netçƒ­é—¨å…³é”®è¯')
    input_group.add_argument('--all', action='store_true', help='å®Œæ•´æµç¨‹ï¼šæ•´åˆå¤šæ•°æ®æºæœç´¢çƒ­é—¨å…³é”®è¯ï¼Œå†è¿›è¡Œå¤šå¹³å°å‘ç°')
    input_group.add_argument('--demand-validation', action='store_true', help='éœ€æ±‚éªŒè¯ï¼šå¯¹é«˜æœºä¼šå…³é”®è¯è¿›è¡Œå¤šå¹³å°éœ€æ±‚åˆ†æ')
    input_group.add_argument('--expand', nargs='+', help='å¢å¼ºå…³é”®è¯æ‰©å±•ï¼šä½¿ç”¨Googleè‡ªåŠ¨å®Œæˆã€Trendsç›¸å…³æœç´¢å’Œè¯­ä¹‰ç›¸ä¼¼è¯æ‰©å±•')
    
    # å¢å¼ºåŠŸèƒ½ç»„
    enhanced_group = parser.add_argument_group('å¢å¼ºåŠŸèƒ½')
    enhanced_group.add_argument('--monitor-competitors', action='store_true', help='ç›‘æ§ç«å“å…³é”®è¯å˜åŒ–')
    enhanced_group.add_argument('--sites', nargs='+', help='ç«å“ç½‘ç«™åˆ—è¡¨')
    enhanced_group.add_argument('--predict-trends', action='store_true', help='é¢„æµ‹å…³é”®è¯è¶‹åŠ¿')
    enhanced_group.add_argument('--timeframe', default='30d', help='é¢„æµ‹æ—¶é—´èŒƒå›´')
    enhanced_group.add_argument('--seo-audit', action='store_true', help='ç”ŸæˆSEOä¼˜åŒ–å»ºè®®')
    enhanced_group.add_argument('--domain', help='è¦å®¡è®¡çš„åŸŸå')
    enhanced_group.add_argument('--build-websites', action='store_true', help='æ‰¹é‡ç”Ÿæˆç½‘ç«™')
    enhanced_group.add_argument('--top-keywords', type=int, default=10, help='ä½¿ç”¨å‰Nä¸ªå…³é”®è¯')

    # å…¶ä»–å‚æ•°
    parser.add_argument('--output', default=get_reports_dir(), help='è¾“å‡ºç›®å½•')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œåªæ˜¾ç¤ºæœ€ç»ˆç»“æœ')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†æ¨¡å¼ï¼Œæ˜¾ç¤ºæ‰€æœ‰ä¸­é—´è¿‡ç¨‹')
    parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--use-root-words', action='store_true', help='ä½¿ç”¨51ä¸ªè¯æ ¹è¿›è¡Œè¶‹åŠ¿åˆ†æ')
    parser.add_argument('--serp', action='store_true', help='å¯ç”¨SERPåˆ†æåŠŸèƒ½')
    parser.add_argument('--seed-profile', help='æŒ‡å®šé…ç½®ä¸­çš„ç§å­å…³é”®è¯æ¡£æ¡ˆï¼ˆç”¨äºå¤šå¹³å°å‘ç°ï¼‰')
    parser.add_argument('--seed-limit', type=int, help='é™åˆ¶å¤šå¹³å°å‘ç°é˜¶æ®µä½¿ç”¨çš„ç§å­å…³é”®è¯æ•°é‡')
    parser.add_argument('--min-seed-terms', type=int, help='ç¡®ä¿è‡³å°‘ä½¿ç”¨çš„ç§å­å…³é”®è¯æ•°é‡')

    return parser


def display_analysis_parameters(args):
    """æ˜¾ç¤ºåˆ†æå‚æ•°"""
    if not args.quiet:
        if args.input:
            print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {args.input}")
        elif args.keywords:
            print(f"ğŸ”¤ åˆ†æå…³é”®è¯: {', '.join(args.keywords)}")
        elif args.report:
            print("ğŸ“Š ç”Ÿæˆä»Šæ—¥åˆ†ææŠ¥å‘Š")
        if getattr(args, 'seed_profile', None):
            print(f"ğŸŒ± ç§å­é…ç½®: {args.seed_profile}")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output}")
        print("")


def print_quiet_summary(result):
    """é™é»˜æ¨¡å¼ä¸‹çš„ç®€è¦ç»“æœæ˜¾ç¤º"""
    print("\nğŸ¯ éœ€æ±‚æŒ–æ˜åˆ†æç»“æœæ‘˜è¦:")
    print(f"   â€¢ å…³é”®è¯æ€»æ•°: {result.get('total_keywords', 0)}")
    print(f"   â€¢ é«˜æœºä¼šå…³é”®è¯: {result.get('market_insights', {}).get('high_opportunity_count', 0)}")
    print(f"   â€¢ å¹³å‡æœºä¼šåˆ†æ•°: {result.get('market_insights', {}).get('avg_opportunity_score', 0)}")
    
    # æ˜¾ç¤ºTop 3å…³é”®è¯
    top_keywords = result.get('market_insights', {}).get('top_opportunities', [])[:3]
    if top_keywords:
        print("\nğŸ† Top 3 æœºä¼šå…³é”®è¯:")
        for i, kw in enumerate(top_keywords):
            intent_desc = kw.get('intent', {}).get('intent_description', 'æœªçŸ¥')
            score = kw.get('opportunity_score', 0)
            print(f"   {i+1}. {kw['keyword']} (æœºä¼šåˆ†æ•°: {score}, æ„å›¾: {intent_desc})")
