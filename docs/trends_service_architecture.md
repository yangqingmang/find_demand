# Google Trends 服务化重构方案（重构级）

本方案将 Google Trends 调用从单机脚本改为集中式服务，统一管控限速、缓存与任务调度，适合高频或多任务场景。

## 1. 服务化拆分
- 新建 `TrendsWorker`（守护进程 / 微服务）封装 `GoogleTrendsSession`、代理池、限速器、退避策略。
- 提供 RPC/HTTP/消息队列接口（如 FastAPI + Redis 队列），主流程通过 `TrendsServiceClient` 提交查询任务并异步取回结果。
- 所有请求统一排队，避免多个流程并发击穿同一 API。

## 2. 全局缓存与数据层
- 维护集中式缓存（Redis/SQLite + 文件/Parquet），以 `keyword+timeframe+geo` 作为键，TTL 可配置。
- 服务端先查缓存、命中即返回；miss 时才真正调用 Google Trends，并将结果写入缓存以供所有客户端复用。
- 支持缓存版本管理、数据质量评分和快速回退。

## 3. 策略调度与优先级
- 按关键词热度划分优先级：热词即时处理，冷门词可延迟或合并批量执行。
- 先对宽窗口（如 `today 12-m`）做“探针”查询，根据结果决定是否继续请求细分窗口。
- 记录请求历史、429 次数、自适应调整速率及代理轮换。

## 4. 定时刷新与监控
- 定时任务（Cron / Celery Beat）批量刷新核心关键词，保持缓存新鲜度。
- 集成监控：统计请求量、429 频率、成功率及当前冷却状态；可用 Prometheus/Grafana 或简单的报表。
- 异常告警：连续 429 或 TLS 错误触发通知，便于及时切换代理或人工介入。

## 5. 主流程整合
- 分析流程只负责提交任务并读取结果，缺失数据时可选择“等待”、使用旧缓存或标记为 pending。
- 去掉流程内的直接冷却逻辑，由服务端统一处理；提升回退能力并方便扩展其他数据源。

> 部署成本：**高**。需要新增服务/队列、部署缓存与监控，并重写主流程与 Trend 服务的交互协议。适合长期、高频调用以及团队协作的环境。***
